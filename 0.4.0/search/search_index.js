var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Nuke addon","text":"<p>Nuke integration for AYON.</p>"},{"location":"license.html","title":"License","text":"<pre><code>                             Apache License\n                       Version 2.0, January 2004\n                    http://www.apache.org/licenses/\n</code></pre> <p>TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION</p> <ol> <li> <p>Definitions.</p> <p>\"License\" shall mean the terms and conditions for use, reproduction,   and distribution as defined by Sections 1 through 9 of this document.</p> <p>\"Licensor\" shall mean the copyright owner or entity authorized by   the copyright owner that is granting the License.</p> <p>\"Legal Entity\" shall mean the union of the acting entity and all   other entities that control, are controlled by, or are under common   control with that entity. For the purposes of this definition,   \"control\" means (i) the power, direct or indirect, to cause the   direction or management of such entity, whether by contract or   otherwise, or (ii) ownership of fifty percent (50%) or more of the   outstanding shares, or (iii) beneficial ownership of such entity.</p> <p>\"You\" (or \"Your\") shall mean an individual or Legal Entity   exercising permissions granted by this License.</p> <p>\"Source\" form shall mean the preferred form for making modifications,   including but not limited to software source code, documentation   source, and configuration files.</p> <p>\"Object\" form shall mean any form resulting from mechanical   transformation or translation of a Source form, including but   not limited to compiled object code, generated documentation,   and conversions to other media types.</p> <p>\"Work\" shall mean the work of authorship, whether in Source or   Object form, made available under the License, as indicated by a   copyright notice that is included in or attached to the work   (an example is provided in the Appendix below).</p> <p>\"Derivative Works\" shall mean any work, whether in Source or Object   form, that is based on (or derived from) the Work and for which the   editorial revisions, annotations, elaborations, or other modifications   represent, as a whole, an original work of authorship. For the purposes   of this License, Derivative Works shall not include works that remain   separable from, or merely link (or bind by name) to the interfaces of,   the Work and Derivative Works thereof.</p> <p>\"Contribution\" shall mean any work of authorship, including   the original version of the Work and any modifications or additions   to that Work or Derivative Works thereof, that is intentionally   submitted to Licensor for inclusion in the Work by the copyright owner   or by an individual or Legal Entity authorized to submit on behalf of   the copyright owner. For the purposes of this definition, \"submitted\"   means any form of electronic, verbal, or written communication sent   to the Licensor or its representatives, including but not limited to   communication on electronic mailing lists, source code control systems,   and issue tracking systems that are managed by, or on behalf of, the   Licensor for the purpose of discussing and improving the Work, but   excluding communication that is conspicuously marked or otherwise   designated in writing by the copyright owner as \"Not a Contribution.\"</p> <p>\"Contributor\" shall mean Licensor and any individual or Legal Entity   on behalf of whom a Contribution has been received by Licensor and   subsequently incorporated within the Work.</p> </li> <li> <p>Grant of Copyright License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       copyright license to reproduce, prepare Derivative Works of,       publicly display, publicly perform, sublicense, and distribute the       Work and such Derivative Works in Source or Object form.</p> </li> <li> <p>Grant of Patent License. Subject to the terms and conditions of       this License, each Contributor hereby grants to You a perpetual,       worldwide, non-exclusive, no-charge, royalty-free, irrevocable       (except as stated in this section) patent license to make, have made,       use, offer to sell, sell, import, and otherwise transfer the Work,       where such license applies only to those patent claims licensable       by such Contributor that are necessarily infringed by their       Contribution(s) alone or by combination of their Contribution(s)       with the Work to which such Contribution(s) was submitted. If You       institute patent litigation against any entity (including a       cross-claim or counterclaim in a lawsuit) alleging that the Work       or a Contribution incorporated within the Work constitutes direct       or contributory patent infringement, then any patent licenses       granted to You under this License for that Work shall terminate       as of the date such litigation is filed.</p> </li> <li> <p>Redistribution. You may reproduce and distribute copies of the       Work or Derivative Works thereof in any medium, with or without       modifications, and in Source or Object form, provided that You       meet the following conditions:</p> <p>(a) You must give any other recipients of the Work or       Derivative Works a copy of this License; and</p> <p>(b) You must cause any modified files to carry prominent notices       stating that You changed the files; and</p> <p>(c) You must retain, in the Source form of any Derivative Works       that You distribute, all copyright, patent, trademark, and       attribution notices from the Source form of the Work,       excluding those notices that do not pertain to any part of       the Derivative Works; and</p> <p>(d) If the Work includes a \"NOTICE\" text file as part of its       distribution, then any Derivative Works that You distribute must       include a readable copy of the attribution notices contained       within such NOTICE file, excluding those notices that do not       pertain to any part of the Derivative Works, in at least one       of the following places: within a NOTICE text file distributed       as part of the Derivative Works; within the Source form or       documentation, if provided along with the Derivative Works; or,       within a display generated by the Derivative Works, if and       wherever such third-party notices normally appear. The contents       of the NOTICE file are for informational purposes only and       do not modify the License. You may add Your own attribution       notices within Derivative Works that You distribute, alongside       or as an addendum to the NOTICE text from the Work, provided       that such additional attribution notices cannot be construed       as modifying the License.</p> <p>You may add Your own copyright statement to Your modifications and   may provide additional or different license terms and conditions   for use, reproduction, or distribution of Your modifications, or   for any such Derivative Works as a whole, provided Your use,   reproduction, and distribution of the Work otherwise complies with   the conditions stated in this License.</p> </li> <li> <p>Submission of Contributions. Unless You explicitly state otherwise,       any Contribution intentionally submitted for inclusion in the Work       by You to the Licensor shall be under the terms and conditions of       this License, without any additional terms or conditions.       Notwithstanding the above, nothing herein shall supersede or modify       the terms of any separate license agreement you may have executed       with Licensor regarding such Contributions.</p> </li> <li> <p>Trademarks. This License does not grant permission to use the trade       names, trademarks, service marks, or product names of the Licensor,       except as required for reasonable and customary use in describing the       origin of the Work and reproducing the content of the NOTICE file.</p> </li> <li> <p>Disclaimer of Warranty. Unless required by applicable law or       agreed to in writing, Licensor provides the Work (and each       Contributor provides its Contributions) on an \"AS IS\" BASIS,       WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or       implied, including, without limitation, any warranties or conditions       of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A       PARTICULAR PURPOSE. You are solely responsible for determining the       appropriateness of using or redistributing the Work and assume any       risks associated with Your exercise of permissions under this License.</p> </li> <li> <p>Limitation of Liability. In no event and under no legal theory,       whether in tort (including negligence), contract, or otherwise,       unless required by applicable law (such as deliberate and grossly       negligent acts) or agreed to in writing, shall any Contributor be       liable to You for damages, including any direct, indirect, special,       incidental, or consequential damages of any character arising as a       result of this License or out of the use or inability to use the       Work (including but not limited to damages for loss of goodwill,       work stoppage, computer failure or malfunction, or any and all       other commercial damages or losses), even if such Contributor       has been advised of the possibility of such damages.</p> </li> <li> <p>Accepting Warranty or Additional Liability. While redistributing       the Work or Derivative Works thereof, You may choose to offer,       and charge a fee for, acceptance of support, warranty, indemnity,       or other liability obligations and/or rights consistent with this       License. However, in accepting such obligations, You may act only       on Your own behalf and on Your sole responsibility, not on behalf       of any other Contributor, and only if You agree to indemnify,       defend, and hold each Contributor harmless for any liability       incurred by, or claims asserted against, such Contributor by reason       of your accepting any such warranty or additional liability.</p> </li> </ol> <p>END OF TERMS AND CONDITIONS</p> <p>APPENDIX: How to apply the Apache License to your work.</p> <pre><code>  To apply the Apache License to your work, attach the following\n  boilerplate notice, with the fields enclosed by brackets \"[]\"\n  replaced with your own identifying information. (Don't include\n  the brackets!)  The text should be enclosed in the appropriate\n  comment syntax for the file format. We also recommend that a\n  file or class name and description of purpose be included on the\n  same \"printed page\" as the copyright notice for easier\n  identification within third-party archives.\n</code></pre> <p>Copyright [yyyy][name of copyright owner]</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\");    you may not use this file except in compliance with the License.    You may obtain a copy of the License at</p> <pre><code>   http://www.apache.org/licenses/LICENSE-2.0\n</code></pre> <p>Unless required by applicable law or agreed to in writing, software    distributed under the License is distributed on an \"AS IS\" BASIS,    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.    See the License for the specific language governing permissions and    limitations under the License.</p>"},{"location":"autoapi/summary.html","title":"Summary","text":"<ul> <li>client<ul> <li>ayon_nuke<ul> <li>addon</li> <li>api<ul> <li>actions</li> <li>colorspace</li> <li>command</li> <li>constants</li> <li>gizmo_menu</li> <li>lib</li> <li>pipeline</li> <li>plugin</li> <li>push_to_project</li> <li>utils</li> <li>workfile_template_builder</li> <li>workio</li> </ul> </li> <li>hooks<ul> <li>pre_nukeassist_setup</li> </ul> </li> <li>plugins<ul> <li>create<ul> <li>convert_legacy</li> <li>create_backdrop</li> <li>create_camera</li> <li>create_gizmo</li> <li>create_model</li> <li>create_source</li> <li>create_write_image</li> <li>create_write_prerender</li> <li>create_write_render</li> <li>workfile_creator</li> </ul> </li> <li>inventory<ul> <li>lock_version</li> <li>repair_old_loaders</li> <li>select_containers</li> </ul> </li> <li>load<ul> <li>actions</li> <li>load_backdrop</li> <li>load_camera</li> <li>load_camera_usd</li> <li>load_clip</li> <li>load_effects</li> <li>load_gizmo</li> <li>load_image</li> <li>load_matchmove</li> <li>load_model</li> <li>load_ociolook</li> <li>load_script_precomp</li> <li>load_usd</li> </ul> </li> <li>publish<ul> <li>collect_backdrop</li> <li>collect_context_data</li> <li>collect_framerate</li> <li>collect_gizmo</li> <li>collect_headless_farm</li> <li>collect_model</li> <li>collect_nuke_instance_data</li> <li>collect_reads</li> <li>collect_slate_node</li> <li>collect_workfile</li> <li>collect_writes</li> <li>extract_backdrop</li> <li>extract_camera</li> <li>extract_gizmo</li> <li>extract_headless_farm</li> <li>extract_model</li> <li>extract_ouput_node</li> <li>extract_output_directory</li> <li>extract_render_local</li> <li>extract_review_data</li> <li>extract_review_intermediates</li> <li>extract_script_save</li> <li>extract_slate_frame</li> <li>increment_script_version</li> <li>increment_write_node</li> <li>remove_ouput_node</li> <li>validate_asset_context</li> <li>validate_backdrop</li> <li>validate_exposed_knobs</li> <li>validate_gizmo</li> <li>validate_knobs</li> <li>validate_output_resolution</li> <li>validate_proxy_mode</li> <li>validate_rendered_frames</li> <li>validate_script_attributes</li> <li>validate_write_nodes</li> </ul> </li> <li>workfile_build<ul> <li>create_placeholder</li> <li>load_placeholder</li> </ul> </li> </ul> </li> <li>startup<ul> <li>clear_rendered</li> <li>custom_write_node</li> <li>frame_setting_for_read_nodes</li> <li>menu</li> <li>write_to_read</li> </ul> </li> <li>vendor<ul> <li>google<ul> <li>protobuf<ul> <li>any_pb2</li> <li>api_pb2</li> <li>compiler<ul> <li>plugin_pb2</li> </ul> </li> <li>descriptor</li> <li>descriptor_database</li> <li>descriptor_pb2</li> <li>descriptor_pool</li> <li>duration_pb2</li> <li>empty_pb2</li> <li>field_mask_pb2</li> <li>internal<ul> <li>_parameterized</li> <li>api_implementation</li> <li>builder</li> <li>containers</li> <li>decoder</li> <li>encoder</li> <li>enum_type_wrapper</li> <li>extension_dict</li> <li>message_listener</li> <li>message_set_extensions_pb2</li> <li>missing_enum_values_pb2</li> <li>more_extensions_dynamic_pb2</li> <li>more_extensions_pb2</li> <li>more_messages_pb2</li> <li>no_package_pb2</li> <li>python_message</li> <li>type_checkers</li> <li>well_known_types</li> <li>wire_format</li> </ul> </li> <li>json_format</li> <li>message</li> <li>message_factory</li> <li>proto_builder</li> <li>pyext<ul> <li>cpp_message</li> <li>python_pb2</li> </ul> </li> <li>reflection</li> <li>service</li> <li>service_reflection</li> <li>source_context_pb2</li> <li>struct_pb2</li> <li>symbol_database</li> <li>text_encoding</li> <li>text_format</li> <li>timestamp_pb2</li> <li>type_pb2</li> <li>util<ul> <li>json_format_pb2</li> <li>json_format_proto3_pb2</li> </ul> </li> <li>wrappers_pb2</li> </ul> </li> </ul> </li> </ul> </li> <li>version</li> </ul> </li> </ul> </li> <li>server<ul> <li>settings<ul> <li>common</li> <li>conversion</li> <li>create_plugins</li> <li>dirmap</li> <li>general</li> <li>gizmo</li> <li>imageio</li> <li>loader_plugins</li> <li>main</li> <li>publish_plugins</li> <li>scriptsmenu</li> <li>templated_workfile_build</li> <li>workfile_builder</li> </ul> </li> </ul> </li> </ul>"},{"location":"autoapi/client/ayon_nuke/index.html","title":"ayon_nuke","text":""},{"location":"autoapi/client/ayon_nuke/addon.html","title":"addon","text":""},{"location":"autoapi/client/ayon_nuke/version.html","title":"version","text":"<p>Package declaring AYON addon 'nuke' version.</p>"},{"location":"autoapi/client/ayon_nuke/api/index.html","title":"api","text":""},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeCreator","title":"<code>NukeCreator</code>","text":"<p>               Bases: <code>Creator</code></p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class NukeCreator(Creator):\n    node_class_name = None\n\n    def _pass_pre_attributes_to_instance(\n        self,\n        instance_data,\n        pre_create_data,\n        keys=None\n    ):\n        if keys is None:\n            keys = pre_create_data.keys()\n        creator_attrs = instance_data[\"creator_attributes\"] = {}\n\n        creator_attrs.update({\n            key: value\n            for key, value in pre_create_data.items()\n            if key in keys\n        })\n\n    def check_existing_product(self, product_name):\n        \"\"\"Make sure product name is unique.\n\n        It search within all nodes recursively\n        and checks if product name is found in\n        any node having instance data knob.\n\n        Arguments:\n            product_name (str): Product name\n        \"\"\"\n\n        for node in nuke.allNodes(recurseGroups=True):\n            # make sure testing node is having instance knob\n            if INSTANCE_DATA_KNOB not in node.knobs().keys():\n                continue\n            node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n\n            if not node_data:\n                # a node has no instance data\n                continue\n\n            # QUESTION what is this logic? Why product name is compared\n            #   against product type?\n            # test if product name is matching\n            product_base_type = node_data.get(\"productBaseType\")\n            if not product_base_type:\n                product_base_type = node_data.get(\"productType\")\n            if product_base_type == product_name:\n                raise NukeCreatorError(\n                    f\"A publish instance for '{product_name}' already exists\"\n                    \" in nodes! Please change the variant name to ensure\"\n                    \" unique output.\"\n                )\n\n    def create_instance_node(\n        self,\n        node_name,\n        knobs=None,\n        parent=None,\n        node_type=None,\n        node_selection=None,\n    ):\n        \"\"\"Create node representing instance.\n\n        Arguments:\n            node_name (str): Name of the new node.\n            knobs (OrderedDict): node knobs name and values\n            parent (str): Name of the parent node.\n            node_type (str, optional): Nuke node Class.\n            node_selection (Optional[list[nuke.Node]]): The node selection.\n\n        Returns:\n            nuke.Node: Newly created instance node.\n\n        \"\"\"\n        node_type = node_type or \"NoOp\"\n\n        node_knobs = knobs or {}\n\n        # set parent node\n        parent_node = nuke.root()\n        if parent:\n            parent_node = nuke.toNode(parent)\n\n        try:\n            with parent_node:\n                created_node = nuke.createNode(node_type)\n                created_node[\"name\"].setValue(node_name)\n\n                for key, values in node_knobs.items():\n                    if key in created_node.knobs():\n                        created_node[\"key\"].setValue(values)\n        except Exception as _err:\n            raise NukeCreatorError(\"Creating have failed: {}\".format(_err))\n\n        return created_node\n\n    def _get_current_selected_nodes(\n        self,\n        pre_create_data,\n        class_name: str = None,\n    ):\n        \"\"\" Get current node selection.\n\n        Arguments:\n            pre_create_data (dict): The creator initial data.\n            class_name (Optional[str]): Filter on a class name.\n\n        Returns:\n            list[nuke.Node]: node selection.\n        \"\"\"\n        class_name = class_name or self.node_class_name\n        use_selection = pre_create_data.get(\"use_selection\")\n\n        if use_selection:\n            selected_nodes = nuke.selectedNodes()\n        else:\n            selected_nodes = nuke.allNodes()\n\n        if class_name:\n            # Allow class name implicit last versions of class names like\n            # `Camera` to match any of its explicit versions, e.g.\n            # `Camera3` or `Camera4`.\n            if not class_name[-1].isdigit():\n                # Match name with any digit\n                pattern = rf\"^{class_name}\\d*$\"\n            else:\n                pattern = class_name\n            regex = re.compile(pattern)\n            selected_nodes = [\n                node\n                for node in selected_nodes\n                if regex.match(node.Class())\n            ]\n\n        if class_name and use_selection and not selected_nodes:\n            raise NukeCreatorError(f\"Select a {class_name} node.\")\n\n        return selected_nodes\n\n    def create(self, product_name, instance_data, pre_create_data):\n\n        # make sure selected nodes are detected early on.\n        # we do not want any further Nuke operation to change the selection.\n        node_selection = self._get_current_selected_nodes(pre_create_data)\n\n        # make sure product name is unique\n        self.check_existing_product(product_name)\n\n        product_type = instance_data.get(\"productType\")\n        if not product_type:\n            product_type = self.product_base_type\n\n        try:\n            instance_node = self.create_instance_node(\n                product_name,\n                node_type=instance_data.pop(\"node_type\", None),\n                node_selection=node_selection,\n            )\n            instance = CreatedInstance(\n                product_base_type=self.product_base_type,\n                product_type=product_type,\n                product_name=product_name,\n                data=instance_data,\n                creator=self,\n            )\n\n            self.apply_staging_dir(instance)\n            instance.transient_data[\"node\"] = instance_node\n\n            self._add_instance_to_context(instance)\n\n            set_node_data(\n                instance_node, INSTANCE_DATA_KNOB, instance.data_to_store())\n\n            return instance\n\n        except Exception as exc:\n            raise NukeCreatorError(f\"Creator error: {exc}\") from exc\n\n    def collect_instances(self):\n        cached_instances = _collect_and_cache_nodes(self)\n        attr_def_keys = {\n            attr_def.key\n            for attr_def in self.get_instance_attr_defs()\n        }\n        attr_def_keys.discard(None)\n\n        for (node, data) in cached_instances[self.identifier]:\n            created_instance = CreatedInstance.from_existing(\n                data, self\n            )\n\n            self.apply_staging_dir(created_instance)\n            created_instance.transient_data[\"node\"] = node\n            self._add_instance_to_context(created_instance)\n\n            for key in (\n                set(created_instance[\"creator_attributes\"].keys())\n                - attr_def_keys\n            ):\n                created_instance[\"creator_attributes\"].pop(key)\n\n    def update_instances(self, update_list):\n        for created_inst, changes in update_list:\n            instance_node = created_inst.transient_data[\"node\"]\n\n            # in case node is not existing anymore (user erased it manually)\n            try:\n                instance_node.fullName()\n            except ValueError:\n                self._remove_instance_from_context(created_inst)\n                continue\n\n            # update instance node name if product name changed\n            if \"productName\" in changes.changed_keys:\n                instance_node[\"name\"].setValue(\n                    changes[\"productName\"].new_value\n                )\n\n            set_node_data(\n                instance_node,\n                INSTANCE_DATA_KNOB,\n                created_inst.data_to_store()\n            )\n\n    def remove_instances(self, instances):\n        for instance in instances:\n            remove_instance(instance)\n            self._remove_instance_from_context(instance)\n\n    def get_pre_create_attr_defs(self):\n        return [\n            BoolDef(\n                \"use_selection\",\n                default=not self.create_context.headless,\n                label=\"Use selection\"\n            )\n        ]\n\n    def get_creator_settings(self, project_settings, settings_key=None):\n        if not settings_key:\n            settings_key = self.__class__.__name__\n        return project_settings[\"nuke\"][\"create\"][settings_key]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeCreator.check_existing_product","title":"<code>check_existing_product(product_name)</code>","text":"<p>Make sure product name is unique.</p> <p>It search within all nodes recursively and checks if product name is found in any node having instance data knob.</p> <p>Parameters:</p> Name Type Description Default <code>product_name</code> <code>str</code> <p>Product name</p> required Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def check_existing_product(self, product_name):\n    \"\"\"Make sure product name is unique.\n\n    It search within all nodes recursively\n    and checks if product name is found in\n    any node having instance data knob.\n\n    Arguments:\n        product_name (str): Product name\n    \"\"\"\n\n    for node in nuke.allNodes(recurseGroups=True):\n        # make sure testing node is having instance knob\n        if INSTANCE_DATA_KNOB not in node.knobs().keys():\n            continue\n        node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n\n        if not node_data:\n            # a node has no instance data\n            continue\n\n        # QUESTION what is this logic? Why product name is compared\n        #   against product type?\n        # test if product name is matching\n        product_base_type = node_data.get(\"productBaseType\")\n        if not product_base_type:\n            product_base_type = node_data.get(\"productType\")\n        if product_base_type == product_name:\n            raise NukeCreatorError(\n                f\"A publish instance for '{product_name}' already exists\"\n                \" in nodes! Please change the variant name to ensure\"\n                \" unique output.\"\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeCreator.create_instance_node","title":"<code>create_instance_node(node_name, knobs=None, parent=None, node_type=None, node_selection=None)</code>","text":"<p>Create node representing instance.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Name of the new node.</p> required <code>knobs</code> <code>OrderedDict</code> <p>node knobs name and values</p> <code>None</code> <code>parent</code> <code>str</code> <p>Name of the parent node.</p> <code>None</code> <code>node_type</code> <code>str</code> <p>Nuke node Class.</p> <code>None</code> <code>node_selection</code> <code>Optional[list[Node]]</code> <p>The node selection.</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: Newly created instance node.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def create_instance_node(\n    self,\n    node_name,\n    knobs=None,\n    parent=None,\n    node_type=None,\n    node_selection=None,\n):\n    \"\"\"Create node representing instance.\n\n    Arguments:\n        node_name (str): Name of the new node.\n        knobs (OrderedDict): node knobs name and values\n        parent (str): Name of the parent node.\n        node_type (str, optional): Nuke node Class.\n        node_selection (Optional[list[nuke.Node]]): The node selection.\n\n    Returns:\n        nuke.Node: Newly created instance node.\n\n    \"\"\"\n    node_type = node_type or \"NoOp\"\n\n    node_knobs = knobs or {}\n\n    # set parent node\n    parent_node = nuke.root()\n    if parent:\n        parent_node = nuke.toNode(parent)\n\n    try:\n        with parent_node:\n            created_node = nuke.createNode(node_type)\n            created_node[\"name\"].setValue(node_name)\n\n            for key, values in node_knobs.items():\n                if key in created_node.knobs():\n                    created_node[\"key\"].setValue(values)\n    except Exception as _err:\n        raise NukeCreatorError(\"Creating have failed: {}\".format(_err))\n\n    return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeHost","title":"<code>NukeHost</code>","text":"<p>               Bases: <code>HostBase</code>, <code>IWorkfileHost</code>, <code>ILoadHost</code>, <code>IPublishHost</code></p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>class NukeHost(\n    HostBase, IWorkfileHost, ILoadHost, IPublishHost\n):\n    name = \"nuke\"\n\n    def open_workfile(self, filepath):\n        return open_file(filepath)\n\n    def save_workfile(self, filepath=None):\n        return save_file(filepath)\n\n    def work_root(self, session):\n        return work_root(session)\n\n    def get_current_workfile(self):\n        return current_file()\n\n    def workfile_has_unsaved_changes(self):\n        return has_unsaved_changes()\n\n    def get_workfile_extensions(self):\n        return file_extensions()\n\n    def get_containers(self):\n        return ls()\n\n    def install(self):\n        \"\"\"Installing all requirements for Nuke host\"\"\"\n\n        pyblish.api.register_host(\"nuke\")\n\n        self.log.info(\"Registering Nuke plug-ins..\")\n        pyblish.api.register_plugin_path(PUBLISH_PATH)\n        register_loader_plugin_path(LOAD_PATH)\n        register_creator_plugin_path(CREATE_PATH)\n        register_inventory_action_path(INVENTORY_PATH)\n        register_workfile_build_plugin_path(WORKFILE_BUILD_PATH)\n\n        # Register AYON event for workfiles loading.\n        register_event_callback(\"workio.open_file\", check_inventory_versions)\n        register_event_callback(\"taskChanged\", change_context_label)\n        project_settings = get_current_project_settings()\n        if nuke.GUI:\n            _install_menu(project_settings)\n\n            # add script menu\n            add_scripts_menu()\n            add_scripts_gizmo()\n\n        add_nuke_callbacks(project_settings)\n\n        launch_workfiles_app()\n\n    def get_context_data(self):\n        root_node = nuke.root()\n        return get_node_data(root_node, ROOT_DATA_KNOB)\n\n    def update_context_data(self, data, changes):\n        root_node = nuke.root()\n        set_node_data(root_node, ROOT_DATA_KNOB, data)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeHost.install","title":"<code>install()</code>","text":"<p>Installing all requirements for Nuke host</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def install(self):\n    \"\"\"Installing all requirements for Nuke host\"\"\"\n\n    pyblish.api.register_host(\"nuke\")\n\n    self.log.info(\"Registering Nuke plug-ins..\")\n    pyblish.api.register_plugin_path(PUBLISH_PATH)\n    register_loader_plugin_path(LOAD_PATH)\n    register_creator_plugin_path(CREATE_PATH)\n    register_inventory_action_path(INVENTORY_PATH)\n    register_workfile_build_plugin_path(WORKFILE_BUILD_PATH)\n\n    # Register AYON event for workfiles loading.\n    register_event_callback(\"workio.open_file\", check_inventory_versions)\n    register_event_callback(\"taskChanged\", change_context_label)\n    project_settings = get_current_project_settings()\n    if nuke.GUI:\n        _install_menu(project_settings)\n\n        # add script menu\n        add_scripts_menu()\n        add_scripts_gizmo()\n\n    add_nuke_callbacks(project_settings)\n\n    launch_workfiles_app()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeWriteCreator","title":"<code>NukeWriteCreator</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Write node</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class NukeWriteCreator(NukeCreator):\n    \"\"\"Add Publishable Write node\"\"\"\n\n    identifier = \"create_write\"\n    label = \"Create Write\"\n    product_type = \"write\"\n    product_base_type = \"write\"\n    icon = \"sign-out\"\n\n    temp_rendering_path_template = (  # default to be applied if settings is missing\n        \"{work}/renders/nuke/{product[name]}/{product[name]}.{frame}.{ext}\")\n\n    render_target = \"local\"  # default to be applied if settings is missing\n\n    def get_linked_knobs(self):\n        linked_knobs = []\n        if \"channels\" in self.instance_attributes:\n            linked_knobs.append(\"channels\")\n        if \"ordered\" in self.instance_attributes:\n            linked_knobs.append(\"render_order\")\n        if \"use_range_limit\" in self.instance_attributes:\n            linked_knobs.extend([\"___\", \"first\", \"last\", \"use_limit\"])\n\n        return linked_knobs\n\n    def integrate_links(self, node_selection, node, outputs=True):\n        # skip if no selection\n        if not node_selection:  # selection should contain either 1 or no node.\n            return\n\n        # collect dependencies\n        input_nodes = node_selection\n        dependent_nodes = node_selection[0].dependent() if outputs else []\n\n        # relinking to collected connections\n        for i, input in enumerate(input_nodes):\n            node.setInput(i, input)\n\n        # make it nicer in graph\n        node.autoplace()\n\n        # relink also dependent nodes\n        for dep_nodes in dependent_nodes:\n            dep_nodes.setInput(0, node)\n\n    def _get_current_selected_nodes(\n        self,\n        pre_create_data,\n    ):\n        \"\"\" Get current node selection.\n\n        Arguments:\n            pre_create_data (dict): The creator initial data.\n            class_name (Optional[str]): Filter on a class name.\n\n        Returns:\n            list[nuke.Node]: node selection.\n\n        Raises:\n            NukeCreatorError. When the selection contains more than 1 Write node.\n        \"\"\"\n        if not pre_create_data.get(\"use_selection\"):\n            return []\n\n        selected_nodes = super()._get_current_selected_nodes(\n            pre_create_data,\n            class_name=None,\n        )\n\n        if not selected_nodes:\n            raise NukeCreatorError(\"No active selection\")\n\n        elif len(selected_nodes) &gt; 1:\n            raise NukeCreatorError(\"Select only one node\")\n\n        return selected_nodes\n\n    def update_instances(self, update_list):\n        super().update_instances(update_list)\n        for created_inst, changes in update_list:\n            # ensure was not deleted by super()\n            if self.create_context.get_instance_by_id(created_inst.id):\n                self._update_write_node_filepath(created_inst, changes)\n\n    def _update_write_node_filepath(self, created_inst, changes):\n        \"\"\"Update instance node on context changes.\n\n        Whenever any of productName, folderPath, task or productType\n        changes then update:\n        - output filepath of the write node\n        - instance node's name to the product name\n        \"\"\"\n        keys = (\"productName\", \"folderPath\", \"task\", \"productType\")\n        if not any(key in changes.changed_keys for key in keys):\n            # No relevant changes, no need to update\n            return\n\n        data = created_inst.data_to_store()\n        # Update values with new formatted path\n        instance_node = created_inst.transient_data[\"node\"]\n        formatting_data = copy.deepcopy(data)\n        write_node = nuke.allNodes(group=instance_node, filter=\"Write\")[0]\n        _, ext = os.path.splitext(write_node[\"file\"].value())\n        formatting_data.update({\"ext\": ext[1:]})\n\n        # Retieve render template and staging directory.\n        fpath_template = self.temp_rendering_path_template\n        formatting_data[\"work\"] = get_work_default_directory(formatting_data)\n        fpath = StringTemplate(fpath_template).format_strict(formatting_data)\n\n        staging_dir = self.apply_staging_dir(created_inst)\n        if staging_dir:\n            basename = os.path.basename(fpath)\n            staging_path = pathlib.Path(staging_dir)/ basename\n            fpath = staging_path.as_posix()\n\n        write_node[\"file\"].setValue(fpath)\n\n    def get_pre_create_attr_defs(self):\n        attrs_defs = super().get_pre_create_attr_defs()\n        attrs_defs.append(self._get_render_target_enum())\n\n        return attrs_defs\n\n    def get_instance_attr_defs(self):\n        attr_defs = [self._get_render_target_enum()]\n\n        # add reviewable attribute\n        if \"reviewable\" in self.instance_attributes:\n            attr_defs.append(\n                BoolDef(\n                    \"review\",\n                    default=True,\n                    label=\"Review\"\n                )\n            )\n\n        return attr_defs\n\n    def _get_render_target_enum(self):\n        rendering_targets = {\n            \"local\": \"Local machine rendering\",\n            \"frames\": \"Use existing frames\"\n        }\n\n        if \"farm_rendering\" in self.instance_attributes:\n            rendering_targets.update({\n                \"frames_farm\": \"Use existing frames - farm\",\n                \"farm\": \"Farm rendering\",\n            })\n\n        return EnumDef(\n            \"render_target\",\n            items=rendering_targets,\n            default=self.render_target,\n            label=\"Render target\",\n            tooltip=\"Define the render target.\"\n        )\n\n    def create(self, product_name, instance_data, pre_create_data):\n        if not pre_create_data:\n            # add no selection for headless\n            pre_create_data = {\n                \"use_selection\": False\n            }\n\n        # pass values from precreate to instance\n        self._pass_pre_attributes_to_instance(\n            instance_data,\n            pre_create_data,\n            [\n                \"active_frame\",\n                \"render_target\"\n            ]\n        )\n        # make sure selected nodes are added\n        node_selection = self._get_current_selected_nodes(pre_create_data)\n\n        # make sure the product name is unique\n        self.check_existing_product(product_name)\n\n        product_type = instance_data.get(\"productType\")\n        if not product_type:\n            product_type = self.product_base_type\n        try:\n            instance = CreatedInstance(\n                product_base_type=self.product_base_type,\n                product_type=product_type,\n                product_name=product_name,\n                data=instance_data,\n                creator=self,\n            )\n\n            staging_dir = self.apply_staging_dir(instance)\n            instance_node = self.create_instance_node(\n                product_name,\n                instance_data,\n                staging_dir=staging_dir,\n                node_selection=node_selection,\n            )\n\n            instance.transient_data[\"node\"] = instance_node\n\n            self._add_instance_to_context(instance)\n\n            set_node_data(\n                instance_node,\n                INSTANCE_DATA_KNOB,\n                instance.data_to_store()\n            )\n\n            exposed_write_knobs(\n                self.project_settings, self.__class__.__name__, instance_node\n            )\n\n            return instance\n\n        except Exception as exc:\n            raise NukeCreatorError(f\"Creator error: {exc}\") from exc\n\n    def apply_settings(self, project_settings):\n        \"\"\"Method called on initialization of plugin to apply settings.\"\"\"\n        # plugin settings for particular creator\n        super().apply_settings(project_settings)\n        plugin_settings = self.get_creator_settings(project_settings)\n        # enabled\n        self.enabled: bool = plugin_settings.get(\"enabled\", True)\n        # order\n        self.order: int = plugin_settings.get(\"order\", 0)\n        temp_rendering_path_template = (\n            plugin_settings.get(\"temp_rendering_path_template\")\n            or self.temp_rendering_path_template\n        )\n        # individual attributes\n        self.instance_attributes = plugin_settings.get(\n            \"instance_attributes\") or self.instance_attributes\n        self.prenodes = plugin_settings[\"prenodes\"]\n        self.default_variants = plugin_settings.get(\n            \"default_variants\") or self.default_variants\n        self.render_target = plugin_settings.get(\n            \"render_target\") or self.render_target\n        self.temp_rendering_path_template = temp_rendering_path_template\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.NukeWriteCreator.apply_settings","title":"<code>apply_settings(project_settings)</code>","text":"<p>Method called on initialization of plugin to apply settings.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def apply_settings(self, project_settings):\n    \"\"\"Method called on initialization of plugin to apply settings.\"\"\"\n    # plugin settings for particular creator\n    super().apply_settings(project_settings)\n    plugin_settings = self.get_creator_settings(project_settings)\n    # enabled\n    self.enabled: bool = plugin_settings.get(\"enabled\", True)\n    # order\n    self.order: int = plugin_settings.get(\"order\", 0)\n    temp_rendering_path_template = (\n        plugin_settings.get(\"temp_rendering_path_template\")\n        or self.temp_rendering_path_template\n    )\n    # individual attributes\n    self.instance_attributes = plugin_settings.get(\n        \"instance_attributes\") or self.instance_attributes\n    self.prenodes = plugin_settings[\"prenodes\"]\n    self.default_variants = plugin_settings.get(\n        \"default_variants\") or self.default_variants\n    self.render_target = plugin_settings.get(\n        \"render_target\") or self.render_target\n    self.temp_rendering_path_template = temp_rendering_path_template\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.SelectInstanceNodeAction","title":"<code>SelectInstanceNodeAction</code>","text":"<p>               Bases: <code>Action</code></p> <p>Select instance node for failed plugin.</p> Source code in <code>client/ayon_nuke/api/actions.py</code> <pre><code>class SelectInstanceNodeAction(pyblish.api.Action):\n    \"\"\"Select instance node for failed plugin.\"\"\"\n    label = \"Select instance node\"\n    on = \"failed\"  # This action is only available on a failed plug-in\n    icon = \"mdi.cursor-default-click\"\n\n    def process(self, context, plugin):\n\n        # Get the errored instances for the plug-in\n        errored_instances = get_errored_instances_from_context(\n            context, plugin)\n\n        # Get the invalid nodes for the plug-ins\n        self.log.info(\"Finding instance nodes..\")\n        nodes = set()\n        for instance in errored_instances:\n            instance_node = instance.data.get(\"transientData\", {}).get(\"node\")\n            if not instance_node:\n                raise RuntimeError(\n                    \"No transientData['node'] found on instance: {}\".format(\n                        instance\n                    )\n                )\n            nodes.add(instance_node)\n\n        if nodes:\n            self.log.info(\"Selecting instance nodes: {}\".format(nodes))\n            reset_selection()\n            select_nodes(nodes)\n        else:\n            self.log.info(\"No instance nodes found.\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.SelectInvalidAction","title":"<code>SelectInvalidAction</code>","text":"<p>               Bases: <code>Action</code></p> <p>Select invalid nodes in Nuke when plug-in failed.</p> <p>To retrieve the invalid nodes this assumes a static <code>get_invalid()</code> method is available on the plugin.</p> Source code in <code>client/ayon_nuke/api/actions.py</code> <pre><code>class SelectInvalidAction(pyblish.api.Action):\n    \"\"\"Select invalid nodes in Nuke when plug-in failed.\n\n    To retrieve the invalid nodes this assumes a static `get_invalid()`\n    method is available on the plugin.\n\n    \"\"\"\n    label = \"Select invalid nodes\"\n    on = \"failed\"  # This action is only available on a failed plug-in\n    icon = \"search\"  # Icon from Awesome Icon\n\n    def process(self, context, plugin):\n\n        errored_instances = get_errored_instances_from_context(context,\n                                                               plugin=plugin)\n\n        # Get the invalid nodes for the plug-ins\n        self.log.info(\"Finding invalid nodes..\")\n        invalid = set()\n        for instance in errored_instances:\n            invalid_nodes = plugin.get_invalid(instance)\n\n            if invalid_nodes:\n                if isinstance(invalid_nodes, (list, tuple)):\n                    invalid.update(invalid_nodes)\n                else:\n                    self.log.warning(\"Plug-in returned to be invalid, \"\n                                     \"but has no selectable nodes.\")\n\n        if invalid:\n            self.log.info(\"Selecting invalid nodes: {}\".format(invalid))\n            reset_selection()\n            select_nodes(invalid)\n        else:\n            self.log.info(\"No invalid nodes found.\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.colorspace_exists_on_node","title":"<code>colorspace_exists_on_node(node, colorspace_name)</code>","text":"<p>Check if colorspace exists on node</p> <p>Look through all options in the colorspace knob, and see if we have an exact match to one of the items.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>nuke node object</p> required <code>colorspace_name</code> <code>str</code> <p>color profile name</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if exists</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def colorspace_exists_on_node(node, colorspace_name):\n    \"\"\" Check if colorspace exists on node\n\n    Look through all options in the colorspace knob, and see if we have an\n    exact match to one of the items.\n\n    Args:\n        node (nuke.Node): nuke node object\n        colorspace_name (str): color profile name\n\n    Returns:\n        bool: True if exists\n    \"\"\"\n    node_knob_keys = node.knobs().keys()\n\n    if \"colorspace\" in node_knob_keys:\n        colorspace_knob = node[\"colorspace\"]\n    elif \"floatLut\" in node_knob_keys:\n        colorspace_knob = node[\"floatLut\"]\n    else:\n        log.warning(f\"Node '{node.name()}' does not have colorspace knob\")\n        return False\n\n    return colorspace_name in get_colorspace_list(colorspace_knob, node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.containerise","title":"<code>containerise(node, name, namespace, context, loader=None, data=None)</code>","text":"<p>Bundle <code>node</code> into an assembly and imprint it with metadata</p> <p>Containerisation enables a tracking of version, author and origin for loaded assets.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Nuke's node object to imprint as container</p> required <code>name</code> <code>str</code> <p>Name of resulting assembly</p> required <code>namespace</code> <code>str</code> <p>Namespace under which to host container</p> required <code>context</code> <code>dict</code> <p>Asset information</p> required <code>loader</code> <code>str</code> <p>Name of node used to produce this container.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>node</code> <code>Node</code> <p>containerised nuke's node object</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def containerise(node,\n                 name,\n                 namespace,\n                 context,\n                 loader=None,\n                 data=None):\n    \"\"\"Bundle `node` into an assembly and imprint it with metadata\n\n    Containerisation enables a tracking of version, author and origin\n    for loaded assets.\n\n    Arguments:\n        node (nuke.Node): Nuke's node object to imprint as container\n        name (str): Name of resulting assembly\n        namespace (str): Namespace under which to host container\n        context (dict): Asset information\n        loader (str, optional): Name of node used to produce this container.\n\n    Returns:\n        node (nuke.Node): containerised nuke's node object\n\n    \"\"\"\n    data = OrderedDict(\n        [\n            (\"schema\", \"ayon:container-3.0\"),\n            (\"id\", AVALON_CONTAINER_ID),\n            (\"name\", name),\n            (\"namespace\", namespace),\n            (\"loader\", str(loader)),\n            (\"representation\", context[\"representation\"][\"id\"]),\n            (\"project_name\", context[\"project\"][\"name\"]),\n        ],\n\n        **data or dict()\n    )\n\n    set_avalon_knob_data(node, data)\n\n    # set tab to first native\n    node.setTab(0)\n\n    return node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.create_write_node","title":"<code>create_write_node(name, data, input=None, prenodes=None, linked_knobs=None, **kwargs)</code>","text":"<p>Creating write node which is group node</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of node</p> required <code>data</code> <code>dict</code> <p>creator write instance data</p> required <code>input (node)[optional]</code> <p>selected node to connect to</p> required <code>prenodes</code> <code>Optional[list[dict]]</code> <p>nodes to be created before write with dependency</p> <code>None</code> <code>review (bool)[optional]</code> <p>adding review knob</p> required <code>farm (bool)[optional]</code> <p>rendering workflow target</p> required <code>kwargs (dict)[optional]</code> <p>additional key arguments for formatting</p> required Example <p>prenodes = {     \"nodeName\": {         \"nodeclass\": \"Reformat\",         \"dependent\": [             following_node_01,             ...         ],         \"knobs\": [             {                 \"type\": \"text\",                 \"name\": \"knobname\",                 \"value\": \"knob value\"             },             ...         ]     },     ... }</p> Return <p>node (obj): group node with avalon data as Knobs</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def create_write_node(\n    name,\n    data,\n    input=None,\n    prenodes=None,\n    linked_knobs=None,\n    **kwargs\n):\n    ''' Creating write node which is group node\n\n    Arguments:\n        name (str): name of node\n        data (dict): creator write instance data\n        input (node)[optional]: selected node to connect to\n        prenodes (Optional[list[dict]]): nodes to be created before write\n            with dependency\n        review (bool)[optional]: adding review knob\n        farm (bool)[optional]: rendering workflow target\n        kwargs (dict)[optional]: additional key arguments for formatting\n\n    Example:\n        prenodes = {\n            \"nodeName\": {\n                \"nodeclass\": \"Reformat\",\n                \"dependent\": [\n                    following_node_01,\n                    ...\n                ],\n                \"knobs\": [\n                    {\n                        \"type\": \"text\",\n                        \"name\": \"knobname\",\n                        \"value\": \"knob value\"\n                    },\n                    ...\n                ]\n            },\n            ...\n        }\n\n\n    Return:\n        node (obj): group node with avalon data as Knobs\n    '''\n    # Ensure name does not contain any invalid characters.\n    special_chars = re.escape(\"!@#$%^&amp;*()=[]{}|\\\\;',.&lt;&gt;/?~+-\")\n    special_chars_regex = re.compile(f\"[{special_chars}]\")\n    found_special_characters = list(special_chars_regex.findall(name))\n\n    msg = (\n        f\"Special characters found in name \\\"{name}\\\": \"\n        f\"{' '.join(found_special_characters)}\"\n    )\n    assert not found_special_characters, msg\n\n    prenodes = prenodes or []\n\n    # filtering variables\n    plugin_name = data[\"creator\"]\n    product_name = data[\"productName\"]\n\n    # get knob settings for write node\n    imageio_writes = get_imageio_node_setting(\n        node_class=\"Write\",\n        plugin_name=plugin_name,\n        product_name=product_name\n    )\n\n    ext = None\n    knobs = imageio_writes[\"knobs\"]\n    knob_names = {knob[\"name\"]: knob for knob in knobs}\n\n    if \"ext\" in knob_names:\n        knob_type = knob_names[\"ext\"][\"type\"]\n        ext = knob_names[\"ext\"][knob_type]\n\n    # For most extensions, setting the \"file_type\"\n    # is enough, however sometimes they differ, e.g.:\n    # ext = sxr / file_type = exr\n    # ext = jpg / file_type = jpeg\n    elif \"file_type\" in knob_names:\n        knob_type = knob_names[\"file_type\"][\"type\"]\n        ext = knob_names[\"file_type\"][knob_type]\n\n    if not ext:\n        raise RuntimeError(\n            \"Could not determine extension from settings for \"\n            f\"plugin_name={plugin_name} product_name={product_name}\"\n        )\n\n    data.update({\n        \"imageio_writes\": imageio_writes,\n        \"ext\": ext\n    })\n\n    # build file path to workfiles\n    data[\"work\"] = get_work_default_directory(data)\n    fpath = StringTemplate(data[\"fpath_template\"]).format_strict(data)\n\n    # Override output directory is provided staging directory.\n    if data.get(\"staging_dir\"):\n        basename = os.path.basename(fpath)\n        staging_path = pathlib.Path(data[\"staging_dir\"]) / basename\n        fpath = staging_path.as_posix()\n\n    # create directory\n    if not os.path.isdir(os.path.dirname(fpath)):\n        log.warning(\"Path does not exist! I am creating it.\")\n        os.makedirs(os.path.dirname(fpath))\n\n    GN = nuke.createNode(\"Group\", \"name {}\".format(name))\n\n    prev_node = None\n    with GN:\n        if input:\n            input_name = str(input.name()).replace(\" \", \"\")\n            # if connected input node was defined\n            prev_node = nuke.createNode(\n                \"Input\",\n                \"name {}\".format(input_name),\n                inpanel=False\n            )\n        else:\n            # generic input node connected to nothing\n            prev_node = nuke.createNode(\n                \"Input\",\n                \"name {}\".format(\"rgba\"),\n                inpanel=False\n            )\n\n        # creating pre-write nodes `prenodes`\n        last_prenode = create_prenodes(\n            prev_node,\n            prenodes,\n            plugin_name,\n            product_name,\n            **kwargs\n        )\n        if last_prenode:\n            prev_node = last_prenode\n\n        # creating write node\n        write_node = now_node = add_write_node(\n            \"inside_{}\".format(name),\n            fpath,\n            imageio_writes[\"knobs\"],\n            **data\n        )\n        # connect to previous node\n        now_node.setInput(0, prev_node)\n\n        # switch actual node to previous\n        prev_node = now_node\n\n        now_node = nuke.createNode(\"Output\", \"name Output1\", inpanel=False)\n\n        # connect to previous node\n        now_node.setInput(0, prev_node)\n\n    # add divider\n    GN.addKnob(nuke.Text_Knob('', 'Rendering'))\n\n    # Add linked knobs.\n    linked_knob_names = []\n\n    # add input linked knobs and create group only if any input\n    if linked_knobs:\n        linked_knob_names.append(\"_grp-start_\")\n        linked_knob_names.extend(linked_knobs)\n        linked_knob_names.append(\"_grp-end_\")\n\n    linked_knob_names.append(\"Render\")\n\n    for _k_name in linked_knob_names:\n        if \"_grp-start_\" in _k_name:\n            knob = nuke.Tab_Knob(\n                \"rnd_attr\", \"Rendering attributes\", nuke.TABBEGINCLOSEDGROUP)\n            GN.addKnob(knob)\n        elif \"_grp-end_\" in _k_name:\n            knob = nuke.Tab_Knob(\n                \"rnd_attr_end\", \"Rendering attributes\", nuke.TABENDGROUP)\n            GN.addKnob(knob)\n        else:\n            if \"___\" in _k_name:\n                # add divider\n                GN.addKnob(nuke.Text_Knob(\"\"))\n            else:\n                # add linked knob by _k_name\n                link = nuke.Link_Knob(\"\")\n                link.makeLink(write_node.name(), _k_name)\n                link.setName(_k_name)\n\n                # make render\n                if \"Render\" in _k_name:\n                    link.setLabel(\"Render Local\")\n                link.setFlag(0x1000)\n                GN.addKnob(link)\n\n    # Adding render farm submission button.\n    if data.get(\"render_on_farm\", False):\n        add_button_render_on_farm(GN)\n\n    # adding write to read button\n    add_button_write_to_read(GN)\n\n    # adding write to read button\n    add_button_clear_rendered(GN, os.path.dirname(fpath))\n\n    # set tile color\n    tile_color = next(\n        iter(\n            k[k[\"type\"]] for k in imageio_writes[\"knobs\"]\n            if \"tile_color\" in k[\"name\"]\n        ), [255, 0, 0, 255]\n    )\n    new_tile_color = []\n    for c in tile_color:\n        if isinstance(c, float):\n            c = int(c * 255)\n        new_tile_color.append(c)\n    GN[\"tile_color\"].setValue(\n        color_gui_to_int(new_tile_color))\n\n    return GN\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.get_colorspace_list","title":"<code>get_colorspace_list(colorspace_knob, node=None, consider_aliases=True)</code>","text":"<p>Get available colorspace profile names</p> <p>Parameters:</p> Name Type Description Default <code>colorspace_knob</code> <code>Knob</code> <p>nuke knob object</p> required <code>node</code> <code>Optional[Node]</code> <p>nuke node for caching differentiation</p> <code>None</code> <code>consider_aliases</code> <code>Optional[bool]</code> <p>optional flag to indicate if</p> <code>True</code> <p>Returns:</p> Name Type Description <code>list</code> <p>list of strings names of profiles</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def get_colorspace_list(colorspace_knob, node=None, consider_aliases=True):\n    \"\"\"Get available colorspace profile names\n\n    Args:\n        colorspace_knob (nuke.Knob): nuke knob object\n        node (Optional[nuke.Node]): nuke node for caching differentiation\n        consider_aliases (Optional[bool]): optional flag to indicate if\n        colorspace aliases should be added to results list\n\n    Returns:\n        list: list of strings names of profiles\n    \"\"\"\n    results = []\n\n    # making sure any node is provided\n    node = node or nuke.root()\n    # unique script based identifier\n    script_name = nuke.root().name()\n    node_name = node.fullName()\n    identifier_key = f\"{script_name}_{node_name}\"\n\n    if _COLORSPACES_CACHE.get(identifier_key) is None:\n        # This pattern is to match with roles which uses an indentation and\n        # parentheses with original colorspace. The value returned from the\n        # colorspace is the string before the indentation, so we'll need to\n        # convert the values to match with value returned from the knob,\n        # ei. knob.value().\n        pattern = r\"[\\t,]+\"\n        for colorspace in nuke.getColorspaceList(colorspace_knob):\n            colorspace_and_aliases = re.split(pattern, colorspace)\n            if consider_aliases:\n                results.extend(colorspace_and_aliases)\n            else:\n                results.append(colorspace_and_aliases[0])\n\n        _COLORSPACES_CACHE[identifier_key] = results\n\n    return _COLORSPACES_CACHE[identifier_key]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.get_instance_group_node_childs","title":"<code>get_instance_group_node_childs(instance)</code>","text":"<p>Return list of instance group node children</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Instance</code> <p>pyblish instance</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>[nuke.Node]</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def get_instance_group_node_childs(instance):\n    \"\"\"Return list of instance group node children\n\n    Args:\n        instance (pyblish.Instance): pyblish instance\n\n    Returns:\n        list: [nuke.Node]\n    \"\"\"\n    node = instance.data[\"transientData\"][\"node\"]\n\n    if node.Class() != \"Group\":\n        return\n\n    # collect child nodes\n    child_nodes = []\n    # iterate all nodes\n    for node in nuke.allNodes(group=node):\n        # add contained nodes to instance's node list\n        child_nodes.append(node)\n\n    return child_nodes\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.get_node_data","title":"<code>get_node_data(node, knobname)</code>","text":"<p>Read data from node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object</p> required <code>knobname</code> <code>str</code> <p>knob name</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>data stored in knob</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_node_data(node, knobname):\n    \"\"\"Read data from node.\n\n    Args:\n        node (nuke.Node): node object\n        knobname (str): knob name\n\n    Returns:\n        dict: data stored in knob\n    \"\"\"\n    if knobname not in node.knobs():\n        return\n\n    rawdata = node[knobname].getValue()\n    if (\n        isinstance(rawdata, str)\n        and rawdata.startswith(JSON_PREFIX)\n    ):\n        try:\n            return json.loads(rawdata[len(JSON_PREFIX):])\n        except json.JSONDecodeError:\n            return\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.link_knobs","title":"<code>link_knobs(knobs, node, group_node)</code>","text":"<p>Link knobs from inside <code>group_node</code></p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def link_knobs(knobs, node, group_node):\n    \"\"\"Link knobs from inside `group_node`\"\"\"\n\n    missing_knobs = []\n    for knob in knobs:\n        if knob in group_node.knobs():\n            continue\n\n        if knob not in node.knobs().keys():\n            missing_knobs.append(knob)\n\n        link = nuke.Link_Knob(\"\")\n        link.makeLink(node.name(), knob)\n        link.setName(knob)\n        link.setFlag(0x1000)\n        group_node.addKnob(link)\n\n    if missing_knobs:\n        raise ValueError(\n            \"Write node exposed knobs missing:\\n\\n{}\\n\\nPlease review\"\n            \" project settings.\".format(\"\\n\".join(missing_knobs))\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.list_instances","title":"<code>list_instances(creator_id=None)</code>","text":"<p>List all created instances to publish from current workfile.</p> <p>For SubsetManager</p> <p>Parameters:</p> Name Type Description Default <code>creator_id</code> <code>Optional[str]</code> <p>creator identifier</p> <code>None</code> <p>Returns:</p> Type Description <p>(list) of dictionaries matching instances format</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def list_instances(creator_id=None):\n    \"\"\"List all created instances to publish from current workfile.\n\n    For SubsetManager\n\n    Args:\n        creator_id (Optional[str]): creator identifier\n\n    Returns:\n        (list) of dictionaries matching instances format\n    \"\"\"\n    instances_by_order = defaultdict(list)\n    product_instances = []\n    instance_ids = set()\n\n    for node in nuke.allNodes(recurseGroups=True):\n\n        if node.Class() in [\"Viewer\", \"Dot\"]:\n            continue\n\n        try:\n            if node[\"disable\"].value():\n                continue\n        except NameError:\n            # pass if disable knob doesn't exist\n            pass\n\n        # get data from avalon knob\n        instance_data = get_node_data(\n            node, INSTANCE_DATA_KNOB)\n\n        if not instance_data:\n            continue\n\n        if instance_data[\"id\"] not in {\n            AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n        }:\n            continue\n\n        if creator_id and instance_data[\"creator_identifier\"] != creator_id:\n            continue\n\n        instance_id = instance_data.get(\"instance_id\")\n        if not instance_id:\n            pass\n        elif instance_id in instance_ids:\n            instance_data.pop(\"instance_id\")\n        else:\n            instance_ids.add(instance_id)\n\n        # node name could change, so update product name data\n        _update_product_name_data(instance_data, node)\n\n        if \"render_order\" not in node.knobs():\n            product_instances.append((node, instance_data))\n            continue\n\n        order = int(node[\"render_order\"].value())\n        instances_by_order[order].append((node, instance_data))\n\n    # Sort instances based on order attribute or product name.\n    # TODO: remove in future Publisher enhanced with sorting\n    ordered_instances = []\n    for key in sorted(instances_by_order.keys()):\n        instances_by_product = defaultdict(list)\n        for node, data_ in instances_by_order[key]:\n            product_name = data_.get(\"productName\")\n            if product_name is None:\n                product_name = data_.get(\"subset\")\n            instances_by_product[product_name].append((node, data_))\n        for subkey in sorted(instances_by_product.keys()):\n            ordered_instances.extend(instances_by_product[subkey])\n\n    instances_by_product = defaultdict(list)\n    for node, data_ in product_instances:\n        product_name = data_.get(\"productName\")\n        if product_name is None:\n            product_name = data_.get(\"subset\")\n        instances_by_product[product_name].append((node, data_))\n    for key in sorted(instances_by_product.keys()):\n        ordered_instances.extend(instances_by_product[key])\n\n    return ordered_instances\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.ls","title":"<code>ls()</code>","text":"<p>List available containers.</p> <p>This function is used by the Container Manager in Nuke. You'll need to implement a for-loop that then yields one Container at a time.</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def ls():\n    \"\"\"List available containers.\n\n    This function is used by the Container Manager in Nuke. You'll\n    need to implement a for-loop that then *yields* one Container at\n    a time.\n    \"\"\"\n    all_nodes = nuke.allNodes(recurseGroups=False)\n\n    nodes = [n for n in all_nodes]\n\n    for n in nodes:\n        container = parse_container(n)\n        if container:\n            yield container\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.maintained_selection","title":"<code>maintained_selection(exclude_nodes=None)</code>","text":"<p>Maintain selection during context</p> <p>Maintain selection during context and unselect all nodes after context is done.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_nodes</code> <code>list[Node]</code> <p>list of nodes to be unselected                              before context is done</p> <code>None</code> Example <p>with maintained_selection(): ...     node[\"selected\"].setValue(True) print(node[\"selected\"].value()) False</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@contextlib.contextmanager\ndef maintained_selection(exclude_nodes=None):\n    \"\"\"Maintain selection during context\n\n    Maintain selection during context and unselect\n    all nodes after context is done.\n\n    Arguments:\n        exclude_nodes (list[nuke.Node]): list of nodes to be unselected\n                                         before context is done\n\n    Example:\n        &gt;&gt;&gt; with maintained_selection():\n        ...     node[\"selected\"].setValue(True)\n        &gt;&gt;&gt; print(node[\"selected\"].value())\n        False\n    \"\"\"\n    if exclude_nodes:\n        for node in exclude_nodes:\n            node[\"selected\"].setValue(False)\n\n    previous_selection = nuke.selectedNodes()\n\n    try:\n        yield\n    finally:\n        # unselect all selection in case there is some\n        reset_selection()\n\n        # and select all previously selected nodes\n        if previous_selection:\n            select_nodes(previous_selection)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.parse_container","title":"<code>parse_container(node)</code>","text":"<p>Returns containerised data of a node</p> <p>Reads the imprinted data from <code>containerise</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Nuke's node object to read imprinted data</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The container schema data for this container node.</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def parse_container(node):\n    \"\"\"Returns containerised data of a node\n\n    Reads the imprinted data from `containerise`.\n\n    Arguments:\n        node (nuke.Node): Nuke's node object to read imprinted data\n\n    Returns:\n        dict: The container schema data for this container node.\n\n    \"\"\"\n    data = read_avalon_data(node)\n\n    # If not all required data return the empty container\n    required = [\"schema\", \"id\", \"name\",\n                \"namespace\", \"loader\", \"representation\"]\n    if not all(key in data for key in required):\n        return\n\n    # Store the node's name\n    data.update({\n        \"objectName\": node.fullName(),\n        \"node\": node,\n    })\n\n    return data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.remove_instance","title":"<code>remove_instance(instance)</code>","text":"<p>Remove instance from current workfile metadata.</p> <p>For SubsetManager</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>dict</code> <p>instance representation from subsetmanager model</p> required Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def remove_instance(instance):\n    \"\"\"Remove instance from current workfile metadata.\n\n    For SubsetManager\n\n    Args:\n        instance (dict): instance representation from subsetmanager model\n    \"\"\"\n    instance_node = instance.transient_data[\"node\"]\n    instance_knob = instance_node.knobs()[INSTANCE_DATA_KNOB]\n    instance_node.removeKnob(instance_knob)\n    nuke.delete(instance_node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.reset_selection","title":"<code>reset_selection()</code>","text":"<p>Deselect all selected nodes</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def reset_selection():\n    \"\"\"Deselect all selected nodes\"\"\"\n    for node in nuke.selectedNodes():\n        node[\"selected\"].setValue(False)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.select_instance","title":"<code>select_instance(instance)</code>","text":"<p>Select instance in Node View</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>dict</code> <p>instance representation from subsetmanager model</p> required Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def select_instance(instance):\n    \"\"\"\n        Select instance in Node View\n\n        Args:\n            instance (dict): instance representation from subsetmanager model\n    \"\"\"\n    instance_node = instance.transient_data[\"node\"]\n    instance_node[\"selected\"].setValue(True)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.select_nodes","title":"<code>select_nodes(nodes)</code>","text":"<p>Selects all inputted nodes</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>Union[list, tuple, set]</code> <p>nuke nodes to be selected</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def select_nodes(nodes):\n    \"\"\"Selects all inputted nodes\n\n    Arguments:\n        nodes (Union[list, tuple, set]): nuke nodes to be selected\n    \"\"\"\n    assert isinstance(nodes, (list, tuple, set)), \\\n        \"nodes has to be list, tuple or set\"\n\n    for node in nodes:\n        node[\"selected\"].setValue(True)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.set_node_data","title":"<code>set_node_data(node, knobname, data)</code>","text":"<p>Write data to node invisible knob</p> <p>Will create new in case it doesn't exists or update the one already created.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object</p> required <code>knobname</code> <code>str</code> <p>knob name</p> required <code>data</code> <code>dict</code> <p>data to be stored in knob</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_node_data(node, knobname, data):\n    \"\"\"Write data to node invisible knob\n\n    Will create new in case it doesn't exists\n    or update the one already created.\n\n    Args:\n        node (nuke.Node): node object\n        knobname (str): knob name\n        data (dict): data to be stored in knob\n    \"\"\"\n    # if exists then update data\n    if knobname in node.knobs():\n        update_node_data(node, knobname, data)\n        return\n\n    # else create new\n    knob_value = JSON_PREFIX + json.dumps(data)\n    knob = nuke.String_Knob(knobname)\n    knob.setValue(knob_value)\n    knob.setFlag(nuke.INVISIBLE)\n    node.addKnob(knob)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.update_container","title":"<code>update_container(node, keys=None)</code>","text":"<p>Returns node with updateted containder data</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The node in Nuke to imprint as container,</p> required <code>keys</code> <code>dict</code> <p>data which should be updated</p> <code>None</code> <p>Returns:</p> Name Type Description <code>node</code> <code>Node</code> <p>nuke node with updated container data</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def update_container(node, keys=None):\n    \"\"\"Returns node with updateted containder data\n\n    Arguments:\n        node (nuke.Node): The node in Nuke to imprint as container,\n        keys (dict, optional): data which should be updated\n\n    Returns:\n        node (nuke.Node): nuke node with updated container data\n\n    Raises:\n        TypeError on given an invalid container node\n\n    \"\"\"\n    keys = keys or dict()\n\n    container = parse_container(node)\n    if not container:\n        raise TypeError(\"Not a valid container node.\")\n\n    container.update(keys)\n    node = set_avalon_knob_data(node, container)\n\n    return node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.update_node_data","title":"<code>update_node_data(node, knobname, data)</code>","text":"<p>Update already present data.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object</p> required <code>knobname</code> <code>str</code> <p>knob name</p> required <code>data</code> <code>dict</code> <p>data to update knob value</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def update_node_data(node, knobname, data):\n    \"\"\"Update already present data.\n\n    Args:\n        node (nuke.Node): node object\n        knobname (str): knob name\n        data (dict): data to update knob value\n    \"\"\"\n    knob = node[knobname]\n    node_data = get_node_data(node, knobname) or {}\n    node_data.update(data)\n    knob_value = JSON_PREFIX + json.dumps(node_data)\n    knob.setValue(knob_value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/index.html#client.ayon_nuke.api.viewer_update_and_undo_stop","title":"<code>viewer_update_and_undo_stop()</code>","text":"<p>Lock viewer from updating and stop recording undo steps</p> Source code in <code>client/ayon_nuke/api/command.py</code> <pre><code>@contextlib.contextmanager\ndef viewer_update_and_undo_stop():\n    \"\"\"Lock viewer from updating and stop recording undo steps\"\"\"\n    try:\n        # stop active viewer to update any change\n        viewer = nuke.activeViewer()\n        if viewer:\n            viewer.stop()\n        else:\n            log.warning(\"No available active Viewer\")\n        nuke.Undo.disable()\n        yield\n    finally:\n        nuke.Undo.enable()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/actions.html","title":"actions","text":""},{"location":"autoapi/client/ayon_nuke/api/actions.html#client.ayon_nuke.api.actions.SelectInstanceNodeAction","title":"<code>SelectInstanceNodeAction</code>","text":"<p>               Bases: <code>Action</code></p> <p>Select instance node for failed plugin.</p> Source code in <code>client/ayon_nuke/api/actions.py</code> <pre><code>class SelectInstanceNodeAction(pyblish.api.Action):\n    \"\"\"Select instance node for failed plugin.\"\"\"\n    label = \"Select instance node\"\n    on = \"failed\"  # This action is only available on a failed plug-in\n    icon = \"mdi.cursor-default-click\"\n\n    def process(self, context, plugin):\n\n        # Get the errored instances for the plug-in\n        errored_instances = get_errored_instances_from_context(\n            context, plugin)\n\n        # Get the invalid nodes for the plug-ins\n        self.log.info(\"Finding instance nodes..\")\n        nodes = set()\n        for instance in errored_instances:\n            instance_node = instance.data.get(\"transientData\", {}).get(\"node\")\n            if not instance_node:\n                raise RuntimeError(\n                    \"No transientData['node'] found on instance: {}\".format(\n                        instance\n                    )\n                )\n            nodes.add(instance_node)\n\n        if nodes:\n            self.log.info(\"Selecting instance nodes: {}\".format(nodes))\n            reset_selection()\n            select_nodes(nodes)\n        else:\n            self.log.info(\"No instance nodes found.\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/actions.html#client.ayon_nuke.api.actions.SelectInvalidAction","title":"<code>SelectInvalidAction</code>","text":"<p>               Bases: <code>Action</code></p> <p>Select invalid nodes in Nuke when plug-in failed.</p> <p>To retrieve the invalid nodes this assumes a static <code>get_invalid()</code> method is available on the plugin.</p> Source code in <code>client/ayon_nuke/api/actions.py</code> <pre><code>class SelectInvalidAction(pyblish.api.Action):\n    \"\"\"Select invalid nodes in Nuke when plug-in failed.\n\n    To retrieve the invalid nodes this assumes a static `get_invalid()`\n    method is available on the plugin.\n\n    \"\"\"\n    label = \"Select invalid nodes\"\n    on = \"failed\"  # This action is only available on a failed plug-in\n    icon = \"search\"  # Icon from Awesome Icon\n\n    def process(self, context, plugin):\n\n        errored_instances = get_errored_instances_from_context(context,\n                                                               plugin=plugin)\n\n        # Get the invalid nodes for the plug-ins\n        self.log.info(\"Finding invalid nodes..\")\n        invalid = set()\n        for instance in errored_instances:\n            invalid_nodes = plugin.get_invalid(instance)\n\n            if invalid_nodes:\n                if isinstance(invalid_nodes, (list, tuple)):\n                    invalid.update(invalid_nodes)\n                else:\n                    self.log.warning(\"Plug-in returned to be invalid, \"\n                                     \"but has no selectable nodes.\")\n\n        if invalid:\n            self.log.info(\"Selecting invalid nodes: {}\".format(invalid))\n            reset_selection()\n            select_nodes(invalid)\n        else:\n            self.log.info(\"No invalid nodes found.\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html","title":"colorspace","text":"<p>Nuke Colorspace related methods</p>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.colorspace_exists_on_node","title":"<code>colorspace_exists_on_node(node, colorspace_name)</code>","text":"<p>Check if colorspace exists on node</p> <p>Look through all options in the colorspace knob, and see if we have an exact match to one of the items.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>nuke node object</p> required <code>colorspace_name</code> <code>str</code> <p>color profile name</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if exists</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def colorspace_exists_on_node(node, colorspace_name):\n    \"\"\" Check if colorspace exists on node\n\n    Look through all options in the colorspace knob, and see if we have an\n    exact match to one of the items.\n\n    Args:\n        node (nuke.Node): nuke node object\n        colorspace_name (str): color profile name\n\n    Returns:\n        bool: True if exists\n    \"\"\"\n    node_knob_keys = node.knobs().keys()\n\n    if \"colorspace\" in node_knob_keys:\n        colorspace_knob = node[\"colorspace\"]\n    elif \"floatLut\" in node_knob_keys:\n        colorspace_knob = node[\"floatLut\"]\n    else:\n        log.warning(f\"Node '{node.name()}' does not have colorspace knob\")\n        return False\n\n    return colorspace_name in get_colorspace_list(colorspace_knob, node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.create_viewer_profile_string","title":"<code>create_viewer_profile_string(viewer, display=None, path_like=False)</code>","text":"<p>Convert viewer and display to string</p> <p>Parameters:</p> Name Type Description Default <code>viewer</code> <code>str</code> <p>viewer name</p> required <code>display</code> <code>Optional[str]</code> <p>display name</p> <code>None</code> <code>path_like</code> <code>Optional[bool]</code> <p>if True, return path like string</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>viewer config string</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def create_viewer_profile_string(viewer, display=None, path_like=False):\n    \"\"\"Convert viewer and display to string\n\n    Args:\n        viewer (str): viewer name\n        display (Optional[str]): display name\n        path_like (Optional[bool]): if True, return path like string\n\n    Returns:\n        str: viewer config string\n    \"\"\"\n    if not display:\n        return viewer\n\n    if path_like:\n        return \"{}/{}\".format(display, viewer)\n    return \"{} ({})\".format(viewer, display)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.get_colorspace_list","title":"<code>get_colorspace_list(colorspace_knob, node=None, consider_aliases=True)</code>","text":"<p>Get available colorspace profile names</p> <p>Parameters:</p> Name Type Description Default <code>colorspace_knob</code> <code>Knob</code> <p>nuke knob object</p> required <code>node</code> <code>Optional[Node]</code> <p>nuke node for caching differentiation</p> <code>None</code> <code>consider_aliases</code> <code>Optional[bool]</code> <p>optional flag to indicate if</p> <code>True</code> <p>Returns:</p> Name Type Description <code>list</code> <p>list of strings names of profiles</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def get_colorspace_list(colorspace_knob, node=None, consider_aliases=True):\n    \"\"\"Get available colorspace profile names\n\n    Args:\n        colorspace_knob (nuke.Knob): nuke knob object\n        node (Optional[nuke.Node]): nuke node for caching differentiation\n        consider_aliases (Optional[bool]): optional flag to indicate if\n        colorspace aliases should be added to results list\n\n    Returns:\n        list: list of strings names of profiles\n    \"\"\"\n    results = []\n\n    # making sure any node is provided\n    node = node or nuke.root()\n    # unique script based identifier\n    script_name = nuke.root().name()\n    node_name = node.fullName()\n    identifier_key = f\"{script_name}_{node_name}\"\n\n    if _COLORSPACES_CACHE.get(identifier_key) is None:\n        # This pattern is to match with roles which uses an indentation and\n        # parentheses with original colorspace. The value returned from the\n        # colorspace is the string before the indentation, so we'll need to\n        # convert the values to match with value returned from the knob,\n        # ei. knob.value().\n        pattern = r\"[\\t,]+\"\n        for colorspace in nuke.getColorspaceList(colorspace_knob):\n            colorspace_and_aliases = re.split(pattern, colorspace)\n            if consider_aliases:\n                results.extend(colorspace_and_aliases)\n            else:\n                results.append(colorspace_and_aliases[0])\n\n        _COLORSPACES_CACHE[identifier_key] = results\n\n    return _COLORSPACES_CACHE[identifier_key]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.get_display_and_view_colorspaces","title":"<code>get_display_and_view_colorspaces(root_node)</code>","text":"<p>Get all possible display and view colorspaces</p> <p>This is stored in class variable to avoid multiple calls.</p> <p>Parameters:</p> Name Type Description Default <code>root_node</code> <code>Node</code> <p>root node</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>all possible display and view colorspaces</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def get_display_and_view_colorspaces(root_node):\n    \"\"\"Get all possible display and view colorspaces\n\n    This is stored in class variable to avoid multiple calls.\n\n    Args:\n        root_node (nuke.Node): root node\n\n    Returns:\n        list: all possible display and view colorspaces\n    \"\"\"\n    script_name = nuke.root().name()\n    if _DISPLAY_AND_VIEW_COLORSPACES_CACHE.get(script_name) is None:\n        # getting it from `monitorOutLUT` because that is the only shared\n        # display and view knob for 13 &gt; nuke version and returns\n        # correct list of display and view colorspace profiles.\n        colorspace_knob = root_node[\"monitorOutLUT\"]\n        colorspaces = nuke.getColorspaceList(colorspace_knob)\n        _DISPLAY_AND_VIEW_COLORSPACES_CACHE[script_name] = colorspaces\n\n    return _DISPLAY_AND_VIEW_COLORSPACES_CACHE[script_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.get_formatted_colorspace","title":"<code>get_formatted_colorspace(colorspace_name, formatting_data, root_node=None)</code>","text":"<p>Format colorspace profile name into string.</p> <p>This method is formatting colorspace profile name. It is iterating over all possible combinations of input string which could be separated by COLOR_VALUE_SEPARATOR defined in constants.</p> <p>If Anatomy template tokens are used but formatting data is not provided, it will try any other available variants in next position of the separator.</p> <p>This method also validate that the formatted colorspace profile name is available in currently run nuke session ocio config.</p> Example <p>from ayon_nuke.api.colorspace import get_formatted_colorspace colorspace_name = \"{project_code}_{context};ACES - ACEScg\" formatting_data = { ...    \"context\": \"01sh010\", ...    \"project_code\": \"proj01\" ...} new_colorspace_name = get_formatted_colorspace( ...    colorspace_name, formatting_data) print(new_colorspace_name) \"proj01_01sh010\"</p> <p>Parameters:</p> Name Type Description Default <code>colorspace_name</code> <code>str</code> <p>colorspace profile name</p> required <code>formatting_data</code> <code>dict</code> <p>formatting data</p> required <code>root_node</code> <code>Optional[Node]</code> <p>root node</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <p>formatted colorspace profile string ex: \"ACES - ACEScg\"</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def get_formatted_colorspace(\n        colorspace_name, formatting_data, root_node=None):\n    \"\"\"Format colorspace profile name into string.\n\n    This method is formatting colorspace profile name. It is iterating\n    over all possible combinations of input string which could be separated\n    by COLOR_VALUE_SEPARATOR defined in constants.\n\n    If Anatomy template tokens are used but formatting data is not provided,\n    it will try any other available variants in next position of the separator.\n\n    This method also validate that the formatted colorspace profile name is\n    available in currently run nuke session ocio config.\n\n    Example:\n        &gt;&gt;&gt; from ayon_nuke.api.colorspace import get_formatted_colorspace\n        &gt;&gt;&gt; colorspace_name = \"{project_code}_{context};ACES - ACEScg\"\n        &gt;&gt;&gt; formatting_data = {\n        ...    \"context\": \"01sh010\",\n        ...    \"project_code\": \"proj01\"\n        ...}\n        &gt;&gt;&gt; new_colorspace_name = get_formatted_colorspace(\n        ...    colorspace_name, formatting_data)\n        &gt;&gt;&gt; print(new_colorspace_name)\n        \"proj01_01sh010\"\n\n\n    Args:\n        colorspace_name (str): colorspace profile name\n        formatting_data (dict): formatting data\n        root_node (Optional[nuke.Node]): root node\n\n    Returns:\n        str: formatted colorspace profile string\n            ex: \"ACES - ACEScg\"\n    \"\"\"\n    if not root_node:\n        root_node = nuke.root()\n\n    colorspaces = colorspace_name.split(COLOR_VALUE_SEPARATOR)\n\n    # iterate via all found colorspaces\n    for citem in colorspaces:\n        # format any template tokens used in the string\n        citem_resolved = StringTemplate(citem.strip()).format_strict(\n            formatting_data)\n        log.debug(\"Resolved colorspace: `{}`\".format(citem_resolved))\n\n        # making sure formatted colorspace exists in running session\n        if colorspace_exists_on_node(root_node, citem_resolved):\n            return citem_resolved\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.get_formatted_display_and_view","title":"<code>get_formatted_display_and_view(view_profile, formatting_data, root_node=None)</code>","text":"<p>Format display and view profile into string.</p> <p>This method is formatting a display and view profile. It is iterating over all possible combinations of display and view colorspaces. Those could be separated by COLOR_VALUE_SEPARATOR defined in constants.</p> <p>If Anatomy template tokens are used but formatting data is not provided, it will try any other available variants in next position of the separator.</p> <p>This method also validate that the formatted display and view profile is available in currently run nuke session ocio config.</p> Example <p>from ayon_nuke.api.colorspace import get_formatted_display_and_view view_profile = { ...     \"view\": \"{context};sRGB\", ...     \"display\": \"{project_code};ACES\" ... } formatting_data = { ...    \"context\": \"01sh010\", ...    \"project_code\": \"proj01\" ...} display_and_view = get_formatted_display_and_view( ...    view_profile, formatting_data) print(display_and_view) \"01sh010 (proj01)\"</p> <p>Parameters:</p> Name Type Description Default <code>view_profile</code> <code>dict</code> <p>view and display profile</p> required <code>formatting_data</code> <code>dict</code> <p>formatting data</p> required <code>root_node</code> <code>Optional[Node]</code> <p>root node</p> <code>None</code> <p>Returns:</p> Name Type Description <code>str</code> <p>formatted display and view profile string ex: \"sRGB (ACES)\"</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def get_formatted_display_and_view(\n        view_profile, formatting_data, root_node=None):\n    \"\"\"Format display and view profile into string.\n\n    This method is formatting a display and view profile. It is iterating\n    over all possible combinations of display and view colorspaces. Those\n    could be separated by COLOR_VALUE_SEPARATOR defined in constants.\n\n    If Anatomy template tokens are used but formatting data is not provided,\n    it will try any other available variants in next position of the separator.\n\n    This method also validate that the formatted display and view profile is\n    available in currently run nuke session ocio config.\n\n    Example:\n        &gt;&gt;&gt; from ayon_nuke.api.colorspace import get_formatted_display_and_view\n        &gt;&gt;&gt; view_profile = {\n        ...     \"view\": \"{context};sRGB\",\n        ...     \"display\": \"{project_code};ACES\"\n        ... }\n        &gt;&gt;&gt; formatting_data = {\n        ...    \"context\": \"01sh010\",\n        ...    \"project_code\": \"proj01\"\n        ...}\n        &gt;&gt;&gt; display_and_view = get_formatted_display_and_view(\n        ...    view_profile, formatting_data)\n        &gt;&gt;&gt; print(display_and_view)\n        \"01sh010 (proj01)\"\n\n\n    Args:\n        view_profile (dict): view and display profile\n        formatting_data (dict): formatting data\n        root_node (Optional[nuke.Node]): root node\n\n    Returns:\n        str: formatted display and view profile string\n            ex: \"sRGB (ACES)\"\n    \"\"\"\n    if not root_node:\n        root_node = nuke.root()\n\n    views = view_profile[\"view\"].split(COLOR_VALUE_SEPARATOR)\n\n    # display could be optional in case nuke_default ocio config is used\n    displays = []\n    if view_profile[\"display\"]:\n        displays = view_profile[\"display\"].split(COLOR_VALUE_SEPARATOR)\n\n    # generate all possible combination of display/view\n    display_views = []\n    for view in views:\n        # display could be optional in case nuke_default ocio config is used\n        if not displays:\n            display_views.append(view.strip())\n            continue\n\n        for display in displays:\n            display_views.append(\n                create_viewer_profile_string(\n                    view.strip(), display.strip(), path_like=False\n                )\n            )\n\n    for dv_item in display_views:\n        # format any template tokens used in the string\n        dv_item_resolved = StringTemplate(dv_item).format_strict(\n            formatting_data)\n        log.debug(\"Resolved display and view: `{}`\".format(dv_item_resolved))\n\n        # making sure formatted colorspace exists in running session\n        if dv_item_resolved in get_display_and_view_colorspaces(root_node):\n            return dv_item_resolved\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/colorspace.html#client.ayon_nuke.api.colorspace.get_formatted_display_and_view_as_dict","title":"<code>get_formatted_display_and_view_as_dict(view_profile, formatting_data, root_node=None)</code>","text":"<p>Format display and view profile into dict.</p> <p>This method is formatting a display and view profile. It is iterating over all possible combinations of display and view colorspaces. Those could be separated by COLOR_VALUE_SEPARATOR defined in constants.</p> <p>If Anatomy template tokens are used but formatting data is not provided, it will try any other available variants in next position of the separator.</p> <p>This method also validate that the formatted display and view profile is available in currently run nuke session ocio config.</p> Example <p>from ayon_nuke.api.colorspace import get_formatted_display_and_view_as_dict  # noqa view_profile = { ...     \"view\": \"{context};sRGB\", ...     \"display\": \"{project_code};ACES\" ... } formatting_data = { ...    \"context\": \"01sh010\", ...    \"project_code\": \"proj01\" ...} display_and_view = get_formatted_display_and_view_as_dict( ...    view_profile, formatting_data) print(display_and_view) {\"view\": \"01sh010\", \"display\": \"proj01\"}</p> <p>Parameters:</p> Name Type Description Default <code>view_profile</code> <code>dict</code> <p>view and display profile</p> required <code>formatting_data</code> <code>dict</code> <p>formatting data</p> required <code>root_node</code> <code>Optional[Node]</code> <p>root node</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>formatted display and view profile in dict ex: {\"view\": \"sRGB\", \"display\": \"ACES\"}</p> Source code in <code>client/ayon_nuke/api/colorspace.py</code> <pre><code>def get_formatted_display_and_view_as_dict(\n        view_profile, formatting_data, root_node=None):\n    \"\"\"Format display and view profile into dict.\n\n    This method is formatting a display and view profile. It is iterating\n    over all possible combinations of display and view colorspaces. Those\n    could be separated by COLOR_VALUE_SEPARATOR defined in constants.\n\n    If Anatomy template tokens are used but formatting data is not provided,\n    it will try any other available variants in next position of the separator.\n\n    This method also validate that the formatted display and view profile is\n    available in currently run nuke session ocio config.\n\n    Example:\n        &gt;&gt;&gt; from ayon_nuke.api.colorspace import get_formatted_display_and_view_as_dict  # noqa\n        &gt;&gt;&gt; view_profile = {\n        ...     \"view\": \"{context};sRGB\",\n        ...     \"display\": \"{project_code};ACES\"\n        ... }\n        &gt;&gt;&gt; formatting_data = {\n        ...    \"context\": \"01sh010\",\n        ...    \"project_code\": \"proj01\"\n        ...}\n        &gt;&gt;&gt; display_and_view = get_formatted_display_and_view_as_dict(\n        ...    view_profile, formatting_data)\n        &gt;&gt;&gt; print(display_and_view)\n        {\"view\": \"01sh010\", \"display\": \"proj01\"}\n\n\n    Args:\n        view_profile (dict): view and display profile\n        formatting_data (dict): formatting data\n        root_node (Optional[nuke.Node]): root node\n\n    Returns:\n        dict: formatted display and view profile in dict\n            ex: {\"view\": \"sRGB\", \"display\": \"ACES\"}\n    \"\"\"\n    if not root_node:\n        root_node = nuke.root()\n\n    views = view_profile[\"view\"].split(COLOR_VALUE_SEPARATOR)\n\n    # display could be optional in case nuke_default ocio config is used\n    displays = []\n    if view_profile[\"display\"]:\n        displays = view_profile[\"display\"].split(COLOR_VALUE_SEPARATOR)\n\n    # generate all possible combination of display/view\n    display_views = []\n    for view in views:\n        # display could be optional in case nuke_default ocio config is used\n        if not displays:\n            display_views.append({\"view\": view.strip(), \"display\": None})\n            continue\n\n        for display in displays:\n            display_views.append(\n                {\"view\": view.strip(), \"display\": display.strip()})\n\n    root_display_and_view = get_display_and_view_colorspaces(root_node)\n    for dv_item in display_views:\n        # format any template tokens used in the string\n        view = StringTemplate.format_strict_template(\n            dv_item[\"view\"], formatting_data\n        )\n        # for config without displays - nuke_default\n        test_string = view\n        display = dv_item[\"display\"]\n        if display:\n            display = StringTemplate.format_strict_template(\n                display, formatting_data\n            )\n            test_string = create_viewer_profile_string(\n                view, display, path_like=False\n            )\n\n        log.debug(f\"Resolved View: '{view}' Display: '{display}'\")\n\n        # Make sure formatted colorspace exists in running ocio config session\n        if test_string in root_display_and_view:\n            return {\n                \"view\": view,\n                \"display\": display,\n            }\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/command.html","title":"command","text":""},{"location":"autoapi/client/ayon_nuke/api/command.html#client.ayon_nuke.api.command.viewer_update_and_undo_stop","title":"<code>viewer_update_and_undo_stop()</code>","text":"<p>Lock viewer from updating and stop recording undo steps</p> Source code in <code>client/ayon_nuke/api/command.py</code> <pre><code>@contextlib.contextmanager\ndef viewer_update_and_undo_stop():\n    \"\"\"Lock viewer from updating and stop recording undo steps\"\"\"\n    try:\n        # stop active viewer to update any change\n        viewer = nuke.activeViewer()\n        if viewer:\n            viewer.stop()\n        else:\n            log.warning(\"No available active Viewer\")\n        nuke.Undo.disable()\n        yield\n    finally:\n        nuke.Undo.enable()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/constants.html","title":"constants","text":""},{"location":"autoapi/client/ayon_nuke/api/gizmo_menu.html","title":"gizmo_menu","text":""},{"location":"autoapi/client/ayon_nuke/api/lib.html","title":"lib","text":""},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.DirmapCache","title":"<code>DirmapCache</code>","text":"<p>Caching class to get settings and sitesync easily and only once.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>class DirmapCache:\n    \"\"\"Caching class to get settings and sitesync easily and only once.\"\"\"\n    _project_name = None\n    _project_settings = None\n    _sitesync_addon_discovered = False\n    _sitesync_addon = None\n    _mapping = None\n\n    @classmethod\n    def project_name(cls):\n        if cls._project_name is None:\n            cls._project_name = os.getenv(\"AYON_PROJECT_NAME\")\n        return cls._project_name\n\n    @classmethod\n    def project_settings(cls):\n        if cls._project_settings is None:\n            cls._project_settings = get_project_settings(cls.project_name())\n        return cls._project_settings\n\n    @classmethod\n    def sitesync_addon(cls):\n        if not cls._sitesync_addon_discovered:\n            cls._sitesync_addon_discovered = True\n            cls._sitesync_addon = AddonsManager().get(\"sitesync\")\n        return cls._sitesync_addon\n\n    @classmethod\n    def mapping(cls):\n        return cls._mapping\n\n    @classmethod\n    def set_mapping(cls, mapping):\n        cls._mapping = mapping\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.Knobby","title":"<code>Knobby</code>","text":"<p>               Bases: <code>object</code></p> <p>[DEPRECATED] For creating knob which it's type isn't                 mapped in <code>create_knobs</code></p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>string</code> <p>Nuke knob type name</p> required <code>value</code> <p>Value to be set with <code>Knob.setValue</code>, put <code>None</code> if not required</p> required <code>flags</code> <code>list</code> <p>Knob flags to be set with <code>Knob.setFlag</code></p> <code>None</code> <code>*args</code> <p>Args other than knob name for initializing knob class</p> <code>()</code> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>class Knobby(object):\n    \"\"\"[DEPRECATED] For creating knob which it's type isn't\n                    mapped in `create_knobs`\n\n    Args:\n        type (string): Nuke knob type name\n        value: Value to be set with `Knob.setValue`, put `None` if not required\n        flags (list, optional): Knob flags to be set with `Knob.setFlag`\n        *args: Args other than knob name for initializing knob class\n\n    \"\"\"\n\n    def __init__(self, type, value, flags=None, *args):\n        self.type = type\n        self.value = value\n        self.flags = flags or []\n        self.args = args\n\n    def create(self, name, nice=None):\n        knob_cls = getattr(nuke, self.type)\n        knob = knob_cls(name, nice, *self.args)\n        if self.value is not None:\n            knob.setValue(self.value)\n        for flag in self.flags:\n            knob.setFlag(flag)\n        return knob\n\n    @staticmethod\n    def nice_naming(key):\n        \"\"\"Convert camelCase name into UI Display Name\"\"\"\n        words = re.findall('[A-Z][^A-Z]*', key[0].upper() + key[1:])\n        return \" \".join(words)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.Knobby.nice_naming","title":"<code>nice_naming(key)</code>  <code>staticmethod</code>","text":"<p>Convert camelCase name into UI Display Name</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@staticmethod\ndef nice_naming(key):\n    \"\"\"Convert camelCase name into UI Display Name\"\"\"\n    words = re.findall('[A-Z][^A-Z]*', key[0].upper() + key[1:])\n    return \" \".join(words)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.NukeDirmap","title":"<code>NukeDirmap</code>","text":"<p>               Bases: <code>HostDirmap</code></p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>class NukeDirmap(HostDirmap):\n    def __init__(self, file_name, *args, **kwargs):\n        \"\"\"\n        Args:\n            file_name (str): full path of referenced file from workfiles\n            *args (tuple): Positional arguments for 'HostDirmap' class\n            **kwargs (dict): Keyword arguments for 'HostDirmap' class\n        \"\"\"\n\n        self.file_name = file_name\n        super(NukeDirmap, self).__init__(*args, **kwargs)\n\n    def on_enable_dirmap(self):\n        pass\n\n    def dirmap_routine(self, source_path, destination_path):\n        source_path = source_path.lower().replace(os.sep, '/')\n        destination_path = destination_path.lower().replace(os.sep, '/')\n        if platform.system().lower() == \"windows\":\n            self.file_name = self.file_name.lower().replace(\n                source_path, destination_path)\n        else:\n            self.file_name = self.file_name.replace(\n                source_path, destination_path)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.NukeDirmap.__init__","title":"<code>__init__(file_name, *args, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>full path of referenced file from workfiles</p> required <code>*args</code> <code>tuple</code> <p>Positional arguments for 'HostDirmap' class</p> <code>()</code> <code>**kwargs</code> <code>dict</code> <p>Keyword arguments for 'HostDirmap' class</p> <code>{}</code> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def __init__(self, file_name, *args, **kwargs):\n    \"\"\"\n    Args:\n        file_name (str): full path of referenced file from workfiles\n        *args (tuple): Positional arguments for 'HostDirmap' class\n        **kwargs (dict): Keyword arguments for 'HostDirmap' class\n    \"\"\"\n\n    self.file_name = file_name\n    super(NukeDirmap, self).__init__(*args, **kwargs)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings","title":"<code>WorkfileSettings</code>","text":"<p>               Bases: <code>object</code></p> <p>All settings for workfile will be set</p> <p>This object is setting all possible root settings to the workfile. Including Colorspace, Frame ranges, Resolution format. It can set it to Root node or to any given node.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>node</code> <p>nuke's root node</p> required <code>nodes</code> <code>list</code> <p>list of nuke's nodes</p> <code>None</code> <code>nodes_filter</code> <code>list</code> <p>filtering classes for nodes</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>class WorkfileSettings(object):\n    \"\"\"\n    All settings for workfile will be set\n\n    This object is setting all possible root settings to the workfile.\n    Including Colorspace, Frame ranges, Resolution format. It can set it\n    to Root node or to any given node.\n\n    Arguments:\n        root (node): nuke's root node\n        nodes (list): list of nuke's nodes\n        nodes_filter (list): filtering classes for nodes\n\n    \"\"\"\n\n    def __init__(self, root_node=None, nodes=None, **kwargs):\n        project_entity = kwargs.get(\"project\")\n        if project_entity is None:\n            project_name = get_current_project_name()\n            project_entity = ayon_api.get_project(project_name)\n        else:\n            project_name = project_entity[\"name\"]\n\n        Context._project_entity = project_entity\n        self._project_name = project_name\n        self._folder_path = get_current_folder_path()\n        self._folder_entity = ayon_api.get_folder_by_path(\n            project_name, self._folder_path\n        )\n        self._task_name = get_current_task_name()\n        self._context_label = \"{} &gt; {}\".format(self._folder_path,\n                                               self._task_name)\n        self._task_entity = ayon_api.get_task_by_name(\n            project_name,\n            self._folder_entity[\"id\"],\n            self._task_name\n        )\n        self._root_node = root_node or nuke.root()\n        self._nodes = self.get_nodes(nodes=nodes)\n\n        context_data = get_template_data_with_names(\n            project_name, self._folder_path, self._task_name, \"nuke\"\n        )\n        self.formatting_data = context_data\n\n    def get_nodes(self, nodes=None, nodes_filter=None):\n\n        if not isinstance(nodes, list) and not isinstance(nodes_filter, list):\n            return [n for n in nuke.allNodes()]\n        elif not isinstance(nodes, list) and isinstance(nodes_filter, list):\n            nodes = list()\n            for filter in nodes_filter:\n                [nodes.append(n) for n in nuke.allNodes(filter=filter)]\n            return nodes\n        elif isinstance(nodes, list) and not isinstance(nodes_filter, list):\n            return [n for n in self._nodes]\n        elif isinstance(nodes, list) and isinstance(nodes_filter, list):\n            for filter in nodes_filter:\n                return [n for n in self._nodes if filter in n.Class()]\n\n    # TODO: move into ./colorspace.py\n    def set_viewers_colorspace(self, imageio_nuke):\n        ''' Adds correct colorspace to viewer\n\n        Arguments:\n            imageio_nuke (dict): nuke colorspace configurations\n\n        '''\n        filter_knobs = [\n            \"viewerProcess\",\n            \"wipe_position\",\n            \"monitorOutOutputTransform\"\n        ]\n        viewer_process = get_formatted_display_and_view(\n            imageio_nuke[\"viewer\"], self.formatting_data, self._root_node\n        )\n        output_transform = get_formatted_display_and_view(\n            imageio_nuke[\"monitor\"], self.formatting_data, self._root_node\n        )\n        erased_viewers = []\n        for v in nuke.allNodes(filter=\"Viewer\"):\n            # set viewProcess to preset from settings\n            v[\"viewerProcess\"].setValue(viewer_process)\n\n            if viewer_process not in v[\"viewerProcess\"].value():\n                copy_inputs = v.dependencies()\n                copy_knobs = {\n                    k: v[k].value() for k in v.knobs()\n                    if k not in filter_knobs\n                }\n\n                # delete viewer with wrong settings\n                erased_viewers.append(v[\"name\"].value())\n                nuke.delete(v)\n\n                # create new viewer\n                nv = nuke.createNode(\"Viewer\")\n\n                # connect to original inputs\n                for i, n in enumerate(copy_inputs):\n                    nv.setInput(i, n)\n\n                # set copied knobs\n                for knob_name, knob_value in copy_knobs.items():\n                    nv[knob_name].setValue(knob_value)\n\n                # set viewerProcess\n                nv[\"viewerProcess\"].setValue(viewer_process)\n                nv[\"monitorOutOutputTransform\"].setValue(output_transform)\n\n        if erased_viewers:\n            log.warning(\n                \"Attention! Viewer nodes {} were erased.\"\n                \"It had wrong color profile\".format(erased_viewers))\n\n    # TODO: move into ./colorspace.py\n    def set_root_colorspace(self, imageio_host):\n        ''' Adds correct colorspace to root\n\n        Arguments:\n            imageio_host (dict): host colorspace configurations\n\n        '''\n        config_data = get_current_context_imageio_config_preset()\n\n        workfile_settings = imageio_host[\"workfile\"]\n        color_management = workfile_settings[\"color_management\"]\n        native_ocio_config = workfile_settings[\"native_ocio_config\"]\n\n        if not config_data:\n            # no ocio config found and no custom path used\n            if self._root_node[\"colorManagement\"].value() \\\n                        not in color_management:\n                self._root_node[\"colorManagement\"].setValue(color_management)\n\n            # second set ocio version\n            if self._root_node[\"OCIO_config\"].value() \\\n                        not in native_ocio_config:\n                self._root_node[\"OCIO_config\"].setValue(native_ocio_config)\n\n        else:\n            # OCIO config path is defined from prelaunch hook\n            self._root_node[\"colorManagement\"].setValue(\"OCIO\")\n\n            # print previous settings in case some were found in workfile\n            residual_path = self._root_node[\"customOCIOConfigPath\"].value()\n            if residual_path:\n                log.info(\"Residual OCIO config path found: `{}`\".format(\n                    residual_path\n                ))\n\n        # set ocio config path\n        if config_data:\n            config_path = config_data[\"path\"].replace(\"\\\\\", \"/\")\n            log.info(\"OCIO config path found: `{}`\".format(\n                config_path))\n\n            # check if there's a mismatch between environment and settings\n            correct_settings = self._is_settings_matching_environment(\n                config_data)\n\n            # if there's no mismatch between environment and settings\n            if correct_settings:\n                self._set_ocio_config_path_to_workfile(config_data)\n\n        workfile_settings_output = {}\n        # get monitor lut from settings respecting Nuke version differences\n        monitor_lut_data = self._get_monitor_settings(\n            workfile_settings[\"monitor_out_lut\"],\n            workfile_settings[\"monitor_lut\"]\n        )\n        workfile_settings_output.update(monitor_lut_data)\n        workfile_settings_output.update(\n            {\n                \"workingSpaceLUT\": workfile_settings[\"working_space\"],\n                \"int8Lut\": workfile_settings[\"int_8_lut\"],\n                \"int16Lut\": workfile_settings[\"int_16_lut\"],\n                \"logLut\": workfile_settings[\"log_lut\"],\n                \"floatLut\": workfile_settings[\"float_lut\"],\n            }\n        )\n\n        # then set the rest\n        for knob, value_ in workfile_settings_output.items():\n            # skip unfilled ocio config path\n            # it will be dict in value\n            if isinstance(value_, dict):\n                continue\n            # skip empty values\n            if not value_:\n                continue\n            self._root_node[knob].setValue(str(value_))\n\n    def _get_monitor_settings(self, viewer_lut, monitor_lut):\n        \"\"\" Get monitor settings from viewer and monitor lut\n\n        Args:\n            viewer_lut (str): viewer lut string\n            monitor_lut (str): monitor lut string\n\n        Returns:\n            dict: monitor settings\n        \"\"\"\n        output_data = {}\n        m_display, m_viewer = get_viewer_config_from_string(monitor_lut)\n        v_display, v_viewer = get_viewer_config_from_string(viewer_lut)\n\n        # set monitor lut differently for nuke version 14\n        if nuke.NUKE_VERSION_MAJOR &gt;= 14:\n            output_data[\"monitorOutLUT\"] = create_viewer_profile_string(\n                m_viewer, m_display, path_like=False)\n            # monitorLut=thumbnails - viewerProcess makes more sense\n            output_data[\"monitorLut\"] = create_viewer_profile_string(\n                v_viewer, v_display, path_like=False)\n\n        if nuke.NUKE_VERSION_MAJOR == 13:\n            output_data[\"monitorOutLUT\"] = create_viewer_profile_string(\n                m_viewer, m_display, path_like=False)\n            # monitorLut=thumbnails - viewerProcess makes more sense\n            output_data[\"monitorLut\"] = create_viewer_profile_string(\n                v_viewer, v_display, path_like=True)\n        if nuke.NUKE_VERSION_MAJOR &lt;= 12:\n            output_data[\"monitorLut\"] = create_viewer_profile_string(\n                m_viewer, m_display, path_like=True)\n\n        return output_data\n\n    def _is_settings_matching_environment(self, config_data):\n        \"\"\" Check if OCIO config path is different from environment\n\n        Args:\n            config_data (dict): OCIO config data from settings\n\n        Returns:\n            bool: True if settings are matching environment, False otherwise\n        \"\"\"\n        current_ocio_path = os.environ[\"OCIO\"]\n        settings_ocio_path = config_data[\"path\"]\n\n        # normalize all paths to forward slashes\n        current_ocio_path = current_ocio_path.replace(\"\\\\\", \"/\")\n        settings_ocio_path = settings_ocio_path.replace(\"\\\\\", \"/\")\n\n        if current_ocio_path != settings_ocio_path:\n            message = \"\"\"\nIt seems like there's a mismatch between the OCIO config path set in your Nuke\nsettings and the actual path set in your OCIO environment.\n\nTo resolve this, please follow these steps:\n1. Close Nuke if it's currently open.\n2. Reopen Nuke.\n\nPlease note the paths for your reference:\n\n- The OCIO environment path currently set:\n  `{env_path}`\n\n- The path in your current Nuke settings:\n  `{settings_path}`\n\nReopening Nuke should synchronize these paths and resolve any discrepancies.\n\"\"\"\n            nuke.message(\n                message.format(\n                    env_path=current_ocio_path,\n                    settings_path=settings_ocio_path\n                )\n            )\n            return False\n\n        return True\n\n    def _set_ocio_config_path_to_workfile(self, config_data):\n        \"\"\" Set OCIO config path to workfile\n\n        Path set into nuke workfile. It is trying to replace path with\n        environment variable if possible. If not, it will set it as it is.\n        It also saves the script to apply the change, but only if it's not\n        empty Untitled script.\n\n        Args:\n            config_data (dict): OCIO config data from settings\n\n        \"\"\"\n        # replace path with env var if possible\n        ocio_path = self._replace_ocio_path_with_env_var(config_data)\n\n        log.info(\"Setting OCIO config path to: `{}`\".format(\n            ocio_path))\n\n        self._root_node[\"customOCIOConfigPath\"].setValue(\n            ocio_path\n        )\n        self._root_node[\"OCIO_config\"].setValue(\"custom\")\n\n        # only save script if it's not empty\n        if self._root_node[\"name\"].value() != \"\":\n            log.info(\"Saving script to apply OCIO config path change.\")\n            nuke.scriptSave()\n\n    def _get_included_vars(self, config_template):\n        \"\"\" Get all environment variables included in template\n\n        Args:\n            config_template (str): OCIO config template from settings\n\n        Returns:\n            list: list of environment variables included in template\n        \"\"\"\n        # resolve all environments for whitelist variables\n        included_vars = [\n            \"BUILTIN_OCIO_ROOT\",\n        ]\n\n        # include all project root related env vars\n        for env_var in os.environ:\n            if env_var.startswith(\"AYON_PROJECT_ROOT_\"):\n                included_vars.append(env_var)\n\n        # use regex to find env var in template with format {ENV_VAR}\n        # this way we make sure only template used env vars are included\n        env_var_regex = r\"\\{([A-Z0-9_]+)\\}\"\n        env_var = re.findall(env_var_regex, config_template)\n        if env_var:\n            included_vars.append(env_var[0])\n\n        return included_vars\n\n    def _replace_ocio_path_with_env_var(self, config_data):\n        \"\"\" Replace OCIO config path with environment variable\n\n        Environment variable is added as TCL expression to path. TCL expression\n        is also replacing backward slashes found in path for windows\n        formatted values.\n\n        Args:\n            config_data (str): OCIO config dict from settings\n\n        Returns:\n            str: OCIO config path with environment variable TCL expression\n        \"\"\"\n        config_path = config_data[\"path\"].replace(\"\\\\\", \"/\")\n        config_template = config_data[\"template\"]\n\n        included_vars = self._get_included_vars(config_template)\n\n        # make sure we return original path if no env var is included\n        new_path = config_path\n\n        for env_var in included_vars:\n            env_path = os.getenv(env_var)\n            if not env_path:\n                continue\n\n            # it has to be directory current process can see\n            if not os.path.isdir(env_path):\n                continue\n\n            # make sure paths are in same format\n            env_path = env_path.replace(\"\\\\\", \"/\")\n            path = config_path.replace(\"\\\\\", \"/\")\n\n            # check if env_path is in path and replace to first found positive\n            if env_path in path:\n                # with regsub we make sure path format of slashes is correct\n                resub_expr = (\n                    \"[regsub -all {{\\\\\\\\}} [getenv {}] \\\"/\\\"]\").format(env_var)\n\n                new_path = path.replace(\n                    env_path, resub_expr\n                )\n                break\n\n        return new_path\n\n    # TODO: move into ./colorspace.py\n    def set_writes_colorspace(self):\n        ''' Adds correct colorspace to write node dict\n\n        '''\n        for node in nuke.allNodes(filter=\"Group\", group=self._root_node):\n            log.info(\"Setting colorspace to `{}`\".format(node.name()))\n\n            # get data from avalon knob\n            avalon_knob_data = read_avalon_data(node)\n            node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n\n            if (\n                # backward compatibility\n                # TODO: remove this once old avalon data api will be removed\n                avalon_knob_data\n                and avalon_knob_data.get(\"id\") not in {\n                    AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n                }\n            ):\n                continue\n            elif (\n                node_data\n                and node_data.get(\"id\") not in {\n                    AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n                }\n            ):\n                continue\n\n            if (\n                # backward compatibility\n                # TODO: remove this once old avalon data api will be removed\n                avalon_knob_data\n                and \"creator\" not in avalon_knob_data\n            ):\n                continue\n            elif (\n                node_data\n                and \"creator_identifier\" not in node_data\n            ):\n                continue\n\n            nuke_imageio_writes = None\n            if avalon_knob_data:\n                # establish families\n                product_base_type = (\n                    avalon_knob_data.get(\"productBaseType\")\n                    or avalon_knob_data.get(\"productType\")\n                )\n                # this shouldn't happen anymore, only with very old data\n                # and should be removed later when all avalon data api is\n                # also removed.\n                if product_base_type is None:\n                    product_base_type = avalon_knob_data[\"family\"]\n                families = [product_base_type]\n                if avalon_knob_data.get(\"families\"):\n                    families.append(avalon_knob_data.get(\"families\"))\n\n                nuke_imageio_writes = get_imageio_node_setting(\n                    node_class=avalon_knob_data[\"families\"],\n                    plugin_name=avalon_knob_data[\"creator\"],\n                    product_name=avalon_knob_data[\"productName\"]\n                )\n            elif node_data:\n                nuke_imageio_writes = get_write_node_template_attr(node)\n\n            if not nuke_imageio_writes:\n                return\n\n            write_node = None\n\n            # get into the group node\n            node.begin()\n            for x in nuke.allNodes():\n                if x.Class() == \"Write\":\n                    write_node = x\n            node.end()\n\n            if not write_node:\n                return\n\n            # Exclude exposed knobs from colorspace nodes.\n            # This ensures that any values overwritten by the user is\n            # not changed by the colorspace knobs set.\n            colorspace_knobs = nuke_imageio_writes[\"knobs\"]\n            all_create_settings =  get_project_settings(Context.project_name)[\"nuke\"][\"create\"]\n            plugin_names_mapping = {\n                \"create_write_image\": \"CreateWriteImage\",\n                \"create_write_prerender\": \"CreateWritePrerender\",\n                \"create_write_render\": \"CreateWriteRender\"\n            }\n            node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n            identifier = node_data[\"creator_identifier\"]\n            creator_settings = all_create_settings[plugin_names_mapping[identifier]]\n            exposed_knobs = creator_settings.get(\"exposed_knobs\")\n\n            colorspace_knobs = [\n                entry for entry in colorspace_knobs\n                if entry[\"name\"] not in exposed_knobs\n            ]\n\n            set_node_knobs_from_settings(write_node, colorspace_knobs)\n\n    # TODO: move into ./colorspace.py\n    def set_reads_colorspace(self, read_clrs_inputs):\n        \"\"\" Setting colorspace to Read nodes\n\n        Looping through all read nodes and tries to set colorspace based\n        on regex rules in presets\n        \"\"\"\n        changes = {}\n        for n in nuke.allNodes():\n            file = nuke.filename(n)\n            if n.Class() != \"Read\":\n                continue\n\n            # check if any colorspace presets for read is matching\n            preset_clrsp = None\n\n            for input in read_clrs_inputs:\n                if not bool(re.search(input[\"regex\"], file)):\n                    continue\n                preset_clrsp = input[\"colorspace\"]\n\n            if preset_clrsp is not None:\n                current = n[\"colorspace\"].value()\n                future = str(preset_clrsp)\n                if current != future:\n                    changes[n.name()] = {\n                        \"from\": current,\n                        \"to\": future\n                    }\n\n        if changes:\n            msg = \"Read nodes are not set to correct colorspace:\\n\\n\"\n            for nname, knobs in changes.items():\n                msg += (\n                    \" - node: '{0}' is now '{1}' but should be '{2}'\\n\"\n                ).format(nname, knobs[\"from\"], knobs[\"to\"])\n\n            msg += \"\\nWould you like to change it?\"\n\n            if nuke.ask(msg):\n                for nname, knobs in changes.items():\n                    n = nuke.toNode(nname)\n                    n[\"colorspace\"].setValue(knobs[\"to\"])\n                    log.info(\n                        \"Setting `{0}` to `{1}`\".format(\n                            nname,\n                            knobs[\"to\"]))\n\n    # TODO: move into ./colorspace.py\n    def set_colorspace(self):\n        ''' Setting colorspace following presets\n        '''\n        # get imageio\n        nuke_colorspace = get_nuke_imageio_settings()\n\n        log.info(\"Setting colorspace to workfile...\")\n        try:\n            self.set_root_colorspace(nuke_colorspace)\n        except AttributeError as _error:\n            msg = \"Set Colorspace to workfile error: {}\".format(_error)\n            nuke.message(msg)\n\n        log.info(\"Setting colorspace to viewers...\")\n        try:\n            self.set_viewers_colorspace(nuke_colorspace)\n        except AttributeError as _error:\n            msg = \"Set Colorspace to viewer error: {}\".format(_error)\n            nuke.message(msg)\n\n        log.info(\"Setting colorspace to write nodes...\")\n        try:\n            self.set_writes_colorspace()\n        except AttributeError as _error:\n            nuke.message(_error)\n            log.error(_error)\n\n        log.info(\"Setting colorspace to read nodes...\")\n        read_clrs_inputs = nuke_colorspace[\"regex_inputs\"].get(\"inputs\", [])\n        if read_clrs_inputs:\n            self.set_reads_colorspace(read_clrs_inputs)\n\n    def reset_frame_range_handles(self):\n        \"\"\"Set frame range to current folder.\"\"\"\n\n        if \"attrib\" not in self._task_entity:\n            msg = \"Task {} doesn't have set any 'attrib'\".format(\n                self._context_label\n            )\n            log.warning(msg)\n            nuke.message(msg)\n            return\n\n        task_attributes = self._task_entity[\"attrib\"]\n\n        missing_cols = []\n        check_cols = [\"fps\", \"frameStart\", \"frameEnd\",\n                      \"handleStart\", \"handleEnd\"]\n\n        for col in check_cols:\n            if col not in task_attributes:\n                missing_cols.append(col)\n\n        if len(missing_cols) &gt; 0:\n            missing = \", \".join(missing_cols)\n            msg = \"'{}' are not set for task '{}'!\".format(\n                missing, self._context_label)\n            log.warning(msg)\n            nuke.message(msg)\n            return\n\n        # get handles values\n        handle_start = task_attributes[\"handleStart\"]\n        handle_end = task_attributes[\"handleEnd\"]\n        frame_start = task_attributes[\"frameStart\"]\n        frame_end = task_attributes[\"frameEnd\"]\n\n        fps = float(task_attributes[\"fps\"])\n        frame_start_handle = frame_start - handle_start\n        frame_end_handle = frame_end + handle_end\n\n        self._root_node[\"lock_range\"].setValue(False)\n        self._root_node[\"fps\"].setValue(fps)\n        self._root_node[\"first_frame\"].setValue(frame_start_handle)\n        self._root_node[\"last_frame\"].setValue(frame_end_handle)\n        self._root_node[\"lock_range\"].setValue(True)\n\n        # update node graph so knobs are updated\n        update_node_graph()\n\n        frame_range = '{0}-{1}'.format(frame_start, frame_end)\n\n        for node in nuke.allNodes(filter=\"Viewer\"):\n            node['frame_range'].setValue(frame_range)\n            node['frame_range_lock'].setValue(True)\n            node['frame_range'].setValue(frame_range)\n            node['frame_range_lock'].setValue(True)\n\n        if not ASSIST:\n            set_node_data(\n                self._root_node,\n                INSTANCE_DATA_KNOB,\n                {\n                    \"handleStart\": int(handle_start),\n                    \"handleEnd\": int(handle_end)\n                }\n            )\n        else:\n            log.warning(\n                \"NukeAssist mode is not allowing \"\n                \"updating custom knobs...\"\n            )\n\n    def reset_resolution(self):\n        \"\"\"Set resolution to project resolution.\"\"\"\n        log.info(\"Resetting resolution\")\n        project_name = get_current_project_name()\n        task_attributes = self._task_entity[\"attrib\"]\n\n        format_data = {\n            \"width\": task_attributes[\"resolutionWidth\"],\n            \"height\": task_attributes[\"resolutionHeight\"],\n            \"pixel_aspect\": task_attributes[\"pixelAspect\"],\n            \"name\": project_name\n        }\n\n        if any(x_ for x_ in format_data.values() if x_ is None):\n            msg = (\"Missing set shot attributes in DB.\"\n                   \"\\nContact your supervisor!.\"\n                   \"\\n\\nWidth: `{width}`\"\n                   \"\\nHeight: `{height}`\"\n                   \"\\nPixel Aspect: `{pixel_aspect}`\").format(**format_data)\n            log.error(msg)\n            nuke.message(msg)\n\n        existing_format = None\n        for format in nuke.formats():\n            if format_data[\"name\"] == format.name():\n                existing_format = format\n                break\n\n        if existing_format:\n            # Enforce existing format to be correct.\n            existing_format.setWidth(format_data[\"width\"])\n            existing_format.setHeight(format_data[\"height\"])\n            existing_format.setPixelAspect(format_data[\"pixel_aspect\"])\n        else:\n            format_string = self.make_format_string(**format_data)\n            log.info(\"Creating new format: {}\".format(format_string))\n            nuke.addFormat(format_string)\n\n        nuke.root()[\"format\"].setValue(format_data[\"name\"])\n        log.info(\"Format is set.\")\n\n        # update node graph so knobs are updated\n        update_node_graph()\n\n    def make_format_string(self, **kwargs):\n        if kwargs.get(\"r\"):\n            return (\n                \"{width} \"\n                \"{height} \"\n                \"{x} \"\n                \"{y} \"\n                \"{r} \"\n                \"{t} \"\n                \"{pixel_aspect:.2f} \"\n                \"{name}\".format(**kwargs)\n            )\n        else:\n            return (\n                \"{width} \"\n                \"{height} \"\n                \"{pixel_aspect:.2f} \"\n                \"{name}\".format(**kwargs)\n            )\n\n    def set_context_settings(self):\n        self.reset_resolution()\n        self.reset_frame_range_handles()\n        # add colorspace menu item\n        self.set_colorspace()\n\n    def set_favorites(self):\n        from .utils import set_context_favorites\n\n        work_dir = os.getenv(\"AYON_WORKDIR\")\n        # TODO validate functionality\n        # - does expect the structure is '{root}/{project}/{folder}'\n        # - this used asset name expecting it is unique in project\n        folder_path = get_current_folder_path()\n        folder_name = folder_path.split(\"/\")[-1]\n        favorite_items = OrderedDict()\n\n        # project\n        # get project's root and split to parts\n        projects_root = os.path.normpath(work_dir.split(\n            Context.project_name)[0])\n        # add project name\n        project_dir = os.path.join(projects_root, Context.project_name) + \"/\"\n        # add to favorites\n        favorite_items.update({\"Project dir\": project_dir.replace(\"\\\\\", \"/\")})\n\n        # folder\n        folder_root = os.path.normpath(work_dir.split(\n            folder_name)[0])\n        # add folder name\n        folder_dir = os.path.join(folder_root, folder_name) + \"/\"\n        # add to favorites\n        favorite_items.update({\"Shot dir\": folder_dir.replace(\"\\\\\", \"/\")})\n\n        # workdir\n        favorite_items.update({\"Work dir\": work_dir.replace(\"\\\\\", \"/\")})\n\n        set_context_favorites(favorite_items)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.reset_frame_range_handles","title":"<code>reset_frame_range_handles()</code>","text":"<p>Set frame range to current folder.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def reset_frame_range_handles(self):\n    \"\"\"Set frame range to current folder.\"\"\"\n\n    if \"attrib\" not in self._task_entity:\n        msg = \"Task {} doesn't have set any 'attrib'\".format(\n            self._context_label\n        )\n        log.warning(msg)\n        nuke.message(msg)\n        return\n\n    task_attributes = self._task_entity[\"attrib\"]\n\n    missing_cols = []\n    check_cols = [\"fps\", \"frameStart\", \"frameEnd\",\n                  \"handleStart\", \"handleEnd\"]\n\n    for col in check_cols:\n        if col not in task_attributes:\n            missing_cols.append(col)\n\n    if len(missing_cols) &gt; 0:\n        missing = \", \".join(missing_cols)\n        msg = \"'{}' are not set for task '{}'!\".format(\n            missing, self._context_label)\n        log.warning(msg)\n        nuke.message(msg)\n        return\n\n    # get handles values\n    handle_start = task_attributes[\"handleStart\"]\n    handle_end = task_attributes[\"handleEnd\"]\n    frame_start = task_attributes[\"frameStart\"]\n    frame_end = task_attributes[\"frameEnd\"]\n\n    fps = float(task_attributes[\"fps\"])\n    frame_start_handle = frame_start - handle_start\n    frame_end_handle = frame_end + handle_end\n\n    self._root_node[\"lock_range\"].setValue(False)\n    self._root_node[\"fps\"].setValue(fps)\n    self._root_node[\"first_frame\"].setValue(frame_start_handle)\n    self._root_node[\"last_frame\"].setValue(frame_end_handle)\n    self._root_node[\"lock_range\"].setValue(True)\n\n    # update node graph so knobs are updated\n    update_node_graph()\n\n    frame_range = '{0}-{1}'.format(frame_start, frame_end)\n\n    for node in nuke.allNodes(filter=\"Viewer\"):\n        node['frame_range'].setValue(frame_range)\n        node['frame_range_lock'].setValue(True)\n        node['frame_range'].setValue(frame_range)\n        node['frame_range_lock'].setValue(True)\n\n    if not ASSIST:\n        set_node_data(\n            self._root_node,\n            INSTANCE_DATA_KNOB,\n            {\n                \"handleStart\": int(handle_start),\n                \"handleEnd\": int(handle_end)\n            }\n        )\n    else:\n        log.warning(\n            \"NukeAssist mode is not allowing \"\n            \"updating custom knobs...\"\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.reset_resolution","title":"<code>reset_resolution()</code>","text":"<p>Set resolution to project resolution.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def reset_resolution(self):\n    \"\"\"Set resolution to project resolution.\"\"\"\n    log.info(\"Resetting resolution\")\n    project_name = get_current_project_name()\n    task_attributes = self._task_entity[\"attrib\"]\n\n    format_data = {\n        \"width\": task_attributes[\"resolutionWidth\"],\n        \"height\": task_attributes[\"resolutionHeight\"],\n        \"pixel_aspect\": task_attributes[\"pixelAspect\"],\n        \"name\": project_name\n    }\n\n    if any(x_ for x_ in format_data.values() if x_ is None):\n        msg = (\"Missing set shot attributes in DB.\"\n               \"\\nContact your supervisor!.\"\n               \"\\n\\nWidth: `{width}`\"\n               \"\\nHeight: `{height}`\"\n               \"\\nPixel Aspect: `{pixel_aspect}`\").format(**format_data)\n        log.error(msg)\n        nuke.message(msg)\n\n    existing_format = None\n    for format in nuke.formats():\n        if format_data[\"name\"] == format.name():\n            existing_format = format\n            break\n\n    if existing_format:\n        # Enforce existing format to be correct.\n        existing_format.setWidth(format_data[\"width\"])\n        existing_format.setHeight(format_data[\"height\"])\n        existing_format.setPixelAspect(format_data[\"pixel_aspect\"])\n    else:\n        format_string = self.make_format_string(**format_data)\n        log.info(\"Creating new format: {}\".format(format_string))\n        nuke.addFormat(format_string)\n\n    nuke.root()[\"format\"].setValue(format_data[\"name\"])\n    log.info(\"Format is set.\")\n\n    # update node graph so knobs are updated\n    update_node_graph()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.set_colorspace","title":"<code>set_colorspace()</code>","text":"<p>Setting colorspace following presets</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_colorspace(self):\n    ''' Setting colorspace following presets\n    '''\n    # get imageio\n    nuke_colorspace = get_nuke_imageio_settings()\n\n    log.info(\"Setting colorspace to workfile...\")\n    try:\n        self.set_root_colorspace(nuke_colorspace)\n    except AttributeError as _error:\n        msg = \"Set Colorspace to workfile error: {}\".format(_error)\n        nuke.message(msg)\n\n    log.info(\"Setting colorspace to viewers...\")\n    try:\n        self.set_viewers_colorspace(nuke_colorspace)\n    except AttributeError as _error:\n        msg = \"Set Colorspace to viewer error: {}\".format(_error)\n        nuke.message(msg)\n\n    log.info(\"Setting colorspace to write nodes...\")\n    try:\n        self.set_writes_colorspace()\n    except AttributeError as _error:\n        nuke.message(_error)\n        log.error(_error)\n\n    log.info(\"Setting colorspace to read nodes...\")\n    read_clrs_inputs = nuke_colorspace[\"regex_inputs\"].get(\"inputs\", [])\n    if read_clrs_inputs:\n        self.set_reads_colorspace(read_clrs_inputs)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.set_reads_colorspace","title":"<code>set_reads_colorspace(read_clrs_inputs)</code>","text":"<p>Setting colorspace to Read nodes</p> <p>Looping through all read nodes and tries to set colorspace based on regex rules in presets</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_reads_colorspace(self, read_clrs_inputs):\n    \"\"\" Setting colorspace to Read nodes\n\n    Looping through all read nodes and tries to set colorspace based\n    on regex rules in presets\n    \"\"\"\n    changes = {}\n    for n in nuke.allNodes():\n        file = nuke.filename(n)\n        if n.Class() != \"Read\":\n            continue\n\n        # check if any colorspace presets for read is matching\n        preset_clrsp = None\n\n        for input in read_clrs_inputs:\n            if not bool(re.search(input[\"regex\"], file)):\n                continue\n            preset_clrsp = input[\"colorspace\"]\n\n        if preset_clrsp is not None:\n            current = n[\"colorspace\"].value()\n            future = str(preset_clrsp)\n            if current != future:\n                changes[n.name()] = {\n                    \"from\": current,\n                    \"to\": future\n                }\n\n    if changes:\n        msg = \"Read nodes are not set to correct colorspace:\\n\\n\"\n        for nname, knobs in changes.items():\n            msg += (\n                \" - node: '{0}' is now '{1}' but should be '{2}'\\n\"\n            ).format(nname, knobs[\"from\"], knobs[\"to\"])\n\n        msg += \"\\nWould you like to change it?\"\n\n        if nuke.ask(msg):\n            for nname, knobs in changes.items():\n                n = nuke.toNode(nname)\n                n[\"colorspace\"].setValue(knobs[\"to\"])\n                log.info(\n                    \"Setting `{0}` to `{1}`\".format(\n                        nname,\n                        knobs[\"to\"]))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.set_root_colorspace","title":"<code>set_root_colorspace(imageio_host)</code>","text":"<p>Adds correct colorspace to root</p> <p>Parameters:</p> Name Type Description Default <code>imageio_host</code> <code>dict</code> <p>host colorspace configurations</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_root_colorspace(self, imageio_host):\n    ''' Adds correct colorspace to root\n\n    Arguments:\n        imageio_host (dict): host colorspace configurations\n\n    '''\n    config_data = get_current_context_imageio_config_preset()\n\n    workfile_settings = imageio_host[\"workfile\"]\n    color_management = workfile_settings[\"color_management\"]\n    native_ocio_config = workfile_settings[\"native_ocio_config\"]\n\n    if not config_data:\n        # no ocio config found and no custom path used\n        if self._root_node[\"colorManagement\"].value() \\\n                    not in color_management:\n            self._root_node[\"colorManagement\"].setValue(color_management)\n\n        # second set ocio version\n        if self._root_node[\"OCIO_config\"].value() \\\n                    not in native_ocio_config:\n            self._root_node[\"OCIO_config\"].setValue(native_ocio_config)\n\n    else:\n        # OCIO config path is defined from prelaunch hook\n        self._root_node[\"colorManagement\"].setValue(\"OCIO\")\n\n        # print previous settings in case some were found in workfile\n        residual_path = self._root_node[\"customOCIOConfigPath\"].value()\n        if residual_path:\n            log.info(\"Residual OCIO config path found: `{}`\".format(\n                residual_path\n            ))\n\n    # set ocio config path\n    if config_data:\n        config_path = config_data[\"path\"].replace(\"\\\\\", \"/\")\n        log.info(\"OCIO config path found: `{}`\".format(\n            config_path))\n\n        # check if there's a mismatch between environment and settings\n        correct_settings = self._is_settings_matching_environment(\n            config_data)\n\n        # if there's no mismatch between environment and settings\n        if correct_settings:\n            self._set_ocio_config_path_to_workfile(config_data)\n\n    workfile_settings_output = {}\n    # get monitor lut from settings respecting Nuke version differences\n    monitor_lut_data = self._get_monitor_settings(\n        workfile_settings[\"monitor_out_lut\"],\n        workfile_settings[\"monitor_lut\"]\n    )\n    workfile_settings_output.update(monitor_lut_data)\n    workfile_settings_output.update(\n        {\n            \"workingSpaceLUT\": workfile_settings[\"working_space\"],\n            \"int8Lut\": workfile_settings[\"int_8_lut\"],\n            \"int16Lut\": workfile_settings[\"int_16_lut\"],\n            \"logLut\": workfile_settings[\"log_lut\"],\n            \"floatLut\": workfile_settings[\"float_lut\"],\n        }\n    )\n\n    # then set the rest\n    for knob, value_ in workfile_settings_output.items():\n        # skip unfilled ocio config path\n        # it will be dict in value\n        if isinstance(value_, dict):\n            continue\n        # skip empty values\n        if not value_:\n            continue\n        self._root_node[knob].setValue(str(value_))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.set_viewers_colorspace","title":"<code>set_viewers_colorspace(imageio_nuke)</code>","text":"<p>Adds correct colorspace to viewer</p> <p>Parameters:</p> Name Type Description Default <code>imageio_nuke</code> <code>dict</code> <p>nuke colorspace configurations</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_viewers_colorspace(self, imageio_nuke):\n    ''' Adds correct colorspace to viewer\n\n    Arguments:\n        imageio_nuke (dict): nuke colorspace configurations\n\n    '''\n    filter_knobs = [\n        \"viewerProcess\",\n        \"wipe_position\",\n        \"monitorOutOutputTransform\"\n    ]\n    viewer_process = get_formatted_display_and_view(\n        imageio_nuke[\"viewer\"], self.formatting_data, self._root_node\n    )\n    output_transform = get_formatted_display_and_view(\n        imageio_nuke[\"monitor\"], self.formatting_data, self._root_node\n    )\n    erased_viewers = []\n    for v in nuke.allNodes(filter=\"Viewer\"):\n        # set viewProcess to preset from settings\n        v[\"viewerProcess\"].setValue(viewer_process)\n\n        if viewer_process not in v[\"viewerProcess\"].value():\n            copy_inputs = v.dependencies()\n            copy_knobs = {\n                k: v[k].value() for k in v.knobs()\n                if k not in filter_knobs\n            }\n\n            # delete viewer with wrong settings\n            erased_viewers.append(v[\"name\"].value())\n            nuke.delete(v)\n\n            # create new viewer\n            nv = nuke.createNode(\"Viewer\")\n\n            # connect to original inputs\n            for i, n in enumerate(copy_inputs):\n                nv.setInput(i, n)\n\n            # set copied knobs\n            for knob_name, knob_value in copy_knobs.items():\n                nv[knob_name].setValue(knob_value)\n\n            # set viewerProcess\n            nv[\"viewerProcess\"].setValue(viewer_process)\n            nv[\"monitorOutOutputTransform\"].setValue(output_transform)\n\n    if erased_viewers:\n        log.warning(\n            \"Attention! Viewer nodes {} were erased.\"\n            \"It had wrong color profile\".format(erased_viewers))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.WorkfileSettings.set_writes_colorspace","title":"<code>set_writes_colorspace()</code>","text":"<p>Adds correct colorspace to write node dict</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_writes_colorspace(self):\n    ''' Adds correct colorspace to write node dict\n\n    '''\n    for node in nuke.allNodes(filter=\"Group\", group=self._root_node):\n        log.info(\"Setting colorspace to `{}`\".format(node.name()))\n\n        # get data from avalon knob\n        avalon_knob_data = read_avalon_data(node)\n        node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n\n        if (\n            # backward compatibility\n            # TODO: remove this once old avalon data api will be removed\n            avalon_knob_data\n            and avalon_knob_data.get(\"id\") not in {\n                AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n            }\n        ):\n            continue\n        elif (\n            node_data\n            and node_data.get(\"id\") not in {\n                AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n            }\n        ):\n            continue\n\n        if (\n            # backward compatibility\n            # TODO: remove this once old avalon data api will be removed\n            avalon_knob_data\n            and \"creator\" not in avalon_knob_data\n        ):\n            continue\n        elif (\n            node_data\n            and \"creator_identifier\" not in node_data\n        ):\n            continue\n\n        nuke_imageio_writes = None\n        if avalon_knob_data:\n            # establish families\n            product_base_type = (\n                avalon_knob_data.get(\"productBaseType\")\n                or avalon_knob_data.get(\"productType\")\n            )\n            # this shouldn't happen anymore, only with very old data\n            # and should be removed later when all avalon data api is\n            # also removed.\n            if product_base_type is None:\n                product_base_type = avalon_knob_data[\"family\"]\n            families = [product_base_type]\n            if avalon_knob_data.get(\"families\"):\n                families.append(avalon_knob_data.get(\"families\"))\n\n            nuke_imageio_writes = get_imageio_node_setting(\n                node_class=avalon_knob_data[\"families\"],\n                plugin_name=avalon_knob_data[\"creator\"],\n                product_name=avalon_knob_data[\"productName\"]\n            )\n        elif node_data:\n            nuke_imageio_writes = get_write_node_template_attr(node)\n\n        if not nuke_imageio_writes:\n            return\n\n        write_node = None\n\n        # get into the group node\n        node.begin()\n        for x in nuke.allNodes():\n            if x.Class() == \"Write\":\n                write_node = x\n        node.end()\n\n        if not write_node:\n            return\n\n        # Exclude exposed knobs from colorspace nodes.\n        # This ensures that any values overwritten by the user is\n        # not changed by the colorspace knobs set.\n        colorspace_knobs = nuke_imageio_writes[\"knobs\"]\n        all_create_settings =  get_project_settings(Context.project_name)[\"nuke\"][\"create\"]\n        plugin_names_mapping = {\n            \"create_write_image\": \"CreateWriteImage\",\n            \"create_write_prerender\": \"CreateWritePrerender\",\n            \"create_write_render\": \"CreateWriteRender\"\n        }\n        node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n        identifier = node_data[\"creator_identifier\"]\n        creator_settings = all_create_settings[plugin_names_mapping[identifier]]\n        exposed_knobs = creator_settings.get(\"exposed_knobs\")\n\n        colorspace_knobs = [\n            entry for entry in colorspace_knobs\n            if entry[\"name\"] not in exposed_knobs\n        ]\n\n        set_node_knobs_from_settings(write_node, colorspace_knobs)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.add_publish_knob","title":"<code>add_publish_knob(node)</code>","text":"<p>[DEPRECATED] Add Publish knob to node</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>nuke node to be processed</p> required <p>Returns:</p> Name Type Description <code>node</code> <code>Node</code> <p>processed nuke node</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@deprecated\ndef add_publish_knob(node):\n    \"\"\"[DEPRECATED] Add Publish knob to node\n\n    Arguments:\n        node (nuke.Node): nuke node to be processed\n\n    Returns:\n        node (nuke.Node): processed nuke node\n\n    \"\"\"\n    if \"publish\" not in node.knobs():\n        body = OrderedDict()\n        body[(\"divd\", \"Publishing\")] = Knobby(\"Text_Knob\", '')\n        body[\"publish\"] = True\n        imprint(node, body)\n    return node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.add_write_node","title":"<code>add_write_node(name, file_path, knobs, **kwarg)</code>","text":"<p>Adding nuke write node</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>nuke node name</p> required <code>file_path</code> <code>str</code> <p>file path to write</p> required <code>knobs</code> <code>list[dict]</code> <p>nuke knobs to be set from settings</p> required <code>kwarg</code> <code>dict</code> <p>formatting attributes data for nuke knobs, must at least include <code>frame_range</code> key.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>node</code> <code>obj</code> <p>nuke write node</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def add_write_node(name, file_path, knobs, **kwarg):\n    \"\"\"Adding nuke write node\n\n    Arguments:\n        name (str): nuke node name\n        file_path (str): file path to write\n        knobs (list[dict]): nuke knobs to be set from settings\n        kwarg (dict): formatting attributes data for nuke knobs,\n            must at least include `frame_range` key.\n\n    Returns:\n        node (obj): nuke write node\n    \"\"\"\n    use_range_limit = kwarg.get(\"use_range_limit\", None)\n\n    w = nuke.createNode(\n        \"Write\",\n        \"name {}\".format(name),\n        inpanel=False\n    )\n\n    w[\"file\"].setValue(file_path)\n\n    # finally add knob overrides\n    set_node_knobs_from_settings(w, knobs, **kwarg)\n\n    if use_range_limit:\n        w[\"use_limit\"].setValue(True)\n        w[\"first\"].setValue(kwarg[\"frame_range\"][0])\n        w[\"last\"].setValue(kwarg[\"frame_range\"][1])\n\n    return w\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.check_inventory_versions","title":"<code>check_inventory_versions()</code>","text":"<p>Update loaded container nodes' colors based on version state.</p> <p>This will group containers by their version to outdated, not found, invalid or latest and colorize the nodes based on the category.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def check_inventory_versions():\n    \"\"\"Update loaded container nodes' colors based on version state.\n\n    This will group containers by their version to outdated, not found,\n    invalid or latest and colorize the nodes based on the category.\n    \"\"\"\n    try:\n        host = registered_host()\n        containers = host.get_containers()\n        project_name = get_current_project_name()\n\n        filtered_containers = filter_containers(containers, project_name)\n        for category, containers in filtered_containers._asdict().items():\n            if category not in LOADER_CATEGORY_COLORS:\n                continue\n            color = LOADER_CATEGORY_COLORS[category]\n            color = int(color, 16)  # convert hex to nuke tile color int\n            for container in containers:\n                container[\"node\"][\"tile_color\"].setValue(color)\n    except Exception as error:\n        log.warning(error)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.check_product_name_exists","title":"<code>check_product_name_exists(nodes, product_name)</code>","text":"<p>Checking if node is not already created to secure there is no duplicity</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list of nuke.Node objects</p> required <code>product_name</code> <code>str</code> <p>name we try to find</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True of False</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def check_product_name_exists(nodes, product_name):\n    \"\"\"\n    Checking if node is not already created to secure there is no duplicity\n\n    Arguments:\n        nodes (list): list of nuke.Node objects\n        product_name (str): name we try to find\n\n    Returns:\n        bool: True of False\n    \"\"\"\n    return next((True for n in nodes\n                 if product_name in read_avalon_data(n).get(\"productName\", \"\")),\n                False)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.create_backdrop","title":"<code>create_backdrop(label='', color=None, layer=0, nodes=None)</code>","text":"<p>Create Backdrop node</p> <p>Parameters:</p> Name Type Description Default <code>color</code> <code>str</code> <p>nuke compatible string with color code</p> <code>None</code> <code>layer</code> <code>int</code> <p>layer of node usually used (self.pos_layer - 1)</p> <code>0</code> <code>label</code> <code>str</code> <p>the message</p> <code>''</code> <code>nodes</code> <code>list</code> <p>list of nodes to be wrapped into backdrop</p> <code>None</code> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def create_backdrop(label=\"\", color=None, layer=0,\n                    nodes=None):\n    \"\"\"\n    Create Backdrop node\n\n    Arguments:\n        color (str): nuke compatible string with color code\n        layer (int): layer of node usually used (self.pos_layer - 1)\n        label (str): the message\n        nodes (list): list of nodes to be wrapped into backdrop\n\n    \"\"\"\n    assert isinstance(nodes, list), \"`nodes` should be a list of nodes\"\n\n    # Calculate bounds for the backdrop node.\n    bdX = min([node.xpos() for node in nodes])\n    bdY = min([node.ypos() for node in nodes])\n    bdW = max([node.xpos() + node.screenWidth() for node in nodes]) - bdX\n    bdH = max([node.ypos() + node.screenHeight() for node in nodes]) - bdY\n\n    # Expand the bounds to leave a little border. Elements are offsets\n    # for left, top, right and bottom edges respectively\n    left, top, right, bottom = (-20, -65, 20, 60)\n    bdX += left\n    bdY += top\n    bdW += (right - left)\n    bdH += (bottom - top)\n\n    bdn = nuke.createNode(\"BackdropNode\")\n    bdn[\"z_order\"].setValue(layer)\n\n    if color:\n        bdn[\"tile_color\"].setValue(int(color, 16))\n\n    bdn[\"xpos\"].setValue(bdX)\n    bdn[\"ypos\"].setValue(bdY)\n    bdn[\"bdwidth\"].setValue(bdW)\n    bdn[\"bdheight\"].setValue(bdH)\n\n    if label:\n        bdn[\"label\"].setValue(label)\n\n    bdn[\"note_font_size\"].setValue(20)\n    return bdn\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.create_camera_node_by_version","title":"<code>create_camera_node_by_version()</code>","text":"<p>Function to create the camera with the latest node class For Nuke version 14.0 or later, the Camera4 camera node class     would be used For the version before, the Camera2 camera node class     would be used Returns:     Node: camera node</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def create_camera_node_by_version():\n    \"\"\"Function to create the camera with the latest node class\n    For Nuke version 14.0 or later, the Camera4 camera node class\n        would be used\n    For the version before, the Camera2 camera node class\n        would be used\n    Returns:\n        Node: camera node\n    \"\"\"\n    nuke_number_version = nuke.NUKE_VERSION_MAJOR\n    if nuke_number_version &gt;= 14:\n        return nuke.createNode(\"Camera4\")\n    else:\n        return nuke.createNode(\"Camera2\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.create_knobs","title":"<code>create_knobs(data, tab=None)</code>","text":"<p>Create knobs by data</p> <p>Depending on the type of each dict value and creates the correct Knob.</p> Mapped types <p>bool: nuke.Boolean_Knob int: nuke.Int_Knob float: nuke.Double_Knob list: nuke.Enumeration_Knob str: nuke.String_Knob</p> <p>dict: If it's a nested dict (all values are dict), will turn into     A tabs group. Or just a knobs group.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>collection of attributes and their value</p> required <code>tab</code> <code>string</code> <p>Knobs' tab name</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list of <code>nuke.Knob</code> objects</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def create_knobs(data, tab=None):\n    \"\"\"Create knobs by data\n\n    Depending on the type of each dict value and creates the correct Knob.\n\n    Mapped types:\n        bool: nuke.Boolean_Knob\n        int: nuke.Int_Knob\n        float: nuke.Double_Knob\n        list: nuke.Enumeration_Knob\n        str: nuke.String_Knob\n\n        dict: If it's a nested dict (all values are dict), will turn into\n            A tabs group. Or just a knobs group.\n\n    Args:\n        data (dict): collection of attributes and their value\n        tab (string, optional): Knobs' tab name\n\n    Returns:\n        list: A list of `nuke.Knob` objects\n\n    \"\"\"\n    def nice_naming(key):\n        \"\"\"Convert camelCase name into UI Display Name\"\"\"\n        words = re.findall('[A-Z][^A-Z]*', key[0].upper() + key[1:])\n        return \" \".join(words)\n\n    # Turn key-value pairs into knobs\n    knobs = list()\n\n    if tab:\n        knobs.append(nuke.Tab_Knob(tab))\n\n    for key, value in data.items():\n        # Knob name\n        if isinstance(key, tuple):\n            name, nice = key\n        else:\n            name, nice = key, nice_naming(key)\n\n        # Create knob by value type\n        if isinstance(value, Knobby):\n            knobby = value\n            knob = knobby.create(name, nice)\n\n        elif isinstance(value, float):\n            knob = nuke.Double_Knob(name, nice)\n            knob.setValue(value)\n\n        elif isinstance(value, bool):\n            knob = nuke.Boolean_Knob(name, nice)\n            knob.setValue(value)\n            knob.setFlag(nuke.STARTLINE)\n\n        elif isinstance(value, int):\n            knob = nuke.Int_Knob(name, nice)\n            knob.setValue(value)\n\n        elif isinstance(value, str):\n            knob = nuke.String_Knob(name, nice)\n            knob.setValue(value)\n\n        elif isinstance(value, list):\n            knob = nuke.Enumeration_Knob(name, nice, value)\n\n        elif isinstance(value, dict):\n            if all(isinstance(v, dict) for v in value.values()):\n                # Create a group of tabs\n                begain = nuke.BeginTabGroup_Knob()\n                end = nuke.EndTabGroup_Knob()\n                begain.setName(name)\n                end.setName(name + \"_End\")\n                knobs.append(begain)\n                for k, v in value.items():\n                    knobs += create_knobs(v, tab=k)\n                knobs.append(end)\n            else:\n                # Create a group of knobs\n                knobs.append(nuke.Tab_Knob(\n                    name, nice, nuke.TABBEGINCLOSEDGROUP))\n                knobs += create_knobs(value)\n                knobs.append(\n                    nuke.Tab_Knob(name + \"_End\", nice, nuke.TABENDGROUP))\n            continue\n\n        else:\n            raise TypeError(\n                f\"Unsupported type for key: '{key}': {type(value)}\")\n\n        knobs.append(knob)\n\n    return knobs\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.create_viewer_profile_string","title":"<code>create_viewer_profile_string(viewer, display=None, path_like=False)</code>","text":"<p>Convert viewer and display to string</p> <p>Parameters:</p> Name Type Description Default <code>viewer</code> <code>str</code> <p>viewer name</p> required <code>display</code> <code>Optional[str]</code> <p>display name</p> <code>None</code> <code>path_like</code> <code>Optional[bool]</code> <p>if True, return path like string</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>viewer config string</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def create_viewer_profile_string(viewer, display=None, path_like=False):\n    \"\"\"Convert viewer and display to string\n\n    Args:\n        viewer (str): viewer name\n        display (Optional[str]): display name\n        path_like (Optional[bool]): if True, return path like string\n\n    Returns:\n        str: viewer config string\n    \"\"\"\n    if not display:\n        return viewer\n\n    if path_like:\n        return \"{}/{}\".format(display, viewer)\n    return \"{} ({})\".format(viewer, display)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.create_write_node","title":"<code>create_write_node(name, data, input=None, prenodes=None, linked_knobs=None, **kwargs)</code>","text":"<p>Creating write node which is group node</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>name of node</p> required <code>data</code> <code>dict</code> <p>creator write instance data</p> required <code>input (node)[optional]</code> <p>selected node to connect to</p> required <code>prenodes</code> <code>Optional[list[dict]]</code> <p>nodes to be created before write with dependency</p> <code>None</code> <code>review (bool)[optional]</code> <p>adding review knob</p> required <code>farm (bool)[optional]</code> <p>rendering workflow target</p> required <code>kwargs (dict)[optional]</code> <p>additional key arguments for formatting</p> required Example <p>prenodes = {     \"nodeName\": {         \"nodeclass\": \"Reformat\",         \"dependent\": [             following_node_01,             ...         ],         \"knobs\": [             {                 \"type\": \"text\",                 \"name\": \"knobname\",                 \"value\": \"knob value\"             },             ...         ]     },     ... }</p> Return <p>node (obj): group node with avalon data as Knobs</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def create_write_node(\n    name,\n    data,\n    input=None,\n    prenodes=None,\n    linked_knobs=None,\n    **kwargs\n):\n    ''' Creating write node which is group node\n\n    Arguments:\n        name (str): name of node\n        data (dict): creator write instance data\n        input (node)[optional]: selected node to connect to\n        prenodes (Optional[list[dict]]): nodes to be created before write\n            with dependency\n        review (bool)[optional]: adding review knob\n        farm (bool)[optional]: rendering workflow target\n        kwargs (dict)[optional]: additional key arguments for formatting\n\n    Example:\n        prenodes = {\n            \"nodeName\": {\n                \"nodeclass\": \"Reformat\",\n                \"dependent\": [\n                    following_node_01,\n                    ...\n                ],\n                \"knobs\": [\n                    {\n                        \"type\": \"text\",\n                        \"name\": \"knobname\",\n                        \"value\": \"knob value\"\n                    },\n                    ...\n                ]\n            },\n            ...\n        }\n\n\n    Return:\n        node (obj): group node with avalon data as Knobs\n    '''\n    # Ensure name does not contain any invalid characters.\n    special_chars = re.escape(\"!@#$%^&amp;*()=[]{}|\\\\;',.&lt;&gt;/?~+-\")\n    special_chars_regex = re.compile(f\"[{special_chars}]\")\n    found_special_characters = list(special_chars_regex.findall(name))\n\n    msg = (\n        f\"Special characters found in name \\\"{name}\\\": \"\n        f\"{' '.join(found_special_characters)}\"\n    )\n    assert not found_special_characters, msg\n\n    prenodes = prenodes or []\n\n    # filtering variables\n    plugin_name = data[\"creator\"]\n    product_name = data[\"productName\"]\n\n    # get knob settings for write node\n    imageio_writes = get_imageio_node_setting(\n        node_class=\"Write\",\n        plugin_name=plugin_name,\n        product_name=product_name\n    )\n\n    ext = None\n    knobs = imageio_writes[\"knobs\"]\n    knob_names = {knob[\"name\"]: knob for knob in knobs}\n\n    if \"ext\" in knob_names:\n        knob_type = knob_names[\"ext\"][\"type\"]\n        ext = knob_names[\"ext\"][knob_type]\n\n    # For most extensions, setting the \"file_type\"\n    # is enough, however sometimes they differ, e.g.:\n    # ext = sxr / file_type = exr\n    # ext = jpg / file_type = jpeg\n    elif \"file_type\" in knob_names:\n        knob_type = knob_names[\"file_type\"][\"type\"]\n        ext = knob_names[\"file_type\"][knob_type]\n\n    if not ext:\n        raise RuntimeError(\n            \"Could not determine extension from settings for \"\n            f\"plugin_name={plugin_name} product_name={product_name}\"\n        )\n\n    data.update({\n        \"imageio_writes\": imageio_writes,\n        \"ext\": ext\n    })\n\n    # build file path to workfiles\n    data[\"work\"] = get_work_default_directory(data)\n    fpath = StringTemplate(data[\"fpath_template\"]).format_strict(data)\n\n    # Override output directory is provided staging directory.\n    if data.get(\"staging_dir\"):\n        basename = os.path.basename(fpath)\n        staging_path = pathlib.Path(data[\"staging_dir\"]) / basename\n        fpath = staging_path.as_posix()\n\n    # create directory\n    if not os.path.isdir(os.path.dirname(fpath)):\n        log.warning(\"Path does not exist! I am creating it.\")\n        os.makedirs(os.path.dirname(fpath))\n\n    GN = nuke.createNode(\"Group\", \"name {}\".format(name))\n\n    prev_node = None\n    with GN:\n        if input:\n            input_name = str(input.name()).replace(\" \", \"\")\n            # if connected input node was defined\n            prev_node = nuke.createNode(\n                \"Input\",\n                \"name {}\".format(input_name),\n                inpanel=False\n            )\n        else:\n            # generic input node connected to nothing\n            prev_node = nuke.createNode(\n                \"Input\",\n                \"name {}\".format(\"rgba\"),\n                inpanel=False\n            )\n\n        # creating pre-write nodes `prenodes`\n        last_prenode = create_prenodes(\n            prev_node,\n            prenodes,\n            plugin_name,\n            product_name,\n            **kwargs\n        )\n        if last_prenode:\n            prev_node = last_prenode\n\n        # creating write node\n        write_node = now_node = add_write_node(\n            \"inside_{}\".format(name),\n            fpath,\n            imageio_writes[\"knobs\"],\n            **data\n        )\n        # connect to previous node\n        now_node.setInput(0, prev_node)\n\n        # switch actual node to previous\n        prev_node = now_node\n\n        now_node = nuke.createNode(\"Output\", \"name Output1\", inpanel=False)\n\n        # connect to previous node\n        now_node.setInput(0, prev_node)\n\n    # add divider\n    GN.addKnob(nuke.Text_Knob('', 'Rendering'))\n\n    # Add linked knobs.\n    linked_knob_names = []\n\n    # add input linked knobs and create group only if any input\n    if linked_knobs:\n        linked_knob_names.append(\"_grp-start_\")\n        linked_knob_names.extend(linked_knobs)\n        linked_knob_names.append(\"_grp-end_\")\n\n    linked_knob_names.append(\"Render\")\n\n    for _k_name in linked_knob_names:\n        if \"_grp-start_\" in _k_name:\n            knob = nuke.Tab_Knob(\n                \"rnd_attr\", \"Rendering attributes\", nuke.TABBEGINCLOSEDGROUP)\n            GN.addKnob(knob)\n        elif \"_grp-end_\" in _k_name:\n            knob = nuke.Tab_Knob(\n                \"rnd_attr_end\", \"Rendering attributes\", nuke.TABENDGROUP)\n            GN.addKnob(knob)\n        else:\n            if \"___\" in _k_name:\n                # add divider\n                GN.addKnob(nuke.Text_Knob(\"\"))\n            else:\n                # add linked knob by _k_name\n                link = nuke.Link_Knob(\"\")\n                link.makeLink(write_node.name(), _k_name)\n                link.setName(_k_name)\n\n                # make render\n                if \"Render\" in _k_name:\n                    link.setLabel(\"Render Local\")\n                link.setFlag(0x1000)\n                GN.addKnob(link)\n\n    # Adding render farm submission button.\n    if data.get(\"render_on_farm\", False):\n        add_button_render_on_farm(GN)\n\n    # adding write to read button\n    add_button_write_to_read(GN)\n\n    # adding write to read button\n    add_button_clear_rendered(GN, os.path.dirname(fpath))\n\n    # set tile color\n    tile_color = next(\n        iter(\n            k[k[\"type\"]] for k in imageio_writes[\"knobs\"]\n            if \"tile_color\" in k[\"name\"]\n        ), [255, 0, 0, 255]\n    )\n    new_tile_color = []\n    for c in tile_color:\n        if isinstance(c, float):\n            c = int(c * 255)\n        new_tile_color.append(c)\n    GN[\"tile_color\"].setValue(\n        color_gui_to_int(new_tile_color))\n\n    return GN\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.deprecated","title":"<code>deprecated(new_destination)</code>","text":"<p>Mark functions as deprecated.</p> <p>It will result in a warning being emitted when the function is used.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def deprecated(new_destination):\n    \"\"\"Mark functions as deprecated.\n\n    It will result in a warning being emitted when the function is used.\n    \"\"\"\n\n    func = None\n    if callable(new_destination):\n        func = new_destination\n        new_destination = None\n\n    def _decorator(decorated_func):\n        if new_destination is None:\n            warning_message = (\n                \" Please check content of deprecated function to figure out\"\n                \" possible replacement.\"\n            )\n        else:\n            warning_message = \" Please replace your usage with '{}'.\".format(\n                new_destination\n            )\n\n        @functools.wraps(decorated_func)\n        def wrapper(*args, **kwargs):\n            warnings.simplefilter(\"always\", DeprecatedWarning)\n            warnings.warn(\n                (\n                    \"Call to deprecated function '{}'\"\n                    \"\\nFunction was moved or removed.{}\"\n                ).format(decorated_func.__name__, warning_message),\n                category=DeprecatedWarning,\n                stacklevel=4\n            )\n            return decorated_func(*args, **kwargs)\n        return wrapper\n\n    if func is None:\n        return _decorator\n    return _decorator(func)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.dirmap_file_name_filter","title":"<code>dirmap_file_name_filter(file_name)</code>","text":"<p>Nuke callback function with single full path argument.</p> <p>Checks project settings for potential mapping from source to dest.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def dirmap_file_name_filter(file_name):\n    \"\"\"Nuke callback function with single full path argument.\n\n        Checks project settings for potential mapping from source to dest.\n    \"\"\"\n\n    dirmap_processor = NukeDirmap(\n        file_name,\n        \"nuke\",\n        DirmapCache.project_name(),\n        DirmapCache.project_settings(),\n        DirmapCache.sitesync_addon(),\n    )\n    if not DirmapCache.mapping():\n        DirmapCache.set_mapping(dirmap_processor.get_mappings())\n\n    dirmap_processor.process_dirmap(DirmapCache.mapping())\n    if os.path.exists(dirmap_processor.file_name):\n        return dirmap_processor.file_name\n    return file_name\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.find_free_space_to_paste_nodes","title":"<code>find_free_space_to_paste_nodes(nodes, group=nuke.root(), direction='right', offset=300)</code>","text":"<p>For getting coordinates in DAG (node graph) for placing new nodes</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list of nuke.Node objects</p> required <code>group (nuke.Node) [optional]</code> <p>object in which context it is</p> required <code>direction (str) [optional]</code> <p>where we want it to be placed                         [left, right, top, bottom]</p> required <code>offset (int) [optional]</code> <p>what offset it is from rest of nodes</p> required <p>Returns:</p> Name Type Description <code>xpos</code> <code>int</code> <p>x coordinace in DAG</p> <code>ypos</code> <code>int</code> <p>y coordinace in DAG</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def find_free_space_to_paste_nodes(\n    nodes,\n    group=nuke.root(),\n    direction=\"right\",\n    offset=300\n):\n    \"\"\"\n    For getting coordinates in DAG (node graph) for placing new nodes\n\n    Arguments:\n        nodes (list): list of nuke.Node objects\n        group (nuke.Node) [optional]: object in which context it is\n        direction (str) [optional]: where we want it to be placed\n                                    [left, right, top, bottom]\n        offset (int) [optional]: what offset it is from rest of nodes\n\n    Returns:\n        xpos (int): x coordinace in DAG\n        ypos (int): y coordinace in DAG\n    \"\"\"\n    if len(nodes) == 0:\n        return 0, 0\n\n    group_xpos = list()\n    group_ypos = list()\n\n    # get local coordinates of all nodes\n    nodes_xpos = [n.xpos() for n in nodes] + \\\n                 [n.xpos() + n.screenWidth() for n in nodes]\n\n    nodes_ypos = [n.ypos() for n in nodes] + \\\n                 [n.ypos() + n.screenHeight() for n in nodes]\n\n    # get complete screen size of all nodes to be placed in\n    nodes_screen_width = max(nodes_xpos) - min(nodes_xpos)\n    nodes_screen_heigth = max(nodes_ypos) - min(nodes_ypos)\n\n    # get screen size (r,l,t,b) of all nodes in `group`\n    with group:\n        group_xpos = [n.xpos() for n in nuke.allNodes() if n not in nodes] + \\\n                     [n.xpos() + n.screenWidth() for n in nuke.allNodes()\n                      if n not in nodes]\n        group_ypos = [n.ypos() for n in nuke.allNodes() if n not in nodes] + \\\n                     [n.ypos() + n.screenHeight() for n in nuke.allNodes()\n                      if n not in nodes]\n\n        if len(group_xpos) == 0:\n            group_xpos = [0]\n        if len(group_ypos) == 0:\n            group_ypos = [0]\n\n        # calc output left\n        if direction in \"left\":\n            xpos = min(group_xpos) - abs(nodes_screen_width) - abs(offset)\n            ypos = min(group_ypos)\n            return xpos, ypos\n        # calc output right\n        if direction in \"right\":\n            xpos = max(group_xpos) + abs(offset)\n            ypos = min(group_ypos)\n            return xpos, ypos\n        # calc output top\n        if direction in \"top\":\n            xpos = min(group_xpos)\n            ypos = min(group_ypos) - abs(nodes_screen_heigth) - abs(offset)\n            return xpos, ypos\n        # calc output bottom\n        if direction in \"bottom\":\n            xpos = min(group_xpos)\n            ypos = max(group_ypos) + abs(offset)\n            return xpos, ypos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_avalon_knob_data","title":"<code>get_avalon_knob_data(node, prefix='avalon:', create=True)</code>","text":"<p>[DEPRECATED]  Gets a data from nodes's avalon knob</p> <p>This function is still used but soon will be deprecated. Use <code>get_node_data</code> instead.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>obj</code> <p>Nuke node to search for data,</p> required <code>prefix</code> <code>str | list[str]</code> <p>filtering prefix</p> <code>'avalon:'</code> <p>Returns:</p> Type Description <p>data (dict)</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@deprecated(\"ayon_nuke.api.lib.get_node_data\")\ndef get_avalon_knob_data(node, prefix=\"avalon:\", create=True):\n    \"\"\"[DEPRECATED]  Gets a data from nodes's avalon knob\n\n    This function is still used but soon will be deprecated.\n    Use `get_node_data` instead.\n\n    Arguments:\n        node (obj): Nuke node to search for data,\n        prefix (str | list[str]): filtering prefix\n\n    Returns:\n        data (dict)\n    \"\"\"\n\n    data = {}\n    if NODE_TAB_NAME not in node.knobs():\n        return data\n\n    # check if lists\n    if not isinstance(prefix, list):\n        prefix = [prefix]\n\n    # loop prefix\n    for p in prefix:\n        # check if the node is avalon tracked\n        try:\n            # check if data available on the node\n            _ = node[DATA_GROUP_KEY].value()\n        except NameError:\n            # if it doesn't then create it\n            if create:\n                node = set_avalon_knob_data(node)\n                return get_avalon_knob_data(node)\n            return {}\n\n        # get data from filtered knobs\n        data.update({k.replace(p, ''): node[k].value()\n                    for k in node.knobs().keys()\n                    if p in k})\n\n    return data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_current_context_template_data_and_environ","title":"<code>get_current_context_template_data_and_environ()</code>","text":"<p>Return current context template data and os environ.</p> Output contains <ul> <li>Regular template data from <code>get_template_data</code></li> <li>Anatomy Roots</li> <li>os.environ keys</li> </ul> <p>Returns:</p> Type Description <p>dict[str, Any]: Template data to fill templates.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_current_context_template_data_and_environ():\n    \"\"\"Return current context template data and os environ.\n\n    Output contains:\n      - Regular template data from `get_template_data`\n      - Anatomy Roots\n      - os.environ keys\n\n    Returns:\n         dict[str, Any]: Template data to fill templates.\n\n    \"\"\"\n    context = get_current_context()\n    project_name = context[\"project_name\"]\n    folder_path = context[\"folder_path\"]\n    task_name = context[\"task_name\"]\n    host_name = get_current_host_name()\n\n    project_entity = ayon_api.get_project(project_name)\n    anatomy = Anatomy(project_name, project_entity=project_entity)\n    folder_entity = ayon_api.get_folder_by_path(project_name, folder_path)\n    task_entity = ayon_api.get_task_by_name(\n        project_name, folder_entity[\"id\"], task_name\n    )\n\n    template_data = get_template_data(\n        project_entity, folder_entity, task_entity, host_name\n    )\n    template_data[\"root\"] = anatomy.roots\n\n    template_data.update(os.environ)\n\n    return template_data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_dependent_nodes","title":"<code>get_dependent_nodes(nodes)</code>","text":"<p>Get all dependent nodes connected to the list of nodes.</p> <p>Looking for connections outside of the nodes in incoming argument.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list</code> <p>list of nuke.Node objects</p> required <p>Returns:</p> Name Type Description <code>connections_in</code> <p>dictionary of nodes and its dependencies</p> <code>connections_out</code> <p>dictionary of nodes and its dependency</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_dependent_nodes(nodes):\n    \"\"\"Get all dependent nodes connected to the list of nodes.\n\n    Looking for connections outside of the nodes in incoming argument.\n\n    Arguments:\n        nodes (list): list of nuke.Node objects\n\n    Returns:\n        connections_in: dictionary of nodes and its dependencies\n        connections_out: dictionary of nodes and its dependency\n    \"\"\"\n\n    connections_in = dict()\n    connections_out = dict()\n    node_names = [n.name() for n in nodes]\n    for node in nodes:\n        inputs = node.dependencies()\n        outputs = node.dependent()\n        # collect all inputs outside\n        test_in = [(i, n) for i, n in enumerate(inputs)\n                   if n.name() not in node_names]\n        if test_in:\n            connections_in.update({\n                node: test_in\n            })\n        # collect all outputs outside\n        test_out = [i for i in outputs if i.name() not in node_names]\n        if test_out:\n            # only one dependent node is allowed\n            connections_out.update({\n                node: test_out[-1]\n            })\n\n    return connections_in, connections_out\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_extreme_positions","title":"<code>get_extreme_positions(nodes)</code>","text":"<p>Get the 4 numbers that represent the box of a group of nodes.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_extreme_positions(nodes):\n    \"\"\"Get the 4 numbers that represent the box of a group of nodes.\"\"\"\n\n    if not nodes:\n        raise ValueError(\"there is no nodes in the list\")\n\n    nodes_xpos = [n.xpos() for n in nodes] + \\\n        [n.xpos() + n.screenWidth() for n in nodes]\n\n    nodes_ypos = [n.ypos() for n in nodes] + \\\n        [n.ypos() + n.screenHeight() for n in nodes]\n\n    min_x, min_y = (min(nodes_xpos), min(nodes_ypos))\n    max_x, max_y = (max(nodes_xpos), max(nodes_ypos))\n    return min_x, min_y, max_x, max_y\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_filenames_without_hash","title":"<code>get_filenames_without_hash(filename, frame_start, frame_end)</code>","text":"<p>Get filenames without frame hash     i.e. \"renderCompositingMain.baking.0001.exr\"</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>filename with frame hash</p> required <code>frame_start</code> <code>str</code> <p>start of the frame</p> required <code>frame_end</code> <code>str</code> <p>end of the frame</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>filename per frame of the sequence</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_filenames_without_hash(filename, frame_start, frame_end):\n    \"\"\"Get filenames without frame hash\n        i.e. \"renderCompositingMain.baking.0001.exr\"\n\n    Args:\n        filename (str): filename with frame hash\n        frame_start (str): start of the frame\n        frame_end (str): end of the frame\n\n    Returns:\n        list: filename per frame of the sequence\n    \"\"\"\n    filenames = []\n    for frame in range(int(frame_start), (int(frame_end) + 1)):\n        if \"#\" in filename:\n            # use regex to convert #### to {:0&gt;4}\n            def replace(match):\n                return \"{{:0&gt;{}}}\".format(len(match.group()))\n            filename_without_hashes = re.sub(\"#+\", replace, filename)\n            new_filename = filename_without_hashes.format(frame)\n            filenames.append(new_filename)\n    return filenames\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_group_io_nodes","title":"<code>get_group_io_nodes(nodes)</code>","text":"<p>Get the input and the output of a group of nodes.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_group_io_nodes(nodes):\n    \"\"\"Get the input and the output of a group of nodes.\"\"\"\n\n    if not nodes:\n        raise ValueError(\"there is no nodes in the list\")\n\n    input_node = None\n    output_node = None\n\n    if len(nodes) == 1:\n        input_node = output_node = nodes[0]\n\n    else:\n        for node in nodes:\n            if \"Input\" in node.name():\n                input_node = node\n\n            if \"Output\" in node.name():\n                output_node = node\n\n            if input_node is not None and output_node is not None:\n                break\n\n        if input_node is None:\n            log.warning(\"No Input found\")\n\n        if output_node is None:\n            log.warning(\"No Output found\")\n\n    return input_node, output_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_imageio_input_colorspace","title":"<code>get_imageio_input_colorspace(filename)</code>","text":"<p>Get input file colorspace based on regex in settings.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_imageio_input_colorspace(filename):\n    ''' Get input file colorspace based on regex in settings.\n    '''\n    imageio_regex_inputs = (\n        get_nuke_imageio_settings()[\"regex_inputs\"][\"inputs\"])\n\n    preset_clrsp = None\n    for regexInput in imageio_regex_inputs:\n        if bool(re.search(regexInput[\"regex\"], filename)):\n            preset_clrsp = str(regexInput[\"colorspace\"])\n\n    return preset_clrsp\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_imageio_node_override_setting","title":"<code>get_imageio_node_override_setting(node_class, plugin_name, product_name, knobs_settings)</code>","text":"<p>Get imageio node overrides from settings</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_imageio_node_override_setting(\n    node_class, plugin_name, product_name, knobs_settings\n):\n    ''' Get imageio node overrides from settings\n    '''\n    # find matching override node\n    override_imageio_node = get_matching_override_node(\n        node_class, plugin_name, product_name\n    )\n\n    # add overrides to imageio_node\n    if override_imageio_node:\n        # get all knob names in imageio_node\n        knob_names = [k[\"name\"] for k in knobs_settings]\n\n        for oknob in override_imageio_node[\"knobs\"]:\n            oknob_name = oknob[\"name\"]\n            oknob_type = oknob[\"type\"]\n            oknob_value = oknob[oknob_type]\n            for knob in knobs_settings:\n                # add missing knobs into imageio_node\n                if oknob_name not in knob_names:\n                    knobs_settings.append(oknob)\n                    knob_names.append(oknob_name)\n                    continue\n\n                if oknob_name != knob[\"name\"]:\n                    continue\n\n                knob_type = knob[\"type\"]\n                # override matching knob name\n                if not oknob_value:\n                    # remove original knob if no value found in oknob\n                    knobs_settings.remove(knob)\n                else:\n                    # override knob value with oknob's\n                    knob[knob_type] = oknob_value\n\n    return knobs_settings\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_imageio_node_setting","title":"<code>get_imageio_node_setting(node_class, plugin_name, product_name)</code>","text":"<p>Get preset data for dataflow (fileType, compression, bitDepth)</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_imageio_node_setting(node_class, plugin_name, product_name):\n    ''' Get preset data for dataflow (fileType, compression, bitDepth)\n    '''\n    imageio_nodes = get_nuke_imageio_settings()[\"nodes\"]\n    required_nodes = imageio_nodes[\"required_nodes\"]\n\n    imageio_node = None\n    for node in required_nodes:\n        node_class_preset = node[\"nuke_node_class\"]\n        if node.get(\"custom_class\"):\n            node_class_preset = node[\"custom_class\"]\n        if (\n            node_class in node_class_preset\n            and plugin_name in node[\"plugins\"]\n        ):\n            imageio_node = node\n            break\n\n    if not imageio_node:\n        return\n\n    # Check if a node override exists for this configuration\n    override_imageio_node = get_matching_override_node(\n        node_class, plugin_name, product_name\n    )\n\n    # If node override exists,\n    # use only override knobs\n    # (don't merge with original master knobs)\n    if override_imageio_node:\n        imageio_node[\"knobs\"] = override_imageio_node.get(\"knobs\", [])\n    else:\n        # Otherwise apply partial overrides to original master knobs\n        imageio_node[\"knobs\"] = get_imageio_node_override_setting(\n            node_class,\n            plugin_name,\n            product_name,\n            imageio_node[\"knobs\"]\n        )\n    return imageio_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_main_window","title":"<code>get_main_window()</code>","text":"<p>Acquire Nuke's main window</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_main_window():\n    \"\"\"Acquire Nuke's main window\"\"\"\n    if Context.main_window is None:\n\n        top_widgets = QtWidgets.QApplication.topLevelWidgets()\n        name = \"Foundry::UI::DockMainWindow\"\n        for widget in top_widgets:\n            if (\n                widget.inherits(\"QMainWindow\")\n                and widget.metaObject().className() == name\n            ):\n                Context.main_window = widget\n                break\n    return Context.main_window\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_matching_override_node","title":"<code>get_matching_override_node(node_class, plugin_name, product_name)</code>","text":"<p>Find matching override node for the given configuration.</p> <p>Parameters:</p> Name Type Description Default <code>node_class</code> <code>str</code> <p>Nuke node class name</p> required <code>plugin_name</code> <code>str</code> <p>Plugin name</p> required <code>product_name</code> <code>str</code> <p>Product name</p> required <p>Returns:</p> Type Description <p>dict or None: Matching override node or None if not found</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_matching_override_node(node_class, plugin_name, product_name):\n    \"\"\"Find matching override node for the given configuration.\n\n    Args:\n        node_class (str): Nuke node class name\n        plugin_name (str): Plugin name\n        product_name (str): Product name\n\n    Returns:\n        dict or None: Matching override node or None if not found\n    \"\"\"\n    imageio_nodes = get_nuke_imageio_settings()[\"nodes\"]\n    override_nodes = imageio_nodes[\"override_nodes\"]\n\n    for override_node in override_nodes:\n        node_class_preset = override_node[\"nuke_node_class\"]\n\n        if override_node.get(\"custom_class\"):\n            node_class_preset = override_node[\"custom_class\"]\n\n        if node_class not in node_class_preset:\n            continue\n\n        if plugin_name not in override_node[\"plugins\"]:\n            continue\n\n        product_names = override_node[\"product_names\"]\n\n        if (\n            product_names\n            and not any(\n                re.search(s.lower(), product_name.lower())\n                for s in product_names\n            )\n        ):\n            continue\n\n        return override_node\n\n    return None\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_names_from_nodes","title":"<code>get_names_from_nodes(nodes)</code>","text":"<p>Get list of nodes names.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>List[Node]</code> <p>List of nodes to convert into names.</p> required <p>Returns:</p> Type Description <p>List[str]: Name of passed nodes.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_names_from_nodes(nodes):\n    \"\"\"Get list of nodes names.\n\n    Args:\n        nodes(List[nuke.Node]): List of nodes to convert into names.\n\n    Returns:\n        List[str]: Name of passed nodes.\n    \"\"\"\n\n    return [\n        node.name()\n        for node in nodes\n    ]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_node_data","title":"<code>get_node_data(node, knobname)</code>","text":"<p>Read data from node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object</p> required <code>knobname</code> <code>str</code> <p>knob name</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>data stored in knob</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_node_data(node, knobname):\n    \"\"\"Read data from node.\n\n    Args:\n        node (nuke.Node): node object\n        knobname (str): knob name\n\n    Returns:\n        dict: data stored in knob\n    \"\"\"\n    if knobname not in node.knobs():\n        return\n\n    rawdata = node[knobname].getValue()\n    if (\n        isinstance(rawdata, str)\n        and rawdata.startswith(JSON_PREFIX)\n    ):\n        try:\n            return json.loads(rawdata[len(JSON_PREFIX):])\n        except json.JSONDecodeError:\n            return\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_node_path","title":"<code>get_node_path(path, padding=4)</code>","text":"<p>Get filename for the Nuke write with padded number as '#'</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>The path to render to.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>head, padding, tail (extension)</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_frame_path(\"test.exr\")\n('test', 4, '.exr')\n</code></pre> <pre><code>&gt;&gt;&gt; get_frame_path(\"filename.#####.tif\")\n('filename.', 5, '.tif')\n</code></pre> <pre><code>&gt;&gt;&gt; get_frame_path(\"foobar##.tif\")\n('foobar', 2, '.tif')\n</code></pre> <pre><code>&gt;&gt;&gt; get_frame_path(\"foobar_%08d.tif\")\n('foobar_', 8, '.tif')\n</code></pre> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_node_path(path, padding=4):\n    \"\"\"Get filename for the Nuke write with padded number as '#'\n\n    Arguments:\n        path (str): The path to render to.\n\n    Returns:\n        tuple: head, padding, tail (extension)\n\n    Examples:\n        &gt;&gt;&gt; get_frame_path(\"test.exr\")\n        ('test', 4, '.exr')\n\n        &gt;&gt;&gt; get_frame_path(\"filename.#####.tif\")\n        ('filename.', 5, '.tif')\n\n        &gt;&gt;&gt; get_frame_path(\"foobar##.tif\")\n        ('foobar', 2, '.tif')\n\n        &gt;&gt;&gt; get_frame_path(\"foobar_%08d.tif\")\n        ('foobar_', 8, '.tif')\n    \"\"\"\n    filename, ext = os.path.splitext(path)\n\n    # Find a final number group\n    if '%' in filename:\n        match = re.match('.*?(%[0-9]+d)$', filename)\n        if match:\n            padding = int(match.group(1).replace('%', '').replace('d', ''))\n            # remove number from end since fusion\n            # will swap it with the frame number\n            filename = filename.replace(match.group(1), '')\n    elif '#' in filename:\n        match = re.match('.*?(#+)$', filename)\n\n        if match:\n            padding = len(match.group(1))\n            # remove number from end since fusion\n            # will swap it with the frame number\n            filename = filename.replace(match.group(1), '')\n\n    return filename, padding, ext\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_nodes_by_names","title":"<code>get_nodes_by_names(names)</code>","text":"<p>Get list of nuke nodes based on their names.</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>List[str]</code> <p>List of node names to be found.</p> required <p>Returns:</p> Type Description <p>List[nuke.Node]: List of nodes found by name.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_nodes_by_names(names):\n    \"\"\"Get list of nuke nodes based on their names.\n\n    Args:\n        names (List[str]): List of node names to be found.\n\n    Returns:\n        List[nuke.Node]: List of nodes found by name.\n    \"\"\"\n\n    return [\n        nuke.toNode(name)\n        for name in names\n    ]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_version_from_path","title":"<code>get_version_from_path(file)</code>","text":"<p>Find version number in file path string.</p> <p>Looks for formats: - <code>_v0001</code> - <code>.v001</code> - <code>/v001/</code> - difference from ayon-core.path_tools.get_version_from_path</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>file path</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>version number in string ('001')</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_version_from_path(file):\n    \"\"\"Find version number in file path string.\n\n    Looks for formats:\n    - `_v0001`\n    - `.v001`\n    - `/v001/` - difference from ayon-core.path_tools.get_version_from_path\n\n    Args:\n        file (str): file path\n\n    Returns:\n        str: version number in string ('001')\n    \"\"\"\n\n    pattern = re.compile(r\"[\\._/]v([0-9]+)\", re.IGNORECASE)\n    try:\n        return pattern.findall(file)[-1]\n    except IndexError:\n        log.error(\n            \"templates:get_version_from_workfile:\"\n            \"`{}` missing version string.\"\n            \"Example `v004`\".format(file)\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_viewer_config_from_string","title":"<code>get_viewer_config_from_string(input_string)</code>","text":"<p>Convert string to display and viewer string</p> <p>Parameters:</p> Name Type Description Default <code>input_string</code> <code>str</code> <p>string with viewer</p> required <p>Raises:</p> Type Description <code>IndexError</code> <p>if more then one slash in input string</p> <code>IndexError</code> <p>if missing closing bracket</p> <p>Returns:</p> Type Description <p>tuple[str]: display, viewer</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_viewer_config_from_string(input_string):\n    \"\"\"Convert string to display and viewer string\n\n    Args:\n        input_string (str): string with viewer\n\n    Raises:\n        IndexError: if more then one slash in input string\n        IndexError: if missing closing bracket\n\n    Returns:\n        tuple[str]: display, viewer\n    \"\"\"\n    display = None\n    viewer = input_string\n    # check if () or / or \\ in name\n    if \"/\" in viewer:\n        split = viewer.split(\"/\")\n\n        # rise if more then one column\n        if len(split) &gt; 2:\n            raise IndexError((\n                \"Viewer Input string is not correct. \"\n                \"more then two `/` slashes! {}\"\n            ).format(input_string))\n\n        viewer = split[1]\n        display = split[0]\n    elif \"(\" in viewer:\n        pattern = r\"([\\w\\d\\s\\.\\-]+).*[(](.*)[)]\"\n        result_ = re.findall(pattern, viewer)\n        try:\n            result_ = result_.pop()\n            display = str(result_[1]).rstrip()\n            viewer = str(result_[0]).rstrip()\n        except IndexError:\n            raise IndexError((\n                \"Viewer Input string is not correct. \"\n                \"Missing bracket! {}\"\n            ).format(input_string))\n\n    return (display, viewer)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_work_default_directory","title":"<code>get_work_default_directory(data)</code>","text":"<p>Helping function for formatting of anatomy paths</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict</code> <p>dictionary with attributes used for formatting</p> required Return <p>path (str)</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_work_default_directory(data):\n    ''' Helping function for formatting of anatomy paths\n\n    Arguments:\n        data (dict): dictionary with attributes used for formatting\n\n    Return:\n        path (str)\n    '''\n\n    project_name = get_current_project_name()\n    anatomy = Anatomy(project_name)\n\n    frame_padding = anatomy.templates_obj.frame_padding\n\n    version = data.get(\"version\")\n    if version is None:\n        file = script_name()\n        data[\"version\"] = get_version_from_path(file)\n\n    folder_path = data[\"folderPath\"]\n    task_name = data[\"task\"]\n    host_name = get_current_host_name()\n\n    context_data = get_template_data_with_names(\n        project_name, folder_path, task_name, host_name\n    )\n    data.update(context_data)\n    product_type = data[\"productType\"]\n    product_base_type = data.get(\"productBaseType\")\n    if not product_base_type:\n        product_base_type = product_type\n\n    data.update({\n        \"subset\": data[\"productName\"],\n        \"family\": product_base_type,\n        \"product\": {\n            \"name\": data[\"productName\"],\n            \"type\": product_type,\n            \"basetype\": product_base_type,\n        },\n        \"frame\": \"#\" * frame_padding,\n    })\n\n    work_default_dir_template = anatomy.get_template_item(\"work\", \"default\", \"directory\")\n    normalized_dir = work_default_dir_template.format_strict(data).normalized()\n    return str(normalized_dir).replace(\"\\\\\", \"/\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.get_write_node_template_attr","title":"<code>get_write_node_template_attr(node)</code>","text":"<p>Gets all defined data from presets</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def get_write_node_template_attr(node):\n    ''' Gets all defined data from presets\n\n    '''\n\n    # TODO: add identifiers to settings and rename settings key\n    plugin_names_mapping = {\n        \"create_write_image\": \"CreateWriteImage\",\n        \"create_write_prerender\": \"CreateWritePrerender\",\n        \"create_write_render\": \"CreateWriteRender\"\n    }\n    # get AYON data from node\n    node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n    identifier = node_data[\"creator_identifier\"]\n\n    # return template data\n    product_name = node_data.get(\"productName\")\n    if product_name is None:\n        product_name = node_data[\"subset\"]\n    return get_imageio_node_setting(\n        node_class=\"Write\",\n        plugin_name=plugin_names_mapping[identifier],\n        product_name=product_name\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.imprint","title":"<code>imprint(node, data, tab=None)</code>","text":"<p>Store attributes with value on node</p> <p>Parse user data into Node knobs. Use <code>collections.OrderedDict</code> to ensure knob order.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object from Nuke</p> required <code>data</code> <code>dict</code> <p>collection of attributes and their value</p> required <p>Returns:</p> Type Description <p>None</p> <p>Examples:</p> <pre><code>import nuke\nfrom ayon_nuke.api import lib\n\nnode = nuke.createNode(\"NoOp\")\ndata = {\n    # Regular type of attributes\n    \"myList\": [\"x\", \"y\", \"z\"],\n    \"myBool\": True,\n    \"myFloat\": 0.1,\n    \"myInt\": 5,\n\n    # Creating non-default imprint type of knob\n    \"MyFilePath\": lib.Knobby(\"File_Knob\", \"/file/path\"),\n    \"divider\": lib.Knobby(\"Text_Knob\", \"\"),\n\n    # Manual nice knob naming\n    (\"my_knob\", \"Nice Knob Name\"): \"some text\",\n\n    # dict type will be created as knob group\n    \"KnobGroup\": {\n        \"knob1\": 5,\n        \"knob2\": \"hello\",\n        \"knob3\": [\"a\", \"b\"],\n    },\n\n    # Nested dict will be created as tab group\n    \"TabGroup\": {\n        \"tab1\": {\"count\": 5},\n        \"tab2\": {\"isGood\": True},\n        \"tab3\": {\"direction\": [\"Left\", \"Right\"]},\n    },\n}\nlib.imprint(node, data, tab=\"Demo\")\n\n</code></pre> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def imprint(node, data, tab=None):\n    \"\"\"Store attributes with value on node\n\n    Parse user data into Node knobs.\n    Use `collections.OrderedDict` to ensure knob order.\n\n    Args:\n        node(nuke.Node): node object from Nuke\n        data(dict): collection of attributes and their value\n\n    Returns:\n        None\n\n    Examples:\n        ```\n        import nuke\n        from ayon_nuke.api import lib\n\n        node = nuke.createNode(\"NoOp\")\n        data = {\n            # Regular type of attributes\n            \"myList\": [\"x\", \"y\", \"z\"],\n            \"myBool\": True,\n            \"myFloat\": 0.1,\n            \"myInt\": 5,\n\n            # Creating non-default imprint type of knob\n            \"MyFilePath\": lib.Knobby(\"File_Knob\", \"/file/path\"),\n            \"divider\": lib.Knobby(\"Text_Knob\", \"\"),\n\n            # Manual nice knob naming\n            (\"my_knob\", \"Nice Knob Name\"): \"some text\",\n\n            # dict type will be created as knob group\n            \"KnobGroup\": {\n                \"knob1\": 5,\n                \"knob2\": \"hello\",\n                \"knob3\": [\"a\", \"b\"],\n            },\n\n            # Nested dict will be created as tab group\n            \"TabGroup\": {\n                \"tab1\": {\"count\": 5},\n                \"tab2\": {\"isGood\": True},\n                \"tab3\": {\"direction\": [\"Left\", \"Right\"]},\n            },\n        }\n        lib.imprint(node, data, tab=\"Demo\")\n\n        ```\n\n    \"\"\"\n    for knob in create_knobs(data, tab):\n        # If knob name exists we set the value. Technically there could be\n        # multiple knobs with the same name, but the intent is not to have\n        # duplicated knobs so we do not account for that.\n        if knob.name() in node.knobs().keys():\n            node[knob.name()].setValue(knob.value())\n        else:\n            node.addKnob(knob)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.launch_workfiles_app","title":"<code>launch_workfiles_app()</code>","text":"<p>Show workfiles tool on nuke launch.</p> <p>Trigger to show workfiles tool on application launch. Can be executed only once all other calls are ignored.</p> <p>Workfiles tool show is deferred after application initialization using QTimer.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def launch_workfiles_app():\n    \"\"\"Show workfiles tool on nuke launch.\n\n    Trigger to show workfiles tool on application launch. Can be executed only\n    once all other calls are ignored.\n\n    Workfiles tool show is deferred after application initialization using\n    QTimer.\n    \"\"\"\n\n    if Context.workfiles_launched:\n        return\n\n    Context.workfiles_launched = True\n\n    # get all important settings\n    open_at_start = env_value_to_bool(\n        env_key=\"AYON_WORKFILE_TOOL_ON_START\",\n        default=None)\n\n    # return if none is defined\n    if not open_at_start:\n        return\n\n    # Show workfiles tool using timer\n    # - this will be probably triggered during initialization in that case\n    #   the application is not be able to show uis so it must be\n    #   deferred using timer\n    # - timer should be processed when initialization ends\n    #       When applications starts to process events.\n    timer = QtCore.QTimer()\n    timer.timeout.connect(_launch_workfile_app)\n    timer.setInterval(100)\n    Context.workfiles_tool_timer = timer\n    timer.start()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.link_knobs","title":"<code>link_knobs(knobs, node, group_node)</code>","text":"<p>Link knobs from inside <code>group_node</code></p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def link_knobs(knobs, node, group_node):\n    \"\"\"Link knobs from inside `group_node`\"\"\"\n\n    missing_knobs = []\n    for knob in knobs:\n        if knob in group_node.knobs():\n            continue\n\n        if knob not in node.knobs().keys():\n            missing_knobs.append(knob)\n\n        link = nuke.Link_Knob(\"\")\n        link.makeLink(node.name(), knob)\n        link.setName(knob)\n        link.setFlag(0x1000)\n        group_node.addKnob(link)\n\n    if missing_knobs:\n        raise ValueError(\n            \"Write node exposed knobs missing:\\n\\n{}\\n\\nPlease review\"\n            \" project settings.\".format(\"\\n\".join(missing_knobs))\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.maintained_selection","title":"<code>maintained_selection(exclude_nodes=None)</code>","text":"<p>Maintain selection during context</p> <p>Maintain selection during context and unselect all nodes after context is done.</p> <p>Parameters:</p> Name Type Description Default <code>exclude_nodes</code> <code>list[Node]</code> <p>list of nodes to be unselected                              before context is done</p> <code>None</code> Example <p>with maintained_selection(): ...     node[\"selected\"].setValue(True) print(node[\"selected\"].value()) False</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@contextlib.contextmanager\ndef maintained_selection(exclude_nodes=None):\n    \"\"\"Maintain selection during context\n\n    Maintain selection during context and unselect\n    all nodes after context is done.\n\n    Arguments:\n        exclude_nodes (list[nuke.Node]): list of nodes to be unselected\n                                         before context is done\n\n    Example:\n        &gt;&gt;&gt; with maintained_selection():\n        ...     node[\"selected\"].setValue(True)\n        &gt;&gt;&gt; print(node[\"selected\"].value())\n        False\n    \"\"\"\n    if exclude_nodes:\n        for node in exclude_nodes:\n            node[\"selected\"].setValue(False)\n\n    previous_selection = nuke.selectedNodes()\n\n    try:\n        yield\n    finally:\n        # unselect all selection in case there is some\n        reset_selection()\n\n        # and select all previously selected nodes\n        if previous_selection:\n            select_nodes(previous_selection)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.node_tempfile","title":"<code>node_tempfile()</code>","text":"<p>Create a temp file where node is pasted during duplication.</p> <p>This is to avoid using clipboard for node duplication.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@contextlib.contextmanager\ndef node_tempfile():\n    \"\"\"Create a temp file where node is pasted during duplication.\n\n    This is to avoid using clipboard for node duplication.\n    \"\"\"\n\n    tmp_file = tempfile.NamedTemporaryFile(\n        mode=\"w\", prefix=\"AYON_nuke_temp_\", suffix=\".nk\", delete=False\n    )\n    tmp_file.close()\n    node_tempfile_path = tmp_file.name\n\n    try:\n        # Yield the path where node can be copied\n        yield node_tempfile_path\n\n    finally:\n        # Remove the file at the end\n        os.remove(node_tempfile_path)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.on_script_load","title":"<code>on_script_load()</code>","text":"<p>Callback for ffmpeg support</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def on_script_load():\n    ''' Callback for ffmpeg support\n    '''\n    if nuke.env[\"LINUX\"]:\n        nuke.tcl('load ffmpegReader')\n        nuke.tcl('load ffmpegWriter')\n    else:\n        nuke.tcl('load movReader')\n        nuke.tcl('load movWriter')\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.process_workfile_builder","title":"<code>process_workfile_builder()</code>","text":"<p>[DEPRECATED] Process workfile builder on nuke start</p> <p>This function is deprecated and will be removed in future versions. Use settings for <code>project_settings/nuke/templated_workfile_build</code> which are supported by api <code>start_workfile_template_builder()</code>.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@deprecated(\"ayon_nuke.api.lib.start_workfile_template_builder\")\ndef process_workfile_builder():\n    \"\"\" [DEPRECATED] Process workfile builder on nuke start\n\n    This function is deprecated and will be removed in future versions.\n    Use settings for `project_settings/nuke/templated_workfile_build` which are\n    supported by api `start_workfile_template_builder()`.\n    \"\"\"\n\n    # to avoid looping of the callback, remove it!\n    nuke.removeOnCreate(process_workfile_builder, nodeClass=\"Root\")\n\n    # get state from settings\n    project_settings = get_current_project_settings()\n    workfile_builder = project_settings[\"nuke\"].get(\n        \"workfile_builder\", {})\n\n    # get settings\n    create_fv_on = workfile_builder.get(\"create_first_version\") or None\n    builder_on = workfile_builder.get(\"builder_on_start\") or None\n\n    last_workfile_path = os.environ.get(\"AYON_LAST_WORKFILE\")\n\n    # generate first version in file not existing and feature is enabled\n    if create_fv_on and not os.path.exists(last_workfile_path):\n        # get custom template path if any\n        custom_template_path = get_current_context_custom_workfile_template(\n            project_settings=project_settings\n        )\n\n        # if custom template is defined\n        if custom_template_path:\n            log.info(\"Adding nodes from `{}`...\".format(\n                custom_template_path\n            ))\n            try:\n                # import nodes into current script\n                nuke.nodePaste(custom_template_path)\n            except RuntimeError:\n                raise RuntimeError((\n                    \"Template defined for project: {} is not working. \"\n                    \"Talk to your manager for an advise\").format(\n                        custom_template_path))\n\n        # if builder at start is defined\n        if builder_on:\n            log.info(\"Building nodes from presets...\")\n            # build nodes by defined presets\n            BuildWorkfile().process()\n\n        log.info(\"Saving script as version `{}`...\".format(\n            last_workfile_path\n        ))\n        # safe file as version\n        save_file(last_workfile_path)\n        return\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.read_avalon_data","title":"<code>read_avalon_data(node)</code>","text":"<p>Return user-defined knobs from given <code>node</code></p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Nuke node object</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of nuke.Knob object</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def read_avalon_data(node):\n    \"\"\"Return user-defined knobs from given `node`\n\n    Args:\n        node (nuke.Node): Nuke node object\n\n    Returns:\n        list: A list of nuke.Knob object\n\n    \"\"\"\n    def compat_prefixed(knob_name):\n        if knob_name.startswith(\"avalon:\"):\n            return knob_name[len(\"avalon:\"):]\n        elif knob_name.startswith(\"ak:\"):\n            return knob_name[len(\"ak:\"):]\n\n    data = dict()\n\n    pattern = (\"(?&lt;=addUserKnob {)\"\n               \"([0-9]*) (\\\\S*)\"  # Matching knob type and knob name\n               \"(?=[ |}])\")\n    tcl_script = node.writeKnobs(nuke.WRITE_USER_KNOB_DEFS)\n    result = re.search(pattern, tcl_script)\n\n    if result:\n        first_user_knob = result.group(2)\n        # Collect user knobs from the end of the knob list\n        for knob in reversed(node.allKnobs()):\n            knob_name = knob.name()\n            if not knob_name:\n                # Ignore unnamed knob\n                continue\n            try:\n                knob_type = nuke.knob(knob.fullyQualifiedName(), type=True)\n                value = knob.value()\n            except Exception:\n                log.debug(\n                    f\"Error in knob {knob_name}, node {node['name'].value()}\")\n                continue\n            if (\n                knob_type not in EXCLUDED_KNOB_TYPE_ON_READ or\n                # For compating read-only string data that imprinted\n                # by `nuke.Text_Knob`.\n                (knob_type == 26 and value)\n            ):\n                key = compat_prefixed(knob_name)\n                if key is not None:\n                    data[key] = value\n\n            if knob_name == first_user_knob:\n                break\n\n    return data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.refresh_node","title":"<code>refresh_node(node)</code>","text":"<p>Correct a bug caused by the multi-threading of nuke.</p> <p>Refresh the node to make sure that it takes the desired attributes.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def refresh_node(node):\n    \"\"\"Correct a bug caused by the multi-threading of nuke.\n\n    Refresh the node to make sure that it takes the desired attributes.\n    \"\"\"\n\n    x = node.xpos()\n    y = node.ypos()\n    nuke.autoplaceSnap(node)\n    node.setXYpos(x, y)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.reset_selection","title":"<code>reset_selection()</code>","text":"<p>Deselect all selected nodes</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def reset_selection():\n    \"\"\"Deselect all selected nodes\"\"\"\n    for node in nuke.selectedNodes():\n        node[\"selected\"].setValue(False)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.script_name","title":"<code>script_name()</code>","text":"<p>Returns nuke script path</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def script_name():\n    ''' Returns nuke script path\n    '''\n    return nuke.root().knob(\"name\").value()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.select_nodes","title":"<code>select_nodes(nodes)</code>","text":"<p>Selects all inputted nodes</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>Union[list, tuple, set]</code> <p>nuke nodes to be selected</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def select_nodes(nodes):\n    \"\"\"Selects all inputted nodes\n\n    Arguments:\n        nodes (Union[list, tuple, set]): nuke nodes to be selected\n    \"\"\"\n    assert isinstance(nodes, (list, tuple, set)), \\\n        \"nodes has to be list, tuple or set\"\n\n    for node in nodes:\n        node[\"selected\"].setValue(True)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.set_avalon_knob_data","title":"<code>set_avalon_knob_data(node, data=None, prefix='avalon:')</code>","text":"<p>[DEPRECATED] Sets data into nodes's avalon knob</p> <p>This function is still used but soon will be deprecated. Use <code>set_node_data</code> instead.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Nuke node to imprint with data,</p> required <code>data</code> <code>dict</code> <p>Data to be imprinted into AvalonTab</p> <code>None</code> <code>prefix</code> <code>str</code> <p>filtering prefix</p> <code>'avalon:'</code> <p>Returns:</p> Type Description <p>node (nuke.Node)</p> <p>Examples:</p> <p>data = {     'folderPath': 'sq020sh0280',     'productBaseType': 'render',     'productName': 'productMain' }</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@deprecated(\"ayon_nuke.api.lib.set_node_data\")\ndef set_avalon_knob_data(node, data=None, prefix=\"avalon:\"):\n    \"\"\"[DEPRECATED] Sets data into nodes's avalon knob\n\n    This function is still used but soon will be deprecated.\n    Use `set_node_data` instead.\n\n    Arguments:\n        node (nuke.Node): Nuke node to imprint with data,\n        data (dict, optional): Data to be imprinted into AvalonTab\n        prefix (str, optional): filtering prefix\n\n    Returns:\n        node (nuke.Node)\n\n    Examples:\n        data = {\n            'folderPath': 'sq020sh0280',\n            'productBaseType': 'render',\n            'productName': 'productMain'\n        }\n    \"\"\"\n    data = data or dict()\n    create = OrderedDict()\n\n    tab_name = NODE_TAB_NAME\n    editable = [\"folderPath\", \"productName\", \"name\", \"namespace\"]\n\n    existed_knobs = node.knobs()\n\n    for key, value in data.items():\n        knob_name = prefix + key\n        gui_name = key\n\n        if knob_name in existed_knobs:\n            # Set value\n            try:\n                node[knob_name].setValue(value)\n            except TypeError:\n                node[knob_name].setValue(str(value))\n        else:\n            # New knob\n            name = (knob_name, gui_name)  # Hide prefix on GUI\n            if key in editable:\n                create[name] = value\n            else:\n                create[name] = Knobby(\"String_Knob\",\n                                      str(value),\n                                      flags=[nuke.READ_ONLY])\n    if tab_name in existed_knobs:\n        tab_name = None\n    else:\n        tab = OrderedDict()\n        warn = Knobby(\"Text_Knob\", \"Warning! Do not change following data!\")\n        divd = Knobby(\"Text_Knob\", \"\")\n        head = [\n            ((\"warn\", \"\"), warn),\n            ((\"divd\", \"\"), divd),\n        ]\n        tab[DATA_GROUP_KEY] = OrderedDict(head + list(create.items()))\n        create = tab\n\n    imprint(node, create, tab=tab_name)\n    return node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.set_node_data","title":"<code>set_node_data(node, knobname, data)</code>","text":"<p>Write data to node invisible knob</p> <p>Will create new in case it doesn't exists or update the one already created.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object</p> required <code>knobname</code> <code>str</code> <p>knob name</p> required <code>data</code> <code>dict</code> <p>data to be stored in knob</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_node_data(node, knobname, data):\n    \"\"\"Write data to node invisible knob\n\n    Will create new in case it doesn't exists\n    or update the one already created.\n\n    Args:\n        node (nuke.Node): node object\n        knobname (str): knob name\n        data (dict): data to be stored in knob\n    \"\"\"\n    # if exists then update data\n    if knobname in node.knobs():\n        update_node_data(node, knobname, data)\n        return\n\n    # else create new\n    knob_value = JSON_PREFIX + json.dumps(data)\n    knob = nuke.String_Knob(knobname)\n    knob.setValue(knob_value)\n    knob.setFlag(nuke.INVISIBLE)\n    node.addKnob(knob)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.set_node_knobs_from_settings","title":"<code>set_node_knobs_from_settings(node, knob_settings, **kwargs)</code>","text":"<p>Overriding knob values from settings</p> <p>Using <code>schema_nuke_knob_inputs</code> for knob type definitions.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>nuke node</p> required <code>knob_settings</code> <code>list</code> <p>list of dict. Keys are <code>type</code>, <code>name</code>, <code>value</code></p> required <code>kwargs (dict)[optional]</code> <p>keys for formattable knob settings</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def set_node_knobs_from_settings(node, knob_settings, **kwargs):\n    \"\"\" Overriding knob values from settings\n\n    Using `schema_nuke_knob_inputs` for knob type definitions.\n\n    Args:\n        node (nuke.Node): nuke node\n        knob_settings (list): list of dict. Keys are `type`, `name`, `value`\n        kwargs (dict)[optional]: keys for formattable knob settings\n    \"\"\"\n    for knob in knob_settings:\n        knob_name = knob[\"name\"]\n        if knob_name not in node.knobs():\n            continue\n\n        knob_type = knob[\"type\"]\n        knob_value = knob[knob_type]\n        if knob_type == \"expression\":\n            node[knob_name].setExpression(knob_value)\n            continue\n\n        # first deal with formattable knob settings\n        if knob_type == \"formatable\":\n            template = knob_value[\"template\"]\n            to_type = knob_value[\"to_type\"]\n            try:\n                knob_value = template.format(**kwargs)\n            except KeyError as msg:\n                raise KeyError(\n                    \"Not able to format expression: {}\".format(msg))\n\n            # convert value to correct type\n            if to_type == \"2d_vector\":\n                knob_value = knob_value.split(\";\").split(\",\")\n\n            knob_type = to_type\n\n        if not knob_value:\n            continue\n\n        knob_value = convert_knob_value_to_correct_type(\n            knob_type, knob_value)\n\n        node[knob_name].setValue(knob_value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.swap_node_with_dependency","title":"<code>swap_node_with_dependency(old_node, new_node)</code>","text":"<p>Swap node with dependency</p> <p>Swap node with dependency and reconnect all inputs and outputs. It removes old node.</p> <p>Parameters:</p> Name Type Description Default <code>old_node</code> <code>Node</code> <p>node to be replaced</p> required <code>new_node</code> <code>Node</code> <p>node to replace with</p> required Example <p>old_node_name = old_node[\"name\"].value() print(old_node_name) old_node_name_01 with swap_node_with_dependency(old_node, new_node) as node_name: ...     new_node[\"name\"].setValue(node_name) print(new_node[\"name\"].value()) old_node_name_01</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>@contextlib.contextmanager\ndef swap_node_with_dependency(old_node, new_node):\n    \"\"\" Swap node with dependency\n\n    Swap node with dependency and reconnect all inputs and outputs.\n    It removes old node.\n\n    Arguments:\n        old_node (nuke.Node): node to be replaced\n        new_node (nuke.Node): node to replace with\n\n    Example:\n        &gt;&gt;&gt; old_node_name = old_node[\"name\"].value()\n        &gt;&gt;&gt; print(old_node_name)\n        old_node_name_01\n        &gt;&gt;&gt; with swap_node_with_dependency(old_node, new_node) as node_name:\n        ...     new_node[\"name\"].setValue(node_name)\n        &gt;&gt;&gt; print(new_node[\"name\"].value())\n        old_node_name_01\n    \"\"\"\n    # preserve position\n    xpos, ypos = old_node.xpos(), old_node.ypos()\n    # preserve selection after all is done\n    outputs = get_node_outputs(old_node)\n    inputs = old_node.dependencies()\n    node_name = old_node[\"name\"].value()\n\n    try:\n        nuke.delete(old_node)\n\n        yield node_name\n    finally:\n\n        # Reconnect inputs\n        for i, node in enumerate(inputs):\n            new_node.setInput(i, node)\n        # Reconnect outputs\n        if outputs:\n            for n, pipes in outputs.items():\n                for i in pipes:\n                    n.setInput(i, new_node)\n        # return to original position\n        new_node.setXYpos(xpos, ypos)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.update_node_data","title":"<code>update_node_data(node, knobname, data)</code>","text":"<p>Update already present data.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>node object</p> required <code>knobname</code> <code>str</code> <p>knob name</p> required <code>data</code> <code>dict</code> <p>data to update knob value</p> required Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def update_node_data(node, knobname, data):\n    \"\"\"Update already present data.\n\n    Args:\n        node (nuke.Node): node object\n        knobname (str): knob name\n        data (dict): data to update knob value\n    \"\"\"\n    knob = node[knobname]\n    node_data = get_node_data(node, knobname) or {}\n    node_data.update(data)\n    knob_value = JSON_PREFIX + json.dumps(node_data)\n    knob.setValue(knob_value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/lib.html#client.ayon_nuke.api.lib.writes_version_sync","title":"<code>writes_version_sync(write_node, log)</code>","text":"<p>Callback synchronizing version of publishable write nodes</p> <p>Tries to find version string in render path of write node and bump it to workfile version.</p> Source code in <code>client/ayon_nuke/api/lib.py</code> <pre><code>def writes_version_sync(write_node, log):\n    \"\"\" Callback synchronizing version of publishable write nodes\n\n    Tries to find version string in render path of write node and bump it to\n    workfile version.\n\n    Args:\n        write_node (nuke.Node)\n        log (logging.Logger) - logger to output messages into Publisher\n\n    \"\"\"\n    try:\n        rootVersion = get_version_from_path(nuke.root().name())\n        padding = len(rootVersion)\n        new_version = \"v\" + str(\"{\" + \":0&gt;{}\".format(padding) + \"}\").format(\n            int(rootVersion)\n        )\n    except Exception:\n        log.warning(\"Scene name doesn't have version part.\", exc_info=True)\n        return\n\n    try:\n        write_path = write_node[\"file\"].value()\n        node_version = \"v\" + get_version_from_path(write_path)\n        node_new_file = write_path.replace(node_version, new_version)\n\n        def replace_match(match):\n            x_value = int(match.group(1))  # Extract the number X\n            return '#' * x_value  # Return '#' repeated X times\n\n        # Use regex to find all occurrences of '%0Xd' with `#`s\n        node_new_file = re.sub(r'%0*(\\d+)d', replace_match, node_new_file)\n\n        log.debug(f\"Overwriting Write path to '{node_new_file}'\")\n        write_node[\"file\"].setValue(node_new_file)\n        render_dir = os.path.dirname(node_new_file)\n        if not os.path.isdir(render_dir):\n            log.warning(f\"Path '{render_dir}' does not exist! Creating it.\")\n            os.makedirs(render_dir)\n    except Exception:\n        log.warning(\n            f\"Write node: `{write_node.name()}` has no version \"\n            f\"in path: '{write_path}'. Expected format as `.vXXX` or `_vXXX`.\",\n            exc_info=True\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html","title":"pipeline","text":""},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.NukeHost","title":"<code>NukeHost</code>","text":"<p>               Bases: <code>HostBase</code>, <code>IWorkfileHost</code>, <code>ILoadHost</code>, <code>IPublishHost</code></p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>class NukeHost(\n    HostBase, IWorkfileHost, ILoadHost, IPublishHost\n):\n    name = \"nuke\"\n\n    def open_workfile(self, filepath):\n        return open_file(filepath)\n\n    def save_workfile(self, filepath=None):\n        return save_file(filepath)\n\n    def work_root(self, session):\n        return work_root(session)\n\n    def get_current_workfile(self):\n        return current_file()\n\n    def workfile_has_unsaved_changes(self):\n        return has_unsaved_changes()\n\n    def get_workfile_extensions(self):\n        return file_extensions()\n\n    def get_containers(self):\n        return ls()\n\n    def install(self):\n        \"\"\"Installing all requirements for Nuke host\"\"\"\n\n        pyblish.api.register_host(\"nuke\")\n\n        self.log.info(\"Registering Nuke plug-ins..\")\n        pyblish.api.register_plugin_path(PUBLISH_PATH)\n        register_loader_plugin_path(LOAD_PATH)\n        register_creator_plugin_path(CREATE_PATH)\n        register_inventory_action_path(INVENTORY_PATH)\n        register_workfile_build_plugin_path(WORKFILE_BUILD_PATH)\n\n        # Register AYON event for workfiles loading.\n        register_event_callback(\"workio.open_file\", check_inventory_versions)\n        register_event_callback(\"taskChanged\", change_context_label)\n        project_settings = get_current_project_settings()\n        if nuke.GUI:\n            _install_menu(project_settings)\n\n            # add script menu\n            add_scripts_menu()\n            add_scripts_gizmo()\n\n        add_nuke_callbacks(project_settings)\n\n        launch_workfiles_app()\n\n    def get_context_data(self):\n        root_node = nuke.root()\n        return get_node_data(root_node, ROOT_DATA_KNOB)\n\n    def update_context_data(self, data, changes):\n        root_node = nuke.root()\n        set_node_data(root_node, ROOT_DATA_KNOB, data)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.NukeHost.install","title":"<code>install()</code>","text":"<p>Installing all requirements for Nuke host</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def install(self):\n    \"\"\"Installing all requirements for Nuke host\"\"\"\n\n    pyblish.api.register_host(\"nuke\")\n\n    self.log.info(\"Registering Nuke plug-ins..\")\n    pyblish.api.register_plugin_path(PUBLISH_PATH)\n    register_loader_plugin_path(LOAD_PATH)\n    register_creator_plugin_path(CREATE_PATH)\n    register_inventory_action_path(INVENTORY_PATH)\n    register_workfile_build_plugin_path(WORKFILE_BUILD_PATH)\n\n    # Register AYON event for workfiles loading.\n    register_event_callback(\"workio.open_file\", check_inventory_versions)\n    register_event_callback(\"taskChanged\", change_context_label)\n    project_settings = get_current_project_settings()\n    if nuke.GUI:\n        _install_menu(project_settings)\n\n        # add script menu\n        add_scripts_menu()\n        add_scripts_gizmo()\n\n    add_nuke_callbacks(project_settings)\n\n    launch_workfiles_app()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.add_nuke_callbacks","title":"<code>add_nuke_callbacks(project_settings=None)</code>","text":"<p>Adding all available nuke callbacks</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def add_nuke_callbacks(project_settings: dict = None):\n    \"\"\"Adding all available nuke callbacks\"\"\"\n    if project_settings is None:\n        project_settings = get_current_project_settings()\n\n    nuke_settings = project_settings[\"nuke\"]\n    workfile_settings = WorkfileSettings()\n\n    # Set context settings.\n    nuke.addOnCreate(\n        workfile_settings.set_context_settings, nodeClass=\"Root\")\n\n    # adding favorites to file browser\n    nuke.addOnCreate(workfile_settings.set_favorites, nodeClass=\"Root\")\n\n    # template builder callbacks\n    nuke.addOnCreate(start_workfile_template_builder, nodeClass=\"Root\")\n\n    # fix ffmpeg settings on script\n    nuke.addOnScriptLoad(on_script_load)\n\n    # set checker for last versions on loaded containers\n    nuke.addOnScriptLoad(check_inventory_versions)\n    nuke.addOnScriptSave(check_inventory_versions)\n\n    # set apply all workfile settings on script load and save\n    nuke.addOnScriptLoad(WorkfileSettings().set_context_settings)\n\n    if nuke_settings[\"dirmap\"][\"enabled\"]:\n        log.info(\"Added Nuke's dir-mapping callback ...\")\n        # Add dirmap for file paths.\n        nuke.addFilenameFilter(dirmap_file_name_filter)\n\n    log.info(\"Added Nuke callbacks ...\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.containerise","title":"<code>containerise(node, name, namespace, context, loader=None, data=None)</code>","text":"<p>Bundle <code>node</code> into an assembly and imprint it with metadata</p> <p>Containerisation enables a tracking of version, author and origin for loaded assets.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Nuke's node object to imprint as container</p> required <code>name</code> <code>str</code> <p>Name of resulting assembly</p> required <code>namespace</code> <code>str</code> <p>Namespace under which to host container</p> required <code>context</code> <code>dict</code> <p>Asset information</p> required <code>loader</code> <code>str</code> <p>Name of node used to produce this container.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>node</code> <code>Node</code> <p>containerised nuke's node object</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def containerise(node,\n                 name,\n                 namespace,\n                 context,\n                 loader=None,\n                 data=None):\n    \"\"\"Bundle `node` into an assembly and imprint it with metadata\n\n    Containerisation enables a tracking of version, author and origin\n    for loaded assets.\n\n    Arguments:\n        node (nuke.Node): Nuke's node object to imprint as container\n        name (str): Name of resulting assembly\n        namespace (str): Namespace under which to host container\n        context (dict): Asset information\n        loader (str, optional): Name of node used to produce this container.\n\n    Returns:\n        node (nuke.Node): containerised nuke's node object\n\n    \"\"\"\n    data = OrderedDict(\n        [\n            (\"schema\", \"ayon:container-3.0\"),\n            (\"id\", AVALON_CONTAINER_ID),\n            (\"name\", name),\n            (\"namespace\", namespace),\n            (\"loader\", str(loader)),\n            (\"representation\", context[\"representation\"][\"id\"]),\n            (\"project_name\", context[\"project\"][\"name\"]),\n        ],\n\n        **data or dict()\n    )\n\n    set_avalon_knob_data(node, data)\n\n    # set tab to first native\n    node.setTab(0)\n\n    return node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.list_instances","title":"<code>list_instances(creator_id=None)</code>","text":"<p>List all created instances to publish from current workfile.</p> <p>For SubsetManager</p> <p>Parameters:</p> Name Type Description Default <code>creator_id</code> <code>Optional[str]</code> <p>creator identifier</p> <code>None</code> <p>Returns:</p> Type Description <p>(list) of dictionaries matching instances format</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def list_instances(creator_id=None):\n    \"\"\"List all created instances to publish from current workfile.\n\n    For SubsetManager\n\n    Args:\n        creator_id (Optional[str]): creator identifier\n\n    Returns:\n        (list) of dictionaries matching instances format\n    \"\"\"\n    instances_by_order = defaultdict(list)\n    product_instances = []\n    instance_ids = set()\n\n    for node in nuke.allNodes(recurseGroups=True):\n\n        if node.Class() in [\"Viewer\", \"Dot\"]:\n            continue\n\n        try:\n            if node[\"disable\"].value():\n                continue\n        except NameError:\n            # pass if disable knob doesn't exist\n            pass\n\n        # get data from avalon knob\n        instance_data = get_node_data(\n            node, INSTANCE_DATA_KNOB)\n\n        if not instance_data:\n            continue\n\n        if instance_data[\"id\"] not in {\n            AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n        }:\n            continue\n\n        if creator_id and instance_data[\"creator_identifier\"] != creator_id:\n            continue\n\n        instance_id = instance_data.get(\"instance_id\")\n        if not instance_id:\n            pass\n        elif instance_id in instance_ids:\n            instance_data.pop(\"instance_id\")\n        else:\n            instance_ids.add(instance_id)\n\n        # node name could change, so update product name data\n        _update_product_name_data(instance_data, node)\n\n        if \"render_order\" not in node.knobs():\n            product_instances.append((node, instance_data))\n            continue\n\n        order = int(node[\"render_order\"].value())\n        instances_by_order[order].append((node, instance_data))\n\n    # Sort instances based on order attribute or product name.\n    # TODO: remove in future Publisher enhanced with sorting\n    ordered_instances = []\n    for key in sorted(instances_by_order.keys()):\n        instances_by_product = defaultdict(list)\n        for node, data_ in instances_by_order[key]:\n            product_name = data_.get(\"productName\")\n            if product_name is None:\n                product_name = data_.get(\"subset\")\n            instances_by_product[product_name].append((node, data_))\n        for subkey in sorted(instances_by_product.keys()):\n            ordered_instances.extend(instances_by_product[subkey])\n\n    instances_by_product = defaultdict(list)\n    for node, data_ in product_instances:\n        product_name = data_.get(\"productName\")\n        if product_name is None:\n            product_name = data_.get(\"subset\")\n        instances_by_product[product_name].append((node, data_))\n    for key in sorted(instances_by_product.keys()):\n        ordered_instances.extend(instances_by_product[key])\n\n    return ordered_instances\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.ls","title":"<code>ls()</code>","text":"<p>List available containers.</p> <p>This function is used by the Container Manager in Nuke. You'll need to implement a for-loop that then yields one Container at a time.</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def ls():\n    \"\"\"List available containers.\n\n    This function is used by the Container Manager in Nuke. You'll\n    need to implement a for-loop that then *yields* one Container at\n    a time.\n    \"\"\"\n    all_nodes = nuke.allNodes(recurseGroups=False)\n\n    nodes = [n for n in all_nodes]\n\n    for n in nodes:\n        container = parse_container(n)\n        if container:\n            yield container\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.parse_container","title":"<code>parse_container(node)</code>","text":"<p>Returns containerised data of a node</p> <p>Reads the imprinted data from <code>containerise</code>.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>Nuke's node object to read imprinted data</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>The container schema data for this container node.</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def parse_container(node):\n    \"\"\"Returns containerised data of a node\n\n    Reads the imprinted data from `containerise`.\n\n    Arguments:\n        node (nuke.Node): Nuke's node object to read imprinted data\n\n    Returns:\n        dict: The container schema data for this container node.\n\n    \"\"\"\n    data = read_avalon_data(node)\n\n    # If not all required data return the empty container\n    required = [\"schema\", \"id\", \"name\",\n                \"namespace\", \"loader\", \"representation\"]\n    if not all(key in data for key in required):\n        return\n\n    # Store the node's name\n    data.update({\n        \"objectName\": node.fullName(),\n        \"node\": node,\n    })\n\n    return data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.reload_config","title":"<code>reload_config()</code>","text":"<p>Attempt to reload pipeline at run-time.</p> <p>CAUTION: This is primarily for development and debugging purposes.</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def reload_config():\n    \"\"\"Attempt to reload pipeline at run-time.\n\n    CAUTION: This is primarily for development and debugging purposes.\n\n    \"\"\"\n\n    for module in (\n        \"ayon_nuke.api.actions\",\n        \"ayon_nuke.api.menu\",\n        \"ayon_nuke.api.plugin\",\n        \"ayon_nuke.api.lib\",\n    ):\n        log.info(\"Reloading module: {}...\".format(module))\n\n        module = importlib.import_module(module)\n\n        try:\n            importlib.reload(module)\n        except AttributeError as e:\n            from importlib import reload\n            log.warning(\"Cannot reload module: {}\".format(e))\n            reload(module)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.remove_instance","title":"<code>remove_instance(instance)</code>","text":"<p>Remove instance from current workfile metadata.</p> <p>For SubsetManager</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>dict</code> <p>instance representation from subsetmanager model</p> required Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def remove_instance(instance):\n    \"\"\"Remove instance from current workfile metadata.\n\n    For SubsetManager\n\n    Args:\n        instance (dict): instance representation from subsetmanager model\n    \"\"\"\n    instance_node = instance.transient_data[\"node\"]\n    instance_knob = instance_node.knobs()[INSTANCE_DATA_KNOB]\n    instance_node.removeKnob(instance_knob)\n    nuke.delete(instance_node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.select_instance","title":"<code>select_instance(instance)</code>","text":"<p>Select instance in Node View</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>dict</code> <p>instance representation from subsetmanager model</p> required Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def select_instance(instance):\n    \"\"\"\n        Select instance in Node View\n\n        Args:\n            instance (dict): instance representation from subsetmanager model\n    \"\"\"\n    instance_node = instance.transient_data[\"node\"]\n    instance_node[\"selected\"].setValue(True)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/pipeline.html#client.ayon_nuke.api.pipeline.update_container","title":"<code>update_container(node, keys=None)</code>","text":"<p>Returns node with updateted containder data</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>Node</code> <p>The node in Nuke to imprint as container,</p> required <code>keys</code> <code>dict</code> <p>data which should be updated</p> <code>None</code> <p>Returns:</p> Name Type Description <code>node</code> <code>Node</code> <p>nuke node with updated container data</p> Source code in <code>client/ayon_nuke/api/pipeline.py</code> <pre><code>def update_container(node, keys=None):\n    \"\"\"Returns node with updateted containder data\n\n    Arguments:\n        node (nuke.Node): The node in Nuke to imprint as container,\n        keys (dict, optional): data which should be updated\n\n    Returns:\n        node (nuke.Node): nuke node with updated container data\n\n    Raises:\n        TypeError on given an invalid container node\n\n    \"\"\"\n    keys = keys or dict()\n\n    container = parse_container(node)\n    if not container:\n        raise TypeError(\"Not a valid container node.\")\n\n    container.update(keys)\n    node = set_avalon_knob_data(node, container)\n\n    return node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html","title":"plugin","text":""},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.ExporterReview","title":"<code>ExporterReview</code>","text":"<p>               Bases: <code>object</code></p> <p>Base class object for generating review data from Nuke</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>plugin</code> <p>pyblish plugin parent</p> required <code>instance</code> <code>instance</code> <p>instance of pyblish context</p> required Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class ExporterReview(object):\n    \"\"\"\n    Base class object for generating review data from Nuke\n\n    Args:\n        klass (pyblish.plugin): pyblish plugin parent\n        instance (pyblish.instance): instance of pyblish context\n\n    \"\"\"\n    data = None\n    publish_on_farm = False\n\n    def __init__(self,\n                 klass,\n                 instance,\n                 multiple_presets=True\n                 ):\n\n        self.log = klass.log\n        self.instance = instance\n        self.multiple_presets = multiple_presets\n        self.path_in = self.instance.data.get(\"path\", None)\n        self.staging_dir = self.instance.data[\"stagingDir\"]\n        self.collection = self.instance.data.get(\"collection\", None)\n        self.data = {\"representations\": []}\n        if self.instance.data.get(\"stagingDir_is_custom\"):\n            self.staging_dir = self._update_staging_dir(\n                self.instance.context.data[\"currentFile\"],\n                self.staging_dir\n            )\n\n    def get_file_info(self):\n        if self.collection:\n            # get path\n            self.fname = os.path.basename(\n                self.collection.format(\"{head}{padding}{tail}\")\n            )\n            self.fhead = self.collection.format(\"{head}\")\n\n            # get first and last frame\n            self.first_frame = min(self.collection.indexes)\n            self.last_frame = max(self.collection.indexes)\n\n            # make sure slate frame is not included\n            frame_start_handle = self.instance.data[\"frameStartHandle\"]\n            if frame_start_handle &gt; self.first_frame:\n                self.first_frame = frame_start_handle\n\n        else:\n            self.fname = os.path.basename(self.path_in)\n            self.fhead = os.path.splitext(self.fname)[0] + \".\"\n            self.first_frame = self.instance.data[\"frameStartHandle\"]\n            self.last_frame = self.instance.data[\"frameEndHandle\"]\n\n        if \"#\" in self.fhead:\n            self.fhead = self.fhead.replace(\"#\", \"\")[:-1]\n\n    def get_representation_data(\n        self,\n        tags=None,\n        range=False,\n        custom_tags=None,\n        colorspace=None,\n    ):\n        \"\"\" Add representation data to self.data\n\n        Args:\n            tags (list[str], optional): list of defined tags.\n                                        Defaults to None.\n            range (bool, optional): flag for adding ranges.\n                                    Defaults to False.\n            custom_tags (list[str], optional): user inputted custom tags.\n                                               Defaults to None.\n            colorspace (str, optional): colorspace name.\n                                        Defaults to None.\n        \"\"\"\n        add_tags = tags or []\n        repre = {\n            \"name\": self.name,\n            \"outputName\": self.name,\n            \"ext\": self.ext,\n            \"files\": self.file,\n            \"stagingDir\": self.staging_dir,\n            \"tags\": [self.name.replace(\"_\", \"-\")] + add_tags,\n            \"data\": {\n                # making sure that once intermediate file is published\n                # as representation, we will be able to then identify it\n                # from representation.data.isIntermediate\n                \"isIntermediate\": True,\n                \"isMultiIntermediates\": self.multiple_presets\n            },\n        }\n\n        if custom_tags:\n            repre[\"custom_tags\"] = custom_tags\n\n        if range:\n            repre.update({\n                \"frameStart\": self.first_frame,\n                \"frameEnd\": self.last_frame,\n            })\n        if \".{}\".format(self.ext) not in VIDEO_EXTENSIONS:\n            filenames = get_filenames_without_hash(\n                self.file, self.first_frame, self.last_frame)\n            repre[\"files\"] = filenames\n\n        if self.publish_on_farm:\n            repre[\"tags\"].append(\"publish_on_farm\")\n\n        # add colorspace data to representation\n        if colorspace:\n            set_colorspace_data_to_representation(\n                repre,\n                self.instance.context.data,\n                colorspace=colorspace,\n                log=self.log\n            )\n        self.data[\"representations\"].append(repre)\n\n    def get_imageio_baking_profile(self):\n        from . import lib as opnlib\n        nuke_imageio = opnlib.get_nuke_imageio_settings()\n\n        if nuke_imageio[\"baking_target\"][\"enabled\"]:\n            return nuke_imageio[\"baking_target\"]\n        else:\n            # viewer is having display and view keys only and it is\n            # display_view type\n            return {\n                \"type\": \"display_view\",\n                \"display_view\": nuke_imageio[\"viewer\"],\n            }\n\n    def _update_staging_dir(self, current_file, staging_dir):\n        \"\"\"Update staging dir with current file version.\n\n        Staging dir is used as a place where intermediate review files should\n        be stored. If render path contains version portion, which is replaced\n        by version from workfile, it must be reflected even for baking scripts.\n        \"\"\"\n        try:\n            root_version = get_version_from_path(current_file)\n            padding = len(root_version)\n            root_version = int(root_version)\n        except (TypeError, IndexError):\n            self.log.warning(\n                f\"Current file '{current_file}' doesn't contain version number. \"\n                \"No replacement necessary\",\n                exc_info=True)\n            return staging_dir\n        try:\n            staging_dir_version = \"v\" + get_version_from_path(staging_dir)\n        except (TypeError, IndexError):\n            self.log.warning(\n                f\"Staging directory '{staging_dir}' doesn't contain version number. \"\n                \"No replacement necessary\",\n                exc_info=True)\n            return staging_dir\n\n        new_version = \"v\" + str(\"{\" + \":0&gt;{}\".format(padding) + \"}\").format(\n            root_version\n        )\n        self.log.debug(\n            f\"Update version in staging dir from {staging_dir_version} \"\n            f\"to {new_version}\"\n        )\n        return staging_dir.replace(staging_dir_version, new_version)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.ExporterReview.get_representation_data","title":"<code>get_representation_data(tags=None, range=False, custom_tags=None, colorspace=None)</code>","text":"<p>Add representation data to self.data</p> <p>Parameters:</p> Name Type Description Default <code>tags</code> <code>list[str]</code> <p>list of defined tags.                         Defaults to None.</p> <code>None</code> <code>range</code> <code>bool</code> <p>flag for adding ranges.                     Defaults to False.</p> <code>False</code> <code>custom_tags</code> <code>list[str]</code> <p>user inputted custom tags.                                Defaults to None.</p> <code>None</code> <code>colorspace</code> <code>str</code> <p>colorspace name.                         Defaults to None.</p> <code>None</code> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def get_representation_data(\n    self,\n    tags=None,\n    range=False,\n    custom_tags=None,\n    colorspace=None,\n):\n    \"\"\" Add representation data to self.data\n\n    Args:\n        tags (list[str], optional): list of defined tags.\n                                    Defaults to None.\n        range (bool, optional): flag for adding ranges.\n                                Defaults to False.\n        custom_tags (list[str], optional): user inputted custom tags.\n                                           Defaults to None.\n        colorspace (str, optional): colorspace name.\n                                    Defaults to None.\n    \"\"\"\n    add_tags = tags or []\n    repre = {\n        \"name\": self.name,\n        \"outputName\": self.name,\n        \"ext\": self.ext,\n        \"files\": self.file,\n        \"stagingDir\": self.staging_dir,\n        \"tags\": [self.name.replace(\"_\", \"-\")] + add_tags,\n        \"data\": {\n            # making sure that once intermediate file is published\n            # as representation, we will be able to then identify it\n            # from representation.data.isIntermediate\n            \"isIntermediate\": True,\n            \"isMultiIntermediates\": self.multiple_presets\n        },\n    }\n\n    if custom_tags:\n        repre[\"custom_tags\"] = custom_tags\n\n    if range:\n        repre.update({\n            \"frameStart\": self.first_frame,\n            \"frameEnd\": self.last_frame,\n        })\n    if \".{}\".format(self.ext) not in VIDEO_EXTENSIONS:\n        filenames = get_filenames_without_hash(\n            self.file, self.first_frame, self.last_frame)\n        repre[\"files\"] = filenames\n\n    if self.publish_on_farm:\n        repre[\"tags\"].append(\"publish_on_farm\")\n\n    # add colorspace data to representation\n    if colorspace:\n        set_colorspace_data_to_representation(\n            repre,\n            self.instance.context.data,\n            colorspace=colorspace,\n            log=self.log\n        )\n    self.data[\"representations\"].append(repre)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.ExporterReviewLut","title":"<code>ExporterReviewLut</code>","text":"<p>               Bases: <code>ExporterReview</code></p> <p>Generator object for review lut from Nuke</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>plugin</code> <p>pyblish plugin parent</p> required <code>instance</code> <code>instance</code> <p>instance of pyblish context</p> required Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class ExporterReviewLut(ExporterReview):\n    \"\"\"\n    Generator object for review lut from Nuke\n\n    Args:\n        klass (pyblish.plugin): pyblish plugin parent\n        instance (pyblish.instance): instance of pyblish context\n\n\n    \"\"\"\n    _temp_nodes = []\n\n    def __init__(self,\n                 klass,\n                 instance,\n                 name=None,\n                 ext=None,\n                 cube_size=None,\n                 lut_size=None,\n                 lut_style=None,\n                 multiple_presets=True):\n        # initialize parent class\n        super(ExporterReviewLut, self).__init__(\n            klass, instance, multiple_presets)\n\n        # deal with now lut defined in viewer lut\n        if hasattr(klass, \"viewer_lut_raw\"):\n            self.viewer_lut_raw = klass.viewer_lut_raw\n        else:\n            self.viewer_lut_raw = False\n\n        self.name = name or \"baked_lut\"\n        self.ext = ext or \"cube\"\n        self.cube_size = cube_size or 32\n        self.lut_size = lut_size or 1024\n        self.lut_style = lut_style or \"linear\"\n\n        # set frame start / end and file name to self\n        self.get_file_info()\n\n        self.log.info(\"File info was set...\")\n\n        self.file = self.fhead + self.name + \".{}\".format(self.ext)\n        self.path = os.path.join(\n            self.staging_dir, self.file).replace(\"\\\\\", \"/\")\n\n    def clean_nodes(self):\n        for node in self._temp_nodes:\n            nuke.delete(node)\n        self._temp_nodes = []\n        self.log.info(\"Deleted nodes...\")\n\n    def generate_lut(self, **kwargs):\n        bake_viewer_process = kwargs[\"bake_viewer_process\"]\n        bake_viewer_input_process_node = kwargs[\n            \"bake_viewer_input_process\"]\n\n        # ---------- start nodes creation\n\n        # CMSTestPattern\n        cms_node = nuke.createNode(\"CMSTestPattern\")\n        cms_node[\"cube_size\"].setValue(self.cube_size)\n        # connect\n        self._temp_nodes.append(cms_node)\n        self.previous_node = cms_node\n\n        if bake_viewer_process:\n            # Node View Process\n            if bake_viewer_input_process_node:\n                ipn = get_view_process_node()\n                if ipn is not None:\n                    # connect\n                    ipn.setInput(0, self.previous_node)\n                    self._temp_nodes.append(ipn)\n                    self.previous_node = ipn\n                    self.log.debug(\n                        \"ViewProcess...   `{}`\".format(self._temp_nodes))\n\n            if not self.viewer_lut_raw:\n                # OCIODisplay\n                dag_node = nuke.createNode(\"OCIODisplay\")\n                # connect\n                dag_node.setInput(0, self.previous_node)\n                self._temp_nodes.append(dag_node)\n                self.previous_node = dag_node\n                self.log.debug(\n                    \"OCIODisplay...   `{}`\".format(self._temp_nodes))\n\n        # GenerateLUT\n        gen_lut_node = nuke.createNode(\"GenerateLUT\")\n        gen_lut_node[\"file\"].setValue(self.path)\n        gen_lut_node[\"file_type\"].setValue(\".{}\".format(self.ext))\n        gen_lut_node[\"lut1d\"].setValue(self.lut_size)\n        gen_lut_node[\"style1d\"].setValue(self.lut_style)\n        # connect\n        gen_lut_node.setInput(0, self.previous_node)\n        self._temp_nodes.append(gen_lut_node)\n        # ---------- end nodes creation\n\n        # Export lut file\n        nuke.execute(\n            gen_lut_node.name(),\n            int(self.first_frame),\n            int(self.first_frame))\n\n        self.log.info(\"Exported...\")\n\n        # ---------- generate representation data\n        self.get_representation_data()\n\n        # ---------- Clean up\n        self.clean_nodes()\n\n        return self.data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.ExporterReviewMov","title":"<code>ExporterReviewMov</code>","text":"<p>               Bases: <code>ExporterReview</code></p> <p>Metaclass for generating review mov files</p> <p>Parameters:</p> Name Type Description Default <code>klass</code> <code>plugin</code> <p>pyblish plugin parent</p> required <code>instance</code> <code>instance</code> <p>instance of pyblish context</p> required Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class ExporterReviewMov(ExporterReview):\n    \"\"\"\n    Metaclass for generating review mov files\n\n    Args:\n        klass (pyblish.plugin): pyblish plugin parent\n        instance (pyblish.instance): instance of pyblish context\n\n    \"\"\"\n    _temp_nodes = {}\n\n    def __init__(self,\n                 klass,\n                 instance,\n                 name=None,\n                 ext=None,\n                 multiple_presets=True\n                 ):\n        # initialize parent class\n        super(ExporterReviewMov, self).__init__(\n            klass, instance, multiple_presets)\n        # passing presets for nodes to self\n        self.nodes = klass.nodes if hasattr(klass, \"nodes\") else {}\n\n        # deal with now lut defined in viewer lut\n        self.viewer_lut_raw = klass.viewer_lut_raw\n        self.write_colorspace = instance.data[\"colorspace\"]\n        self.color_channels = instance.data[\"color_channels\"]\n        self.formatting_data = instance.data[\"anatomyData\"]\n\n        self.name = name or \"baked\"\n        self.ext = ext or \"mov\"\n\n        # set frame start / end and file name to self\n        self.get_file_info()\n\n        self.log.info(\"File info was set...\")\n\n        if \".{}\".format(self.ext) in VIDEO_EXTENSIONS:\n            self.file = \"{}{}.{}\".format(\n                self.fhead, self.name, self.ext)\n        else:\n            # Output is image (or image sequence)\n            # When the file is an image it's possible it\n            # has extra information after the `fhead` that\n            # we want to preserve, e.g. like frame numbers\n            # or frames hashes like `####`\n            filename_no_ext = os.path.splitext(\n                os.path.basename(self.path_in))[0]\n            after_head = filename_no_ext[len(self.fhead):]\n            self.file = \"{}{}.{}.{}\".format(\n                self.fhead, self.name, after_head, self.ext)\n        self.path = os.path.join(\n            self.staging_dir, self.file).replace(\"\\\\\", \"/\")\n\n    def clean_nodes(self, node_name):\n        for node in self._temp_nodes[node_name]:\n            nuke.delete(node)\n        self._temp_nodes[node_name] = []\n        self.log.info(\"Deleted nodes...\")\n\n    def render(self, render_node_name):\n        self.log.info(\"Rendering...  \")\n        # Render Write node\n        nuke.execute(\n            render_node_name,\n            int(self.first_frame),\n            int(self.last_frame))\n\n        self.log.info(\"Rendered...\")\n\n    def save_file(self):\n        import shutil\n        with maintained_selection():\n            self.log.info(\"Saving nodes as file...  \")\n            # create nk path\n            path = f\"{os.path.splitext(self.path)[0]}.nk\"\n            # save file to the path\n            if not os.path.exists(os.path.dirname(path)):\n                os.makedirs(os.path.dirname(path))\n            shutil.copyfile(self.instance.context.data[\"currentFile\"], path)\n\n        self.log.info(\"Nodes exported...\")\n        return path\n\n    def generate_mov(self, farm=False, delete=True, **kwargs):\n        # colorspace data\n        colorspace = self.write_colorspace\n\n        # get colorspace settings\n        # get colorspace data from context\n        config_data, _ = get_colorspace_settings_from_publish_context(\n            self.instance.context.data)\n\n        add_tags = []\n        self.publish_on_farm = farm\n        read_raw = kwargs[\"read_raw\"]\n        bake_viewer_process = kwargs[\"bake_viewer_process\"]\n        bake_viewer_input_process_node = kwargs[\n            \"bake_viewer_input_process\"]\n\n        baking_colorspace = self.get_imageio_baking_profile()\n\n        colorspace_override = kwargs[\"colorspace_override\"]\n        if colorspace_override[\"enabled\"]:\n            baking_colorspace = colorspace_override\n\n        fps = self.instance.context.data[\"fps\"]\n\n        self.log.debug(f\"&gt;&gt; baking_view_profile   `{baking_colorspace}`\")\n\n        add_custom_tags = kwargs.get(\"add_custom_tags\", [])\n\n        self.log.info(f\"__ add_custom_tags: `{add_custom_tags}`\")\n\n        product_name = self.instance.data[\"productName\"]\n        self._temp_nodes[product_name] = []\n\n        # Read node\n        r_node = nuke.createNode(\"Read\")\n        r_node[\"file\"].setValue(self.path_in)\n        r_node[\"first\"].setValue(self.first_frame)\n        r_node[\"origfirst\"].setValue(self.first_frame)\n        r_node[\"last\"].setValue(self.last_frame)\n        r_node[\"origlast\"].setValue(self.last_frame)\n        r_node[\"colorspace\"].setValue(self.write_colorspace)\n        r_node[\"on_error\"].setValue(kwargs.get(\"fill_missing_frames\", \"0\"))\n\n        # do not rely on defaults, set explicitly\n        # to be sure it is set correctly\n        r_node[\"frame_mode\"].setValue(\"expression\")\n        r_node[\"frame\"].setValue(\"\")\n\n        if read_raw:\n            r_node[\"raw\"].setValue(1)\n\n        # connect to Read node\n        self._shift_to_previous_node_and_temp(\n            product_name, r_node, \"Read...   `{}`\"\n        )\n\n        # only create colorspace baking if toggled on\n        if bake_viewer_process:\n            if bake_viewer_input_process_node:\n                # View Process node\n                ipn = get_view_process_node()\n                if ipn is not None:\n                    # connect to ViewProcess node\n                    self._connect_to_above_nodes(\n                        ipn, product_name, \"ViewProcess...   `{}`\"\n                    )\n\n            if not self.viewer_lut_raw:\n                # OCIODisplay\n                if baking_colorspace[\"type\"] == \"display_view\":\n                    display_view = baking_colorspace[\"display_view\"]\n\n                    display_view_f = get_formatted_display_and_view_as_dict(\n                        display_view, self.formatting_data\n                    )\n\n                    if not display_view_f:\n                        raise ValueError(\n                            \"Invalid display and view profile: \"\n                            f\"'{display_view}'\"\n                        )\n\n                    # assign display and view\n                    display = display_view_f[\"display\"]\n                    view = display_view_f[\"view\"]\n\n                    message = \"OCIODisplay...   '{}'\"\n                    node = nuke.createNode(\"OCIODisplay\")\n\n                    # display could not be set in nuke_default config\n                    if display:\n                        node[\"display\"].setValue(display)\n\n                    node[\"view\"].setValue(view)\n\n                    if config_data:\n                        # convert display and view to colorspace\n                        colorspace = get_display_view_colorspace_name(\n                            config_path=config_data[\"path\"],\n                            display=display, view=view\n                        )\n\n                # OCIOColorSpace\n                elif baking_colorspace[\"type\"] == \"colorspace\":\n                    baking_colorspace = baking_colorspace[\"colorspace\"]\n                    # format colorspace string with anatomy data\n                    baking_colorspace = get_formatted_colorspace(\n                        baking_colorspace, self.formatting_data\n                    )\n                    if not baking_colorspace:\n                        raise ValueError(\n                            f\"Invalid baking color space: '{baking_colorspace}'\"\n                        )\n                    node = nuke.createNode(\"OCIOColorSpace\")\n                    message = \"OCIOColorSpace...   '{}'\"\n                    # no need to set input colorspace since it is driven by\n                    # working colorspace\n                    node[\"out_colorspace\"].setValue(baking_colorspace)\n                    colorspace = baking_colorspace\n\n                else:\n                    raise ValueError(\n                        \"Invalid baking color space type: \"\n                        f\"{baking_colorspace['type']}\"\n                    )\n\n                self._connect_to_above_nodes(\n                    node, product_name, message\n                )\n\n        # add reformat node\n        reformat_nodes_config = kwargs[\"reformat_nodes_config\"]\n        if reformat_nodes_config[\"enabled\"]:\n            reposition_nodes = reformat_nodes_config[\"reposition_nodes\"]\n            for reposition_node in reposition_nodes:\n                node_class = reposition_node[\"node_class\"]\n                knobs = reposition_node[\"knobs\"]\n                node = nuke.createNode(node_class)\n                set_node_knobs_from_settings(node, knobs)\n\n                # connect in order\n                self._connect_to_above_nodes(\n                    node, product_name, \"Reposition node...   `{}`\"\n                )\n            # append reformatted tag\n            add_tags.append(\"reformatted\")\n\n        # Write node\n        write_node = nuke.createNode(\"Write\")\n        self.log.debug(f\"Path: {self.path}\")\n\n        write_node[\"file\"].setValue(str(self.path))\n        write_node[\"file_type\"].setValue(str(self.ext))\n        write_node[\"channels\"].setValue(str(self.color_channels))\n\n        # Knobs `meta_codec` and `mov64_codec` are not available on centos.\n        # TODO shouldn't this come from settings on outputs?\n        try:\n            write_node[\"meta_codec\"].setValue(\"ap4h\")\n        except Exception:\n            self.log.info(\"`meta_codec` knob was not found\")\n\n        try:\n            write_node[\"mov64_codec\"].setValue(\"ap4h\")\n            write_node[\"mov64_fps\"].setValue(float(fps))\n        except Exception:\n            self.log.info(\"`mov64_codec` knob was not found\")\n\n        try:\n            write_node[\"mov64_write_timecode\"].setValue(1)\n        except Exception:\n            self.log.info(\"`mov64_write_timecode` knob was not found\")\n\n        write_node[\"raw\"].setValue(1)\n\n        # connect\n        write_node.setInput(0, self.previous_node)\n        self._temp_nodes[product_name].append(write_node)\n        self.log.debug(f\"Write...   `{self._temp_nodes[product_name]}`\")\n        # ---------- end nodes creation\n\n        # ---------- render or save to nk\n        if self.publish_on_farm:\n            nuke.scriptSave()\n            path_nk = self.save_file()\n            self.data.update({\n                \"bakeScriptPath\": path_nk,\n                \"bakeWriteNodeName\": write_node.name(),\n                \"bakeRenderPath\": self.path\n            })\n        else:\n            self.render(write_node.name())\n\n        # ---------- generate representation data\n        tags = [\"review\", \"need_thumbnail\"]\n\n        if delete:\n            tags.append(\"delete\")\n\n        self.get_representation_data(\n            tags=tags + add_tags,\n            custom_tags=add_custom_tags,\n            range=True,\n            colorspace=colorspace,\n        )\n\n        self.log.debug(f\"Representation...   `{self.data}`\")\n\n        self.clean_nodes(product_name)\n        nuke.scriptSave()\n\n        return self.data\n\n    def _shift_to_previous_node_and_temp(self, product_name, node, message):\n        self._temp_nodes[product_name].append(node)\n        self.previous_node = node\n        self.log.debug(message.format(self._temp_nodes[product_name]))\n\n    def _connect_to_above_nodes(self, node, product_name, message):\n        node.setInput(0, self.previous_node)\n        self._shift_to_previous_node_and_temp(product_name, node, message)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeCreator","title":"<code>NukeCreator</code>","text":"<p>               Bases: <code>Creator</code></p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class NukeCreator(Creator):\n    node_class_name = None\n\n    def _pass_pre_attributes_to_instance(\n        self,\n        instance_data,\n        pre_create_data,\n        keys=None\n    ):\n        if keys is None:\n            keys = pre_create_data.keys()\n        creator_attrs = instance_data[\"creator_attributes\"] = {}\n\n        creator_attrs.update({\n            key: value\n            for key, value in pre_create_data.items()\n            if key in keys\n        })\n\n    def check_existing_product(self, product_name):\n        \"\"\"Make sure product name is unique.\n\n        It search within all nodes recursively\n        and checks if product name is found in\n        any node having instance data knob.\n\n        Arguments:\n            product_name (str): Product name\n        \"\"\"\n\n        for node in nuke.allNodes(recurseGroups=True):\n            # make sure testing node is having instance knob\n            if INSTANCE_DATA_KNOB not in node.knobs().keys():\n                continue\n            node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n\n            if not node_data:\n                # a node has no instance data\n                continue\n\n            # QUESTION what is this logic? Why product name is compared\n            #   against product type?\n            # test if product name is matching\n            product_base_type = node_data.get(\"productBaseType\")\n            if not product_base_type:\n                product_base_type = node_data.get(\"productType\")\n            if product_base_type == product_name:\n                raise NukeCreatorError(\n                    f\"A publish instance for '{product_name}' already exists\"\n                    \" in nodes! Please change the variant name to ensure\"\n                    \" unique output.\"\n                )\n\n    def create_instance_node(\n        self,\n        node_name,\n        knobs=None,\n        parent=None,\n        node_type=None,\n        node_selection=None,\n    ):\n        \"\"\"Create node representing instance.\n\n        Arguments:\n            node_name (str): Name of the new node.\n            knobs (OrderedDict): node knobs name and values\n            parent (str): Name of the parent node.\n            node_type (str, optional): Nuke node Class.\n            node_selection (Optional[list[nuke.Node]]): The node selection.\n\n        Returns:\n            nuke.Node: Newly created instance node.\n\n        \"\"\"\n        node_type = node_type or \"NoOp\"\n\n        node_knobs = knobs or {}\n\n        # set parent node\n        parent_node = nuke.root()\n        if parent:\n            parent_node = nuke.toNode(parent)\n\n        try:\n            with parent_node:\n                created_node = nuke.createNode(node_type)\n                created_node[\"name\"].setValue(node_name)\n\n                for key, values in node_knobs.items():\n                    if key in created_node.knobs():\n                        created_node[\"key\"].setValue(values)\n        except Exception as _err:\n            raise NukeCreatorError(\"Creating have failed: {}\".format(_err))\n\n        return created_node\n\n    def _get_current_selected_nodes(\n        self,\n        pre_create_data,\n        class_name: str = None,\n    ):\n        \"\"\" Get current node selection.\n\n        Arguments:\n            pre_create_data (dict): The creator initial data.\n            class_name (Optional[str]): Filter on a class name.\n\n        Returns:\n            list[nuke.Node]: node selection.\n        \"\"\"\n        class_name = class_name or self.node_class_name\n        use_selection = pre_create_data.get(\"use_selection\")\n\n        if use_selection:\n            selected_nodes = nuke.selectedNodes()\n        else:\n            selected_nodes = nuke.allNodes()\n\n        if class_name:\n            # Allow class name implicit last versions of class names like\n            # `Camera` to match any of its explicit versions, e.g.\n            # `Camera3` or `Camera4`.\n            if not class_name[-1].isdigit():\n                # Match name with any digit\n                pattern = rf\"^{class_name}\\d*$\"\n            else:\n                pattern = class_name\n            regex = re.compile(pattern)\n            selected_nodes = [\n                node\n                for node in selected_nodes\n                if regex.match(node.Class())\n            ]\n\n        if class_name and use_selection and not selected_nodes:\n            raise NukeCreatorError(f\"Select a {class_name} node.\")\n\n        return selected_nodes\n\n    def create(self, product_name, instance_data, pre_create_data):\n\n        # make sure selected nodes are detected early on.\n        # we do not want any further Nuke operation to change the selection.\n        node_selection = self._get_current_selected_nodes(pre_create_data)\n\n        # make sure product name is unique\n        self.check_existing_product(product_name)\n\n        product_type = instance_data.get(\"productType\")\n        if not product_type:\n            product_type = self.product_base_type\n\n        try:\n            instance_node = self.create_instance_node(\n                product_name,\n                node_type=instance_data.pop(\"node_type\", None),\n                node_selection=node_selection,\n            )\n            instance = CreatedInstance(\n                product_base_type=self.product_base_type,\n                product_type=product_type,\n                product_name=product_name,\n                data=instance_data,\n                creator=self,\n            )\n\n            self.apply_staging_dir(instance)\n            instance.transient_data[\"node\"] = instance_node\n\n            self._add_instance_to_context(instance)\n\n            set_node_data(\n                instance_node, INSTANCE_DATA_KNOB, instance.data_to_store())\n\n            return instance\n\n        except Exception as exc:\n            raise NukeCreatorError(f\"Creator error: {exc}\") from exc\n\n    def collect_instances(self):\n        cached_instances = _collect_and_cache_nodes(self)\n        attr_def_keys = {\n            attr_def.key\n            for attr_def in self.get_instance_attr_defs()\n        }\n        attr_def_keys.discard(None)\n\n        for (node, data) in cached_instances[self.identifier]:\n            created_instance = CreatedInstance.from_existing(\n                data, self\n            )\n\n            self.apply_staging_dir(created_instance)\n            created_instance.transient_data[\"node\"] = node\n            self._add_instance_to_context(created_instance)\n\n            for key in (\n                set(created_instance[\"creator_attributes\"].keys())\n                - attr_def_keys\n            ):\n                created_instance[\"creator_attributes\"].pop(key)\n\n    def update_instances(self, update_list):\n        for created_inst, changes in update_list:\n            instance_node = created_inst.transient_data[\"node\"]\n\n            # in case node is not existing anymore (user erased it manually)\n            try:\n                instance_node.fullName()\n            except ValueError:\n                self._remove_instance_from_context(created_inst)\n                continue\n\n            # update instance node name if product name changed\n            if \"productName\" in changes.changed_keys:\n                instance_node[\"name\"].setValue(\n                    changes[\"productName\"].new_value\n                )\n\n            set_node_data(\n                instance_node,\n                INSTANCE_DATA_KNOB,\n                created_inst.data_to_store()\n            )\n\n    def remove_instances(self, instances):\n        for instance in instances:\n            remove_instance(instance)\n            self._remove_instance_from_context(instance)\n\n    def get_pre_create_attr_defs(self):\n        return [\n            BoolDef(\n                \"use_selection\",\n                default=not self.create_context.headless,\n                label=\"Use selection\"\n            )\n        ]\n\n    def get_creator_settings(self, project_settings, settings_key=None):\n        if not settings_key:\n            settings_key = self.__class__.__name__\n        return project_settings[\"nuke\"][\"create\"][settings_key]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeCreator.check_existing_product","title":"<code>check_existing_product(product_name)</code>","text":"<p>Make sure product name is unique.</p> <p>It search within all nodes recursively and checks if product name is found in any node having instance data knob.</p> <p>Parameters:</p> Name Type Description Default <code>product_name</code> <code>str</code> <p>Product name</p> required Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def check_existing_product(self, product_name):\n    \"\"\"Make sure product name is unique.\n\n    It search within all nodes recursively\n    and checks if product name is found in\n    any node having instance data knob.\n\n    Arguments:\n        product_name (str): Product name\n    \"\"\"\n\n    for node in nuke.allNodes(recurseGroups=True):\n        # make sure testing node is having instance knob\n        if INSTANCE_DATA_KNOB not in node.knobs().keys():\n            continue\n        node_data = get_node_data(node, INSTANCE_DATA_KNOB)\n\n        if not node_data:\n            # a node has no instance data\n            continue\n\n        # QUESTION what is this logic? Why product name is compared\n        #   against product type?\n        # test if product name is matching\n        product_base_type = node_data.get(\"productBaseType\")\n        if not product_base_type:\n            product_base_type = node_data.get(\"productType\")\n        if product_base_type == product_name:\n            raise NukeCreatorError(\n                f\"A publish instance for '{product_name}' already exists\"\n                \" in nodes! Please change the variant name to ensure\"\n                \" unique output.\"\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeCreator.create_instance_node","title":"<code>create_instance_node(node_name, knobs=None, parent=None, node_type=None, node_selection=None)</code>","text":"<p>Create node representing instance.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Name of the new node.</p> required <code>knobs</code> <code>OrderedDict</code> <p>node knobs name and values</p> <code>None</code> <code>parent</code> <code>str</code> <p>Name of the parent node.</p> <code>None</code> <code>node_type</code> <code>str</code> <p>Nuke node Class.</p> <code>None</code> <code>node_selection</code> <code>Optional[list[Node]]</code> <p>The node selection.</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: Newly created instance node.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def create_instance_node(\n    self,\n    node_name,\n    knobs=None,\n    parent=None,\n    node_type=None,\n    node_selection=None,\n):\n    \"\"\"Create node representing instance.\n\n    Arguments:\n        node_name (str): Name of the new node.\n        knobs (OrderedDict): node knobs name and values\n        parent (str): Name of the parent node.\n        node_type (str, optional): Nuke node Class.\n        node_selection (Optional[list[nuke.Node]]): The node selection.\n\n    Returns:\n        nuke.Node: Newly created instance node.\n\n    \"\"\"\n    node_type = node_type or \"NoOp\"\n\n    node_knobs = knobs or {}\n\n    # set parent node\n    parent_node = nuke.root()\n    if parent:\n        parent_node = nuke.toNode(parent)\n\n    try:\n        with parent_node:\n            created_node = nuke.createNode(node_type)\n            created_node[\"name\"].setValue(node_name)\n\n            for key, values in node_knobs.items():\n                if key in created_node.knobs():\n                    created_node[\"key\"].setValue(values)\n    except Exception as _err:\n        raise NukeCreatorError(\"Creating have failed: {}\".format(_err))\n\n    return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeGroupLoader","title":"<code>NukeGroupLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Loader with basic logic of managing load and updates to what should be encompassed on a Single Group node inside Nuke.</p> <p>Child classes usually override only <code>on_load</code> and <code>on_update</code> to adjust the behavior.</p> <p>Exposes 'helper' method <code>connect_active_viewer</code> for child classes. This is not used by default but can be used by child classes for easy access to them.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class NukeGroupLoader(LoaderPlugin):\n    \"\"\"Loader with basic logic of managing load and updates to what should\n    be encompassed on a Single Group node inside Nuke.\n\n    Child classes usually override only `on_load` and `on_update` to adjust\n    the behavior.\n\n    Exposes 'helper' method `connect_active_viewer` for child classes.\n    This is not used by default but can be used by child classes for easy\n    access to them.\n    \"\"\"\n    settings_category = \"nuke\"\n\n    ignore_attr = [\"useLifetime\"]\n    node_color = \"0x3469ffff\"\n\n    def on_load(self, group_node: nuke.Node, namespace: str, context: dict):\n        \"\"\"Logic to be implemented on subclass to describe what to do on load.\n        \"\"\"\n        # Override to do anything\n        pass\n\n    def on_update(\n        self,\n        group_node: nuke.Node,\n        namespace: str,\n        context: dict\n    ) -&gt; nuke.Node:\n        \"\"\"Logic to be implemented on subclass to describe what to do on load.\n\n        Returns:\n            nuke.Node: The group node. This can be a new group node if it is\n                to replace the original group node.\n\n        \"\"\"\n        # Override to do anything\n        return group_node\n\n    def _create_group(self, object_name: str, context: dict):\n        \"\"\"Create a group node with a unique name\n\n        Arguments:\n            object_name (str): name of the object to create.\n            context (dict): context of version\n\n        Returns:\n            nuke.Node: created group node\n        \"\"\"\n        return nuke.createNode(\n            \"Group\",\n            \"name {}_1\".format(object_name),\n            inpanel=False\n        )\n\n    def load(self, context, name=None, namespace=None, options=None):\n        \"\"\"\n        Loading function to get the soft effects to particular read node\n\n        Arguments:\n            context (dict): context of version\n            name (str): name of the version\n            namespace (str): namespace name\n            options (dict): compulsory attribute &gt; not used\n\n        Returns:\n            nuke.Node: containerised nuke node object\n        \"\"\"\n\n        namespace = namespace or context[\"folder\"][\"name\"]\n        object_name = \"{}_{}\".format(name, namespace)\n\n        group_node = self._create_group(object_name, context)\n        self.on_load(group_node, namespace, context)\n        # On load may have deleted the group node. If it did, then we stop here\n        if not group_node:\n            return\n\n        self._set_node_color(group_node, context)\n\n        self.log.info(\n            \"Loaded setup: `{}`\".format(group_node[\"name\"].value()))\n\n        data_imprint = self._get_imprint_data(context)\n        return containerise(\n            node=group_node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n            data=data_imprint)\n\n    def update(self, container, context):\n        \"\"\"Update the Loader's path\n\n        Nuke automatically tries to reset some variables when changing\n        the loader's path to a new file. These automatic changes are to its\n        inputs:\n\n        \"\"\"\n        group_node: nuke.Node = container[\"node\"]  # Group node\n        namespace: str = container[\"namespace\"]\n\n        # Trigger load logic on the created group\n        group_node = self.on_update(group_node, namespace, context)\n\n        # change color of node\n        self._set_node_color(group_node, context)\n\n        # Update the imprinted representation\n        data_imprint = self._get_imprint_data(context)\n        update_container(\n            group_node,\n            data_imprint\n        )\n\n        self.log.info(\n            \"updated to version: {}\".format(context[\"version\"][\"version\"])\n        )\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = container[\"node\"]\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n\n    def connect_active_viewer(self, group_node):\n        \"\"\"\n        Finds Active viewer and\n        place the node under it, also adds\n        name of group into Input Process of the viewer\n\n        Arguments:\n            group_node (nuke node): nuke group node object\n\n        \"\"\"\n        group_node_name = group_node[\"name\"].value()\n\n        viewer = [n for n in nuke.allNodes() if \"Viewer1\" in n[\"name\"].value()]\n        if len(viewer) &gt; 0:\n            viewer = viewer[0]\n        else:\n            msg = \"Please create Viewer node before you run this action again\"\n            self.log.error(msg)\n            nuke.message(msg)\n            return None\n\n        # get coordinates of Viewer1\n        xpos = viewer[\"xpos\"].value()\n        ypos = viewer[\"ypos\"].value()\n\n        ypos += 150\n\n        viewer[\"ypos\"].setValue(ypos)\n\n        # set coordinates to group node\n        group_node[\"xpos\"].setValue(xpos)\n        group_node[\"ypos\"].setValue(ypos + 50)\n\n        # add group node name to Viewer Input Process\n        viewer[\"input_process_node\"].setValue(group_node_name)\n\n        # put backdrop under\n        create_backdrop(\n            label=\"Input Process\",\n            layer=2,\n            nodes=[viewer, group_node],\n            color=\"0x7c7faaff\")\n\n        return True\n\n    def _set_node_color(self, node, context):\n        \"\"\"Set node color based on whether version is latest\"\"\"\n        is_latest = ayon_api.version_is_latest(\n            context[\"project\"][\"name\"], context[\"version\"][\"id\"]\n        )\n        color_value = self.node_color if is_latest else \"0xd84f20ff\"\n        node[\"tile_color\"].setValue(int(color_value, 16))\n\n    def _get_imprint_data(self, context: dict) -&gt; dict:\n        \"\"\"Return data to be imprinted from version.\"\"\"\n        version_entity = context[\"version\"]\n        version_attributes = version_entity[\"attrib\"]\n        data = {\n            \"version\": version_entity[\"version\"],\n            \"colorspaceInput\": version_attributes.get(\"colorSpace\"),\n            # For updating\n            \"representation\": context[\"representation\"][\"id\"]\n        }\n        for k in [\n            \"frameStart\",\n            \"frameEnd\",\n            \"handleStart\",\n            \"handleEnd\",\n            \"source\",\n            \"fps\"\n        ]:\n            data[k] = version_attributes[k]\n\n        for key, value in dict(**data).items():\n            if value is None:\n                self.log.warning(\n                    f\"Skipping imprinting of key with 'None' value` {key}\")\n                data.pop(key)\n\n        return data\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeGroupLoader.connect_active_viewer","title":"<code>connect_active_viewer(group_node)</code>","text":"<p>Finds Active viewer and place the node under it, also adds name of group into Input Process of the viewer</p> <p>Parameters:</p> Name Type Description Default <code>group_node</code> <code>nuke node</code> <p>nuke group node object</p> required Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def connect_active_viewer(self, group_node):\n    \"\"\"\n    Finds Active viewer and\n    place the node under it, also adds\n    name of group into Input Process of the viewer\n\n    Arguments:\n        group_node (nuke node): nuke group node object\n\n    \"\"\"\n    group_node_name = group_node[\"name\"].value()\n\n    viewer = [n for n in nuke.allNodes() if \"Viewer1\" in n[\"name\"].value()]\n    if len(viewer) &gt; 0:\n        viewer = viewer[0]\n    else:\n        msg = \"Please create Viewer node before you run this action again\"\n        self.log.error(msg)\n        nuke.message(msg)\n        return None\n\n    # get coordinates of Viewer1\n    xpos = viewer[\"xpos\"].value()\n    ypos = viewer[\"ypos\"].value()\n\n    ypos += 150\n\n    viewer[\"ypos\"].setValue(ypos)\n\n    # set coordinates to group node\n    group_node[\"xpos\"].setValue(xpos)\n    group_node[\"ypos\"].setValue(ypos + 50)\n\n    # add group node name to Viewer Input Process\n    viewer[\"input_process_node\"].setValue(group_node_name)\n\n    # put backdrop under\n    create_backdrop(\n        label=\"Input Process\",\n        layer=2,\n        nodes=[viewer, group_node],\n        color=\"0x7c7faaff\")\n\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeGroupLoader.load","title":"<code>load(context, name=None, namespace=None, options=None)</code>","text":"<p>Loading function to get the soft effects to particular read node</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>dict</code> <p>context of version</p> required <code>name</code> <code>str</code> <p>name of the version</p> <code>None</code> <code>namespace</code> <code>str</code> <p>namespace name</p> <code>None</code> <code>options</code> <code>dict</code> <p>compulsory attribute &gt; not used</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: containerised nuke node object</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def load(self, context, name=None, namespace=None, options=None):\n    \"\"\"\n    Loading function to get the soft effects to particular read node\n\n    Arguments:\n        context (dict): context of version\n        name (str): name of the version\n        namespace (str): namespace name\n        options (dict): compulsory attribute &gt; not used\n\n    Returns:\n        nuke.Node: containerised nuke node object\n    \"\"\"\n\n    namespace = namespace or context[\"folder\"][\"name\"]\n    object_name = \"{}_{}\".format(name, namespace)\n\n    group_node = self._create_group(object_name, context)\n    self.on_load(group_node, namespace, context)\n    # On load may have deleted the group node. If it did, then we stop here\n    if not group_node:\n        return\n\n    self._set_node_color(group_node, context)\n\n    self.log.info(\n        \"Loaded setup: `{}`\".format(group_node[\"name\"].value()))\n\n    data_imprint = self._get_imprint_data(context)\n    return containerise(\n        node=group_node,\n        name=name,\n        namespace=namespace,\n        context=context,\n        loader=self.__class__.__name__,\n        data=data_imprint)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeGroupLoader.on_load","title":"<code>on_load(group_node, namespace, context)</code>","text":"<p>Logic to be implemented on subclass to describe what to do on load.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def on_load(self, group_node: nuke.Node, namespace: str, context: dict):\n    \"\"\"Logic to be implemented on subclass to describe what to do on load.\n    \"\"\"\n    # Override to do anything\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeGroupLoader.on_update","title":"<code>on_update(group_node, namespace, context)</code>","text":"<p>Logic to be implemented on subclass to describe what to do on load.</p> <p>Returns:</p> Type Description <code>Node</code> <p>nuke.Node: The group node. This can be a new group node if it is to replace the original group node.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def on_update(\n    self,\n    group_node: nuke.Node,\n    namespace: str,\n    context: dict\n) -&gt; nuke.Node:\n    \"\"\"Logic to be implemented on subclass to describe what to do on load.\n\n    Returns:\n        nuke.Node: The group node. This can be a new group node if it is\n            to replace the original group node.\n\n    \"\"\"\n    # Override to do anything\n    return group_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeGroupLoader.update","title":"<code>update(container, context)</code>","text":"<p>Update the Loader's path</p> <p>Nuke automatically tries to reset some variables when changing the loader's path to a new file. These automatic changes are to its inputs:</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def update(self, container, context):\n    \"\"\"Update the Loader's path\n\n    Nuke automatically tries to reset some variables when changing\n    the loader's path to a new file. These automatic changes are to its\n    inputs:\n\n    \"\"\"\n    group_node: nuke.Node = container[\"node\"]  # Group node\n    namespace: str = container[\"namespace\"]\n\n    # Trigger load logic on the created group\n    group_node = self.on_update(group_node, namespace, context)\n\n    # change color of node\n    self._set_node_color(group_node, context)\n\n    # Update the imprinted representation\n    data_imprint = self._get_imprint_data(context)\n    update_container(\n        group_node,\n        data_imprint\n    )\n\n    self.log.info(\n        \"updated to version: {}\".format(context[\"version\"][\"version\"])\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeLoader","title":"<code>NukeLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class NukeLoader(LoaderPlugin):\n    container_id_knob = \"containerId\"\n    container_id = None\n\n    def reset_container_id(self):\n        self.container_id = \"\".join(random.choice(\n            string.ascii_uppercase + string.digits) for _ in range(10))\n\n    def get_container_id(self, node):\n        id_knob = node.knobs().get(self.container_id_knob)\n        return id_knob.value() if id_knob else None\n\n    def get_members(self, source):\n        \"\"\"Return nodes that has same \"containerId\" as `source`\"\"\"\n        source_id = self.get_container_id(source)\n        return [node for node in nuke.allNodes(recurseGroups=True)\n                if self.get_container_id(node) == source_id\n                and node is not source] if source_id else []\n\n    def set_as_member(self, node):\n        source_id = self.get_container_id(node)\n\n        if source_id:\n            node[self.container_id_knob].setValue(source_id)\n        else:\n            HIDEN_FLAG = 0x00040000\n            _knob = Knobby(\n                \"String_Knob\",\n                self.container_id,\n                flags=[\n                    nuke.READ_ONLY,\n                    HIDEN_FLAG\n                ])\n            knob = _knob.create(self.container_id_knob)\n            node.addKnob(knob)\n\n    def clear_members(self, parent_node):\n        parent_class = parent_node.Class()\n        members = self.get_members(parent_node)\n\n        dependent_nodes = None\n        for node in members:\n            _depndc = [n for n in node.dependent() if n not in members]\n            if not _depndc:\n                continue\n\n            dependent_nodes = _depndc\n            break\n\n        for member in members:\n            if member.Class() == parent_class:\n                continue\n            self.log.info(\"removing node: `{}\".format(member.name()))\n            nuke.delete(member)\n\n        return dependent_nodes\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeLoader.get_members","title":"<code>get_members(source)</code>","text":"<p>Return nodes that has same \"containerId\" as <code>source</code></p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def get_members(self, source):\n    \"\"\"Return nodes that has same \"containerId\" as `source`\"\"\"\n    source_id = self.get_container_id(source)\n    return [node for node in nuke.allNodes(recurseGroups=True)\n            if self.get_container_id(node) == source_id\n            and node is not source] if source_id else []\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeWriteCreator","title":"<code>NukeWriteCreator</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Write node</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>class NukeWriteCreator(NukeCreator):\n    \"\"\"Add Publishable Write node\"\"\"\n\n    identifier = \"create_write\"\n    label = \"Create Write\"\n    product_type = \"write\"\n    product_base_type = \"write\"\n    icon = \"sign-out\"\n\n    temp_rendering_path_template = (  # default to be applied if settings is missing\n        \"{work}/renders/nuke/{product[name]}/{product[name]}.{frame}.{ext}\")\n\n    render_target = \"local\"  # default to be applied if settings is missing\n\n    def get_linked_knobs(self):\n        linked_knobs = []\n        if \"channels\" in self.instance_attributes:\n            linked_knobs.append(\"channels\")\n        if \"ordered\" in self.instance_attributes:\n            linked_knobs.append(\"render_order\")\n        if \"use_range_limit\" in self.instance_attributes:\n            linked_knobs.extend([\"___\", \"first\", \"last\", \"use_limit\"])\n\n        return linked_knobs\n\n    def integrate_links(self, node_selection, node, outputs=True):\n        # skip if no selection\n        if not node_selection:  # selection should contain either 1 or no node.\n            return\n\n        # collect dependencies\n        input_nodes = node_selection\n        dependent_nodes = node_selection[0].dependent() if outputs else []\n\n        # relinking to collected connections\n        for i, input in enumerate(input_nodes):\n            node.setInput(i, input)\n\n        # make it nicer in graph\n        node.autoplace()\n\n        # relink also dependent nodes\n        for dep_nodes in dependent_nodes:\n            dep_nodes.setInput(0, node)\n\n    def _get_current_selected_nodes(\n        self,\n        pre_create_data,\n    ):\n        \"\"\" Get current node selection.\n\n        Arguments:\n            pre_create_data (dict): The creator initial data.\n            class_name (Optional[str]): Filter on a class name.\n\n        Returns:\n            list[nuke.Node]: node selection.\n\n        Raises:\n            NukeCreatorError. When the selection contains more than 1 Write node.\n        \"\"\"\n        if not pre_create_data.get(\"use_selection\"):\n            return []\n\n        selected_nodes = super()._get_current_selected_nodes(\n            pre_create_data,\n            class_name=None,\n        )\n\n        if not selected_nodes:\n            raise NukeCreatorError(\"No active selection\")\n\n        elif len(selected_nodes) &gt; 1:\n            raise NukeCreatorError(\"Select only one node\")\n\n        return selected_nodes\n\n    def update_instances(self, update_list):\n        super().update_instances(update_list)\n        for created_inst, changes in update_list:\n            # ensure was not deleted by super()\n            if self.create_context.get_instance_by_id(created_inst.id):\n                self._update_write_node_filepath(created_inst, changes)\n\n    def _update_write_node_filepath(self, created_inst, changes):\n        \"\"\"Update instance node on context changes.\n\n        Whenever any of productName, folderPath, task or productType\n        changes then update:\n        - output filepath of the write node\n        - instance node's name to the product name\n        \"\"\"\n        keys = (\"productName\", \"folderPath\", \"task\", \"productType\")\n        if not any(key in changes.changed_keys for key in keys):\n            # No relevant changes, no need to update\n            return\n\n        data = created_inst.data_to_store()\n        # Update values with new formatted path\n        instance_node = created_inst.transient_data[\"node\"]\n        formatting_data = copy.deepcopy(data)\n        write_node = nuke.allNodes(group=instance_node, filter=\"Write\")[0]\n        _, ext = os.path.splitext(write_node[\"file\"].value())\n        formatting_data.update({\"ext\": ext[1:]})\n\n        # Retieve render template and staging directory.\n        fpath_template = self.temp_rendering_path_template\n        formatting_data[\"work\"] = get_work_default_directory(formatting_data)\n        fpath = StringTemplate(fpath_template).format_strict(formatting_data)\n\n        staging_dir = self.apply_staging_dir(created_inst)\n        if staging_dir:\n            basename = os.path.basename(fpath)\n            staging_path = pathlib.Path(staging_dir)/ basename\n            fpath = staging_path.as_posix()\n\n        write_node[\"file\"].setValue(fpath)\n\n    def get_pre_create_attr_defs(self):\n        attrs_defs = super().get_pre_create_attr_defs()\n        attrs_defs.append(self._get_render_target_enum())\n\n        return attrs_defs\n\n    def get_instance_attr_defs(self):\n        attr_defs = [self._get_render_target_enum()]\n\n        # add reviewable attribute\n        if \"reviewable\" in self.instance_attributes:\n            attr_defs.append(\n                BoolDef(\n                    \"review\",\n                    default=True,\n                    label=\"Review\"\n                )\n            )\n\n        return attr_defs\n\n    def _get_render_target_enum(self):\n        rendering_targets = {\n            \"local\": \"Local machine rendering\",\n            \"frames\": \"Use existing frames\"\n        }\n\n        if \"farm_rendering\" in self.instance_attributes:\n            rendering_targets.update({\n                \"frames_farm\": \"Use existing frames - farm\",\n                \"farm\": \"Farm rendering\",\n            })\n\n        return EnumDef(\n            \"render_target\",\n            items=rendering_targets,\n            default=self.render_target,\n            label=\"Render target\",\n            tooltip=\"Define the render target.\"\n        )\n\n    def create(self, product_name, instance_data, pre_create_data):\n        if not pre_create_data:\n            # add no selection for headless\n            pre_create_data = {\n                \"use_selection\": False\n            }\n\n        # pass values from precreate to instance\n        self._pass_pre_attributes_to_instance(\n            instance_data,\n            pre_create_data,\n            [\n                \"active_frame\",\n                \"render_target\"\n            ]\n        )\n        # make sure selected nodes are added\n        node_selection = self._get_current_selected_nodes(pre_create_data)\n\n        # make sure the product name is unique\n        self.check_existing_product(product_name)\n\n        product_type = instance_data.get(\"productType\")\n        if not product_type:\n            product_type = self.product_base_type\n        try:\n            instance = CreatedInstance(\n                product_base_type=self.product_base_type,\n                product_type=product_type,\n                product_name=product_name,\n                data=instance_data,\n                creator=self,\n            )\n\n            staging_dir = self.apply_staging_dir(instance)\n            instance_node = self.create_instance_node(\n                product_name,\n                instance_data,\n                staging_dir=staging_dir,\n                node_selection=node_selection,\n            )\n\n            instance.transient_data[\"node\"] = instance_node\n\n            self._add_instance_to_context(instance)\n\n            set_node_data(\n                instance_node,\n                INSTANCE_DATA_KNOB,\n                instance.data_to_store()\n            )\n\n            exposed_write_knobs(\n                self.project_settings, self.__class__.__name__, instance_node\n            )\n\n            return instance\n\n        except Exception as exc:\n            raise NukeCreatorError(f\"Creator error: {exc}\") from exc\n\n    def apply_settings(self, project_settings):\n        \"\"\"Method called on initialization of plugin to apply settings.\"\"\"\n        # plugin settings for particular creator\n        super().apply_settings(project_settings)\n        plugin_settings = self.get_creator_settings(project_settings)\n        # enabled\n        self.enabled: bool = plugin_settings.get(\"enabled\", True)\n        # order\n        self.order: int = plugin_settings.get(\"order\", 0)\n        temp_rendering_path_template = (\n            plugin_settings.get(\"temp_rendering_path_template\")\n            or self.temp_rendering_path_template\n        )\n        # individual attributes\n        self.instance_attributes = plugin_settings.get(\n            \"instance_attributes\") or self.instance_attributes\n        self.prenodes = plugin_settings[\"prenodes\"]\n        self.default_variants = plugin_settings.get(\n            \"default_variants\") or self.default_variants\n        self.render_target = plugin_settings.get(\n            \"render_target\") or self.render_target\n        self.temp_rendering_path_template = temp_rendering_path_template\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.NukeWriteCreator.apply_settings","title":"<code>apply_settings(project_settings)</code>","text":"<p>Method called on initialization of plugin to apply settings.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def apply_settings(self, project_settings):\n    \"\"\"Method called on initialization of plugin to apply settings.\"\"\"\n    # plugin settings for particular creator\n    super().apply_settings(project_settings)\n    plugin_settings = self.get_creator_settings(project_settings)\n    # enabled\n    self.enabled: bool = plugin_settings.get(\"enabled\", True)\n    # order\n    self.order: int = plugin_settings.get(\"order\", 0)\n    temp_rendering_path_template = (\n        plugin_settings.get(\"temp_rendering_path_template\")\n        or self.temp_rendering_path_template\n    )\n    # individual attributes\n    self.instance_attributes = plugin_settings.get(\n        \"instance_attributes\") or self.instance_attributes\n    self.prenodes = plugin_settings[\"prenodes\"]\n    self.default_variants = plugin_settings.get(\n        \"default_variants\") or self.default_variants\n    self.render_target = plugin_settings.get(\n        \"render_target\") or self.render_target\n    self.temp_rendering_path_template = temp_rendering_path_template\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.convert_to_valid_instaces","title":"<code>convert_to_valid_instaces()</code>","text":"<p>Check and convert to latest publisher instances</p> <p>Also save as new minor version of workfile.</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def convert_to_valid_instaces():\n    \"\"\" Check and convert to latest publisher instances\n\n    Also save as new minor version of workfile.\n    \"\"\"\n    def product_base_type_to_identifier(product_base_type):\n        mapping = {\n            \"render\": \"create_write_render\",\n            \"prerender\": \"create_write_prerender\",\n            \"still\": \"create_write_image\",\n            \"model\": \"create_model\",\n            \"camera\": \"create_camera\",\n            \"nukenodes\": \"create_backdrop\",\n            \"gizmo\": \"create_gizmo\",\n            \"source\": \"create_source\"\n        }\n        return mapping[product_base_type]\n\n    from ayon_nuke.api import workio\n\n    task_name = get_current_task_name()\n\n    # save into new workfile\n    current_file = workio.current_file()\n\n    # add file suffix if not\n    if \"_publisherConvert\" not in current_file:\n        new_workfile = (\n            current_file[:-3]\n            + \"_publisherConvert\"\n            + current_file[-3:]\n        )\n    else:\n        new_workfile = current_file\n\n    path = new_workfile.replace(\"\\\\\", \"/\")\n    nuke.scriptSaveAs(new_workfile, overwrite=1)\n    nuke.Root()[\"name\"].setValue(path)\n    nuke.Root()[\"project_directory\"].setValue(os.path.dirname(path))\n    nuke.Root().setModified(False)\n\n    _remove_old_knobs(nuke.Root())\n\n    # loop all nodes and convert\n    for node in nuke.allNodes(recurseGroups=True):\n        transfer_data = {\n            \"creator_attributes\": {}\n        }\n        creator_attr = transfer_data[\"creator_attributes\"]\n\n        if node.Class() in [\"Viewer\", \"Dot\"]:\n            continue\n\n        if get_node_data(node, INSTANCE_DATA_KNOB):\n            continue\n\n        # get data from avalon knob\n        avalon_knob_data = get_avalon_knob_data(\n            node, [\"avalon:\", \"ak:\"])\n\n        if not avalon_knob_data:\n            continue\n\n        if avalon_knob_data[\"id\"] not in {\n            AYON_INSTANCE_ID, AVALON_INSTANCE_ID\n        }:\n            continue\n\n        transfer_data.update({\n            k: v for k, v in avalon_knob_data.items()\n            if k not in [\"families\", \"creator\"]\n        })\n\n        transfer_data[\"task\"] = task_name\n\n        product_base_type = (\n            avalon_knob_data.get(\"productBaseType\")\n            or avalon_knob_data.get(\"productType\")\n            or avalon_knob_data.get(\"family\")\n        )\n\n        # establish families\n        families_ak = avalon_knob_data.get(\"families\", [])\n\n        if \"suspend_publish\" in node.knobs():\n            creator_attr[\"suspended_publish\"] = (\n                node[\"suspend_publish\"].value())\n\n        # get review knob value\n        if \"review\" in node.knobs():\n            creator_attr[\"review\"] = (\n                node[\"review\"].value())\n\n        if \"publish\" in node.knobs():\n            transfer_data[\"active\"] = (\n                node[\"publish\"].value())\n\n        # add identifier\n        transfer_data[\"creator_identifier\"] = product_base_type_to_identifier(\n            product_base_type\n        )\n\n        # Add all nodes in group instances.\n        if node.Class() == \"Group\":\n            # only alter families for render product type\n            if families_ak and \"write\" in families_ak.lower():\n                target = node[\"render\"].value()\n                if target == \"Use existing frames\":\n                    creator_attr[\"render_target\"] = \"frames\"\n                elif target == \"Local\":\n                    # Local rendering\n                    creator_attr[\"render_target\"] = \"local\"\n                elif target == \"On farm\":\n                    # Farm rendering\n                    creator_attr[\"render_target\"] = \"farm\"\n\n                if \"deadlinePriority\" in node.knobs():\n                    transfer_data[\"farm_priority\"] = (\n                        node[\"deadlinePriority\"].value())\n                if \"deadlineChunkSize\" in node.knobs():\n                    creator_attr[\"farm_chunk\"] = (\n                        node[\"deadlineChunkSize\"].value())\n                if \"deadlineConcurrentTasks\" in node.knobs():\n                    creator_attr[\"farm_concurrency\"] = (\n                        node[\"deadlineConcurrentTasks\"].value())\n\n        _remove_old_knobs(node)\n\n        # add new instance knob with transfer data\n        set_node_data(\n            node, INSTANCE_DATA_KNOB, transfer_data)\n\n    nuke.scriptSave()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/plugin.html#client.ayon_nuke.api.plugin.get_instance_group_node_childs","title":"<code>get_instance_group_node_childs(instance)</code>","text":"<p>Return list of instance group node children</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Instance</code> <p>pyblish instance</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>[nuke.Node]</p> Source code in <code>client/ayon_nuke/api/plugin.py</code> <pre><code>def get_instance_group_node_childs(instance):\n    \"\"\"Return list of instance group node children\n\n    Args:\n        instance (pyblish.Instance): pyblish instance\n\n    Returns:\n        list: [nuke.Node]\n    \"\"\"\n    node = instance.data[\"transientData\"][\"node\"]\n\n    if node.Class() != \"Group\":\n        return\n\n    # collect child nodes\n    child_nodes = []\n    # iterate all nodes\n    for node in nuke.allNodes(group=node):\n        # add contained nodes to instance's node list\n        child_nodes.append(node)\n\n    return child_nodes\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/push_to_project.html","title":"push_to_project","text":""},{"location":"autoapi/client/ayon_nuke/api/push_to_project.html#client.ayon_nuke.api.push_to_project.bake_container","title":"<code>bake_container(container)</code>","text":"<p>Bake containers to read nodes.</p> Source code in <code>client/ayon_nuke/api/push_to_project.py</code> <pre><code>def bake_container(container):\n    \"\"\"Bake containers to read nodes.\"\"\"\n\n    node = container[\"node\"]\n\n    # Fetch knobs to remove in order.\n    knobs_to_remove = []\n    remove = False\n    for count in range(0, node.numKnobs()):\n        knob = node.knob(count)\n\n        # All knobs from \"AYON\" tab knob onwards.\n        if knob.name() == MENU_LABEL:\n            remove = True\n\n        if remove:\n            knobs_to_remove.append(knob)\n\n        # Dont remove knobs from \"containerId\" onwards.\n        if knob.name() == \"containerId\":\n            remove = False\n\n    # Knobs needs to be remove in reverse order, because child knobs needs to\n    # be remove first.\n    for knob in reversed(knobs_to_remove):\n        node.removeKnob(knob)\n\n    node[\"tile_color\"].setValue(0)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/utils.html","title":"utils","text":""},{"location":"autoapi/client/ayon_nuke/api/utils.html#client.ayon_nuke.api.utils.bake_gizmos_recursively","title":"<code>bake_gizmos_recursively(in_group=None)</code>","text":"<p>Converting a gizmo to group</p> <p>Parameters:</p> Name Type Description Default <code>is_group (nuke.Node)[optonal]</code> <p>group node or all nodes</p> required Source code in <code>client/ayon_nuke/api/utils.py</code> <pre><code>def bake_gizmos_recursively(in_group=None):\n    \"\"\"Converting a gizmo to group\n\n    Arguments:\n        is_group (nuke.Node)[optonal]: group node or all nodes\n    \"\"\"\n    from .lib import maintained_selection\n    if in_group is None:\n        in_group = nuke.Root()\n    # preserve selection after all is done\n    with maintained_selection():\n        # jump to the group\n        with in_group:\n            for node in nuke.allNodes():\n                if is_node_gizmo(node) and not gizmo_is_nuke_default(node):\n                    with node:\n                        outputs = get_node_outputs(node)\n                        group = node.makeGroup()\n                        # Reconnect inputs and outputs if any\n                        if outputs:\n                            for n, pipes in outputs.items():\n                                for i in pipes:\n                                    n.setInput(i, group)\n                        for i in range(node.inputs()):\n                            group.setInput(i, node.input(i))\n                        # set node position and name\n                        group.setXYpos(node.xpos(), node.ypos())\n                        name = node.name()\n                        nuke.delete(node)\n                        group.setName(name)\n                        node = group\n\n                if node.Class() == \"Group\":\n                    bake_gizmos_recursively(node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/utils.html#client.ayon_nuke.api.utils.get_node_outputs","title":"<code>get_node_outputs(node)</code>","text":"<p>Return a dictionary of the nodes and pipes that are connected to node</p> Source code in <code>client/ayon_nuke/api/utils.py</code> <pre><code>def get_node_outputs(node):\n    '''\n    Return a dictionary of the nodes and pipes that are connected to node\n    '''\n    dep_dict = {}\n    dependencies = node.dependent(nuke.INPUTS | nuke.HIDDEN_INPUTS)\n    for d in dependencies:\n        dep_dict[d] = []\n        for i in range(d.inputs()):\n            if d.input(i) == node:\n                dep_dict[d].append(i)\n    return dep_dict\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/utils.html#client.ayon_nuke.api.utils.gizmo_is_nuke_default","title":"<code>gizmo_is_nuke_default(gizmo)</code>","text":"<p>Check if gizmo is in default install path</p> Source code in <code>client/ayon_nuke/api/utils.py</code> <pre><code>def gizmo_is_nuke_default(gizmo):\n    '''Check if gizmo is in default install path'''\n    plug_dir = os.path.join(os.path.dirname(\n        nuke.env['ExecutablePath']), 'plugins')\n    return gizmo.filename().startswith(plug_dir)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/utils.html#client.ayon_nuke.api.utils.is_headless","title":"<code>is_headless()</code>","text":"<p>Returns:</p> Name Type Description <code>bool</code> <p>headless</p> Source code in <code>client/ayon_nuke/api/utils.py</code> <pre><code>def is_headless():\n    \"\"\"\n    Returns:\n        bool: headless\n    \"\"\"\n    return QtWidgets.QApplication.instance() is None\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/utils.html#client.ayon_nuke.api.utils.is_node_gizmo","title":"<code>is_node_gizmo(node)</code>","text":"<p>return True if node is gizmo</p> Source code in <code>client/ayon_nuke/api/utils.py</code> <pre><code>def is_node_gizmo(node):\n    '''\n    return True if node is gizmo\n    '''\n    return 'gizmo_file' in node.knobs()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/utils.html#client.ayon_nuke.api.utils.set_context_favorites","title":"<code>set_context_favorites(favorites=None)</code>","text":"<p>Adding favorite folders to nuke's browser</p> <p>Parameters:</p> Name Type Description Default <code>favorites</code> <code>dict</code> <p>couples of {name:path}</p> <code>None</code> Source code in <code>client/ayon_nuke/api/utils.py</code> <pre><code>def set_context_favorites(favorites=None):\n    \"\"\" Adding favorite folders to nuke's browser\n\n    Arguments:\n        favorites (dict): couples of {name:path}\n    \"\"\"\n    favorites = favorites or {}\n    icon_path = resources.get_resource(\"icons\", \"folder-favorite.png\")\n    for name, path in favorites.items():\n        nuke.addFavoriteDir(\n            name,\n            path,\n            nuke.IMAGE | nuke.SCRIPT | nuke.GEO,\n            icon=icon_path)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/workfile_template_builder.html","title":"workfile_template_builder","text":""},{"location":"autoapi/client/ayon_nuke/api/workfile_template_builder.html#client.ayon_nuke.api.workfile_template_builder.NukePlaceholderPlugin","title":"<code>NukePlaceholderPlugin</code>","text":"<p>               Bases: <code>PlaceholderPlugin</code></p> Source code in <code>client/ayon_nuke/api/workfile_template_builder.py</code> <pre><code>class NukePlaceholderPlugin(PlaceholderPlugin):\n    node_color = 4278190335\n\n    def _collect_scene_placeholders(self):\n        # Cache placeholder data to shared data\n        placeholder_nodes = self.builder.get_shared_populate_data(\n            \"placeholder_nodes\"\n        )\n        if placeholder_nodes is None:\n            placeholder_nodes = {}\n            all_groups = collections.deque()\n            all_groups.append(nuke.thisGroup())\n            while all_groups:\n                group = all_groups.popleft()\n                for node in group.nodes():\n                    if isinstance(node, nuke.Group):\n                        all_groups.append(node)\n\n                    node_knobs = node.knobs()\n                    if (\n                        \"is_placeholder\" not in node_knobs\n                        or not node.knob(\"is_placeholder\").value()\n                    ):\n                        continue\n\n                    if \"empty\" in node_knobs and node.knob(\"empty\").value():\n                        continue\n\n                    placeholder_nodes[node.fullName()] = node\n\n            self.builder.set_shared_populate_data(\n                \"placeholder_nodes\", placeholder_nodes\n            )\n        return placeholder_nodes\n\n    def create_placeholder(self, placeholder_data):\n        placeholder_data[\"plugin_identifier\"] = self.identifier\n\n        placeholder = nuke.nodes.NoOp()\n        placeholder.setName(\"PLACEHOLDER\")\n        placeholder.knob(\"tile_color\").setValue(self.node_color)\n\n        imprint(placeholder, placeholder_data)\n        imprint(placeholder, {\"is_placeholder\": True})\n        placeholder.knob(\"is_placeholder\").setVisible(False)\n\n    def update_placeholder(self, placeholder_item, placeholder_data):\n        node = nuke.toNode(placeholder_item.scene_identifier)\n        imprint(node, placeholder_data)\n\n    def _parse_placeholder_node_data(self, node):\n        placeholder_data = {}\n        for key in self.get_placeholder_keys():\n            knob = node.knob(key)\n            value = None\n            if knob is not None:\n                value = knob.getValue()\n            placeholder_data[key] = value\n        return placeholder_data\n\n    def delete_placeholder(self, placeholder):\n        \"\"\"Remove placeholder if building was successful\"\"\"\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n        nuke.delete(placeholder_node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/workfile_template_builder.html#client.ayon_nuke.api.workfile_template_builder.NukePlaceholderPlugin.delete_placeholder","title":"<code>delete_placeholder(placeholder)</code>","text":"<p>Remove placeholder if building was successful</p> Source code in <code>client/ayon_nuke/api/workfile_template_builder.py</code> <pre><code>def delete_placeholder(self, placeholder):\n    \"\"\"Remove placeholder if building was successful\"\"\"\n    placeholder_node = nuke.toNode(placeholder.scene_identifier)\n    nuke.delete(placeholder_node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/workfile_template_builder.html#client.ayon_nuke.api.workfile_template_builder.NukeTemplateBuilder","title":"<code>NukeTemplateBuilder</code>","text":"<p>               Bases: <code>AbstractTemplateBuilder</code></p> <p>Concrete implementation of AbstractTemplateBuilder for nuke</p> Source code in <code>client/ayon_nuke/api/workfile_template_builder.py</code> <pre><code>class NukeTemplateBuilder(AbstractTemplateBuilder):\n    \"\"\"Concrete implementation of AbstractTemplateBuilder for nuke\"\"\"\n\n    def import_template(self, path):\n        \"\"\"Import template into current scene.\n        Block if a template is already loaded.\n\n        Args:\n            path (str): A path to current template (usually given by\n            get_template_preset implementation)\n\n        Returns:\n            bool: Whether the template was successfully imported or not\n        \"\"\"\n\n        # TODO check if the template is already imported\n\n        nuke.nodePaste(path)\n        reset_selection()\n\n        return True\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/workfile_template_builder.html#client.ayon_nuke.api.workfile_template_builder.NukeTemplateBuilder.import_template","title":"<code>import_template(path)</code>","text":"<p>Import template into current scene. Block if a template is already loaded.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>A path to current template (usually given by</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the template was successfully imported or not</p> Source code in <code>client/ayon_nuke/api/workfile_template_builder.py</code> <pre><code>def import_template(self, path):\n    \"\"\"Import template into current scene.\n    Block if a template is already loaded.\n\n    Args:\n        path (str): A path to current template (usually given by\n        get_template_preset implementation)\n\n    Returns:\n        bool: Whether the template was successfully imported or not\n    \"\"\"\n\n    # TODO check if the template is already imported\n\n    nuke.nodePaste(path)\n    reset_selection()\n\n    return True\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/api/workio.html","title":"workio","text":"<p>Host API required Work Files tool</p>"},{"location":"autoapi/client/ayon_nuke/hooks/index.html","title":"hooks","text":""},{"location":"autoapi/client/ayon_nuke/hooks/pre_nukeassist_setup.html","title":"pre_nukeassist_setup","text":""},{"location":"autoapi/client/ayon_nuke/hooks/pre_nukeassist_setup.html#client.ayon_nuke.hooks.pre_nukeassist_setup.PrelaunchNukeAssistHook","title":"<code>PrelaunchNukeAssistHook</code>","text":"<p>               Bases: <code>PreLaunchHook</code></p> <p>Adding flag when nukeassist</p> Source code in <code>client/ayon_nuke/hooks/pre_nukeassist_setup.py</code> <pre><code>class PrelaunchNukeAssistHook(PreLaunchHook):\n    \"\"\"\n    Adding flag when nukeassist\n    \"\"\"\n    app_groups = {\"nukeassist\"}\n    launch_types = set()\n\n    def execute(self):\n        self.launch_context.env[\"NUKEASSIST\"] = \"1\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/index.html","title":"plugins","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/index.html","title":"create","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/convert_legacy.html","title":"convert_legacy","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_backdrop.html","title":"create_backdrop","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_backdrop.html#client.ayon_nuke.plugins.create.create_backdrop.CreateBackdrop","title":"<code>CreateBackdrop</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Backdrop</p> Source code in <code>client/ayon_nuke/plugins/create/create_backdrop.py</code> <pre><code>class CreateBackdrop(NukeCreator):\n    \"\"\"Add Publishable Backdrop\"\"\"\n\n    settings_category = \"nuke\"\n\n    identifier = \"create_backdrop\"\n    label = \"Nukenodes (backdrop)\"\n    product_base_type = \"nukenodes\"\n    product_type = product_base_type\n    icon = \"file-archive-o\"\n\n    # plugin attributes\n    node_color = \"0xdfea5dff\"\n\n    def create_instance_node(\n        self,\n        node_name,\n        knobs=None,\n        parent=None,\n        node_type=None,\n        node_selection=None,\n    ):\n        \"\"\"Create node representing instance.\n\n        Arguments:\n            node_name (str): Name of the new node.\n            knobs (OrderedDict): node knobs name and values\n            parent (str): Name of the parent node.\n            node_type (str, optional): Nuke node Class.\n            node_selection (Optional[list[nuke.Node]]): The node selection.\n\n        Returns:\n            nuke.Node: Newly created instance node.\n\n        Raises:\n            NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n        \"\"\"\n        with maintained_selection():\n            if len(node_selection) &gt;= 1:\n                select_nodes(node_selection)\n\n            created_node = autoBackdrop()\n            created_node[\"name\"].setValue(node_name)\n            created_node[\"tile_color\"].setValue(int(self.node_color, 16))\n            created_node[\"note_font_size\"].setValue(24)\n            created_node[\"label\"].setValue(\"[{}]\".format(node_name))\n\n            return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_backdrop.html#client.ayon_nuke.plugins.create.create_backdrop.CreateBackdrop.create_instance_node","title":"<code>create_instance_node(node_name, knobs=None, parent=None, node_type=None, node_selection=None)</code>","text":"<p>Create node representing instance.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Name of the new node.</p> required <code>knobs</code> <code>OrderedDict</code> <p>node knobs name and values</p> <code>None</code> <code>parent</code> <code>str</code> <p>Name of the parent node.</p> <code>None</code> <code>node_type</code> <code>str</code> <p>Nuke node Class.</p> <code>None</code> <code>node_selection</code> <code>Optional[list[Node]]</code> <p>The node selection.</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: Newly created instance node.</p> Source code in <code>client/ayon_nuke/plugins/create/create_backdrop.py</code> <pre><code>def create_instance_node(\n    self,\n    node_name,\n    knobs=None,\n    parent=None,\n    node_type=None,\n    node_selection=None,\n):\n    \"\"\"Create node representing instance.\n\n    Arguments:\n        node_name (str): Name of the new node.\n        knobs (OrderedDict): node knobs name and values\n        parent (str): Name of the parent node.\n        node_type (str, optional): Nuke node Class.\n        node_selection (Optional[list[nuke.Node]]): The node selection.\n\n    Returns:\n        nuke.Node: Newly created instance node.\n\n    Raises:\n        NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n    \"\"\"\n    with maintained_selection():\n        if len(node_selection) &gt;= 1:\n            select_nodes(node_selection)\n\n        created_node = autoBackdrop()\n        created_node[\"name\"].setValue(node_name)\n        created_node[\"tile_color\"].setValue(int(self.node_color, 16))\n        created_node[\"note_font_size\"].setValue(24)\n        created_node[\"label\"].setValue(\"[{}]\".format(node_name))\n\n        return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_camera.html","title":"create_camera","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_camera.html#client.ayon_nuke.plugins.create.create_camera.CreateCamera","title":"<code>CreateCamera</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Camera</p> Source code in <code>client/ayon_nuke/plugins/create/create_camera.py</code> <pre><code>class CreateCamera(NukeCreator):\n    \"\"\"Add Publishable Camera\"\"\"\n\n    settings_category = \"nuke\"\n\n    identifier = \"create_camera\"\n    label = \"Camera (3d)\"\n    product_base_type = \"camera\"\n    product_type = product_base_type\n    icon = \"camera\"\n\n    # plugin attributes\n    node_color = \"0xff9100ff\"\n    node_class_name = \"Camera\"\n\n    def create_instance_node(\n        self,\n        node_name,\n        knobs=None,\n        parent=None,\n        node_type=None,\n        node_selection=None,\n    ):\n        \"\"\"Create node representing instance.\n\n        Arguments:\n            node_name (str): Name of the new node.\n            knobs (OrderedDict): node knobs name and values\n            parent (str): Name of the parent node.\n            node_type (str, optional): Nuke node Class.\n            node_selection (Optional[list[nuke.Node]]): The node selection.\n\n        Returns:\n            nuke.Node: Newly created instance node.\n\n        Raises:\n            NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n        \"\"\"\n        with maintained_selection():\n            if node_selection:\n                if len(node_selection) &gt; 1:\n                    raise NukeCreatorError(\n                        \"Creator error: Select only one \"\n                        f\"{self.node_class_name} node\"\n                    )\n\n                created_node = node_selection[0]\n\n            else:\n                created_node = create_camera_node_by_version()\n\n            created_node[\"tile_color\"].setValue(\n                int(self.node_color, 16))\n\n            created_node[\"name\"].setValue(node_name)\n\n            return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_camera.html#client.ayon_nuke.plugins.create.create_camera.CreateCamera.create_instance_node","title":"<code>create_instance_node(node_name, knobs=None, parent=None, node_type=None, node_selection=None)</code>","text":"<p>Create node representing instance.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Name of the new node.</p> required <code>knobs</code> <code>OrderedDict</code> <p>node knobs name and values</p> <code>None</code> <code>parent</code> <code>str</code> <p>Name of the parent node.</p> <code>None</code> <code>node_type</code> <code>str</code> <p>Nuke node Class.</p> <code>None</code> <code>node_selection</code> <code>Optional[list[Node]]</code> <p>The node selection.</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: Newly created instance node.</p> Source code in <code>client/ayon_nuke/plugins/create/create_camera.py</code> <pre><code>def create_instance_node(\n    self,\n    node_name,\n    knobs=None,\n    parent=None,\n    node_type=None,\n    node_selection=None,\n):\n    \"\"\"Create node representing instance.\n\n    Arguments:\n        node_name (str): Name of the new node.\n        knobs (OrderedDict): node knobs name and values\n        parent (str): Name of the parent node.\n        node_type (str, optional): Nuke node Class.\n        node_selection (Optional[list[nuke.Node]]): The node selection.\n\n    Returns:\n        nuke.Node: Newly created instance node.\n\n    Raises:\n        NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n    \"\"\"\n    with maintained_selection():\n        if node_selection:\n            if len(node_selection) &gt; 1:\n                raise NukeCreatorError(\n                    \"Creator error: Select only one \"\n                    f\"{self.node_class_name} node\"\n                )\n\n            created_node = node_selection[0]\n\n        else:\n            created_node = create_camera_node_by_version()\n\n        created_node[\"tile_color\"].setValue(\n            int(self.node_color, 16))\n\n        created_node[\"name\"].setValue(node_name)\n\n        return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_gizmo.html","title":"create_gizmo","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_gizmo.html#client.ayon_nuke.plugins.create.create_gizmo.CreateGizmo","title":"<code>CreateGizmo</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Group as gizmo</p> Source code in <code>client/ayon_nuke/plugins/create/create_gizmo.py</code> <pre><code>class CreateGizmo(NukeCreator):\n    \"\"\"Add Publishable Group as gizmo\"\"\"\n\n    settings_category = \"nuke\"\n\n    identifier = \"create_gizmo\"\n    label = \"Gizmo (group)\"\n    product_base_type = \"gizmo\"\n    product_type = product_base_type\n    icon = \"file-archive-o\"\n    default_variants = [\"ViewerInput\", \"Lut\", \"Effect\"]\n\n    # plugin attributes\n    node_color = \"0x7533c1ff\"\n    node_class_name = \"Group\"\n\n    def create_instance_node(\n        self,\n        node_name,\n        knobs=None,\n        parent=None,\n        node_type=None,\n        node_selection=None,\n    ):\n        \"\"\"Create node representing instance.\n\n        Arguments:\n            node_name (str): Name of the new node.\n            knobs (OrderedDict): node knobs name and values\n            parent (str): Name of the parent node.\n            node_type (str, optional): Nuke node Class.\n            node_selection (Optional[list[nuke.Node]]): The node selection.\n\n        Returns:\n            nuke.Node: Newly created instance node.\n\n        Raises:\n            NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n        \"\"\"\n        with maintained_selection():\n            if node_selection:\n                if len(node_selection) &gt; 1:\n                    raise NukeCreatorError(\n                        \"Creator error: Select only one \"\n                        f\"{self.node_class_name} node\"\n                    )\n\n                created_node = node_selection[0]\n            else:\n                created_node = nuke.collapseToGroup()\n\n            created_node[\"tile_color\"].setValue(\n                int(self.node_color, 16))\n\n            created_node[\"name\"].setValue(node_name)\n\n            return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_gizmo.html#client.ayon_nuke.plugins.create.create_gizmo.CreateGizmo.create_instance_node","title":"<code>create_instance_node(node_name, knobs=None, parent=None, node_type=None, node_selection=None)</code>","text":"<p>Create node representing instance.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Name of the new node.</p> required <code>knobs</code> <code>OrderedDict</code> <p>node knobs name and values</p> <code>None</code> <code>parent</code> <code>str</code> <p>Name of the parent node.</p> <code>None</code> <code>node_type</code> <code>str</code> <p>Nuke node Class.</p> <code>None</code> <code>node_selection</code> <code>Optional[list[Node]]</code> <p>The node selection.</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: Newly created instance node.</p> Source code in <code>client/ayon_nuke/plugins/create/create_gizmo.py</code> <pre><code>def create_instance_node(\n    self,\n    node_name,\n    knobs=None,\n    parent=None,\n    node_type=None,\n    node_selection=None,\n):\n    \"\"\"Create node representing instance.\n\n    Arguments:\n        node_name (str): Name of the new node.\n        knobs (OrderedDict): node knobs name and values\n        parent (str): Name of the parent node.\n        node_type (str, optional): Nuke node Class.\n        node_selection (Optional[list[nuke.Node]]): The node selection.\n\n    Returns:\n        nuke.Node: Newly created instance node.\n\n    Raises:\n        NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n    \"\"\"\n    with maintained_selection():\n        if node_selection:\n            if len(node_selection) &gt; 1:\n                raise NukeCreatorError(\n                    \"Creator error: Select only one \"\n                    f\"{self.node_class_name} node\"\n                )\n\n            created_node = node_selection[0]\n        else:\n            created_node = nuke.collapseToGroup()\n\n        created_node[\"tile_color\"].setValue(\n            int(self.node_color, 16))\n\n        created_node[\"name\"].setValue(node_name)\n\n        return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_model.html","title":"create_model","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_model.html#client.ayon_nuke.plugins.create.create_model.CreateModel","title":"<code>CreateModel</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Camera</p> Source code in <code>client/ayon_nuke/plugins/create/create_model.py</code> <pre><code>class CreateModel(NukeCreator):\n    \"\"\"Add Publishable Camera\"\"\"\n\n    settings_category = \"nuke\"\n\n    identifier = \"create_model\"\n    label = \"Model (3d)\"\n    product_base_type = \"model\"\n    product_type = product_base_type\n    icon = \"cube\"\n    default_variants = [\"Main\"]\n\n    # plugin attributes\n    node_color = \"0xff3200ff\"\n    node_class_name = \"Scene\"\n\n    def create_instance_node(\n        self,\n        node_name,\n        knobs=None,\n        parent=None,\n        node_type=None,\n        node_selection=None,\n    ):\n        \"\"\"Create node representing instance.\n\n        Arguments:\n            node_name (str): Name of the new node.\n            knobs (OrderedDict): node knobs name and values\n            parent (str): Name of the parent node.\n            node_type (str, optional): Nuke node Class.\n            node_selection (Optional[list[nuke.Node]]): The node selection.\n\n        Returns:\n            nuke.Node: Newly created instance node.\n\n        Raises:\n            NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n        \"\"\"\n        with maintained_selection():\n            if node_selection:\n                if len(node_selection) &gt; 1:\n                    raise NukeCreatorError(\n                        \"Creator error: Select only one \"\n                        f\"{self.node_class_name} node\"\n                    )\n\n                created_node = node_selection[0]\n            else:\n                created_node = nuke.createNode(self.node_class_name)\n\n            created_node[\"tile_color\"].setValue(\n                int(self.node_color, 16))\n\n            created_node[\"name\"].setValue(node_name)\n\n            return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_model.html#client.ayon_nuke.plugins.create.create_model.CreateModel.create_instance_node","title":"<code>create_instance_node(node_name, knobs=None, parent=None, node_type=None, node_selection=None)</code>","text":"<p>Create node representing instance.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Name of the new node.</p> required <code>knobs</code> <code>OrderedDict</code> <p>node knobs name and values</p> <code>None</code> <code>parent</code> <code>str</code> <p>Name of the parent node.</p> <code>None</code> <code>node_type</code> <code>str</code> <p>Nuke node Class.</p> <code>None</code> <code>node_selection</code> <code>Optional[list[Node]]</code> <p>The node selection.</p> <code>None</code> <p>Returns:</p> Type Description <p>nuke.Node: Newly created instance node.</p> Source code in <code>client/ayon_nuke/plugins/create/create_model.py</code> <pre><code>def create_instance_node(\n    self,\n    node_name,\n    knobs=None,\n    parent=None,\n    node_type=None,\n    node_selection=None,\n):\n    \"\"\"Create node representing instance.\n\n    Arguments:\n        node_name (str): Name of the new node.\n        knobs (OrderedDict): node knobs name and values\n        parent (str): Name of the parent node.\n        node_type (str, optional): Nuke node Class.\n        node_selection (Optional[list[nuke.Node]]): The node selection.\n\n    Returns:\n        nuke.Node: Newly created instance node.\n\n    Raises:\n        NukeCreatorError. When multiple Camera nodes are part of the selection.\n\n    \"\"\"\n    with maintained_selection():\n        if node_selection:\n            if len(node_selection) &gt; 1:\n                raise NukeCreatorError(\n                    \"Creator error: Select only one \"\n                    f\"{self.node_class_name} node\"\n                )\n\n            created_node = node_selection[0]\n        else:\n            created_node = nuke.createNode(self.node_class_name)\n\n        created_node[\"tile_color\"].setValue(\n            int(self.node_color, 16))\n\n        created_node[\"name\"].setValue(node_name)\n\n        return created_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_source.html","title":"create_source","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_source.html#client.ayon_nuke.plugins.create.create_source.CreateSource","title":"<code>CreateSource</code>","text":"<p>               Bases: <code>NukeCreator</code></p> <p>Add Publishable Read with source</p> Source code in <code>client/ayon_nuke/plugins/create/create_source.py</code> <pre><code>class CreateSource(NukeCreator):\n    \"\"\"Add Publishable Read with source\"\"\"\n\n    settings_category = \"nuke\"\n\n    identifier = \"create_source\"\n    label = \"Source (read)\"\n    product_base_type = \"source\"\n    product_type = product_base_type\n    icon = \"film\"\n    default_variants = [\"Effect\", \"Backplate\", \"Fire\", \"Smoke\"]\n\n    # plugin attributes\n    node_color = \"0xff9100ff\"\n    node_class_name = \"Read\"\n\n    def create_instance_node(\n        self,\n        node_name,\n        read_node\n    ):\n        read_node[\"tile_color\"].setValue(\n            int(self.node_color, 16))\n        read_node[\"name\"].setValue(node_name)\n\n        return read_node\n\n    def create(self, product_name, instance_data, pre_create_data):\n\n        # make sure selected nodes are added\n        node_selection = self._get_current_selected_nodes(\n            pre_create_data,\n            class_name=self.node_class_name\n        )\n\n        try:\n            for read_node in node_selection:\n\n                node_name = read_node.name()\n                _product_name = product_name + node_name\n\n                # make sure product name is unique\n                self.check_existing_product(_product_name)\n\n                instance_node = self.create_instance_node(\n                    _product_name,\n                    read_node\n                )\n                product_type = instance_data.get(\"productType\")\n                if not product_type:\n                    product_type = self.product_base_type\n                instance = CreatedInstance(\n                    product_base_type=self.product_base_type,\n                    product_type=product_type,\n                    product_name=_product_name,\n                    data=instance_data,\n                    creator=self,\n                )\n\n                # add staging dir related data to transient data\n                self.apply_staging_dir(instance)\n\n                instance.transient_data[\"node\"] = instance_node\n\n                self._add_instance_to_context(instance)\n\n                set_node_data(\n                    instance_node,\n                    INSTANCE_DATA_KNOB,\n                    instance.data_to_store()\n                )\n\n        except Exception as exc:\n            raise NukeCreatorError(f\"Creator error: {exc}\") from exc\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/create/create_write_image.html","title":"create_write_image","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_write_prerender.html","title":"create_write_prerender","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/create_write_render.html","title":"create_write_render","text":""},{"location":"autoapi/client/ayon_nuke/plugins/create/workfile_creator.html","title":"workfile_creator","text":""},{"location":"autoapi/client/ayon_nuke/plugins/inventory/index.html","title":"inventory","text":""},{"location":"autoapi/client/ayon_nuke/plugins/inventory/lock_version.html","title":"lock_version","text":""},{"location":"autoapi/client/ayon_nuke/plugins/inventory/repair_old_loaders.html","title":"repair_old_loaders","text":""},{"location":"autoapi/client/ayon_nuke/plugins/inventory/select_containers.html","title":"select_containers","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/index.html","title":"load","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/actions.html","title":"actions","text":"<p>A module containing generic loader actions that will display in the Loader.</p>"},{"location":"autoapi/client/ayon_nuke/plugins/load/actions.html#client.ayon_nuke.plugins.load.actions.SetFrameRangeLoader","title":"<code>SetFrameRangeLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Set frame range excluding pre- and post-handles</p> Source code in <code>client/ayon_nuke/plugins/load/actions.py</code> <pre><code>class SetFrameRangeLoader(load.LoaderPlugin):\n    \"\"\"Set frame range excluding pre- and post-handles\"\"\"\n\n    product_base_types = {\n        \"animation\",\n        \"camera\",\n        \"write\",\n        \"yeticache\",\n        \"pointcache\",\n    }\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"*\"}\n\n    label = \"Set frame range\"\n    order = 11\n    icon = \"clock-o\"\n    color = \"white\"\n\n    def load(self, context, name, namespace, data):\n        version_entity = context[\"version\"]\n        version_attributes = version_entity[\"attrib\"]\n\n        start = version_attributes.get(\"frameStart\")\n        end = version_attributes.get(\"frameEnd\")\n\n        log.info(\"start: {}, end: {}\".format(start, end))\n        if start is None or end is None:\n            log.info(\"Skipping setting frame range because start or \"\n                     \"end frame data is missing..\")\n            return\n\n        lib.update_frame_range(start, end)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/actions.html#client.ayon_nuke.plugins.load.actions.SetFrameRangeWithHandlesLoader","title":"<code>SetFrameRangeWithHandlesLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Set frame range including pre- and post-handles</p> Source code in <code>client/ayon_nuke/plugins/load/actions.py</code> <pre><code>class SetFrameRangeWithHandlesLoader(load.LoaderPlugin):\n    \"\"\"Set frame range including pre- and post-handles\"\"\"\n\n    product_base_types = {\n        \"animation\",\n        \"camera\",\n        \"write\",\n        \"yeticache\",\n        \"pointcache\",\n    }\n    product_types = product_base_types\n    representations = {\"*\"}\n\n    label = \"Set frame range (with handles)\"\n    order = 12\n    icon = \"clock-o\"\n    color = \"white\"\n\n    def load(self, context, name, namespace, data):\n        version_attributes = context[\"version\"][\"attrib\"]\n        start = version_attributes.get(\"frameStart\")\n        end = version_attributes.get(\"frameEnd\")\n\n        if start is None or end is None:\n            print(\"Skipping setting frame range because start or \"\n                  \"end frame data is missing..\")\n            return\n\n        # Include handles\n        start -= version_attributes.get(\"handleStart\") or 0\n        end += version_attributes.get(\"handleEnd\") or 0\n\n        lib.update_frame_range(start, end)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_backdrop.html","title":"load_backdrop","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_backdrop.html#client.ayon_nuke.plugins.load.load_backdrop.LoadBackdropNodes","title":"<code>LoadBackdropNodes</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Loading published .nk files to backdrop nodes</p> Source code in <code>client/ayon_nuke/plugins/load/load_backdrop.py</code> <pre><code>class LoadBackdropNodes(load.LoaderPlugin):\n    \"\"\"Loading published .nk files to backdrop nodes\"\"\"\n\n    product_base_types = {\"*\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"nk\"}\n\n    settings_category = \"nuke\"\n\n    label = \"Import Nuke Nodes\"\n    order = 0\n    icon = \"eye\"\n    color = \"white\"\n    node_color = \"0x7533c1ff\"\n    remove_nodes_from_backdrop = False\n\n    def load(self, context, name, namespace, data):\n        \"\"\"\n        Loading function to import .nk file into script and wrap\n        it on backdrop\n\n        Arguments:\n            context (dict): context of version\n            name (str): name of the version\n            namespace (str): namespace name\n            data (dict): compulsory attribute &gt; not used\n\n        Returns:\n            nuke node: containerised nuke node object\n        \"\"\"\n\n        # get main variables\n        namespace = namespace or context[\"folder\"][\"name\"]\n        version_entity = context[\"version\"]\n\n        version_attributes = version_entity[\"attrib\"]\n        colorspace = version_attributes.get(\"colorSpace\")\n\n        object_name = \"{}_{}\".format(name, namespace)\n\n        # prepare data for imprinting\n        data_imprint = {\n            \"version\": version_entity[\"version\"],\n            \"colorspaceInput\": colorspace\n        }\n\n        # add attributes from the version to imprint to metadata knob\n        for k in [\"source\", \"fps\"]:\n            data_imprint[k] = version_attributes[k]\n\n        # getting file path\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        # adding nodes to node graph\n        # just in case we are in group lets jump out of it\n        nuke.endGroup()\n\n        # Get mouse position\n        n = nuke.createNode(\"NoOp\")\n        xcursor, ycursor = (n.xpos(), n.ypos())\n        reset_selection()\n        nuke.delete(n)\n\n        bdn_frame = 50\n\n        with maintained_selection():\n\n            # add group from nk\n            nuke.nodePaste(file)\n\n            # get all pasted nodes\n            new_nodes = list()\n            nodes = nuke.selectedNodes()\n\n            # get pointer position in DAG\n            xpointer, ypointer = find_free_space_to_paste_nodes(\n                nodes, direction=\"right\", offset=200 + bdn_frame\n            )\n\n            # reset position to all nodes and replace inputs and output\n            for n in nodes:\n                reset_selection()\n                xpos = (n.xpos() - xcursor) + xpointer\n                ypos = (n.ypos() - ycursor) + ypointer\n                n.setXYpos(xpos, ypos)\n\n                # replace Input nodes for dots\n                if n.Class() in \"Input\":\n                    dot = nuke.createNode(\"Dot\")\n                    new_name = n.name().replace(\"INP\", \"DOT\")\n                    dot.setName(new_name)\n                    dot[\"label\"].setValue(new_name)\n                    dot.setXYpos(xpos, ypos)\n                    new_nodes.append(dot)\n\n                    # rewire\n                    dep = n.dependent()\n                    for d in dep:\n                        index = next((i for i, dpcy in enumerate(\n                                      d.dependencies())\n                                      if n is dpcy), 0)\n                        d.setInput(index, dot)\n\n                    # remove Input node\n                    reset_selection()\n                    nuke.delete(n)\n                    continue\n\n                # replace Input nodes for dots\n                elif n.Class() in \"Output\":\n                    dot = nuke.createNode(\"Dot\")\n                    new_name = n.name() + \"_DOT\"\n                    dot.setName(new_name)\n                    dot[\"label\"].setValue(new_name)\n                    dot.setXYpos(xpos, ypos)\n                    new_nodes.append(dot)\n\n                    # rewire\n                    dep = next((d for d in n.dependencies()), None)\n                    if dep:\n                        dot.setInput(0, dep)\n\n                    # remove Input node\n                    reset_selection()\n                    nuke.delete(n)\n                    continue\n                else:\n                    new_nodes.append(n)\n\n            # reselect nodes with new Dot instead of Inputs and Output\n            reset_selection()\n            select_nodes(new_nodes)\n            # place on backdrop\n            bdn = self.set_autobackdrop(xpos, ypos, object_name)\n            return containerise(\n                node=bdn,\n                name=name,\n                namespace=namespace,\n                context=context,\n                loader=self.__class__.__name__,\n                data=data_imprint)\n\n    def update(self, container, context):\n        \"\"\"Update the Loader's path\n\n        Nuke automatically tries to reset some variables when changing\n        the loader's path to a new file. These automatic changes are to its\n        inputs:\n\n        \"\"\"\n\n        # get main variables\n        # Get version from io\n        project_name = context[\"project\"][\"name\"]\n        version_entity = context[\"version\"]\n        repre_entity = context[\"representation\"]\n\n        # get corresponding node\n        GN = container[\"node\"]\n\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        name = container[\"name\"]\n        namespace = container[\"namespace\"]\n        object_name = \"{}_{}\".format(name, namespace)\n\n        version_attributes = version_entity[\"attrib\"]\n        colorspace = version_attributes.get(\"colorSpace\")\n\n        data_imprint = {\n            \"representation\": repre_entity[\"id\"],\n            \"version\": version_entity[\"version\"],\n            \"colorspaceInput\": colorspace,\n        }\n\n        for k in [\"source\", \"fps\"]:\n            data_imprint[k] = version_attributes[k]\n\n        # adding nodes to node graph\n        # just in case we are in group lets jump out of it\n        nuke.endGroup()\n\n        xpos = GN.xpos()\n        ypos = GN.ypos()\n        avalon_data = get_avalon_knob_data(GN)\n\n        # Preserve external connections (to/from outside the backdrop)\n        backdrop_nodes = GN.getNodes()\n        with restore_node_connections(backdrop_nodes):\n            for node in backdrop_nodes:\n                # Delete old backdrop nodes\n                nuke.delete(node)\n            nuke.delete(GN)\n\n            with maintained_selection():\n                # add group from nk\n                nuke.nodePaste(file)\n                # create new backdrop so that the nodes can be\n                # filled within it\n                GN = self.set_autobackdrop(xpos, ypos, object_name)\n                set_avalon_knob_data(GN, avalon_data)\n\n        # get all versions in list\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = self.node_color\n        else:\n            color_value = \"0xd88467ff\"\n        GN[\"tile_color\"].setValue(int(color_value, 16))\n\n        self.log.info(\n            \"updated to version: {}\".format(version_entity[\"version\"])\n        )\n\n        return update_container(GN, data_imprint)\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = container[\"node\"]\n        with viewer_update_and_undo_stop():\n            if self.remove_nodes_from_backdrop:\n                for child_node in node.getNodes():\n                    nuke.delete(child_node)\n            nuke.delete(node)\n\n    def set_autobackdrop(self, xpos, ypos, object_name, bdn_frame=50):\n        \"\"\"Set auto backdrop around selected nodes\n\n        Args:\n            xpos (int): x position\n            ypos (int): y position\n            object_name (str): name of the object\n            bdn_frame (int, optional): frame size around the backdrop. Defaults to 50.\n\n        Returns:\n            nuke.BackdropNode: the created backdrop node\n        \"\"\"\n        # place on backdrop\n        bdn = nukescripts.autoBackdrop()\n\n        # add frame offset\n        xpos = bdn.xpos() - bdn_frame\n        ypos = bdn.ypos() - bdn_frame\n        bdwidth = bdn[\"bdwidth\"].value() + (bdn_frame*2)\n        bdheight = bdn[\"bdheight\"].value() + (bdn_frame*2)\n\n        bdn[\"xpos\"].setValue(xpos)\n        bdn[\"ypos\"].setValue(ypos)\n        bdn[\"bdwidth\"].setValue(bdwidth)\n        bdn[\"bdheight\"].setValue(bdheight)\n\n        bdn[\"name\"].setValue(object_name)\n        bdn[\"label\"].setValue(\"Version tracked frame: \\n`{}`\\n\\nPLEASE DO NOT REMOVE OR MOVE \\nANYTHING FROM THIS FRAME!\".format(object_name))\n        bdn[\"note_font_size\"].setValue(20)\n\n        return bdn\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_backdrop.html#client.ayon_nuke.plugins.load.load_backdrop.LoadBackdropNodes.load","title":"<code>load(context, name, namespace, data)</code>","text":"<p>Loading function to import .nk file into script and wrap it on backdrop</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>dict</code> <p>context of version</p> required <code>name</code> <code>str</code> <p>name of the version</p> required <code>namespace</code> <code>str</code> <p>namespace name</p> required <code>data</code> <code>dict</code> <p>compulsory attribute &gt; not used</p> required <p>Returns:</p> Type Description <p>nuke node: containerised nuke node object</p> Source code in <code>client/ayon_nuke/plugins/load/load_backdrop.py</code> <pre><code>def load(self, context, name, namespace, data):\n    \"\"\"\n    Loading function to import .nk file into script and wrap\n    it on backdrop\n\n    Arguments:\n        context (dict): context of version\n        name (str): name of the version\n        namespace (str): namespace name\n        data (dict): compulsory attribute &gt; not used\n\n    Returns:\n        nuke node: containerised nuke node object\n    \"\"\"\n\n    # get main variables\n    namespace = namespace or context[\"folder\"][\"name\"]\n    version_entity = context[\"version\"]\n\n    version_attributes = version_entity[\"attrib\"]\n    colorspace = version_attributes.get(\"colorSpace\")\n\n    object_name = \"{}_{}\".format(name, namespace)\n\n    # prepare data for imprinting\n    data_imprint = {\n        \"version\": version_entity[\"version\"],\n        \"colorspaceInput\": colorspace\n    }\n\n    # add attributes from the version to imprint to metadata knob\n    for k in [\"source\", \"fps\"]:\n        data_imprint[k] = version_attributes[k]\n\n    # getting file path\n    file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n    # adding nodes to node graph\n    # just in case we are in group lets jump out of it\n    nuke.endGroup()\n\n    # Get mouse position\n    n = nuke.createNode(\"NoOp\")\n    xcursor, ycursor = (n.xpos(), n.ypos())\n    reset_selection()\n    nuke.delete(n)\n\n    bdn_frame = 50\n\n    with maintained_selection():\n\n        # add group from nk\n        nuke.nodePaste(file)\n\n        # get all pasted nodes\n        new_nodes = list()\n        nodes = nuke.selectedNodes()\n\n        # get pointer position in DAG\n        xpointer, ypointer = find_free_space_to_paste_nodes(\n            nodes, direction=\"right\", offset=200 + bdn_frame\n        )\n\n        # reset position to all nodes and replace inputs and output\n        for n in nodes:\n            reset_selection()\n            xpos = (n.xpos() - xcursor) + xpointer\n            ypos = (n.ypos() - ycursor) + ypointer\n            n.setXYpos(xpos, ypos)\n\n            # replace Input nodes for dots\n            if n.Class() in \"Input\":\n                dot = nuke.createNode(\"Dot\")\n                new_name = n.name().replace(\"INP\", \"DOT\")\n                dot.setName(new_name)\n                dot[\"label\"].setValue(new_name)\n                dot.setXYpos(xpos, ypos)\n                new_nodes.append(dot)\n\n                # rewire\n                dep = n.dependent()\n                for d in dep:\n                    index = next((i for i, dpcy in enumerate(\n                                  d.dependencies())\n                                  if n is dpcy), 0)\n                    d.setInput(index, dot)\n\n                # remove Input node\n                reset_selection()\n                nuke.delete(n)\n                continue\n\n            # replace Input nodes for dots\n            elif n.Class() in \"Output\":\n                dot = nuke.createNode(\"Dot\")\n                new_name = n.name() + \"_DOT\"\n                dot.setName(new_name)\n                dot[\"label\"].setValue(new_name)\n                dot.setXYpos(xpos, ypos)\n                new_nodes.append(dot)\n\n                # rewire\n                dep = next((d for d in n.dependencies()), None)\n                if dep:\n                    dot.setInput(0, dep)\n\n                # remove Input node\n                reset_selection()\n                nuke.delete(n)\n                continue\n            else:\n                new_nodes.append(n)\n\n        # reselect nodes with new Dot instead of Inputs and Output\n        reset_selection()\n        select_nodes(new_nodes)\n        # place on backdrop\n        bdn = self.set_autobackdrop(xpos, ypos, object_name)\n        return containerise(\n            node=bdn,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n            data=data_imprint)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_backdrop.html#client.ayon_nuke.plugins.load.load_backdrop.LoadBackdropNodes.set_autobackdrop","title":"<code>set_autobackdrop(xpos, ypos, object_name, bdn_frame=50)</code>","text":"<p>Set auto backdrop around selected nodes</p> <p>Parameters:</p> Name Type Description Default <code>xpos</code> <code>int</code> <p>x position</p> required <code>ypos</code> <code>int</code> <p>y position</p> required <code>object_name</code> <code>str</code> <p>name of the object</p> required <code>bdn_frame</code> <code>int</code> <p>frame size around the backdrop. Defaults to 50.</p> <code>50</code> <p>Returns:</p> Type Description <p>nuke.BackdropNode: the created backdrop node</p> Source code in <code>client/ayon_nuke/plugins/load/load_backdrop.py</code> <pre><code>def set_autobackdrop(self, xpos, ypos, object_name, bdn_frame=50):\n    \"\"\"Set auto backdrop around selected nodes\n\n    Args:\n        xpos (int): x position\n        ypos (int): y position\n        object_name (str): name of the object\n        bdn_frame (int, optional): frame size around the backdrop. Defaults to 50.\n\n    Returns:\n        nuke.BackdropNode: the created backdrop node\n    \"\"\"\n    # place on backdrop\n    bdn = nukescripts.autoBackdrop()\n\n    # add frame offset\n    xpos = bdn.xpos() - bdn_frame\n    ypos = bdn.ypos() - bdn_frame\n    bdwidth = bdn[\"bdwidth\"].value() + (bdn_frame*2)\n    bdheight = bdn[\"bdheight\"].value() + (bdn_frame*2)\n\n    bdn[\"xpos\"].setValue(xpos)\n    bdn[\"ypos\"].setValue(ypos)\n    bdn[\"bdwidth\"].setValue(bdwidth)\n    bdn[\"bdheight\"].setValue(bdheight)\n\n    bdn[\"name\"].setValue(object_name)\n    bdn[\"label\"].setValue(\"Version tracked frame: \\n`{}`\\n\\nPLEASE DO NOT REMOVE OR MOVE \\nANYTHING FROM THIS FRAME!\".format(object_name))\n    bdn[\"note_font_size\"].setValue(20)\n\n    return bdn\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_backdrop.html#client.ayon_nuke.plugins.load.load_backdrop.LoadBackdropNodes.update","title":"<code>update(container, context)</code>","text":"<p>Update the Loader's path</p> <p>Nuke automatically tries to reset some variables when changing the loader's path to a new file. These automatic changes are to its inputs:</p> Source code in <code>client/ayon_nuke/plugins/load/load_backdrop.py</code> <pre><code>def update(self, container, context):\n    \"\"\"Update the Loader's path\n\n    Nuke automatically tries to reset some variables when changing\n    the loader's path to a new file. These automatic changes are to its\n    inputs:\n\n    \"\"\"\n\n    # get main variables\n    # Get version from io\n    project_name = context[\"project\"][\"name\"]\n    version_entity = context[\"version\"]\n    repre_entity = context[\"representation\"]\n\n    # get corresponding node\n    GN = container[\"node\"]\n\n    file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n    name = container[\"name\"]\n    namespace = container[\"namespace\"]\n    object_name = \"{}_{}\".format(name, namespace)\n\n    version_attributes = version_entity[\"attrib\"]\n    colorspace = version_attributes.get(\"colorSpace\")\n\n    data_imprint = {\n        \"representation\": repre_entity[\"id\"],\n        \"version\": version_entity[\"version\"],\n        \"colorspaceInput\": colorspace,\n    }\n\n    for k in [\"source\", \"fps\"]:\n        data_imprint[k] = version_attributes[k]\n\n    # adding nodes to node graph\n    # just in case we are in group lets jump out of it\n    nuke.endGroup()\n\n    xpos = GN.xpos()\n    ypos = GN.ypos()\n    avalon_data = get_avalon_knob_data(GN)\n\n    # Preserve external connections (to/from outside the backdrop)\n    backdrop_nodes = GN.getNodes()\n    with restore_node_connections(backdrop_nodes):\n        for node in backdrop_nodes:\n            # Delete old backdrop nodes\n            nuke.delete(node)\n        nuke.delete(GN)\n\n        with maintained_selection():\n            # add group from nk\n            nuke.nodePaste(file)\n            # create new backdrop so that the nodes can be\n            # filled within it\n            GN = self.set_autobackdrop(xpos, ypos, object_name)\n            set_avalon_knob_data(GN, avalon_data)\n\n    # get all versions in list\n    last_version_entity = ayon_api.get_last_version_by_product_id(\n        project_name, version_entity[\"productId\"], fields={\"id\"}\n    )\n\n    # change color of node\n    if version_entity[\"id\"] == last_version_entity[\"id\"]:\n        color_value = self.node_color\n    else:\n        color_value = \"0xd88467ff\"\n    GN[\"tile_color\"].setValue(int(color_value, 16))\n\n    self.log.info(\n        \"updated to version: {}\".format(version_entity[\"version\"])\n    )\n\n    return update_container(GN, data_imprint)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_backdrop.html#client.ayon_nuke.plugins.load.load_backdrop.restore_node_connections","title":"<code>restore_node_connections(backdrop_nodes)</code>","text":"<p>Context manager to capture and restore node connections.</p> <p>Captures all incoming and outgoing connections before backdrop nodes are deleted, then restores them after new nodes are pasted. Uses serialized node names to avoid \"PythonObject not attached\" errors.</p> <p>Parameters:</p> Name Type Description Default <code>backdrop_nodes</code> <code>list</code> <p>List of nodes whose connections to preserve.</p> required <p>Yields:</p> Type Description <p>None</p> Source code in <code>client/ayon_nuke/plugins/load/load_backdrop.py</code> <pre><code>@contextlib.contextmanager\ndef restore_node_connections(backdrop_nodes):\n    \"\"\"Context manager to capture and restore node connections.\n\n    Captures all incoming and outgoing connections before backdrop nodes\n    are deleted, then restores them after new nodes are pasted.\n    Uses serialized node names to avoid \"PythonObject not attached\" errors.\n\n    Args:\n        backdrop_nodes (list): List of nodes whose connections to preserve.\n\n    Yields:\n        None\n    \"\"\"\n    original_connections = _capture_node_connections(backdrop_nodes)\n    try:\n        yield\n    finally:\n        # Build node map by name from current nodes\n        node_map = {\n            node.name(): node\n            for node in nuke.allNodes()\n        }\n        # Restore connections using the node map\n        for conn in original_connections:\n            _restore_connection(conn, node_map)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera.html","title":"load_camera","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera.html#client.ayon_nuke.plugins.load.load_camera.AlembicCameraLoader","title":"<code>AlembicCameraLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>This will load a camera into script.</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera.py</code> <pre><code>class AlembicCameraLoader(load.LoaderPlugin):\n    \"\"\"\n    This will load a camera into script.\n    \"\"\"\n\n    product_base_types = {\"camera\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"abc\"}\n    label = \"Load Alembic Camera\"\n    enabled = True\n\n    settings_category = \"nuke\"\n\n    icon = \"camera\"\n    color = \"orange\"\n    node_color = \"0x3469ffff\"\n\n    def load(self, context, name, namespace, data):\n        # get main variables\n        version_entity = context[\"version\"]\n\n        version_attributes = version_entity[\"attrib\"]\n        first = version_attributes.get(\"frameStart\")\n        last = version_attributes.get(\"frameEnd\")\n        fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n        namespace = namespace or context[\"folder\"][\"name\"]\n        object_name = \"{}_{}\".format(name, namespace)\n\n        # prepare data for imprinting\n        # add additional metadata from the version to imprint to metadata knob\n        data_imprint = {\n            \"frameStart\": first,\n            \"frameEnd\": last,\n            \"version\": version_entity[\"version\"],\n        }\n        for k in [\"source\", \"fps\"]:\n            data_imprint[k] = version_attributes[k]\n\n        # getting file path\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n\n            try:\n                camera_node = nuke.createNode(\n                    \"Camera3\",\n                    \"name {} file {} read_from_file True\".format(\n                        object_name, file),\n                    inpanel=False,\n                )\n            except RuntimeError: # older nuke version\n                camera_node = nuke.createNode(\n                    \"Camera2\",\n                    \"name {} file {} read_from_file True\".format(\n                        object_name, file),\n                    inpanel=False,\n                )\n\n            # get the actual name of the camera node\n            # might be different if a the desired name is already in use\n            object_name = camera_node.name()\n\n            camera_node.forceValidate()\n            camera_node[\"frame_rate\"].setValue(float(fps))\n\n            # workaround because nuke's bug is not adding\n            # animation keys properly\n            xpos = camera_node.xpos()\n            ypos = camera_node.ypos()\n            nuke.nodeCopy(\"%clipboard%\")\n            nuke.delete(camera_node)\n            nuke.nodePaste(\"%clipboard%\")\n            camera_node = nuke.toNode(object_name)\n            camera_node.setXYpos(xpos, ypos)\n\n        # color node by correct color by actual version\n        self.node_version_color(\n            context[\"project\"][\"name\"], version_entity, camera_node\n        )\n\n        return containerise(\n            node=camera_node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n            data=data_imprint)\n\n    def update(self, container, context):\n        \"\"\"\n            Called by Scene Inventory when look should be updated to current\n            version.\n            If any reference edits cannot be applied, eg. shader renamed and\n            material not present, reference is unloaded and cleaned.\n            All failed edits are highlighted to the user via message box.\n\n        Args:\n            container: object that has look to be updated\n            representation: (dict): relationship data to get proper\n                                    representation from DB and persisted\n                                    data in .json\n        Returns:\n            None\n        \"\"\"\n        # Get version from io\n        version_entity = context[\"version\"]\n        repre_entity = context[\"representation\"]\n\n        # get main variables\n        version_attributes = version_entity[\"attrib\"]\n        first = version_attributes.get(\"frameStart\")\n        last = version_attributes.get(\"frameEnd\")\n        fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n        # prepare data for imprinting\n        data_imprint = {\n            \"representation\": repre_entity[\"id\"],\n            \"frameStart\": first,\n            \"frameEnd\": last,\n            \"version\": version_entity[\"version\"]\n        }\n\n        # add attributes from the version to imprint to metadata knob\n        for k in [\"source\", \"fps\"]:\n            data_imprint[k] = version_attributes[k]\n\n        # getting file path\n        file = get_representation_path(repre_entity).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            camera_node = container[\"node\"]\n            camera_node['selected'].setValue(True)\n\n            # collect input output dependencies\n            dependencies = camera_node.dependencies()\n            dependent = camera_node.dependent()\n\n            camera_node[\"frame_rate\"].setValue(float(fps))\n            camera_node[\"file\"].setValue(file)\n\n            # workaround because nuke's bug is\n            # not adding animation keys properly\n            xpos = camera_node.xpos()\n            ypos = camera_node.ypos()\n            nuke.nodeCopy(\"%clipboard%\")\n            camera_name = camera_node.name()\n            nuke.delete(camera_node)\n            nuke.nodePaste(\"%clipboard%\")\n            camera_node = nuke.toNode(camera_name)\n            camera_node.setXYpos(xpos, ypos)\n\n            # link to original input nodes\n            for i, input in enumerate(dependencies):\n                camera_node.setInput(i, input)\n            # link to original output nodes\n            for d in dependent:\n                index = next((i for i, dpcy in enumerate(\n                              d.dependencies())\n                              if camera_node is dpcy), 0)\n                d.setInput(index, camera_node)\n\n        # color node by correct color by actual version\n        self.node_version_color(\n            context[\"project\"][\"name\"], version_entity, camera_node\n        )\n\n        self.log.info(\n            \"updated to version: {}\".format(version_entity[\"version\"])\n        )\n\n        return update_container(camera_node, data_imprint)\n\n    def node_version_color(self, project_name, version_entity, node):\n        \"\"\" Coloring a node by correct color by actual version\n        \"\"\"\n        # get all versions in list\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = self.node_color\n        else:\n            color_value = \"0xd88467ff\"\n        node[\"tile_color\"].setValue(int(color_value, 16))\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = container[\"node\"]\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera.html#client.ayon_nuke.plugins.load.load_camera.AlembicCameraLoader.node_version_color","title":"<code>node_version_color(project_name, version_entity, node)</code>","text":"<p>Coloring a node by correct color by actual version</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera.py</code> <pre><code>def node_version_color(self, project_name, version_entity, node):\n    \"\"\" Coloring a node by correct color by actual version\n    \"\"\"\n    # get all versions in list\n    last_version_entity = ayon_api.get_last_version_by_product_id(\n        project_name, version_entity[\"productId\"], fields={\"id\"}\n    )\n\n    # change color of node\n    if version_entity[\"id\"] == last_version_entity[\"id\"]:\n        color_value = self.node_color\n    else:\n        color_value = \"0xd88467ff\"\n    node[\"tile_color\"].setValue(int(color_value, 16))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera.html#client.ayon_nuke.plugins.load.load_camera.AlembicCameraLoader.update","title":"<code>update(container, context)</code>","text":"<pre><code>Called by Scene Inventory when look should be updated to current\nversion.\nIf any reference edits cannot be applied, eg. shader renamed and\nmaterial not present, reference is unloaded and cleaned.\nAll failed edits are highlighted to the user via message box.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>container</code> <p>object that has look to be updated</p> required <code>representation</code> <p>(dict): relationship data to get proper                     representation from DB and persisted                     data in .json</p> required <p>Returns:     None</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera.py</code> <pre><code>def update(self, container, context):\n    \"\"\"\n        Called by Scene Inventory when look should be updated to current\n        version.\n        If any reference edits cannot be applied, eg. shader renamed and\n        material not present, reference is unloaded and cleaned.\n        All failed edits are highlighted to the user via message box.\n\n    Args:\n        container: object that has look to be updated\n        representation: (dict): relationship data to get proper\n                                representation from DB and persisted\n                                data in .json\n    Returns:\n        None\n    \"\"\"\n    # Get version from io\n    version_entity = context[\"version\"]\n    repre_entity = context[\"representation\"]\n\n    # get main variables\n    version_attributes = version_entity[\"attrib\"]\n    first = version_attributes.get(\"frameStart\")\n    last = version_attributes.get(\"frameEnd\")\n    fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n    # prepare data for imprinting\n    data_imprint = {\n        \"representation\": repre_entity[\"id\"],\n        \"frameStart\": first,\n        \"frameEnd\": last,\n        \"version\": version_entity[\"version\"]\n    }\n\n    # add attributes from the version to imprint to metadata knob\n    for k in [\"source\", \"fps\"]:\n        data_imprint[k] = version_attributes[k]\n\n    # getting file path\n    file = get_representation_path(repre_entity).replace(\"\\\\\", \"/\")\n\n    with maintained_selection():\n        camera_node = container[\"node\"]\n        camera_node['selected'].setValue(True)\n\n        # collect input output dependencies\n        dependencies = camera_node.dependencies()\n        dependent = camera_node.dependent()\n\n        camera_node[\"frame_rate\"].setValue(float(fps))\n        camera_node[\"file\"].setValue(file)\n\n        # workaround because nuke's bug is\n        # not adding animation keys properly\n        xpos = camera_node.xpos()\n        ypos = camera_node.ypos()\n        nuke.nodeCopy(\"%clipboard%\")\n        camera_name = camera_node.name()\n        nuke.delete(camera_node)\n        nuke.nodePaste(\"%clipboard%\")\n        camera_node = nuke.toNode(camera_name)\n        camera_node.setXYpos(xpos, ypos)\n\n        # link to original input nodes\n        for i, input in enumerate(dependencies):\n            camera_node.setInput(i, input)\n        # link to original output nodes\n        for d in dependent:\n            index = next((i for i, dpcy in enumerate(\n                          d.dependencies())\n                          if camera_node is dpcy), 0)\n            d.setInput(index, camera_node)\n\n    # color node by correct color by actual version\n    self.node_version_color(\n        context[\"project\"][\"name\"], version_entity, camera_node\n    )\n\n    self.log.info(\n        \"updated to version: {}\".format(version_entity[\"version\"])\n    )\n\n    return update_container(camera_node, data_imprint)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera.html#client.ayon_nuke.plugins.load.load_camera.FbxCameraLoader","title":"<code>FbxCameraLoader</code>","text":"<p>               Bases: <code>AlembicCameraLoader</code></p> <p>This will load fbx camera into script.</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera.py</code> <pre><code>class FbxCameraLoader(AlembicCameraLoader):\n    \"\"\"\n    This will load fbx camera into script.\n    \"\"\"\n    extensions = {\"fbx\"}\n    label = \"Load FBX Camera\"\n\n    def load(self, context, name, namespace, data):\n        fbx_camera_node = super().load(context, name, namespace,data)\n\n        # Nuke forces 7 standard FBX cameras\n        # Producer Perspective, Producer Top, Producer Bottom...\n        # https://learn.foundry.com/nuke/11.1/content/comp_environment\n        # /3d_compositing/importing_fbx_cameras.html\n        # The following ensure the camera node is set to exported camera data.\n        fbx_camera_node.forceValidate() \n\n        try:\n            knob = fbx_camera_node[\"fbx_take_name\"]\n            knob.setValue(0)\n\n        except NameError:\n            # WARNING - Nuke 15: Camera3 validate does not play along\n            # very well when mixing abc + fbx nodes in the same script.\n            # They need to reloaded manually.\n            #\n            # Hopefully this will be fixed by upcoming Camera4            \n            raise RuntimeError(\n                \"Could not load incoming FBX camera properly. \"\n                \"This could be caused by a mix of abc and fbx \"\n                \"into the script.\"\n            )\n\n        knob = fbx_camera_node[\"fbx_node_name\"]\n        knob.setValue(knob.values()[-1])\n\n        return fbx_camera_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera_usd.html","title":"load_camera_usd","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera_usd.html#client.ayon_nuke.plugins.load.load_camera_usd.UsdCameraLoader","title":"<code>UsdCameraLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>This will load usd camera into script.</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera_usd.py</code> <pre><code>class UsdCameraLoader(load.LoaderPlugin):\n    \"\"\"\n    This will load usd camera into script.\n    \"\"\"\n\n    label = \"Load USD Camera\"\n    icon = \"camera\"\n    color = \"orange\"\n    order = 2\n\n    extensions = {\"usd\", \"usda\", \"usdc\"}\n    # There are essentially no 'camera' product type USD publishers available\n    # in the majority of integrations, so we allow loading any usd\n    # file. This way also USD Shots with cameras can be loaded.\n    product_base_types = {\"*\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n\n    node_color = \"0x3469ffff\"\n    settings_category = \"nuke\"\n\n    def load(self, context, name, namespace, data):\n        version_entity = context[\"version\"]\n        version_attributes = version_entity[\"attrib\"]\n        fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n        namespace: str = namespace or context[\"folder\"][\"name\"]\n        object_name: str = \"{}_{}\".format(name, namespace)\n\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            camera_node = nuke.createNode(\n                \"Camera4\",\n                \"name {} file {} import_enabled True\".format(\n                    object_name, file\n                ),\n                inpanel=False,\n            )\n            camera_node.forceValidate()\n            camera_node[\"frame_rate\"].setValue(float(fps))\n\n        # color node by correct color by actual version\n        self.node_version_color(\n            context[\"project\"][\"name\"], version_entity, camera_node\n        )\n\n        self.set_usd_camera_prim_path(camera_node)\n\n        return containerise(\n            node=camera_node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n        )\n\n    def update(self, container, context):\n        version_entity = context[\"version\"]\n        version_attributes = version_entity[\"attrib\"]\n        fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            camera_node = container[\"node\"]\n            camera_node[\"frame_rate\"].setValue(float(fps))\n            camera_node[\"file\"].setValue(file)\n\n        self.set_usd_camera_prim_path(camera_node)\n\n        # color node by correct color by actual version\n        self.node_version_color(\n            context[\"project\"][\"name\"], version_entity, camera_node\n        )\n\n        self.log.info(\n            \"updated to version: {}\".format(version_entity[\"version\"])\n        )\n\n        return update_container(camera_node, {\n            \"representation\": context[\"representation\"][\"id\"]\n        })\n\n    def node_version_color(self, project_name, version_entity, node):\n        \"\"\"Coloring a node by correct color by actual version\"\"\"\n        # get all versions in list\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = self.node_color\n        else:\n            color_value = \"0xd88467ff\"\n        node[\"tile_color\"].setValue(int(color_value, 16))\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = container[\"node\"]\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n\n    def set_usd_camera_prim_path(self, camera_node):\n        \"\"\"Set the camera prim path on the Camera4 node.\n\n        If already set and valid, does nothing. Otherwise, finds the first\n        camera prim in the USD file and sets it.\n        \"\"\"\n        # Get the USD file path from the node\n        usd_path = camera_node[\"file\"].value()\n        if not usd_path:\n            self.log.error(\"No USD file set on Camera4 node\")\n            return\n\n        # Open USD stage\n        stage = Usd.Stage.Open(usd_path)\n        if not stage:\n            self.log.error(\"Failed to open USD stage\")\n            return\n\n        # If prim path is already set (e.g. on update) and the prim\n        # is an existing camera in the stage, do nothing.\n        existing_prim_path = camera_node[\"import_prim_path\"].value()\n        if existing_prim_path:\n            prim = stage.GetPrimAtPath(existing_prim_path)\n            if prim and prim.IsA(UsdGeom.Camera):\n                self.log.info(\n                    f\"Camera prim path already set to: {existing_prim_path}\"\n                )\n                return\n\n        # Find first camera prim\n        for prim in stage.Traverse():\n            if prim.IsA(UsdGeom.Camera):\n                prim_path = prim.GetPath().pathString\n\n                # Set Import Prim Path\n                camera_node[\"import_prim_path\"].setValue(prim_path)\n\n                self.log.info(f\"Set camera to: {prim_path}\")\n                return\n\n        self.log.error(\"No camera found in USD file\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera_usd.html#client.ayon_nuke.plugins.load.load_camera_usd.UsdCameraLoader.node_version_color","title":"<code>node_version_color(project_name, version_entity, node)</code>","text":"<p>Coloring a node by correct color by actual version</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera_usd.py</code> <pre><code>def node_version_color(self, project_name, version_entity, node):\n    \"\"\"Coloring a node by correct color by actual version\"\"\"\n    # get all versions in list\n    last_version_entity = ayon_api.get_last_version_by_product_id(\n        project_name, version_entity[\"productId\"], fields={\"id\"}\n    )\n\n    # change color of node\n    if version_entity[\"id\"] == last_version_entity[\"id\"]:\n        color_value = self.node_color\n    else:\n        color_value = \"0xd88467ff\"\n    node[\"tile_color\"].setValue(int(color_value, 16))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_camera_usd.html#client.ayon_nuke.plugins.load.load_camera_usd.UsdCameraLoader.set_usd_camera_prim_path","title":"<code>set_usd_camera_prim_path(camera_node)</code>","text":"<p>Set the camera prim path on the Camera4 node.</p> <p>If already set and valid, does nothing. Otherwise, finds the first camera prim in the USD file and sets it.</p> Source code in <code>client/ayon_nuke/plugins/load/load_camera_usd.py</code> <pre><code>def set_usd_camera_prim_path(self, camera_node):\n    \"\"\"Set the camera prim path on the Camera4 node.\n\n    If already set and valid, does nothing. Otherwise, finds the first\n    camera prim in the USD file and sets it.\n    \"\"\"\n    # Get the USD file path from the node\n    usd_path = camera_node[\"file\"].value()\n    if not usd_path:\n        self.log.error(\"No USD file set on Camera4 node\")\n        return\n\n    # Open USD stage\n    stage = Usd.Stage.Open(usd_path)\n    if not stage:\n        self.log.error(\"Failed to open USD stage\")\n        return\n\n    # If prim path is already set (e.g. on update) and the prim\n    # is an existing camera in the stage, do nothing.\n    existing_prim_path = camera_node[\"import_prim_path\"].value()\n    if existing_prim_path:\n        prim = stage.GetPrimAtPath(existing_prim_path)\n        if prim and prim.IsA(UsdGeom.Camera):\n            self.log.info(\n                f\"Camera prim path already set to: {existing_prim_path}\"\n            )\n            return\n\n    # Find first camera prim\n    for prim in stage.Traverse():\n        if prim.IsA(UsdGeom.Camera):\n            prim_path = prim.GetPath().pathString\n\n            # Set Import Prim Path\n            camera_node[\"import_prim_path\"].setValue(prim_path)\n\n            self.log.info(f\"Set camera to: {prim_path}\")\n            return\n\n    self.log.error(\"No camera found in USD file\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_clip.html","title":"load_clip","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_clip.html#client.ayon_nuke.plugins.load.load_clip.LoadClip","title":"<code>LoadClip</code>","text":"<p>               Bases: <code>NukeLoader</code></p> <p>Load clip into Nuke</p> <p>Either it is image sequence or video file.</p> Source code in <code>client/ayon_nuke/plugins/load/load_clip.py</code> <pre><code>class LoadClip(plugin.NukeLoader):\n    \"\"\"Load clip into Nuke\n\n    Either it is image sequence or video file.\n    \"\"\"\n    log = Logger.get_logger(__name__)\n\n    product_base_types = {\n        \"source\",\n        \"plate\",\n        \"render\",\n        \"prerender\",\n        \"review\",\n    }\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = set(\n        ext.lstrip(\".\") for ext in IMAGE_EXTENSIONS.union(VIDEO_EXTENSIONS)\n    )\n\n    settings_category = \"nuke\"\n\n    label = \"Load Clip\"\n    order = -20\n    icon = \"file-video-o\"\n    color = \"white\"\n\n    # Loaded from settings\n    representations_include = []\n\n    script_start = int(nuke.root()[\"first_frame\"].value())\n\n    # option gui\n    options_defaults = {\n        \"start_at_workfile\": True,\n        \"add_retime\": True,\n        \"node_type\": \"auto\",\n    }\n\n    node_name_template = \"{class_name}_{ext}\"\n\n    @classmethod\n    def get_options(cls, *args):\n        return [\n            BoolDef(\n                \"start_at_workfile\",\n                label=\"Start at workfile's start frame\",\n                default=cls.options_defaults[\"start_at_workfile\"]\n            ),\n            BoolDef(\n                \"add_retime\",\n                label=\"Load with retime\",\n                default=cls.options_defaults[\"add_retime\"]\n            ),\n            EnumDef(\n                \"node_type\",\n                label=\"Read Node Type\",\n                tooltip=\"Which type of Read Node to create.\",\n                items=[\"auto\", \"Read\", \"DeepRead\"],\n                default=\"auto\",\n            ),\n        ]\n\n    @classmethod\n    def get_representations(cls):\n        return cls.representations_include or cls.representations\n\n    def load(self, context, name, namespace, options):\n        \"\"\"Load asset via database.\"\"\"\n        project_name = context[\"project\"][\"name\"]\n        repre_entity = context[\"representation\"]\n        version_entity = context[\"version\"]\n        version_attributes = version_entity[\"attrib\"]\n        version_data = version_entity[\"data\"]\n\n        # reset container id so it is always unique for each instance\n        self.reset_container_id()\n\n        # Calculate the node type before frame in path is replaced with hashes.\n        node_type = options.get(\"node_type\", self.options_defaults[\"node_type\"])\n        if node_type == \"auto\":\n            original_filepath = self.filepath_from_context(context)\n            node_type = nuke.tcl(\"node_for_sequence\", original_filepath)\n\n        is_sequence = len(repre_entity[\"files\"]) &gt; 1\n\n        if is_sequence:\n            context[\"representation\"] = (\n                self._representation_with_hash_in_frame(repre_entity)\n            )\n\n        filepath = self.filepath_from_context(context)\n        filepath = filepath.replace(\"\\\\\", \"/\")\n        self.log.debug(\"_ filepath: {}\".format(filepath))\n\n        start_at_workfile = options.get(\n            \"start_at_workfile\", self.options_defaults[\"start_at_workfile\"])\n\n        add_retime = options.get(\n            \"add_retime\", self.options_defaults[\"add_retime\"])\n\n        repre_id = repre_entity[\"id\"]\n\n        self.log.debug(\n            \"Representation id `{}` \".format(repre_id))\n\n        handle_start = version_attributes.get(\"handleStart\") or 0\n        handle_end = version_attributes.get(\"handleEnd\") or 0\n\n        first, last = self._get_frame_range(\n            version_attributes, handle_start, handle_end\n        )\n\n        # If a slate is present, the frame range is 1 frame longer for movies,\n        # but file sequences its the first frame that is 1 frame lower.\n        slate_frames = repre_entity[\"data\"].get(\"slateFrames\", 0)\n        extension = \".\" + repre_entity[\"context\"][\"ext\"]\n        files_count = len(repre_entity[\"files\"])\n\n        if first is not None and last is not None:\n            if not is_sequence:\n                duration = last - first\n                first = 1\n                last = first + duration\n            if extension in VIDEO_EXTENSIONS:\n                last += slate_frames\n            elif extension in IMAGE_EXTENSIONS and files_count != 1:\n                first -= slate_frames\n\n        # Fallback to folder name when namespace is None\n        if namespace is None:\n            namespace = context[\"folder\"][\"name\"]\n\n        if not filepath:\n            self.log.warning(\n                \"Representation id `{}` is failing to load\".format(repre_id))\n            return\n\n        read_name = self._get_node_name(context)\n        read_node = nuke.createNode(\n            node_type,\n            \"name {}\".format(read_name),\n            inpanel=False\n        )\n\n        # to avoid multiple undo steps for rest of process\n        # we will switch off undo-ing\n        with viewer_update_and_undo_stop():\n            read_node[\"file\"].setValue(filepath)\n            if read_node.Class() == \"Read\":\n                self.set_colorspace_to_node(\n                    read_node,\n                    filepath,\n                    project_name,\n                    version_entity,\n                    repre_entity\n                )\n            if first and last:\n                self._set_range_to_node(\n                    read_node, first, last, start_at_workfile, slate_frames\n                )\n            else:\n                self._set_range_to_node_by_nuke(\n                    read_node, filepath, start_at_workfile, slate_frames\n                )\n\n            version_name = version_entity[\"version\"]\n            if version_name &lt; 0:\n                version_name = \"hero\"\n\n            data_imprint = {\n                \"version\": version_name,\n            }\n\n            # add attributes from the version to imprint metadata knob\n            for key in [\n                \"frameStart\",\n                \"frameEnd\",\n                \"source\",\n                \"fps\",\n                \"handleStart\",\n                \"handleEnd\",\n            ]:\n                value = version_attributes.get(key, str(None))\n                if isinstance(value, str):\n                    value = value.replace(\"\\\\\", \"/\")\n                data_imprint[key] = value\n\n            if add_retime and version_data.get(\"retime\"):\n                data_imprint[\"addRetime\"] = True\n\n            read_node[\"tile_color\"].setValue(int(\"0x4ecd25ff\", 16))\n\n            container = containerise(\n                read_node,\n                name=name,\n                namespace=namespace,\n                context=context,\n                loader=self.__class__.__name__,\n                data=data_imprint)\n\n        if add_retime and version_data.get(\"retime\"):\n            self._make_retimes(\n                read_node,\n                version_attributes,\n                version_data,\n                handle_start\n            )\n\n        self.set_as_member(read_node)\n\n        return container\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def _representation_with_hash_in_frame(self, repre_entity):\n        \"\"\"Convert frame key value to padded hash\n\n        Args:\n            repre_entity (dict): Representation entity.\n\n        Returns:\n            dict: altered representation data\n\n        \"\"\"\n        new_repre_entity = deepcopy(repre_entity)\n        context = new_repre_entity[\"context\"]\n\n        # Get the frame from the context and hash it\n        frame = context[\"frame\"]\n        hashed_frame = \"#\" * len(str(frame))\n\n        # Replace the frame with the hash in the originalBasename\n        if (\n            \"{originalBasename}\" in new_repre_entity[\"attrib\"][\"template\"]\n        ):\n            origin_basename = context[\"originalBasename\"]\n            context[\"originalBasename\"] = origin_basename.replace(\n                frame, hashed_frame\n            )\n\n        # Replace the frame with the hash in the frame\n        new_repre_entity[\"context\"][\"frame\"] = hashed_frame\n        return new_repre_entity\n\n    def update(self, container, context):\n        \"\"\"Update the Loader's path\n\n        Nuke automatically tries to reset some variables when changing\n        the loader's path to a new file. These automatic changes are to its\n        inputs:\n\n        \"\"\"\n\n        project_name = context[\"project\"][\"name\"]\n        version_entity = context[\"version\"]\n        repre_entity = context[\"representation\"]\n\n        version_attributes = version_entity[\"attrib\"]\n        version_data = version_entity[\"data\"]\n\n        is_sequence = len(repre_entity[\"files\"]) &gt; 1\n\n        read_node = container[\"node\"]\n\n        if is_sequence:\n            repre_entity = self._representation_with_hash_in_frame(\n                repre_entity\n            )\n\n        filepath = (\n            get_representation_path(repre_entity)\n        ).replace(\"\\\\\", \"/\")\n        self.log.debug(\"_ filepath: {}\".format(filepath))\n\n        start_at_workfile = \"start at\" in read_node['frame_mode'].value()\n\n        add_retime = [\n            key for key in read_node.knobs().keys()\n            if \"addRetime\" in key\n        ]\n\n        repre_id = repre_entity[\"id\"]\n\n        handle_start = version_attributes.get(\"handleStart\") or 0\n        handle_end = version_attributes.get(\"handleEnd\") or 0\n\n        first, last = self._get_frame_range(\n            version_attributes, handle_start, handle_end\n        )\n\n        if first is not None and last is not None and not is_sequence:\n            duration = last - first\n            first = 1\n            last = first + duration\n\n        if not filepath:\n            self.log.warning(\n                \"Representation id `{}` is failing to load\".format(repre_id))\n            return\n\n        read_node[\"file\"].setValue(filepath)\n\n        # to avoid multiple undo steps for rest of process\n        # we will switch off undo-ing\n        with viewer_update_and_undo_stop():\n            if read_node.Class() == \"Read\":\n                self.set_colorspace_to_node(\n                    read_node,\n                    filepath,\n                    project_name,\n                    version_entity,\n                    repre_entity\n                )\n            if first and last:\n                self._set_range_to_node(\n                    read_node, first, last, start_at_workfile\n                )\n            else:\n                first, last = self._set_range_to_node_by_nuke(\n                    read_node, filepath, start_at_workfile\n                )\n\n            updated_dict = {\n                \"representation\": repre_entity[\"id\"],\n                \"frameStart\": str(first),\n                \"frameEnd\": str(last),\n                \"version\": str(version_entity[\"version\"]),\n                \"source\": version_attributes.get(\"source\"),\n                \"handleStart\": str(handle_start),\n                \"handleEnd\": str(handle_end),\n                \"fps\": str(version_attributes.get(\"fps\"))\n            }\n\n            last_version_entity = ayon_api.get_last_version_by_product_id(\n                project_name, version_entity[\"productId\"], fields={\"id\"}\n            )\n            # change color of read_node\n            if version_entity[\"id\"] == last_version_entity[\"id\"]:\n                color_value = \"0x4ecd25ff\"\n            else:\n                color_value = \"0xd84f20ff\"\n            read_node[\"tile_color\"].setValue(int(color_value, 16))\n\n            # Update the imprinted representation\n            update_container(read_node, updated_dict)\n            self.log.info(\n                \"updated to version: {}\".format(version_entity[\"version\"])\n            )\n\n        if add_retime and version_data.get(\"retime\"):\n            self._make_retimes(\n                read_node,\n                version_attributes,\n                version_data,\n                handle_start\n            )\n        else:\n            self.clear_members(read_node)\n\n        self.set_as_member(read_node)\n\n    def set_colorspace_to_node(\n        self,\n        read_node,\n        filepath,\n        project_name,\n        version_entity,\n        repre_entity,\n    ):\n        \"\"\"Set colorspace to read node.\n\n        Sets colorspace with available names validation.\n\n        Args:\n            read_node (nuke.Node): The nuke's read node\n            filepath (str): File path.\n            project_name (str): Project name.\n            version_entity (dict): Version entity.\n            repre_entity (dict): Representation entity.\n\n        \"\"\"\n        used_colorspace = self._get_colorspace_data(\n            project_name, version_entity, repre_entity, filepath\n        )\n        if (\n            used_colorspace\n            and colorspace_exists_on_node(read_node, used_colorspace)\n        ):\n            self.log.info(f\"Used colorspace: {used_colorspace}\")\n            read_node[\"colorspace\"].setValue(used_colorspace)\n        else:\n            self.log.info(\"Colorspace not set...\")\n\n    def remove(self, container):\n        read_node = container[\"node\"]\n        assert read_node.Class() == \"Read\", \"Must be Read\"\n\n        with viewer_update_and_undo_stop():\n            members = self.get_members(read_node)\n            nuke.delete(read_node)\n            for member in members:\n                nuke.delete(member)\n\n    def _set_range_to_node(\n        self, read_node, first, last, start_at_workfile, slate_frames=0\n    ):\n\n        read_node['origfirst'].setValue(int(first))\n        read_node['first'].setValue(int(first))\n        read_node['origlast'].setValue(int(last))\n        read_node['last'].setValue(int(last))\n\n        # set start frame depending on workfile or version\n        if start_at_workfile:\n            self._start_at_workfile_frame(read_node, slate_frames)\n\n    def _set_range_to_node_by_nuke(\n        self, read_node,filepath, start_at_workfile, slate_frames=0\n    ):\n        basename = os.path.basename(filepath)\n        dirname = os.path.dirname(filepath)\n\n        for nuke_file_name in nuke.getFileNameList(dirname):\n            if basename in nuke_file_name :\n                break\n        else:\n            raise LoadError(f\"Cannot find nuke media path for: {filepath}.\")\n\n        # Let nuke configure read node from media source.\n        nuke_media_path = os.path.join(dirname, nuke_file_name)\n        read_node[\"file\"].fromUserText(nuke_media_path)\n        frame_start = int(read_node['first'].value())\n        frame_end = int(read_node['last'].value())\n\n        if start_at_workfile:\n            self._start_at_workfile_frame(read_node, slate_frames)\n\n        return frame_start, frame_end\n\n    def _start_at_workfile_frame(self, read_node, slate_frames):\n        \"\"\"Set read node to start at workfile's start frame\"\"\"\n        read_node['frame_mode'].setValue(\"start at\")\n        start_frame = self.script_start - slate_frames\n        read_node['frame'].setValue(str(start_frame))\n\n    def _make_retimes(self, parent_node, version_attributes, version_data, handle_start):\n        ''' Create all retime and timewarping nodes with copied animation '''\n        speed = version_data.get('speed', 1)\n        time_warp_nodes = version_data.get('timewarps', [])\n        last_node = None\n        source_id = self.get_container_id(parent_node)\n        self.log.debug(\"__ source_id: {}\".format(source_id))\n        self.log.debug(\"__ members: {}\".format(\n            self.get_members(parent_node)))\n\n        dependent_nodes = self.clear_members(parent_node)\n\n        with maintained_selection():\n            parent_node['selected'].setValue(True)\n\n            if speed != 1:\n                rtn = nuke.createNode(\n                    \"Retime\",\n                    \"speed {}\".format(abs(speed))\n                )\n\n                rtn[\"before\"].setValue(\"continue\")\n                rtn[\"after\"].setValue(\"continue\")\n                rtn[\"reverse\"].setValue(speed &lt; 0)\n\n                rtn[\"input.first_lock\"].setValue(True)\n                rtn[\"input.first\"].setValue(\n                    version_attributes[\"frameStart\"]\n                )\n                rtn[\"input.last_lock\"].setValue(True)\n                rtn[\"input.last\"].setValue(\n                    version_attributes[\"frameEnd\"]\n                )\n\n                self.set_as_member(rtn)\n                last_node = rtn\n\n            if time_warp_nodes != []:\n                start_anim = self.script_start + (handle_start / speed)\n                for timewarp in time_warp_nodes:\n                    twn = nuke.createNode(\n                        timewarp[\"Class\"],\n                        \"name {}\".format(timewarp[\"name\"])\n                    )\n                    if isinstance(timewarp[\"lookup\"], list):\n                        # if array for animation\n                        twn[\"lookup\"].setAnimated()\n                        for i, value in enumerate(timewarp[\"lookup\"]):\n                            twn[\"lookup\"].setValueAt(\n                                (start_anim + i) + value,\n                                (start_anim + i))\n                    else:\n                        # if static value `int`\n                        twn[\"lookup\"].setValue(timewarp[\"lookup\"])\n\n                    self.set_as_member(twn)\n                    last_node = twn\n\n            if dependent_nodes:\n                # connect to original inputs\n                for i, n in enumerate(dependent_nodes):\n                    last_node.setInput(i, n)\n\n    def _get_node_name(self, context):\n        folder_entity = context[\"folder\"]\n        product_name = context[\"product\"][\"name\"]\n        repre_entity = context[\"representation\"]\n\n        folder_name = folder_entity[\"name\"]\n        repre_cont = repre_entity[\"context\"]\n        name_data = {\n            \"folder\": {\n                \"name\": folder_name,\n            },\n            \"product\": {\n                \"name\": product_name,\n            },\n            \"asset\": folder_name,\n            \"subset\": product_name,\n            \"representation\": repre_entity[\"name\"],\n            \"ext\": repre_cont[\"representation\"],\n            \"id\": repre_entity[\"id\"],\n            \"class_name\": self.__class__.__name__\n        }\n\n        return self.node_name_template.format(**name_data)\n\n    def _get_colorspace_data(\n        self, project_name, version_entity, repre_entity, filepath\n    ):\n        \"\"\"Get colorspace data from version and representation documents\n\n        Args:\n            project_name (str): Project name.\n            version_entity (dict): Version entity.\n            repre_entity (dict): Representation entity.\n            filepath (str): File path.\n\n        Returns:\n            Any[str,None]: colorspace name or None\n        \"\"\"\n        # Get colorspace from representation colorspaceData if colorspace is\n        # not found.\n        colorspace_data = repre_entity[\"data\"].get(\"colorspaceData\", {})\n        colorspace = colorspace_data.get(\"colorspace\")\n        self.log.debug(\n            f\"Colorspace from representation colorspaceData: {colorspace}\"\n        )\n\n        if not colorspace:\n            # Get backward compatible colorspace key.\n            colorspace = repre_entity[\"data\"].get(\"colorspace\")\n            self.log.debug(\n                f\"Colorspace from representation colorspace: {colorspace}\"\n            )\n\n        # Get backward compatible version data key if colorspace is not found.\n        if not colorspace:\n            colorspace = version_entity[\"attrib\"].get(\"colorSpace\")\n            self.log.debug(\n                f\"Colorspace from version colorspace: {colorspace}\"\n            )\n\n        config_data = get_current_context_imageio_config_preset()\n        # check if any filerules are not applicable\n        new_parsed_colorspace = get_imageio_file_rules_colorspace_from_filepath( # noqa\n            filepath, \"nuke\", project_name, config_data=config_data\n        )\n        self.log.debug(f\"Colorspace new filerules: {new_parsed_colorspace}\")\n\n        # colorspace from `project_settings/nuke/imageio/regexInputs`\n        old_parsed_colorspace = get_imageio_input_colorspace(filepath)\n        self.log.debug(f\"Colorspace old filerules: {old_parsed_colorspace}\")\n\n        return (\n            new_parsed_colorspace\n            or old_parsed_colorspace\n            or colorspace\n        )\n\n    def _get_frame_range(self, version_attributes, handle_start, handle_end):\n        \"\"\"Get first and last frame from version attributes\n\n        Args:\n            version_attributes (dict): version attributes\n            handle_start (int): handle start frames\n            handle_end (int): handle end frames\n\n        Returns:\n            tuple: first and last frame numbers\n        \"\"\"\n\n        first = version_attributes.get(\"frameStart\")\n\n        last = version_attributes.get(\"frameEnd\")\n        if not first or not last:\n            return None, None\n\n        first -= handle_start\n        last += handle_end\n\n        return first, last\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_clip.html#client.ayon_nuke.plugins.load.load_clip.LoadClip.load","title":"<code>load(context, name, namespace, options)</code>","text":"<p>Load asset via database.</p> Source code in <code>client/ayon_nuke/plugins/load/load_clip.py</code> <pre><code>def load(self, context, name, namespace, options):\n    \"\"\"Load asset via database.\"\"\"\n    project_name = context[\"project\"][\"name\"]\n    repre_entity = context[\"representation\"]\n    version_entity = context[\"version\"]\n    version_attributes = version_entity[\"attrib\"]\n    version_data = version_entity[\"data\"]\n\n    # reset container id so it is always unique for each instance\n    self.reset_container_id()\n\n    # Calculate the node type before frame in path is replaced with hashes.\n    node_type = options.get(\"node_type\", self.options_defaults[\"node_type\"])\n    if node_type == \"auto\":\n        original_filepath = self.filepath_from_context(context)\n        node_type = nuke.tcl(\"node_for_sequence\", original_filepath)\n\n    is_sequence = len(repre_entity[\"files\"]) &gt; 1\n\n    if is_sequence:\n        context[\"representation\"] = (\n            self._representation_with_hash_in_frame(repre_entity)\n        )\n\n    filepath = self.filepath_from_context(context)\n    filepath = filepath.replace(\"\\\\\", \"/\")\n    self.log.debug(\"_ filepath: {}\".format(filepath))\n\n    start_at_workfile = options.get(\n        \"start_at_workfile\", self.options_defaults[\"start_at_workfile\"])\n\n    add_retime = options.get(\n        \"add_retime\", self.options_defaults[\"add_retime\"])\n\n    repre_id = repre_entity[\"id\"]\n\n    self.log.debug(\n        \"Representation id `{}` \".format(repre_id))\n\n    handle_start = version_attributes.get(\"handleStart\") or 0\n    handle_end = version_attributes.get(\"handleEnd\") or 0\n\n    first, last = self._get_frame_range(\n        version_attributes, handle_start, handle_end\n    )\n\n    # If a slate is present, the frame range is 1 frame longer for movies,\n    # but file sequences its the first frame that is 1 frame lower.\n    slate_frames = repre_entity[\"data\"].get(\"slateFrames\", 0)\n    extension = \".\" + repre_entity[\"context\"][\"ext\"]\n    files_count = len(repre_entity[\"files\"])\n\n    if first is not None and last is not None:\n        if not is_sequence:\n            duration = last - first\n            first = 1\n            last = first + duration\n        if extension in VIDEO_EXTENSIONS:\n            last += slate_frames\n        elif extension in IMAGE_EXTENSIONS and files_count != 1:\n            first -= slate_frames\n\n    # Fallback to folder name when namespace is None\n    if namespace is None:\n        namespace = context[\"folder\"][\"name\"]\n\n    if not filepath:\n        self.log.warning(\n            \"Representation id `{}` is failing to load\".format(repre_id))\n        return\n\n    read_name = self._get_node_name(context)\n    read_node = nuke.createNode(\n        node_type,\n        \"name {}\".format(read_name),\n        inpanel=False\n    )\n\n    # to avoid multiple undo steps for rest of process\n    # we will switch off undo-ing\n    with viewer_update_and_undo_stop():\n        read_node[\"file\"].setValue(filepath)\n        if read_node.Class() == \"Read\":\n            self.set_colorspace_to_node(\n                read_node,\n                filepath,\n                project_name,\n                version_entity,\n                repre_entity\n            )\n        if first and last:\n            self._set_range_to_node(\n                read_node, first, last, start_at_workfile, slate_frames\n            )\n        else:\n            self._set_range_to_node_by_nuke(\n                read_node, filepath, start_at_workfile, slate_frames\n            )\n\n        version_name = version_entity[\"version\"]\n        if version_name &lt; 0:\n            version_name = \"hero\"\n\n        data_imprint = {\n            \"version\": version_name,\n        }\n\n        # add attributes from the version to imprint metadata knob\n        for key in [\n            \"frameStart\",\n            \"frameEnd\",\n            \"source\",\n            \"fps\",\n            \"handleStart\",\n            \"handleEnd\",\n        ]:\n            value = version_attributes.get(key, str(None))\n            if isinstance(value, str):\n                value = value.replace(\"\\\\\", \"/\")\n            data_imprint[key] = value\n\n        if add_retime and version_data.get(\"retime\"):\n            data_imprint[\"addRetime\"] = True\n\n        read_node[\"tile_color\"].setValue(int(\"0x4ecd25ff\", 16))\n\n        container = containerise(\n            read_node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n            data=data_imprint)\n\n    if add_retime and version_data.get(\"retime\"):\n        self._make_retimes(\n            read_node,\n            version_attributes,\n            version_data,\n            handle_start\n        )\n\n    self.set_as_member(read_node)\n\n    return container\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_clip.html#client.ayon_nuke.plugins.load.load_clip.LoadClip.set_colorspace_to_node","title":"<code>set_colorspace_to_node(read_node, filepath, project_name, version_entity, repre_entity)</code>","text":"<p>Set colorspace to read node.</p> <p>Sets colorspace with available names validation.</p> <p>Parameters:</p> Name Type Description Default <code>read_node</code> <code>Node</code> <p>The nuke's read node</p> required <code>filepath</code> <code>str</code> <p>File path.</p> required <code>project_name</code> <code>str</code> <p>Project name.</p> required <code>version_entity</code> <code>dict</code> <p>Version entity.</p> required <code>repre_entity</code> <code>dict</code> <p>Representation entity.</p> required Source code in <code>client/ayon_nuke/plugins/load/load_clip.py</code> <pre><code>def set_colorspace_to_node(\n    self,\n    read_node,\n    filepath,\n    project_name,\n    version_entity,\n    repre_entity,\n):\n    \"\"\"Set colorspace to read node.\n\n    Sets colorspace with available names validation.\n\n    Args:\n        read_node (nuke.Node): The nuke's read node\n        filepath (str): File path.\n        project_name (str): Project name.\n        version_entity (dict): Version entity.\n        repre_entity (dict): Representation entity.\n\n    \"\"\"\n    used_colorspace = self._get_colorspace_data(\n        project_name, version_entity, repre_entity, filepath\n    )\n    if (\n        used_colorspace\n        and colorspace_exists_on_node(read_node, used_colorspace)\n    ):\n        self.log.info(f\"Used colorspace: {used_colorspace}\")\n        read_node[\"colorspace\"].setValue(used_colorspace)\n    else:\n        self.log.info(\"Colorspace not set...\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_clip.html#client.ayon_nuke.plugins.load.load_clip.LoadClip.update","title":"<code>update(container, context)</code>","text":"<p>Update the Loader's path</p> <p>Nuke automatically tries to reset some variables when changing the loader's path to a new file. These automatic changes are to its inputs:</p> Source code in <code>client/ayon_nuke/plugins/load/load_clip.py</code> <pre><code>def update(self, container, context):\n    \"\"\"Update the Loader's path\n\n    Nuke automatically tries to reset some variables when changing\n    the loader's path to a new file. These automatic changes are to its\n    inputs:\n\n    \"\"\"\n\n    project_name = context[\"project\"][\"name\"]\n    version_entity = context[\"version\"]\n    repre_entity = context[\"representation\"]\n\n    version_attributes = version_entity[\"attrib\"]\n    version_data = version_entity[\"data\"]\n\n    is_sequence = len(repre_entity[\"files\"]) &gt; 1\n\n    read_node = container[\"node\"]\n\n    if is_sequence:\n        repre_entity = self._representation_with_hash_in_frame(\n            repre_entity\n        )\n\n    filepath = (\n        get_representation_path(repre_entity)\n    ).replace(\"\\\\\", \"/\")\n    self.log.debug(\"_ filepath: {}\".format(filepath))\n\n    start_at_workfile = \"start at\" in read_node['frame_mode'].value()\n\n    add_retime = [\n        key for key in read_node.knobs().keys()\n        if \"addRetime\" in key\n    ]\n\n    repre_id = repre_entity[\"id\"]\n\n    handle_start = version_attributes.get(\"handleStart\") or 0\n    handle_end = version_attributes.get(\"handleEnd\") or 0\n\n    first, last = self._get_frame_range(\n        version_attributes, handle_start, handle_end\n    )\n\n    if first is not None and last is not None and not is_sequence:\n        duration = last - first\n        first = 1\n        last = first + duration\n\n    if not filepath:\n        self.log.warning(\n            \"Representation id `{}` is failing to load\".format(repre_id))\n        return\n\n    read_node[\"file\"].setValue(filepath)\n\n    # to avoid multiple undo steps for rest of process\n    # we will switch off undo-ing\n    with viewer_update_and_undo_stop():\n        if read_node.Class() == \"Read\":\n            self.set_colorspace_to_node(\n                read_node,\n                filepath,\n                project_name,\n                version_entity,\n                repre_entity\n            )\n        if first and last:\n            self._set_range_to_node(\n                read_node, first, last, start_at_workfile\n            )\n        else:\n            first, last = self._set_range_to_node_by_nuke(\n                read_node, filepath, start_at_workfile\n            )\n\n        updated_dict = {\n            \"representation\": repre_entity[\"id\"],\n            \"frameStart\": str(first),\n            \"frameEnd\": str(last),\n            \"version\": str(version_entity[\"version\"]),\n            \"source\": version_attributes.get(\"source\"),\n            \"handleStart\": str(handle_start),\n            \"handleEnd\": str(handle_end),\n            \"fps\": str(version_attributes.get(\"fps\"))\n        }\n\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n        # change color of read_node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = \"0x4ecd25ff\"\n        else:\n            color_value = \"0xd84f20ff\"\n        read_node[\"tile_color\"].setValue(int(color_value, 16))\n\n        # Update the imprinted representation\n        update_container(read_node, updated_dict)\n        self.log.info(\n            \"updated to version: {}\".format(version_entity[\"version\"])\n        )\n\n    if add_retime and version_data.get(\"retime\"):\n        self._make_retimes(\n            read_node,\n            version_attributes,\n            version_data,\n            handle_start\n        )\n    else:\n        self.clear_members(read_node)\n\n    self.set_as_member(read_node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_effects.html","title":"load_effects","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_effects.html#client.ayon_nuke.plugins.load.load_effects.LoadEffects","title":"<code>LoadEffects</code>","text":"<p>               Bases: <code>NukeGroupLoader</code></p> <p>Loading colorspace soft effect exported from nukestudio</p> Source code in <code>client/ayon_nuke/plugins/load/load_effects.py</code> <pre><code>class LoadEffects(plugin.NukeGroupLoader):\n    \"\"\"Loading colorspace soft effect exported from nukestudio\"\"\"\n\n    product_base_types = {\"effect\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"json\"}\n\n    label = \"Load Effects - nodes\"\n    order = 0\n    icon = \"cc\"\n    color = \"white\"\n\n    def on_load(self, group_node, namespace, context):\n        assign_to = self._load_effects_to_group(context, group_node=group_node)\n        self.connect_read_node(group_node, namespace, assign_to)\n\n    def on_update(self, group_node, namespace, context):\n        # Do the exact same os on load\n        self.on_load(group_node, namespace, context)\n        return group_node\n\n    def connect_read_node(self, group_node, namespace, product_name):\n        \"\"\"\n        Finds read node and selects it\n\n        Arguments:\n            group_node (nuke.Node): Group node to connect to.\n            namespace (str): namespace name to search read node for.\n            product_name (str): product name to search read node for.\n\n        Returns:\n            nuke node: node is selected\n            None: if nothing found\n        \"\"\"\n        search_name = \"{0}_{1}\".format(namespace, product_name)\n\n        read_node = next(\n            (\n                n for n in nuke.allNodes(filter=\"Read\")\n                if search_name in n[\"file\"].value()\n            ),\n            None\n        )\n\n        # Parent read node has been found\n        # solving connections\n        if read_node:\n            dep_nodes = read_node.dependent()\n\n            if len(dep_nodes) &gt; 0:\n                for dn in dep_nodes:\n                    dn.setInput(0, group_node)\n\n            group_node.setInput(0, read_node)\n            group_node.autoplace()\n\n    def _load_effects_to_group(\n            self, context: dict, group_node: nuke.Node) -&gt; str:\n        \"\"\"Load the json file and create nodes inside the group node\"\"\"\n\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n        with open(file, \"r\") as f:\n            json_f = json.load(f)\n\n        # get correct order of nodes by positions on track and subtrack\n        nodes_order = self._reorder_nodes(json_f)\n\n        # adding content to the group node\n        nuke.endGroup()  # jump out of group if we happen to be in one\n        with group_node:\n            # first remove all nodes if any in the group\n            for node in group_node.nodes():\n                nuke.delete(node)\n            self._create_nodes_order(nodes_order)\n\n        return json_f[\"assignTo\"]\n\n    def _create_nodes_order(self, nodes_order: dict):\n        workfile_first_frame = int(nuke.root()[\"first_frame\"].getValue())\n\n        # create input node\n        pre_node = nuke.createNode(\"Input\")\n        pre_node[\"name\"].setValue(\"rgb\")\n\n        for ef_val in nodes_order.values():\n            node = nuke.createNode(ef_val[\"class\"])\n            for k, v in ef_val[\"node\"].items():\n                if k in self.ignore_attr:\n                    continue\n\n                # Check if attribute is available\n                try:\n                    node[k].value()\n                except NameError as e:\n                    self.log.warning(e)\n                    continue\n\n                # Set node attribute values\n                if isinstance(v, list) and len(v) &gt; 4:\n                    node[k].setAnimated()\n                    for i, value in enumerate(v):\n                        if isinstance(value, list):\n                            for ci, cv in enumerate(value):\n                                node[k].setValueAt(\n                                    cv,\n                                    (workfile_first_frame + i),\n                                    ci)\n                        else:\n                            node[k].setValueAt(\n                                value,\n                                (workfile_first_frame + i))\n                else:\n                    node[k].setValue(v)\n            node.setInput(0, pre_node)\n            pre_node = node\n\n        # create output node\n        output = nuke.createNode(\"Output\")\n        output.setInput(0, pre_node)\n\n        return pre_node\n\n    def _reorder_nodes(self, data: dict) -&gt; dict:\n        track_nums = [\n            v[\"trackIndex\"] for v in data.values() if isinstance(v, dict)]\n        sub_track_nums = [\n            v[\"subTrackIndex\"] for v in data.values() if isinstance(v, dict)]\n\n        new_order = {}\n        for track_index in range(min(track_nums), max(track_nums) + 1):\n            for sub_track_index in range(\n                    min(sub_track_nums), max(sub_track_nums) + 1):\n                item = self._get_item(data, track_index, sub_track_index)\n                if item:\n                    new_order.update(item)\n        return new_order\n\n    def _get_item(\n            self, data: dict, track_index: int, sub_track_index: int) -&gt; dict:\n        return {key: val for key, val in data.items()\n                if isinstance(val, dict)\n                if sub_track_index == val[\"subTrackIndex\"]\n                if track_index == val[\"trackIndex\"]}\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_effects.html#client.ayon_nuke.plugins.load.load_effects.LoadEffects.connect_read_node","title":"<code>connect_read_node(group_node, namespace, product_name)</code>","text":"<p>Finds read node and selects it</p> <p>Parameters:</p> Name Type Description Default <code>group_node</code> <code>Node</code> <p>Group node to connect to.</p> required <code>namespace</code> <code>str</code> <p>namespace name to search read node for.</p> required <code>product_name</code> <code>str</code> <p>product name to search read node for.</p> required <p>Returns:</p> Name Type Description <p>nuke node: node is selected</p> <code>None</code> <p>if nothing found</p> Source code in <code>client/ayon_nuke/plugins/load/load_effects.py</code> <pre><code>def connect_read_node(self, group_node, namespace, product_name):\n    \"\"\"\n    Finds read node and selects it\n\n    Arguments:\n        group_node (nuke.Node): Group node to connect to.\n        namespace (str): namespace name to search read node for.\n        product_name (str): product name to search read node for.\n\n    Returns:\n        nuke node: node is selected\n        None: if nothing found\n    \"\"\"\n    search_name = \"{0}_{1}\".format(namespace, product_name)\n\n    read_node = next(\n        (\n            n for n in nuke.allNodes(filter=\"Read\")\n            if search_name in n[\"file\"].value()\n        ),\n        None\n    )\n\n    # Parent read node has been found\n    # solving connections\n    if read_node:\n        dep_nodes = read_node.dependent()\n\n        if len(dep_nodes) &gt; 0:\n            for dn in dep_nodes:\n                dn.setInput(0, group_node)\n\n        group_node.setInput(0, read_node)\n        group_node.autoplace()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_effects.html#client.ayon_nuke.plugins.load.load_effects.LoadEffectsInputProcess","title":"<code>LoadEffectsInputProcess</code>","text":"<p>               Bases: <code>LoadEffects</code></p> <p>Loading colorspace soft effect exported from nukestudio</p> Source code in <code>client/ayon_nuke/plugins/load/load_effects.py</code> <pre><code>class LoadEffectsInputProcess(LoadEffects):\n    \"\"\"Loading colorspace soft effect exported from nukestudio\"\"\"\n\n    label = \"Load Effects - Input Process\"\n    icon = \"eye\"\n    color = \"#cc0000\"\n\n    def on_load(self, group_node, namespace, context):\n        # try to place it under Viewer1\n        self._load_effects_to_group(context, group_node=group_node)\n        if not self.connect_active_viewer(group_node):\n            nuke.delete(group_node)\n            return\n\n    def on_update(self, group_node, namespace, context):\n        # No post-process on update\n        # Only overridden to avoid behavior of LoadEffects\n        return group_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_gizmo.html","title":"load_gizmo","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_gizmo.html#client.ayon_nuke.plugins.load.load_gizmo.LoadGizmo","title":"<code>LoadGizmo</code>","text":"<p>               Bases: <code>NukeGroupLoader</code></p> <p>Loading nuke Gizmo</p> Source code in <code>client/ayon_nuke/plugins/load/load_gizmo.py</code> <pre><code>class LoadGizmo(plugin.NukeGroupLoader):\n    \"\"\"Loading nuke Gizmo\"\"\"\n\n    product_base_types = {\"gizmo\", \"lensDistortion\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"nk\"}\n\n    label = \"Load Gizmo\"\n    order = 0\n    icon = \"dropbox\"\n    color = \"white\"\n\n    node_color = \"0x75338eff\"\n\n    def _create_group(self, object_name: str, context: dict):\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        # add group from nk\n        nuke.nodePaste(file)\n\n        group_node = nuke.selectedNode()\n        group_node[\"name\"].setValue(object_name)\n\n        return group_node\n\n    def on_load(self, group_node, namespace, context):\n        # Do no post process on load, because `_create_group` did the work\n        # for us already\n        pass\n\n    def on_update(self, group_node, namespace, context):\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        # Replace the group with the new group from a new file 'paste'\n        # into the current comp\n        avalon_data = get_avalon_knob_data(group_node)\n        with maintained_selection([group_node]):\n            # insert nuke script to the script\n            nuke.nodePaste(file)\n            # convert imported to selected node\n            new_group_node = nuke.selectedNode()\n            # swap nodes with maintained connections\n            with swap_node_with_dependency(\n                    group_node, new_group_node) as node_name:\n                new_group_node[\"name\"].setValue(node_name)\n\n                # Transfer data to the new group\n                set_avalon_knob_data(new_group_node, avalon_data)\n\n        return new_group_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_gizmo.html#client.ayon_nuke.plugins.load.load_gizmo.LoadGizmoInputProcess","title":"<code>LoadGizmoInputProcess</code>","text":"<p>               Bases: <code>LoadGizmo</code></p> <p>Loading Nuke Gizmo and connect to active viewer</p> Source code in <code>client/ayon_nuke/plugins/load/load_gizmo.py</code> <pre><code>class LoadGizmoInputProcess(LoadGizmo):\n    \"\"\"Loading Nuke Gizmo and connect to active viewer\"\"\"\n\n    product_base_types = {\"gizmo\"}\n    product_types = product_base_types\n\n    label = \"Load Gizmo - Input Process\"\n    icon = \"eye\"\n    color = \"#cc0000\"\n\n    node_color = \"0x7533c1ff\"\n\n    def on_load(self, group_node, namespace, context):\n        # try to place it under Viewer1\n        if not self.connect_active_viewer(group_node):\n            nuke.delete(group_node)\n            return\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_image.html","title":"load_image","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_image.html#client.ayon_nuke.plugins.load.load_image.LoadImage","title":"<code>LoadImage</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Load still image into Nuke</p> Source code in <code>client/ayon_nuke/plugins/load/load_image.py</code> <pre><code>class LoadImage(load.LoaderPlugin):\n    \"\"\"Load still image into Nuke\"\"\"\n\n    product_base_types = {\n        \"render2d\",\n        \"source\",\n        \"plate\",\n        \"render\",\n        \"prerender\",\n        \"review\",\n        \"image\",\n        \"workfile\"\n    }\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = set(ext.lstrip(\".\") for ext in IMAGE_EXTENSIONS)\n\n    settings_category = \"nuke\"\n\n    label = \"Load Image\"\n    order = -10\n    icon = \"image\"\n    color = \"white\"\n\n    # Loaded from settings\n    representations_include = []\n\n    node_name_template = \"{class_name}_{ext}\"\n\n    options = [\n        qargparse.Integer(\n            \"frame_number\",\n            label=\"Frame Number\",\n            default=int(nuke.root()[\"first_frame\"].getValue()),\n            min=1,\n            max=999999,\n            help=\"What frame is reading from?\"\n        )\n    ]\n\n    @classmethod\n    def get_representations(cls):\n        return cls.representations_include or cls.representations\n\n    def load(self, context, name, namespace, options):\n        project_name = context[\"project\"][\"name\"]\n        repre_entity = context[\"representation\"]\n        version_entity = context[\"version\"]\n\n        self.log.info(\"__ options: `{}`\".format(options))\n        frame_number = options.get(\n            \"frame_number\", int(nuke.root()[\"first_frame\"].getValue())\n        )\n\n        version_entity = context[\"version\"]\n        version_attributes = version_entity[\"attrib\"]\n        repre_entity = context[\"representation\"]\n        repre_id = repre_entity[\"id\"]\n\n        self.log.debug(\n            \"Representation id `{}` \".format(repre_id))\n\n        last = first = int(frame_number)\n\n        # Fallback to folder name when namespace is None\n        if namespace is None:\n            namespace = context[\"folder\"][\"name\"]\n\n        filepath = self.filepath_from_context(context)\n\n        if not filepath:\n            self.log.warning(\n                \"Representation id `{}` is failing to load\".format(repre_id))\n            return\n\n        filepath = filepath.replace(\"\\\\\", \"/\")\n\n        frame = repre_entity[\"context\"].get(\"frame\")\n        if frame:\n            padding = len(frame)\n            filepath = filepath.replace(\n                frame, format(frame_number, \"0{}\".format(padding))\n            )\n\n        read_name = self._get_node_name(context)\n\n        # Create the Loader with the filename path set\n        with viewer_update_and_undo_stop():\n            read_node = nuke.createNode(\n                \"Read\", \"name {}\".format(read_name), inpanel=False\n            )\n\n            self.set_colorspace_to_node(\n                read_node,\n                filepath,\n                project_name,\n                version_entity,\n                repre_entity\n            )\n\n            read_node[\"file\"].setValue(filepath)\n            read_node[\"origfirst\"].setValue(first)\n            read_node[\"first\"].setValue(first)\n            read_node[\"origlast\"].setValue(last)\n            read_node[\"last\"].setValue(last)\n\n            # add attributes from the version to imprint metadata knob\n            data_imprint = {\n                \"frameStart\": first,\n                \"frameEnd\": last,\n                \"version\": version_entity[\"version\"]\n            }\n            for k in [\"source\", \"fps\"]:\n                data_imprint[k] = version_attributes.get(k, str(None))\n\n            read_node[\"tile_color\"].setValue(int(\"0x4ecd25ff\", 16))\n\n            return containerise(\n                read_node,\n                name=name,\n                namespace=namespace,\n                context=context,\n                loader=self.__class__.__name__,\n                data=data_imprint,\n            )\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def update(self, container, context):\n        \"\"\"Update the Loader's path\n\n        Nuke automatically tries to reset some variables when changing\n        the loader's path to a new file. These automatic changes are to its\n        inputs:\n\n        \"\"\"\n        read_node = container[\"node\"]\n        frame_number = read_node[\"first\"].value()\n\n        assert read_node.Class() == \"Read\", \"Must be Read\"\n\n        project_name = context[\"project\"][\"name\"]\n        version_entity = context[\"version\"]\n        repre_entity = context[\"representation\"]\n\n        repr_cont = repre_entity[\"context\"]\n\n        filepath = self.filepath_from_context(context)\n\n        if not filepath:\n            repre_id = repre_entity[\"id\"]\n            self.log.warning(\n                \"Representation id `{}` is failing to load\".format(repre_id))\n            return\n\n        filepath = filepath.replace(\"\\\\\", \"/\")\n\n        frame = repr_cont.get(\"frame\")\n        if frame:\n            padding = len(frame)\n            filepath = filepath.replace(\n                frame, format(frame_number, \"0{}\".format(padding))\n            )\n\n        # Get start frame from version data\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n\n        last = first = int(frame_number)\n\n        self.set_colorspace_to_node(\n            read_node, filepath, project_name, version_entity, repre_entity\n        )\n        # Set the global in to the start frame of the sequence\n        read_node[\"file\"].setValue(filepath)\n        read_node[\"origfirst\"].setValue(first)\n        read_node[\"first\"].setValue(first)\n        read_node[\"origlast\"].setValue(last)\n        read_node[\"last\"].setValue(last)\n\n        version_attributes = version_entity[\"attrib\"]\n        updated_dict = {\n            \"representation\": repre_entity[\"id\"],\n            \"frameStart\": str(first),\n            \"frameEnd\": str(last),\n            \"version\": str(version_entity[\"version\"]),\n            \"source\": version_attributes.get(\"source\"),\n            \"fps\": str(version_attributes.get(\"fps\")),\n        }\n\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = \"0x4ecd25ff\"\n        else:\n            color_value = \"0xd84f20ff\"\n        read_node[\"tile_color\"].setValue(int(color_value, 16))\n\n        # Update the imprinted representation\n        update_container(read_node, updated_dict)\n        self.log.info(\"updated to version: {}\".format(\n            version_entity[\"version\"]\n        ))\n\n    def remove(self, container):\n        node = container[\"node\"]\n        assert node.Class() == \"Read\", \"Must be Read\"\n\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n\n    def _get_node_name(self, context):\n        folder_entity = context[\"folder\"]\n        product_name = context[\"product\"][\"name\"]\n        repre_entity = context[\"representation\"]\n\n        folder_name = folder_entity[\"name\"]\n        repre_cont = repre_entity[\"context\"]\n        name_data = {\n            \"folder\": {\n                \"name\": folder_name,\n            },\n            \"product\": {\n                \"name\": product_name,\n            },\n            \"asset\": folder_name,\n            \"subset\": product_name,\n            \"representation\": repre_entity[\"name\"],\n            \"ext\": repre_cont[\"representation\"],\n            \"id\": repre_entity[\"id\"],\n            \"class_name\": self.__class__.__name__\n        }\n\n        return self.node_name_template.format(**name_data)\n\n    def set_colorspace_to_node(\n        self,\n        read_node,\n        filepath,\n        project_name,\n        version_entity,\n        repre_entity,\n    ):\n        \"\"\"Set colorspace to read node.\n\n        Sets colorspace with available names validation.\n\n        Args:\n            read_node (nuke.Node): The nuke's read node\n            filepath (str): File path.\n            project_name (str): Project name.\n            version_entity (dict): Version entity.\n            repre_entity (dict): Representation entity.\n\n        \"\"\"\n        used_colorspace = self._get_colorspace_data(\n            project_name, version_entity, repre_entity, filepath\n        )\n        if (\n            used_colorspace\n            and colorspace_exists_on_node(read_node, used_colorspace)\n        ):\n            self.log.info(f\"Used colorspace: {used_colorspace}\")\n            read_node[\"colorspace\"].setValue(used_colorspace)\n        else:\n            self.log.info(\"Colorspace not set...\")\n\n    def _get_colorspace_data(\n        self, project_name, version_entity, repre_entity, filepath\n    ):\n        \"\"\"Get colorspace data from version and representation documents\n\n        Args:\n            project_name (str): Project name.\n            version_entity (dict): Version entity.\n            repre_entity (dict): Representation entity.\n            filepath (str): File path.\n\n        Returns:\n            Any[str,None]: colorspace name or None\n        \"\"\"\n        # Get colorspace from representation colorspaceData if colorspace is\n        # not found.\n        colorspace_data = repre_entity[\"data\"].get(\"colorspaceData\", {})\n        colorspace = colorspace_data.get(\"colorspace\")\n        self.log.debug(\n            f\"Colorspace from representation colorspaceData: {colorspace}\")\n\n        if not colorspace:\n            # Get backward compatible colorspace key.\n            colorspace = repre_entity[\"data\"].get(\"colorspace\")\n            self.log.debug(\n                f\"Colorspace from representation colorspace: {colorspace}\")\n\n        # Get backward compatible version data key if colorspace is not found.\n        if not colorspace:\n            colorspace = version_entity[\"attrib\"].get(\"colorSpace\")\n            self.log.debug(\n                f\"Colorspace from version colorspace: {colorspace}\")\n\n        config_data = get_current_context_imageio_config_preset()\n        # check if any filerules are not applicable\n        new_parsed_colorspace = get_imageio_file_rules_colorspace_from_filepath(  # noqa\n            filepath, \"nuke\", project_name, config_data=config_data\n        )\n        self.log.debug(f\"Colorspace new filerules: {new_parsed_colorspace}\")\n\n        # colorspace from `project_settings/nuke/imageio/regexInputs`\n        old_parsed_colorspace = get_imageio_input_colorspace(filepath)\n        self.log.debug(f\"Colorspace old filerules: {old_parsed_colorspace}\")\n\n        return new_parsed_colorspace or old_parsed_colorspace or colorspace\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_image.html#client.ayon_nuke.plugins.load.load_image.LoadImage.set_colorspace_to_node","title":"<code>set_colorspace_to_node(read_node, filepath, project_name, version_entity, repre_entity)</code>","text":"<p>Set colorspace to read node.</p> <p>Sets colorspace with available names validation.</p> <p>Parameters:</p> Name Type Description Default <code>read_node</code> <code>Node</code> <p>The nuke's read node</p> required <code>filepath</code> <code>str</code> <p>File path.</p> required <code>project_name</code> <code>str</code> <p>Project name.</p> required <code>version_entity</code> <code>dict</code> <p>Version entity.</p> required <code>repre_entity</code> <code>dict</code> <p>Representation entity.</p> required Source code in <code>client/ayon_nuke/plugins/load/load_image.py</code> <pre><code>def set_colorspace_to_node(\n    self,\n    read_node,\n    filepath,\n    project_name,\n    version_entity,\n    repre_entity,\n):\n    \"\"\"Set colorspace to read node.\n\n    Sets colorspace with available names validation.\n\n    Args:\n        read_node (nuke.Node): The nuke's read node\n        filepath (str): File path.\n        project_name (str): Project name.\n        version_entity (dict): Version entity.\n        repre_entity (dict): Representation entity.\n\n    \"\"\"\n    used_colorspace = self._get_colorspace_data(\n        project_name, version_entity, repre_entity, filepath\n    )\n    if (\n        used_colorspace\n        and colorspace_exists_on_node(read_node, used_colorspace)\n    ):\n        self.log.info(f\"Used colorspace: {used_colorspace}\")\n        read_node[\"colorspace\"].setValue(used_colorspace)\n    else:\n        self.log.info(\"Colorspace not set...\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_image.html#client.ayon_nuke.plugins.load.load_image.LoadImage.update","title":"<code>update(container, context)</code>","text":"<p>Update the Loader's path</p> <p>Nuke automatically tries to reset some variables when changing the loader's path to a new file. These automatic changes are to its inputs:</p> Source code in <code>client/ayon_nuke/plugins/load/load_image.py</code> <pre><code>def update(self, container, context):\n    \"\"\"Update the Loader's path\n\n    Nuke automatically tries to reset some variables when changing\n    the loader's path to a new file. These automatic changes are to its\n    inputs:\n\n    \"\"\"\n    read_node = container[\"node\"]\n    frame_number = read_node[\"first\"].value()\n\n    assert read_node.Class() == \"Read\", \"Must be Read\"\n\n    project_name = context[\"project\"][\"name\"]\n    version_entity = context[\"version\"]\n    repre_entity = context[\"representation\"]\n\n    repr_cont = repre_entity[\"context\"]\n\n    filepath = self.filepath_from_context(context)\n\n    if not filepath:\n        repre_id = repre_entity[\"id\"]\n        self.log.warning(\n            \"Representation id `{}` is failing to load\".format(repre_id))\n        return\n\n    filepath = filepath.replace(\"\\\\\", \"/\")\n\n    frame = repr_cont.get(\"frame\")\n    if frame:\n        padding = len(frame)\n        filepath = filepath.replace(\n            frame, format(frame_number, \"0{}\".format(padding))\n        )\n\n    # Get start frame from version data\n    last_version_entity = ayon_api.get_last_version_by_product_id(\n        project_name, version_entity[\"productId\"], fields={\"id\"}\n    )\n\n    last = first = int(frame_number)\n\n    self.set_colorspace_to_node(\n        read_node, filepath, project_name, version_entity, repre_entity\n    )\n    # Set the global in to the start frame of the sequence\n    read_node[\"file\"].setValue(filepath)\n    read_node[\"origfirst\"].setValue(first)\n    read_node[\"first\"].setValue(first)\n    read_node[\"origlast\"].setValue(last)\n    read_node[\"last\"].setValue(last)\n\n    version_attributes = version_entity[\"attrib\"]\n    updated_dict = {\n        \"representation\": repre_entity[\"id\"],\n        \"frameStart\": str(first),\n        \"frameEnd\": str(last),\n        \"version\": str(version_entity[\"version\"]),\n        \"source\": version_attributes.get(\"source\"),\n        \"fps\": str(version_attributes.get(\"fps\")),\n    }\n\n    # change color of node\n    if version_entity[\"id\"] == last_version_entity[\"id\"]:\n        color_value = \"0x4ecd25ff\"\n    else:\n        color_value = \"0xd84f20ff\"\n    read_node[\"tile_color\"].setValue(int(color_value, 16))\n\n    # Update the imprinted representation\n    update_container(read_node, updated_dict)\n    self.log.info(\"updated to version: {}\".format(\n        version_entity[\"version\"]\n    ))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_matchmove.html","title":"load_matchmove","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_matchmove.html#client.ayon_nuke.plugins.load.load_matchmove.MatchmoveLoader","title":"<code>MatchmoveLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>This will run matchmove script to create track in script.</p> Source code in <code>client/ayon_nuke/plugins/load/load_matchmove.py</code> <pre><code>class MatchmoveLoader(load.LoaderPlugin):\n    \"\"\"\n    This will run matchmove script to create track in script.\n    \"\"\"\n\n    product_base_types = {\"matchmove\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"py\"}\n\n    settings_category = \"nuke\"\n\n    defaults = [\"Camera\", \"Object\"]\n\n    label = \"Run matchmove script\"\n    icon = \"empire\"\n    color = \"orange\"\n\n    def load(self, context, name, namespace, data):\n        path = self.filepath_from_context(context)\n        if path.lower().endswith(\".py\"):\n            exec(open(path).read())\n\n        else:\n            msg = \"Unsupported script type\"\n            self.log.error(msg)\n            nuke.message(msg)\n\n        return True\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_model.html","title":"load_model","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_model.html#client.ayon_nuke.plugins.load.load_model.AlembicModelLoader","title":"<code>AlembicModelLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>This will load alembic model or anim into script.</p> The class name <code>AlembicModelLoader</code> can't be changed for backward <p>compatibility, even though it can read more than just alembic files.</p> Source code in <code>client/ayon_nuke/plugins/load/load_model.py</code> <pre><code>class AlembicModelLoader(load.LoaderPlugin):\n    \"\"\"\n    This will load alembic model or anim into script.\n\n    Note: The class name `AlembicModelLoader` can't be changed for backward\n        compatibility, even though it can read more than just alembic files.\n    \"\"\"\n\n    product_base_types = {\"model\", \"pointcache\", \"animation\", \"fbx\", \"usd\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"abc\", \"fbx\", \"obj\", \"usd\", \"usda\"}\n\n    settings_category = \"nuke\"\n\n    label = \"Load Geo\"\n    icon = \"cube\"\n    color = \"orange\"\n    node_color = \"0x4ecd91ff\"\n\n    def load(self, context, name, namespace, data):\n        # get main variables\n        project_name = context[\"project\"][\"name\"]\n        version_entity = context[\"version\"]\n\n        version_attributes = version_entity[\"attrib\"]\n        first = version_attributes.get(\"frameStart\")\n        last = version_attributes.get(\"frameEnd\")\n        fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n        namespace = namespace or context[\"folder\"][\"name\"]\n        object_name = \"{}_{}\".format(name, namespace)\n\n        # prepare data for imprinting\n        data_imprint = {\n            \"frameStart\": first,\n            \"frameEnd\": last,\n            \"version\": version_entity[\"version\"]\n        }\n        # add attributes from the version to imprint to metadata knob\n        for k in [\"source\", \"fps\"]:\n            data_imprint[k] = version_attributes[k]\n\n        # getting file path\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            model_node = nuke.createNode(\n                \"ReadGeo2\",\n                \"name {} file {} \".format(\n                    object_name, file),\n                inpanel=False\n            )\n            model_node.forceValidate()\n\n            # Force refresh\n            self._select_all_items(model_node)\n            model_node = self._fix_scene_view_contents(model_node)\n            self._set_fps(model_node, fps)\n\n        # color node by correct color by actual version\n        self.node_version_color(project_name, version_entity, model_node)\n\n        return containerise(\n            node=model_node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n            data=data_imprint)\n\n    def update(self, container, context):\n        \"\"\"\n            Called by Scene Inventory when look should be updated to current\n            version.\n            If any reference edits cannot be applied, eg. shader renamed and\n            material not present, reference is unloaded and cleaned.\n            All failed edits are highlighted to the user via message box.\n\n        Args:\n            container: object that has look to be updated\n            context: (dict): relationship data to get proper\n                                    representation from DB and persisted\n                                    data in .json\n        Returns:\n            None\n        \"\"\"\n        # Get version from io\n        project_name = context[\"project\"][\"name\"]\n        version_entity = context[\"version\"]\n        repre_entity = context[\"representation\"]\n\n        # get corresponding node\n        model_node = container[\"node\"]\n\n        # get main variables\n        version_attributes = version_entity[\"attrib\"]\n        first = version_attributes.get(\"frameStart\")\n        last = version_attributes.get(\"frameEnd\")\n        fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n        # prepare data for imprinting\n        data_imprint = {\n            \"representation\": repre_entity[\"id\"],\n            \"frameStart\": first,\n            \"frameEnd\": last,\n            \"version\": version_entity[\"version\"]\n        }\n\n        # add additional metadata from the version to imprint to Avalon knob\n        for k in [\"source\", \"fps\"]:\n            data_imprint[k] = version_attributes[k]\n\n        # getting file path\n        file = get_representation_path(repre_entity).replace(\"\\\\\", \"/\")\n\n        model_node[\"file\"].setValue(file)\n        self._select_all_items(model_node)\n        with maintained_selection():\n            model_node = self._fix_scene_view_contents(model_node)\n        self._set_fps(model_node, fps)\n\n        # color node by correct color by actual version\n        self.node_version_color(project_name, version_entity, model_node)\n\n        self.log.info(\n            \"updated to version: {}\".format(version_entity[\"version\"])\n        )\n\n        return update_container(model_node, data_imprint)\n\n    def _select_all_items(self, node):\n        # Alembic\n        scene_view = node.knob(\"scene_view\")\n        if scene_view is not None:\n            # Ensure all items are imported and selected.\n            scene_view.setImportedItems(scene_view.getAllItems())\n            scene_view.setSelectedItems(scene_view.getAllItems())\n            return\n\n        # USD\n        scene_graph = node.knob(\"scene_graph\")\n        if scene_graph is not None:\n            items = scene_graph.getItems()\n            names = [x[0] for x in items]\n            scene_graph.setSelectedItems(names)\n            return\n\n    def _fix_scene_view_contents(self, node: nuke.Node) -&gt; nuke.Node:\n        \"\"\"Fix UI not displaying `scene_view` or `scene_graph` correctly.\"\"\"\n        node['selected'].setValue(True)\n\n        # collect input output dependencies\n        dependencies = node.dependencies()\n        dependent = node.dependent()\n\n        # workaround because nuke's bug is\n        # not adding animation keys properly\n        xpos = node.xpos()\n        ypos = node.ypos()\n        nuke.nodeCopy(\"%clipboard%\")\n        nuke.delete(node)\n\n        # paste the node back and set the position\n        nuke.nodePaste(\"%clipboard%\")\n        node = nuke.selectedNode()\n        node.setXYpos(xpos, ypos)\n\n        # link to original input nodes\n        for i, input in enumerate(dependencies):\n            node.setInput(i, input)\n\n        # link to original output nodes\n        for d in dependent:\n            index = next(\n                (\n                    i\n                    for i, dpcy in enumerate(d.dependencies())\n                    if node is dpcy\n                ),\n                0,\n            )\n            d.setInput(index, node)\n\n        return node\n\n    def _set_fps(self, node, fps):\n        # Loaded USD files don't expose frame rate knob so it may not exist\n        # so we only set `frame_rate` if it's exposed, e.g. on loaded Alembic\n        knob = node.knob(\"frame_rate\")\n        if knob is None:\n            return\n        knob.setValue(float(fps))\n\n    def node_version_color(self, project_name, version_entity, node):\n        \"\"\" Coloring a node by correct color by actual version\"\"\"\n\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = self.node_color\n        else:\n            color_value = \"0xd88467ff\"\n        node[\"tile_color\"].setValue(int(color_value, 16))\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = nuke.toNode(container['objectName'])\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_model.html#client.ayon_nuke.plugins.load.load_model.AlembicModelLoader.node_version_color","title":"<code>node_version_color(project_name, version_entity, node)</code>","text":"<p>Coloring a node by correct color by actual version</p> Source code in <code>client/ayon_nuke/plugins/load/load_model.py</code> <pre><code>def node_version_color(self, project_name, version_entity, node):\n    \"\"\" Coloring a node by correct color by actual version\"\"\"\n\n    last_version_entity = ayon_api.get_last_version_by_product_id(\n        project_name, version_entity[\"productId\"], fields={\"id\"}\n    )\n\n    # change color of node\n    if version_entity[\"id\"] == last_version_entity[\"id\"]:\n        color_value = self.node_color\n    else:\n        color_value = \"0xd88467ff\"\n    node[\"tile_color\"].setValue(int(color_value, 16))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_model.html#client.ayon_nuke.plugins.load.load_model.AlembicModelLoader.update","title":"<code>update(container, context)</code>","text":"<pre><code>Called by Scene Inventory when look should be updated to current\nversion.\nIf any reference edits cannot be applied, eg. shader renamed and\nmaterial not present, reference is unloaded and cleaned.\nAll failed edits are highlighted to the user via message box.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>container</code> <p>object that has look to be updated</p> required <code>context</code> <p>(dict): relationship data to get proper                     representation from DB and persisted                     data in .json</p> required <p>Returns:     None</p> Source code in <code>client/ayon_nuke/plugins/load/load_model.py</code> <pre><code>def update(self, container, context):\n    \"\"\"\n        Called by Scene Inventory when look should be updated to current\n        version.\n        If any reference edits cannot be applied, eg. shader renamed and\n        material not present, reference is unloaded and cleaned.\n        All failed edits are highlighted to the user via message box.\n\n    Args:\n        container: object that has look to be updated\n        context: (dict): relationship data to get proper\n                                representation from DB and persisted\n                                data in .json\n    Returns:\n        None\n    \"\"\"\n    # Get version from io\n    project_name = context[\"project\"][\"name\"]\n    version_entity = context[\"version\"]\n    repre_entity = context[\"representation\"]\n\n    # get corresponding node\n    model_node = container[\"node\"]\n\n    # get main variables\n    version_attributes = version_entity[\"attrib\"]\n    first = version_attributes.get(\"frameStart\")\n    last = version_attributes.get(\"frameEnd\")\n    fps = version_attributes.get(\"fps\") or nuke.root()[\"fps\"].getValue()\n\n    # prepare data for imprinting\n    data_imprint = {\n        \"representation\": repre_entity[\"id\"],\n        \"frameStart\": first,\n        \"frameEnd\": last,\n        \"version\": version_entity[\"version\"]\n    }\n\n    # add additional metadata from the version to imprint to Avalon knob\n    for k in [\"source\", \"fps\"]:\n        data_imprint[k] = version_attributes[k]\n\n    # getting file path\n    file = get_representation_path(repre_entity).replace(\"\\\\\", \"/\")\n\n    model_node[\"file\"].setValue(file)\n    self._select_all_items(model_node)\n    with maintained_selection():\n        model_node = self._fix_scene_view_contents(model_node)\n    self._set_fps(model_node, fps)\n\n    # color node by correct color by actual version\n    self.node_version_color(project_name, version_entity, model_node)\n\n    self.log.info(\n        \"updated to version: {}\".format(version_entity[\"version\"])\n    )\n\n    return update_container(model_node, data_imprint)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_ociolook.html","title":"load_ociolook","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_ociolook.html#client.ayon_nuke.plugins.load.load_ociolook.LoadOcioLookNodes","title":"<code>LoadOcioLookNodes</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Loading Ocio look to the nuke.Node graph</p> Source code in <code>client/ayon_nuke/plugins/load/load_ociolook.py</code> <pre><code>class LoadOcioLookNodes(load.LoaderPlugin):\n    \"\"\"Loading Ocio look to the nuke.Node graph\"\"\"\n\n    product_base_types = {\"ociolook\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"json\"}\n\n    settings_category = \"nuke\"\n\n    label = \"Load OcioLook [nodes]\"\n    order = 0\n    icon = \"cc\"\n    color = \"white\"\n    ignore_attr = [\"useLifetime\"]\n\n    # plugin attributes\n    current_node_color = \"0x4ecd91ff\"\n    old_node_color = \"0xd88467ff\"\n\n    # json file variables\n    schema_version = 1\n\n    def load(self, context, name, namespace, data):\n        \"\"\"\n        Loading function to get the soft effects to particular read node\n\n        Arguments:\n            context (dict): context of version\n            name (str): name of the version\n            namespace (str): namespace name\n            data (dict): compulsory attribute &gt; not used\n\n        Returns:\n            nuke.Node: containerized nuke.Node object\n        \"\"\"\n        namespace = namespace or context[\"folder\"][\"name\"]\n        suffix = secrets.token_hex(nbytes=4)\n        node_name = \"{}_{}_{}\".format(\n            name, namespace, suffix)\n\n        # getting file path\n        filepath = self.filepath_from_context(context)\n\n        json_f = self._load_json_data(filepath)\n\n        group_node = self._create_group_node(\n            filepath, json_f[\"data\"])\n        # renaming group node\n        group_node[\"name\"].setValue(node_name)\n\n        self._node_version_color(\n            context[\"project\"][\"name\"],\n            context[\"version\"],\n            group_node\n        )\n\n        self.log.info(\n            \"Loaded lut setup: `{}`\".format(group_node[\"name\"].value()))\n\n        return containerise(\n            node=group_node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__\n        )\n\n    def _create_group_node(\n        self,\n        filepath,\n        data,\n        group_node=None\n    ):\n        \"\"\"Creates group node with all the nodes inside.\n\n        Creating mainly `OCIOFileTransform` nodes with `OCIOColorSpace` nodes\n        in between - in case those are needed.\n\n        Arguments:\n            filepath (str): path to json file\n            data (dict): data from json file\n            group_node (Optional[nuke.Node]): group node or None\n\n        Returns:\n            nuke.Node: group node with all the nodes inside\n        \"\"\"\n        # get corresponding node\n\n        root_working_colorspace = nuke.root()[\"workingSpaceLUT\"].value()\n\n        dir_path = os.path.dirname(filepath)\n        all_files = os.listdir(dir_path)\n\n        ocio_working_colorspace = _colorspace_name_by_type(\n            data[\"ocioLookWorkingSpace\"])\n\n        # adding nodes to node graph\n        # just in case we are in group lets jump out of it\n        nuke.endGroup()\n\n        input_node = None\n        output_node = None\n        if group_node:\n            # remove all nodes between Input and Output nodes\n            for node in group_node.nodes():\n                if node.Class() not in [\"Input\", \"Output\"]:\n                    nuke.delete(node)\n                elif node.Class() == \"Input\":\n                    input_node = node\n                elif node.Class() == \"Output\":\n                    output_node = node\n        else:\n            group_node = nuke.createNode(\n                \"Group\",\n                inpanel=False\n            )\n\n        # adding content to the group node\n        with group_node:\n            pre_colorspace = root_working_colorspace\n\n            # reusing input node if it exists during update\n            if input_node:\n                pre_node = input_node\n            else:\n                pre_node = nuke.createNode(\"Input\")\n                pre_node[\"name\"].setValue(\"rgb\")\n\n            # Compare script working colorspace with ocio working colorspace\n            # found in json file and convert to json's if needed\n            if pre_colorspace != ocio_working_colorspace:\n                pre_node = _add_ocio_colorspace_node(\n                    pre_node,\n                    pre_colorspace,\n                    ocio_working_colorspace\n                )\n                pre_colorspace = ocio_working_colorspace\n\n            for ocio_item in data[\"ocioLookItems\"]:\n                input_space = _colorspace_name_by_type(\n                    ocio_item[\"input_colorspace\"])\n                output_space = _colorspace_name_by_type(\n                    ocio_item[\"output_colorspace\"])\n\n                # making sure we are set to correct colorspace for otio item\n                if pre_colorspace != input_space:\n                    pre_node = _add_ocio_colorspace_node(\n                        pre_node,\n                        pre_colorspace,\n                        input_space\n                    )\n\n                node = nuke.createNode(\"OCIOFileTransform\")\n\n                # file path from lut representation\n                extension = ocio_item[\"ext\"]\n                item_name = ocio_item[\"name\"]\n                lut_suffix = ocio_item.get(\"lut_suffix\", \"\")\n\n                item_lut_file = next(\n                    (\n                        file for file in all_files\n                        if file.endswith(extension)\n                        and os.path.basename(file).endswith(lut_suffix)\n                    ),\n                    None\n                )\n                if not item_lut_file:\n                    raise ValueError(\n                        \"File with extension '{}' not \"\n                        \"found in directory\".format(extension)\n                    )\n\n                item_lut_path = os.path.join(\n                    dir_path, item_lut_file).replace(\"\\\\\", \"/\")\n                node[\"file\"].setValue(item_lut_path)\n                node[\"name\"].setValue(item_name)\n                if ocio_item[\"direction\"] == \"inverse\":\n                    node[\"invert\"].setValue(True)\n                node[\"interpolation\"].setValue(ocio_item[\"interpolation\"])\n                node[\"working_space\"].setValue(input_space)\n\n                pre_node.autoplace()\n                node.setInput(0, pre_node)\n                node.autoplace()\n                # pass output space into pre_colorspace for next iteration\n                # or for output node comparison\n                pre_colorspace = output_space\n                pre_node = node\n\n            # making sure we are back in script working colorspace\n            if pre_colorspace != root_working_colorspace:\n                pre_node = _add_ocio_colorspace_node(\n                    pre_node,\n                    pre_colorspace,\n                    root_working_colorspace\n                )\n\n            # reusing output node if it exists during update\n            if not output_node:\n                output = nuke.createNode(\"Output\")\n            else:\n                output = output_node\n\n            output.setInput(0, pre_node)\n\n        return group_node\n\n    def update(self, container, context):\n        repre_entity = context[\"representation\"]\n\n        group_node = container[\"node\"]\n\n        filepath = get_representation_path(repre_entity)\n\n        json_f = self._load_json_data(filepath)\n\n        group_node = self._create_group_node(\n            filepath,\n            json_f[\"data\"],\n            group_node\n        )\n\n        self._node_version_color(\n            context[\"project\"][\"name\"], context[\"version\"], group_node\n        )\n\n        self.log.info(\"Updated lut setup: `{}`\".format(\n            group_node[\"name\"].value()))\n\n        return update_container(\n            group_node, {\"representation\": repre_entity[\"id\"]})\n\n    def _load_json_data(self, filepath):\n        # getting data from json file with unicode conversion\n        with open(filepath, \"r\") as _file:\n            json_f = {self._bytify(key): self._bytify(value)\n                      for key, value in json.load(_file).items()}\n\n        # check if the version in json_f is the same as plugin version\n        if json_f[\"version\"] != self.schema_version:\n            raise KeyError(\n                \"Version of json file is not the same as plugin version\")\n\n        return json_f\n\n    def _bytify(self, input):\n        \"\"\"\n        Converts unicode strings to strings\n        It goes through all dictionary\n\n        Arguments:\n            input (dict/str): input\n\n        Returns:\n            dict: with fixed values and keys\n\n        \"\"\"\n\n        if isinstance(input, dict):\n            return {self._bytify(key): self._bytify(value)\n                    for key, value in input.items()}\n        elif isinstance(input, list):\n            return [self._bytify(element) for element in input]\n        elif isinstance(input, str):\n            return str(input)\n        else:\n            return input\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = nuke.toNode(container['objectName'])\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n\n    def _node_version_color(self, project_name, version_entity, node):\n        \"\"\" Coloring a node by correct color by actual version\"\"\"\n\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = self.current_node_color\n        else:\n            color_value = self.old_node_color\n        node[\"tile_color\"].setValue(int(color_value, 16))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_ociolook.html#client.ayon_nuke.plugins.load.load_ociolook.LoadOcioLookNodes.load","title":"<code>load(context, name, namespace, data)</code>","text":"<p>Loading function to get the soft effects to particular read node</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>dict</code> <p>context of version</p> required <code>name</code> <code>str</code> <p>name of the version</p> required <code>namespace</code> <code>str</code> <p>namespace name</p> required <code>data</code> <code>dict</code> <p>compulsory attribute &gt; not used</p> required <p>Returns:</p> Type Description <p>nuke.Node: containerized nuke.Node object</p> Source code in <code>client/ayon_nuke/plugins/load/load_ociolook.py</code> <pre><code>def load(self, context, name, namespace, data):\n    \"\"\"\n    Loading function to get the soft effects to particular read node\n\n    Arguments:\n        context (dict): context of version\n        name (str): name of the version\n        namespace (str): namespace name\n        data (dict): compulsory attribute &gt; not used\n\n    Returns:\n        nuke.Node: containerized nuke.Node object\n    \"\"\"\n    namespace = namespace or context[\"folder\"][\"name\"]\n    suffix = secrets.token_hex(nbytes=4)\n    node_name = \"{}_{}_{}\".format(\n        name, namespace, suffix)\n\n    # getting file path\n    filepath = self.filepath_from_context(context)\n\n    json_f = self._load_json_data(filepath)\n\n    group_node = self._create_group_node(\n        filepath, json_f[\"data\"])\n    # renaming group node\n    group_node[\"name\"].setValue(node_name)\n\n    self._node_version_color(\n        context[\"project\"][\"name\"],\n        context[\"version\"],\n        group_node\n    )\n\n    self.log.info(\n        \"Loaded lut setup: `{}`\".format(group_node[\"name\"].value()))\n\n    return containerise(\n        node=group_node,\n        name=name,\n        namespace=namespace,\n        context=context,\n        loader=self.__class__.__name__\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_script_precomp.html","title":"load_script_precomp","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_script_precomp.html#client.ayon_nuke.plugins.load.load_script_precomp.LinkAsGroup","title":"<code>LinkAsGroup</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>Copy the published file to be pasted at the desired location</p> Source code in <code>client/ayon_nuke/plugins/load/load_script_precomp.py</code> <pre><code>class LinkAsGroup(load.LoaderPlugin):\n    \"\"\"Copy the published file to be pasted at the desired location\"\"\"\n\n    product_base_types = {\"workfile\", \"nukenodes\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"nk\"}\n\n    settings_category = \"nuke\"\n\n    label = \"Load Precomp\"\n    order = 0\n    icon = \"file\"\n    color = \"#cc0000\"\n\n    def load(self, context, name, namespace, data):\n        # for k, v in context.items():\n        #     log.info(\"key: `{}`, value: {}\\n\".format(k, v))\n        version_entity = context[\"version\"]\n\n        version_attributes = version_entity[\"attrib\"]\n        first = version_attributes.get(\"frameStart\")\n        last = version_attributes.get(\"frameEnd\")\n        colorspace = version_attributes.get(\"colorSpace\")\n\n        # Fallback to folder name when namespace is None\n        if namespace is None:\n            namespace = context[\"folder\"][\"name\"]\n\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n        self.log.info(\"file: {}\\n\".format(file))\n\n        data_imprint = {\n            \"startingFrame\": first,\n            \"frameStart\": first,\n            \"frameEnd\": last,\n            \"version\": version_entity[\"version\"]\n        }\n        # add additional metadata from the version to imprint to Avalon knob\n        for k in [\n            \"frameStart\",\n            \"frameEnd\",\n            \"handleStart\",\n            \"handleEnd\",\n            \"source\",\n            \"fps\"\n        ]:\n            data_imprint[k] = version_attributes[k]\n\n        # group context is set to precomp, so back up one level.\n        nuke.endGroup()\n\n        # P = nuke.nodes.LiveGroup(\"file {}\".format(file))\n        P = nuke.createNode(\n            \"Precomp\",\n            \"file {}\".format(file),\n            inpanel=False\n        )\n\n        # Set colorspace defined in version data\n        self.log.info(\"colorspace: {}\\n\".format(colorspace))\n\n        P[\"name\"].setValue(\"{}_{}\".format(name, namespace))\n        P[\"useOutput\"].setValue(True)\n\n        with P:\n            # iterate through all nodes in group node and find AYON writes\n            writes = [n.name() for n in nuke.allNodes()\n                      if n.Class() == \"Group\"\n                      if get_avalon_knob_data(n)]\n\n            if writes:\n                # create panel for selecting output\n                panel_choices = \" \".join(writes)\n                panel_label = \"Select write node for output\"\n                p = nuke.Panel(\"Select Write Node\")\n                p.addEnumerationPulldown(\n                    panel_label, panel_choices)\n                p.show()\n                P[\"output\"].setValue(p.value(panel_label))\n\n        P[\"tile_color\"].setValue(0xff0ff0ff)\n\n        return containerise(\n                     node=P,\n                     name=name,\n                     namespace=namespace,\n                     context=context,\n                     loader=self.__class__.__name__,\n                     data=data_imprint)\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def update(self, container, context):\n        \"\"\"Update the Loader's path\n\n        Nuke automatically tries to reset some variables when changing\n        the loader's path to a new file. These automatic changes are to its\n        inputs:\n\n        \"\"\"\n        node = container[\"node\"]\n\n        project_name = context[\"project\"][\"name\"]\n        version_entity = context[\"version\"]\n        repre_entity = context[\"representation\"]\n\n        root = get_representation_path(repre_entity).replace(\"\\\\\", \"/\")\n\n        # Get start frame from version data\n\n        version_attributes = version_entity[\"attrib\"]\n        updated_dict = {\n            \"representation\": repre_entity[\"id\"],\n            \"frameEnd\": version_attributes.get(\"frameEnd\"),\n            \"version\": version_entity[\"version\"],\n            \"colorspace\": version_attributes.get(\"colorSpace\"),\n            \"source\": version_attributes.get(\"source\"),\n            \"fps\": version_attributes.get(\"fps\"),\n        }\n\n        # Update the imprinted representation\n        update_container(\n            node,\n            updated_dict\n        )\n\n        node[\"file\"].setValue(root)\n\n        last_version_entity = ayon_api.get_last_version_by_product_id(\n            project_name, version_entity[\"productId\"], fields={\"id\"}\n        )\n        # change color of node\n        if version_entity[\"id\"] == last_version_entity[\"id\"]:\n            color_value = \"0xff0ff0ff\"\n        else:\n            color_value = \"0xd84f20ff\"\n        node[\"tile_color\"].setValue(int(color_value, 16))\n\n        self.log.info(\n            \"updated to version: {}\".format(version_entity[\"version\"])\n        )\n\n    def remove(self, container):\n        node = container[\"node\"]\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_script_precomp.html#client.ayon_nuke.plugins.load.load_script_precomp.LinkAsGroup.update","title":"<code>update(container, context)</code>","text":"<p>Update the Loader's path</p> <p>Nuke automatically tries to reset some variables when changing the loader's path to a new file. These automatic changes are to its inputs:</p> Source code in <code>client/ayon_nuke/plugins/load/load_script_precomp.py</code> <pre><code>def update(self, container, context):\n    \"\"\"Update the Loader's path\n\n    Nuke automatically tries to reset some variables when changing\n    the loader's path to a new file. These automatic changes are to its\n    inputs:\n\n    \"\"\"\n    node = container[\"node\"]\n\n    project_name = context[\"project\"][\"name\"]\n    version_entity = context[\"version\"]\n    repre_entity = context[\"representation\"]\n\n    root = get_representation_path(repre_entity).replace(\"\\\\\", \"/\")\n\n    # Get start frame from version data\n\n    version_attributes = version_entity[\"attrib\"]\n    updated_dict = {\n        \"representation\": repre_entity[\"id\"],\n        \"frameEnd\": version_attributes.get(\"frameEnd\"),\n        \"version\": version_entity[\"version\"],\n        \"colorspace\": version_attributes.get(\"colorSpace\"),\n        \"source\": version_attributes.get(\"source\"),\n        \"fps\": version_attributes.get(\"fps\"),\n    }\n\n    # Update the imprinted representation\n    update_container(\n        node,\n        updated_dict\n    )\n\n    node[\"file\"].setValue(root)\n\n    last_version_entity = ayon_api.get_last_version_by_product_id(\n        project_name, version_entity[\"productId\"], fields={\"id\"}\n    )\n    # change color of node\n    if version_entity[\"id\"] == last_version_entity[\"id\"]:\n        color_value = \"0xff0ff0ff\"\n    else:\n        color_value = \"0xd84f20ff\"\n    node[\"tile_color\"].setValue(int(color_value, 16))\n\n    self.log.info(\n        \"updated to version: {}\".format(version_entity[\"version\"])\n    )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_usd.html","title":"load_usd","text":""},{"location":"autoapi/client/ayon_nuke/plugins/load/load_usd.html#client.ayon_nuke.plugins.load.load_usd.GeoImportLoader","title":"<code>GeoImportLoader</code>","text":"<p>               Bases: <code>LoaderPlugin</code></p> <p>This will load files to GeoImport node.</p> Source code in <code>client/ayon_nuke/plugins/load/load_usd.py</code> <pre><code>class GeoImportLoader(load.LoaderPlugin):\n    \"\"\"This will load files to GeoImport node.\"\"\"\n\n    product_base_types = {\"*\"}\n    product_types = product_base_types\n    representations = {\"*\"}\n    extensions = {\"abc\", \"usd\", \"usda\", \"usdc\"}\n    order = 2\n\n    settings_category = \"nuke\"\n\n    label = \"Load GeoImport\"\n    icon = \"cube\"\n    color = \"orange\"\n    node_color = \"0x4ecd91ff\"\n\n    node_class = \"GeoImport\"\n    node_file_knob = \"file\"\n\n    def load(self, context, name, namespace, data):\n        namespace = namespace or context[\"folder\"][\"name\"]\n        object_name = \"{}_{}\".format(name, namespace)\n\n        filepath = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            file_knob: str = self.node_file_knob\n            node = nuke.createNode(\n                self.node_class,\n                f\"name {object_name} {file_knob} {filepath}\",\n                inpanel=False,\n            )\n            node.forceValidate()\n\n        # color node by correct color by actual version\n        self.set_node_version_color(node, context)\n\n        return containerise(\n            node=node,\n            name=name,\n            namespace=namespace,\n            context=context,\n            loader=self.__class__.__name__,\n        )\n\n    def update(self, container, context):\n        node: nuke.Node = container[\"node\"]\n        file = self.filepath_from_context(context).replace(\"\\\\\", \"/\")\n        node[self.node_file_knob].setValue(file)\n\n        # color node by correct color by actual version\n        self.set_node_version_color(node, context)\n\n        # update representation id\n        return update_container(\n            node,\n            {\n                \"representation\": context[\"representation\"][\"id\"],\n            },\n        )\n\n    def set_node_version_color(self, node: nuke.Node, context: dict):\n        \"\"\"Coloring a node by correct color by actual version\"\"\"\n        is_latest_version = ayon_api.version_is_latest(\n            context[\"project\"][\"name\"], context[\"version\"][\"id\"]\n        )\n        color_value = self.node_color if is_latest_version else \"0xd88467ff\"\n        node[\"tile_color\"].setValue(int(color_value, 16))\n\n    def switch(self, container, context):\n        self.update(container, context)\n\n    def remove(self, container):\n        node = nuke.toNode(container[\"objectName\"])\n        with viewer_update_and_undo_stop():\n            nuke.delete(node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_usd.html#client.ayon_nuke.plugins.load.load_usd.GeoImportLoader.set_node_version_color","title":"<code>set_node_version_color(node, context)</code>","text":"<p>Coloring a node by correct color by actual version</p> Source code in <code>client/ayon_nuke/plugins/load/load_usd.py</code> <pre><code>def set_node_version_color(self, node: nuke.Node, context: dict):\n    \"\"\"Coloring a node by correct color by actual version\"\"\"\n    is_latest_version = ayon_api.version_is_latest(\n        context[\"project\"][\"name\"], context[\"version\"][\"id\"]\n    )\n    color_value = self.node_color if is_latest_version else \"0xd88467ff\"\n    node[\"tile_color\"].setValue(int(color_value, 16))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/load/load_usd.html#client.ayon_nuke.plugins.load.load_usd.GeoReferenceLoader","title":"<code>GeoReferenceLoader</code>","text":"<p>               Bases: <code>GeoImportLoader</code></p> <p>This will load files to GeoReference node.</p> Source code in <code>client/ayon_nuke/plugins/load/load_usd.py</code> <pre><code>class GeoReferenceLoader(GeoImportLoader):\n    \"\"\"This will load files to GeoReference node.\"\"\"\n    label = \"Load GeoReference\"\n    order = 3\n\n    node_class = \"GeoReference\"\n    node_file_knob = \"file_path\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/index.html","title":"publish","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_backdrop.html","title":"collect_backdrop","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_backdrop.html#client.ayon_nuke.plugins.publish.collect_backdrop.CollectBackdrops","title":"<code>CollectBackdrops</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect Backdrop node instance and its content</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_backdrop.py</code> <pre><code>class CollectBackdrops(pyblish.api.InstancePlugin):\n    \"\"\"Collect Backdrop node instance and its content\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.22\n    label = \"Collect Backdrop\"\n    hosts = [\"nuke\"]\n    families = [\"nukenodes\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        self.log.debug(pformat(instance.data))\n\n        bckn = instance.data[\"transientData\"][\"node\"]\n\n        # define size of the backdrop\n        left = bckn.xpos()\n        top = bckn.ypos()\n        right = left + bckn['bdwidth'].value()\n        bottom = top + bckn['bdheight'].value()\n\n        instance.data[\"transientData\"][\"childNodes\"] = []\n        # iterate all nodes\n        for node in nuke.allNodes():\n\n            # exclude viewer\n            if node.Class() == \"Viewer\":\n                continue\n\n            # find all related nodes\n            if (node.xpos() &gt; left) \\\n                and (node.xpos() + node.screenWidth() &lt; right) \\\n                    and (node.ypos() &gt; top) \\\n                    and (node.ypos() + node.screenHeight() &lt; bottom):\n\n                # add contained nodes to instance's node list\n                instance.data[\"transientData\"][\"childNodes\"].append(node)\n\n        # get all connections from outside of backdrop\n        nodes = instance.data[\"transientData\"][\"childNodes\"]\n        connections_in, connections_out = pnlib.get_dependent_nodes(nodes)\n        instance.data[\"transientData\"][\"nodeConnectionsIn\"] = connections_in\n        instance.data[\"transientData\"][\"nodeConnectionsOut\"] = connections_out\n\n        # make label nicer\n        instance.data[\"label\"] = \"{0} ({1} nodes)\".format(\n            bckn.name(), len(instance.data[\"transientData\"][\"childNodes\"]))\n\n        # get version\n        version = instance.context.data.get('version')\n\n        if version:\n            instance.data['version'] = version\n\n        self.log.debug(\"Backdrop instance collected: `{}`\".format(instance))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_context_data.html","title":"collect_context_data","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_context_data.html#client.ayon_nuke.plugins.publish.collect_context_data.CollectContextData","title":"<code>CollectContextData</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Collect current context publish.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_context_data.py</code> <pre><code>class CollectContextData(pyblish.api.ContextPlugin):\n    \"\"\"Collect current context publish.\"\"\"\n\n    order = pyblish.api.CollectorOrder - 0.499\n    label = \"Collect context data\"\n    hosts = ['nuke']\n\n    settings_category = \"nuke\"\n\n    def process(self, context):  # sourcery skip: avoid-builtin-shadow\n        root_node = nuke.root()\n\n        current_file = os.path.normpath(root_node.name())\n\n        if current_file.lower() == \"root\":\n            raise KnownPublishError(\n                \"Workfile is not correct file name. \\n\"\n                \"Use workfile tool to manage the name correctly.\"\n            )\n\n        # Get frame range\n        first_frame = int(root_node[\"first_frame\"].getValue())\n        last_frame = int(root_node[\"last_frame\"].getValue())\n\n        # get instance data from root\n        root_instance_context = napi.get_node_data(\n            root_node, napi.INSTANCE_DATA_KNOB\n        )\n\n        handle_start = root_instance_context[\"handleStart\"]\n        handle_end = root_instance_context[\"handleEnd\"]\n\n        # Get format\n        format = root_node['format'].value()\n        resolution_width = format.width()\n        resolution_height = format.height()\n        pixel_aspect = format.pixelAspect()\n\n        script_data = {\n            \"frameStart\": first_frame + handle_start,\n            \"frameEnd\": last_frame - handle_end,\n            \"resolutionWidth\": resolution_width,\n            \"resolutionHeight\": resolution_height,\n            \"pixelAspect\": pixel_aspect,\n\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"step\": 1,\n            \"fps\": root_node['fps'].value(),\n\n            \"currentFile\": current_file,\n\n            \"host\": pyblish.api.current_host(),\n            \"hostVersion\": nuke.NUKE_VERSION_STRING\n        }\n\n        context.data[\"scriptData\"] = script_data\n        context.data.update(script_data)\n\n        self.log.debug('Context from Nuke script collected')\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_framerate.html","title":"collect_framerate","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_framerate.html#client.ayon_nuke.plugins.publish.collect_framerate.CollectFramerate","title":"<code>CollectFramerate</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Collect framerate.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_framerate.py</code> <pre><code>class CollectFramerate(pyblish.api.ContextPlugin):\n    \"\"\"Collect framerate.\"\"\"\n\n    order = pyblish.api.CollectorOrder\n    label = \"Collect Framerate\"\n    hosts = [\n        \"nuke\",\n        \"nukeassist\"\n    ]\n\n    settings_category = \"nuke\"\n\n    def process(self, context):\n        context.data[\"fps\"] = nuke.root()[\"fps\"].getValue()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_gizmo.html","title":"collect_gizmo","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_gizmo.html#client.ayon_nuke.plugins.publish.collect_gizmo.CollectGizmo","title":"<code>CollectGizmo</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect Gizmo (group) node instance and its content</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_gizmo.py</code> <pre><code>class CollectGizmo(pyblish.api.InstancePlugin):\n    \"\"\"Collect Gizmo (group) node instance and its content\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.22\n    label = \"Collect Gizmo (group)\"\n    hosts = [\"nuke\"]\n    families = [\"gizmo\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n\n        gizmo_node = instance.data[\"transientData\"][\"node\"]\n\n        # add product type to families\n        instance.data[\"families\"].insert(0, instance.data[\"productBaseType\"])\n        # make label nicer\n        instance.data[\"label\"] = gizmo_node.name()\n\n        # Get frame range\n        handle_start = instance.context.data[\"handleStart\"]\n        handle_end = instance.context.data[\"handleEnd\"]\n        first_frame = int(nuke.root()[\"first_frame\"].getValue())\n        last_frame = int(nuke.root()[\"last_frame\"].getValue())\n\n        # Add version data to instance\n        # QUESTION why is 'productName' stored to version data and\n        #   'families' are explicitly set here?\n        version_data = {\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"frameStart\": first_frame + handle_start,\n            \"frameEnd\": last_frame - handle_end,\n            \"colorspace\": nuke.root().knob('workingSpaceLUT').value(),\n            \"families\": list(instance.data[\"families\"]),\n            \"productName\": instance.data[\"productName\"],\n            \"fps\": instance.context.data[\"fps\"]\n        }\n\n        instance.data.update({\n            \"versionData\": version_data,\n            \"frameStart\": first_frame,\n            \"frameEnd\": last_frame\n        })\n        self.log.debug(\"Gizmo instance collected: `{}`\".format(instance))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_headless_farm.html","title":"collect_headless_farm","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_headless_farm.html#client.ayon_nuke.plugins.publish.collect_headless_farm.CollectRenderOnFarm","title":"<code>CollectRenderOnFarm</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Setup instances for render on farm submission.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_headless_farm.py</code> <pre><code>class CollectRenderOnFarm(pyblish.api.ContextPlugin):\n    \"\"\"Setup instances for render on farm submission.\"\"\"\n\n    # Needs to be after CollectFromCreateContext\n    order = pyblish.api.CollectorOrder - 0.49\n    label = \"Collect Render On Farm\"\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, context):\n        if not context.data.get(\"render_on_farm\", False):\n            return\n\n        for instance in context:\n            if instance.data[\"productBaseType\"] == \"workfile\":\n                instance.data[\"active\"] = False\n                continue\n\n            # Filter out all other instances.\n            node = instance.data[\"transientData\"][\"node\"]\n            if node.name() != instance.context.data[\"node_name\"]:\n                instance.data[\"active\"] = False\n                continue\n\n            instance.data[\"families\"].append(\"render_on_farm\")\n\n            # Enable for farm publishing.\n            instance.data[\"farm\"] = True\n\n        # Skip workfile version incremental save.\n        instance.context.data[\"increment_script_version\"] = False\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_headless_farm.html#client.ayon_nuke.plugins.publish.collect_headless_farm.SetupRenderOnFarm","title":"<code>SetupRenderOnFarm</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>AYONPyblishPluginMixin</code></p> <p>Setup instance for render on farm submission.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_headless_farm.py</code> <pre><code>class SetupRenderOnFarm(pyblish.api.InstancePlugin, AYONPyblishPluginMixin):\n    \"\"\"Setup instance for render on farm submission.\"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.4999\n    label = \"Setup Render On Farm\"\n    hosts = [\"nuke\"]\n    families = [\"render_on_farm\"]\n\n    def process(self, instance):\n        # Clear the families as we only want the main family, ei. no review\n        # etc.\n        instance.data[\"families\"] = [\"render_on_farm\"]\n\n        # Use the workfile instead of published.\n        publish_attributes = instance.data[\"publish_attributes\"]\n        plugin_attributes = publish_attributes[\"NukeSubmitDeadline\"]\n        plugin_attributes[\"use_published_workfile\"] = False\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_model.html","title":"collect_model","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_model.html#client.ayon_nuke.plugins.publish.collect_model.CollectModel","title":"<code>CollectModel</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect Model node instance and its content</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_model.py</code> <pre><code>class CollectModel(pyblish.api.InstancePlugin):\n    \"\"\"Collect Model node instance and its content\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.22\n    label = \"Collect Model\"\n    hosts = [\"nuke\"]\n    families = [\"model\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n\n        geo_node = instance.data[\"transientData\"][\"node\"]\n\n        # add product base type to families\n        instance.data[\"families\"].insert(0, instance.data[\"productBaseType\"])\n        # make label nicer\n        instance.data[\"label\"] = geo_node.name()\n\n        # Get frame range\n        handle_start = instance.context.data[\"handleStart\"]\n        handle_end = instance.context.data[\"handleEnd\"]\n        first_frame = int(nuke.root()[\"first_frame\"].getValue())\n        last_frame = int(nuke.root()[\"last_frame\"].getValue())\n        # Add version data to instance\n        # QUESTION why is 'productName' stored to version data and\n        #   'families' are explicitly set here?\n        version_data = {\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"frameStart\": first_frame + handle_start,\n            \"frameEnd\": last_frame - handle_end,\n            \"colorspace\": nuke.root().knob('workingSpaceLUT').value(),\n            \"families\": list(instance.data[\"families\"]),\n            \"productName\": instance.data[\"productName\"],\n            \"fps\": instance.context.data[\"fps\"]\n        }\n\n        instance.data.update({\n            \"versionData\": version_data,\n            \"frameStart\": first_frame,\n            \"frameEnd\": last_frame\n        })\n        self.log.debug(\"Model instance collected: `{}`\".format(instance))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_nuke_instance_data.html","title":"collect_nuke_instance_data","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_nuke_instance_data.html#client.ayon_nuke.plugins.publish.collect_nuke_instance_data.CollectInstanceData","title":"<code>CollectInstanceData</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect Nuke instance data</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_nuke_instance_data.py</code> <pre><code>class CollectInstanceData(pyblish.api.InstancePlugin):\n    \"\"\"Collect Nuke instance data\n\n    \"\"\"\n\n    order = pyblish.api.CollectorOrder - 0.49\n    label = \"Collect Nuke Instance Data\"\n    hosts = [\"nuke\", \"nukeassist\"]\n\n    settings_category = \"nuke\"\n\n    # presets\n    sync_workfile_version_on_product_base_types: list[str] = []\n\n    def process(self, instance):\n        product_base_type = instance.data[\"productBaseType\"]\n\n        # Get format\n        root = nuke.root()\n        format_ = root['format'].value()\n        resolution_width = format_.width()\n        resolution_height = format_.height()\n        pixel_aspect = format_.pixelAspect()\n\n        # sync workfile version\n        if product_base_type in self.sync_workfile_version_on_product_base_types:  # noqa: E501\n            self.log.debug(\n                \"Syncing version with workfile for '{}'\".format(\n                    product_base_type\n                )\n            )\n            # get version to instance for integration\n            instance.data['version'] = instance.context.data['version']\n\n        instance.data.update({\n            \"step\": 1,\n            \"fps\": root['fps'].value(),\n            \"resolutionWidth\": resolution_width,\n            \"resolutionHeight\": resolution_height,\n            \"pixelAspect\": pixel_aspect\n\n        })\n\n        # add creator attributes to instance\n        creator_attributes = instance.data[\"creator_attributes\"]\n        instance.data.update(creator_attributes)\n\n        # add review family if review activated on instance\n        if instance.data.get(\"review\"):\n            instance.data[\"families\"].append(\"review\")\n\n        # add staging dir information on instance\n        staging_dir = instance.data[\"transientData\"].get(\"stagingDir\")\n        staging_dir_persistent = instance.data[\"transientData\"].get(\n            \"stagingDir_persistent\", False\n        )\n        staging_dir_is_custom = instance.data[\"transientData\"].get(\n            \"stagingDir_is_custom\", False\n        )\n        if staging_dir:\n            instance.data.update({\n                \"stagingDir\": staging_dir,\n                \"stagingDir_persistent\": staging_dir_persistent,\n                \"stagingDir_is_custom\": staging_dir_is_custom,\n            })\n\n        self.log.debug(\"Collected instance: {}\".format(\n            instance.data))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_reads.html","title":"collect_reads","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_reads.html#client.ayon_nuke.plugins.publish.collect_reads.CollectNukeReads","title":"<code>CollectNukeReads</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect all read nodes.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_reads.py</code> <pre><code>class CollectNukeReads(pyblish.api.InstancePlugin):\n    \"\"\"Collect all read nodes.\"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.04\n    label = \"Collect Source Reads\"\n    hosts = [\"nuke\", \"nukeassist\"]\n    families = [\"source\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        self.log.debug(\"checking instance: {}\".format(instance))\n\n        node = instance.data[\"transientData\"][\"node\"]\n        if node.Class() != \"Read\":\n            return\n\n        file_path = node[\"file\"].value()\n        file_name = os.path.basename(file_path)\n        items = file_name.split(\".\")\n\n        if len(items) &lt; 2:\n            raise ValueError\n\n        ext = items[-1]\n\n        # Get frame range\n        handle_start = instance.context.data[\"handleStart\"]\n        handle_end = instance.context.data[\"handleEnd\"]\n        first_frame = node['first'].value()\n        last_frame = node['last'].value()\n\n        # colorspace\n        colorspace = node[\"colorspace\"].value()\n        if \"default\" in colorspace:\n            colorspace = colorspace.replace(\"default (\", \"\").replace(\")\", \"\")\n\n        # # Easier way to sequence - Not tested\n        # isSequence = True\n        # if first_frame == last_frame:\n        #     isSequence = False\n\n        isSequence = False\n        if len(items) &gt; 1:\n            sequence = items[-2]\n            hash_regex = re.compile(r'([#*])')\n            seq_regex = re.compile(r'[%0-9*d]')\n            hash_match = re.match(hash_regex, sequence)\n            seq_match = re.match(seq_regex, sequence)\n            if hash_match or seq_match:\n                isSequence = True\n\n        # get source path\n        path = nuke.filename(node)\n        source_dir = os.path.dirname(path)\n        self.log.debug('source dir: {}'.format(source_dir))\n\n        if isSequence:\n            source_files = [f for f in os.listdir(source_dir)\n                            if ext in f\n                            if items[0] in f]\n        else:\n            source_files = file_name\n\n        # Include start and end render frame in label\n        name = node.name()\n        label = \"{0} ({1}-{2})\".format(\n            name,\n            int(first_frame),\n            int(last_frame)\n        )\n\n        self.log.debug(\"collected_frames: {}\".format(label))\n\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        representation = {\n            'name': ext,\n            'ext': ext,\n            'files': source_files,\n            \"stagingDir\": source_dir,\n            \"frameStart\": \"%0{}d\".format(\n                len(str(last_frame))) % first_frame\n        }\n        instance.data[\"representations\"].append(representation)\n\n        transfer = node[\"publish\"] if \"publish\" in node.knobs() else False\n        instance.data['transfer'] = transfer\n\n        # Add version data to instance\n        # QUESTION why is 'productName' stored to version data and\n        #   'families' are explicitly set here?\n        version_data = {\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"frameStart\": first_frame + handle_start,\n            \"frameEnd\": last_frame - handle_end,\n            \"colorspace\": colorspace,\n            \"families\": [instance.data[\"productBaseType\"]],\n            \"productName\": instance.data[\"productName\"],\n            \"fps\": instance.context.data[\"fps\"]\n        }\n\n        instance.data.update({\n            \"versionData\": version_data,\n            \"path\": path,\n            \"ext\": ext,\n            \"label\": label,\n            \"frameStart\": first_frame,\n            \"frameEnd\": last_frame,\n            \"colorspace\": colorspace,\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"step\": 1,\n            \"fps\": int(nuke.root()['fps'].value())\n        })\n\n        self.log.debug(\"instance.data: {}\".format(instance.data))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_slate_node.html","title":"collect_slate_node","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_slate_node.html#client.ayon_nuke.plugins.publish.collect_slate_node.CollectSlate","title":"<code>CollectSlate</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Check if SLATE node is in scene and connected to rendering tree</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_slate_node.py</code> <pre><code>class CollectSlate(pyblish.api.InstancePlugin):\n    \"\"\"Check if SLATE node is in scene and connected to rendering tree\"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.002\n    label = \"Collect Slate Node\"\n    hosts = [\"nuke\"]\n    families = [\"render\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        node = instance.data[\"transientData\"][\"node\"]\n\n        slate = next(\n            (\n                n_ for n_ in nuke.allNodes()\n                if \"slate\" in n_.name().lower()\n                if not n_[\"disable\"].getValue() and\n                \"publish_instance\" not in n_.knobs()  # Exclude instance nodes.\n            ),\n            None\n        )\n\n        if slate:\n            # check if slate node is connected to write node tree\n            slate_check = 0\n            slate_node = None\n            while slate_check == 0:\n                try:\n                    node = node.dependencies()[0]\n                    if slate.name() in node.name():\n                        slate_node = node\n                        slate_check = 1\n                except IndexError:\n                    break\n\n            if slate_node:\n                instance.data[\"slateNode\"] = slate_node\n                instance.data[\"slate\"] = True\n                instance.data[\"families\"].append(\"slate\")\n                self.log.debug(\n                    \"Slate node is in node graph: `{}`\".format(slate.name()))\n                self.log.debug(\n                    \"__ instance.data: `{}`\".format(instance.data))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_workfile.html","title":"collect_workfile","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_workfile.html#client.ayon_nuke.plugins.publish.collect_workfile.CollectWorkfile","title":"<code>CollectWorkfile</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Collect current script for publish.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_workfile.py</code> <pre><code>class CollectWorkfile(pyblish.api.InstancePlugin):\n    \"\"\"Collect current script for publish.\"\"\"\n\n    order = pyblish.api.CollectorOrder\n    label = \"Collect Workfile\"\n    hosts = ['nuke']\n    families = [\"workfile\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):  # sourcery skip: avoid-builtin-shadow\n\n        script_data = instance.context.data[\"scriptData\"]\n        current_file = os.path.normpath(nuke.root().name())\n\n        # creating instances per write node\n        staging_dir = os.path.dirname(current_file)\n        base_name = os.path.basename(current_file)\n\n        # creating representation\n        representation = {\n            'name': 'nk',\n            'ext': 'nk',\n            'files': base_name,\n            \"stagingDir\": staging_dir,\n        }\n\n        # creating instance data\n        instance.data.update({\n            \"name\": base_name,\n            \"representations\": [representation]\n        })\n\n        # adding basic script data\n        instance.data.update(script_data)\n\n        self.log.debug(\n            \"Collected current script version: {}\".format(current_file)\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_writes.html","title":"collect_writes","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/collect_writes.html#client.ayon_nuke.plugins.publish.collect_writes.CollectNukeWrites","title":"<code>CollectNukeWrites</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>ColormanagedPyblishPluginMixin</code></p> <p>Collect all write nodes.</p> Source code in <code>client/ayon_nuke/plugins/publish/collect_writes.py</code> <pre><code>class CollectNukeWrites(pyblish.api.InstancePlugin,\n                        publish.ColormanagedPyblishPluginMixin):\n    \"\"\"Collect all write nodes.\"\"\"\n\n    order = pyblish.api.CollectorOrder + 0.0021\n    label = \"Collect Writes\"\n    hosts = [\"nuke\", \"nukeassist\"]\n    families = [\"render\", \"prerender\", \"image\"]\n\n    settings_category = \"nuke\"\n\n    # cache\n    _write_nodes = {}\n    _frame_ranges = {}\n\n    def process(self, instance):\n\n        # compatibility. This is mainly focused on `renders`folders which\n        # were previously not cleaned up (and could be used in read notes)\n        # this logic should be removed and replaced with custom staging dir\n        if instance.data.get(\"stagingDir_persistent\") is None:\n            instance.data[\"stagingDir_persistent\"] = True\n\n        group_node = instance.data[\"transientData\"][\"node\"]\n\n        render_target = instance.data[\"render_target\"]\n\n        write_node = self._write_node_helper(instance)\n\n        if write_node is None:\n            self.log.warning(\n                \"Created node '{}' is missing write node!\".format(\n                    group_node.name()\n                )\n            )\n            return\n\n        # get colorspace and add to version data\n        colorspace = napi.get_colorspace_from_node(write_node)\n\n        if render_target == \"frames\":\n            self._set_existing_files_data(instance, colorspace)\n\n        elif render_target == \"frames_farm\":\n            collected_frames = self._set_existing_files_data(\n                instance, colorspace)\n\n            self._set_expected_files(instance, collected_frames)\n\n            self._add_farm_instance_data(instance)\n\n        if render_target == \"farm\":\n            self._add_farm_instance_data(instance)\n\n        # set additional instance data\n        self._set_additional_instance_data(instance, render_target, colorspace)\n\n    def _set_existing_files_data(self, instance, colorspace):\n        \"\"\"Set existing files data to instance data.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            colorspace (str): colorspace\n\n        Returns:\n            list: collected frames\n        \"\"\"\n        collected_frames = self._get_collected_frames(instance)\n\n        representation = self._get_existing_frames_representation(\n            instance, collected_frames\n        )\n\n        # inject colorspace data\n        self.set_representation_colorspace(\n            representation, instance.context,\n            colorspace=colorspace\n        )\n\n        instance.data[\"representations\"].append(representation)\n\n        return collected_frames\n\n    def _set_expected_files(self, instance, collected_frames):\n        \"\"\"Set expected files to instance data.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            collected_frames (list): collected frames\n        \"\"\"\n        write_node = self._write_node_helper(instance)\n\n        write_file_path = nuke.filename(write_node)\n        output_dir = os.path.dirname(write_file_path)\n\n        instance.data[\"expectedFiles\"] = [\n            os.path.join(output_dir, source_file)\n            for source_file in collected_frames\n        ]\n\n    def _get_frame_range_data(self, instance):\n        \"\"\"Get frame range data from instance.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n\n        Returns:\n            tuple: first_frame, last_frame\n        \"\"\"\n\n        instance_name = instance.data[\"name\"]\n\n        if self._frame_ranges.get(instance_name):\n            # return cashed write node\n            return self._frame_ranges[instance_name]\n\n        write_node = self._write_node_helper(instance)\n\n        # Get frame range from workfile\n        first_frame = int(nuke.root()[\"first_frame\"].getValue())\n        last_frame = int(nuke.root()[\"last_frame\"].getValue())\n\n        # Get frame range from write node if activated\n        if write_node[\"use_limit\"].getValue():\n            first_frame = int(write_node[\"first\"].getValue())\n            last_frame = int(write_node[\"last\"].getValue())\n\n        # add to cache\n        self._frame_ranges[instance_name] = (first_frame, last_frame)\n\n        return first_frame, last_frame\n\n    def _set_additional_instance_data(\n        self, instance, render_target, colorspace\n    ):\n        \"\"\"Set additional instance data.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            render_target (str): render target\n            colorspace (str): colorspace\n        \"\"\"\n        product_base_type = instance.data[\"productBaseType\"]\n\n        # add targeted family to families\n        instance.data[\"families\"].append(\n            f\"{product_base_type}.{render_target}\"\n        )\n        self.log.debug(\"Appending render target to families: {}.{}\".format(\n            product_base_type, render_target)\n        )\n\n        write_node = self._write_node_helper(instance)\n        if instance.data.get(\"stagingDir_is_custom\", False):\n            self.log.info(\"Custom staging dir detected. Syncing write nodes output path.\")\n            napi.lib.writes_version_sync(write_node, self.log)\n\n        # Determine defined file type\n        path = write_node[\"file\"].value()\n        ext = os.path.splitext(path)[1].lstrip(\".\")\n\n        # determine defined channel type\n        color_channels = write_node[\"channels\"].value()\n\n        # get frame range data\n        handle_start = instance.context.data[\"handleStart\"]\n        handle_end = instance.context.data[\"handleEnd\"]\n        first_frame, last_frame = self._get_frame_range_data(instance)\n\n        # get output paths\n        write_file_path = nuke.filename(write_node)\n        output_dir = os.path.dirname(write_file_path)\n\n        # TODO: remove this when we have proper colorspace support\n        version_data = {\n            \"colorspace\": colorspace\n        }\n\n        instance.data.update({\n            \"versionData\": version_data,\n            \"path\": write_file_path,\n            \"outputDir\": output_dir,\n            \"ext\": ext,\n            \"colorspace\": colorspace,\n            \"color_channels\": color_channels\n        })\n\n        if product_base_type == \"render\":\n            instance.data.update({\n                \"handleStart\": handle_start,\n                \"handleEnd\": handle_end,\n                \"frameStart\": first_frame + handle_start,\n                \"frameEnd\": last_frame - handle_end,\n                \"frameStartHandle\": first_frame,\n                \"frameEndHandle\": last_frame,\n            })\n        else:\n            instance.data.update({\n                \"handleStart\": 0,\n                \"handleEnd\": 0,\n                \"frameStart\": first_frame,\n                \"frameEnd\": last_frame,\n                \"frameStartHandle\": first_frame,\n                \"frameEndHandle\": last_frame,\n            })\n\n    def _write_node_helper(self, instance):\n        \"\"\"Helper function to get write node from instance.\n\n        Also sets instance transient data with child nodes.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n\n        Returns:\n            nuke.Node: write node\n        \"\"\"\n        instance_name = instance.data[\"name\"]\n\n        if self._write_nodes.get(instance_name):\n            # return cashed write node\n            return self._write_nodes[instance_name]\n\n        # get all child nodes from group node\n        child_nodes = napi.get_instance_group_node_childs(instance)\n\n        # set child nodes to instance transient data\n        instance.data[\"transientData\"][\"childNodes\"] = child_nodes\n\n        write_node = None\n        for node_ in child_nodes:\n            if node_.Class() == \"Write\":\n                write_node = node_\n\n        if write_node:\n            # for slate frame extraction\n            instance.data[\"transientData\"][\"writeNode\"] = write_node\n            # add to cache\n            self._write_nodes[instance_name] = write_node\n\n            return self._write_nodes[instance_name]\n\n    def _get_existing_frames_representation(\n        self,\n        instance,\n        collected_frames\n    ):\n        \"\"\"Get existing frames representation.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            collected_frames (list): collected frames\n\n        Returns:\n            dict: representation\n        \"\"\"\n\n        first_frame, last_frame = self._get_frame_range_data(instance)\n\n        write_node = self._write_node_helper(instance)\n\n        write_file_path = nuke.filename(write_node)\n        output_dir = os.path.dirname(write_file_path)\n\n        # Determine defined file type\n        path = write_node[\"file\"].value()\n        ext = os.path.splitext(path)[1].lstrip(\".\")\n\n        representation = {\n            \"name\": ext,\n            \"ext\": ext,\n            \"stagingDir\": output_dir,\n            \"tags\": []\n        }\n\n        # set slate frame\n        collected_frames = self._add_slate_frame_to_collected_frames(\n            instance,\n            collected_frames,\n            first_frame\n        )\n\n        if len(collected_frames) == 1:\n            representation['files'] = collected_frames.pop()\n        else:\n            representation['files'] = collected_frames\n\n        return representation\n\n    def _get_frame_start_str(self, first_frame, last_frame):\n        \"\"\"Get frame start string.\n\n        Args:\n            first_frame (int): first frame\n            last_frame (int): last frame\n\n        Returns:\n            str: frame start string\n        \"\"\"\n        # convert first frame to string with padding\n        return (\n            \"{{:0{}d}}\".format(len(str(last_frame)))\n        ).format(first_frame)\n\n    def _add_slate_frame_to_collected_frames(\n        self,\n        instance,\n        collected_frames,\n        first_frame\n    ):\n        \"\"\"Add slate frame to collected frames.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n            collected_frames (list): collected frames\n            first_frame (int): first frame\n\n        Returns:\n            list: collected frames\n        \"\"\"\n        if \"slate\" not in instance.data[\"families\"]:\n            return collected_frames\n\n        write_node = self._write_node_helper(instance)\n        expected_slate_frame = first_frame - 1\n        expected_slate_path = write_node[\"file\"].evaluate(expected_slate_frame)\n\n        if not os.path.exists(expected_slate_path):\n            slate_frame = os.path.basename(expected_slate_path)\n            collected_frames.insert(0, slate_frame)\n\n        return collected_frames\n\n    def _add_farm_instance_data(self, instance):\n        \"\"\"Add farm publishing related instance data.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n        \"\"\"\n\n        # make sure rendered sequence on farm will\n        # be used for extract review\n        if not instance.data.get(\"review\"):\n            instance.data[\"useSequenceForReview\"] = False\n\n        # Farm rendering\n        instance.data.update({\n            \"transfer\": False,\n            \"farm\": True  # to skip integrate\n        })\n        self.log.info(\"Farm rendering ON ...\")\n\n    def _get_collected_frames(self, instance):\n        \"\"\"Get collected frames.\n\n        Args:\n            instance (pyblish.api.Instance): pyblish instance\n\n        Returns:\n            list: collected frames\n        \"\"\"\n\n        first_frame, last_frame = self._get_frame_range_data(instance)\n\n        write_node = self._write_node_helper(instance)\n\n        write_file_path = nuke.filename(write_node)\n        output_dir = os.path.dirname(write_file_path)\n\n        # get file path knob\n        node_file_knob = write_node[\"file\"]\n        # list file paths based on input frames\n        expected_paths = list(sorted({\n            node_file_knob.evaluate(frame)\n            for frame in range(first_frame, last_frame + 1)\n        }))\n\n        # convert only to base names\n        expected_filenames = {\n            os.path.basename(filepath)\n            for filepath in expected_paths\n        }\n\n        # make sure files are existing at folder\n        collected_frames = [\n            filename\n            for filename in os.listdir(output_dir)\n            if filename in expected_filenames\n        ]\n\n        return collected_frames\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_backdrop.html","title":"extract_backdrop","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_backdrop.html#client.ayon_nuke.plugins.publish.extract_backdrop.ExtractBackdropNode","title":"<code>ExtractBackdropNode</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>Extracting content of backdrop nodes</p> <p>Will create nuke script only with containing nodes. Also it will solve Input and Output nodes.</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_backdrop.py</code> <pre><code>class ExtractBackdropNode(publish.Extractor):\n    \"\"\"Extracting content of backdrop nodes\n\n    Will create nuke script only with containing nodes.\n    Also it will solve Input and Output nodes.\n\n    \"\"\"\n\n    order = pyblish.api.ExtractorOrder\n    label = \"Extract Backdrop\"\n    hosts = [\"nuke\"]\n    families = [\"nukenodes\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        tmp_nodes = []\n        child_nodes = instance.data[\"transientData\"][\"childNodes\"]\n        # all connections outside of backdrop\n        connections_in = instance.data[\"transientData\"][\"nodeConnectionsIn\"]\n        connections_out = instance.data[\"transientData\"][\"nodeConnectionsOut\"]\n        self.log.debug(\"_ connections_in: `{}`\".format(connections_in))\n        self.log.debug(\"_ connections_out: `{}`\".format(connections_out))\n\n        # Define extract output file path\n        stagingdir = self.staging_dir(instance)\n        filename = \"{0}.nk\".format(instance.name)\n        path = os.path.join(stagingdir, filename)\n\n        # maintain selection\n        with maintained_selection():\n            # create input child_nodes and name them as passing node (*_INP)\n            for n, inputs in connections_in.items():\n                for i, input in inputs:\n                    inpn = nuke.createNode(\"Input\")\n                    inpn[\"name\"].setValue(\"{}_{}_INP\".format(n.name(), i))\n                    n.setInput(i, inpn)\n                    inpn.setXYpos(input.xpos(), input.ypos())\n                    child_nodes.append(inpn)\n                    tmp_nodes.append(inpn)\n\n            reset_selection()\n\n            # connect output node\n            for n, output in connections_out.items():\n                opn = nuke.createNode(\"Output\")\n                output.setInput(\n                    next((i for i, d in enumerate(output.dependencies())\n                          if d.name() in n.name()), 0), opn)\n                opn.setInput(0, n)\n                opn.autoplace()\n                child_nodes.append(opn)\n                tmp_nodes.append(opn)\n                reset_selection()\n\n            # select child_nodes to copy\n            reset_selection()\n            select_nodes(child_nodes)\n            # create tmp nk file\n            # save file to the path\n            nuke.nodeCopy(path)\n\n            # Clean up\n            for tn in tmp_nodes:\n                nuke.delete(tn)\n\n            # restore original connections\n            # reconnect input node\n            for n, inputs in connections_in.items():\n                for i, input in inputs:\n                    n.setInput(i, input)\n\n            # reconnect output node\n            for n, output in connections_out.items():\n                output.setInput(\n                    next((i for i, d in enumerate(output.dependencies())\n                          if d.name() in n.name()), 0), n)\n\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        # create representation\n        representation = {\n            'name': 'nk',\n            'ext': 'nk',\n            'files': filename,\n            \"stagingDir\": stagingdir\n        }\n        instance.data[\"representations\"].append(representation)\n\n        self.log.debug(\"Extracted instance '{}' to: {}\".format(\n            instance.name, path))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_camera.html","title":"extract_camera","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_camera.html#client.ayon_nuke.plugins.publish.extract_camera.ExtractCamera","title":"<code>ExtractCamera</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>3D camera extractor</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_camera.py</code> <pre><code>class ExtractCamera(publish.Extractor):\n    \"\"\" 3D camera extractor\n    \"\"\"\n    label = 'Extract Camera'\n    order = pyblish.api.ExtractorOrder\n    families = [\"camera\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def _get_camera_export_presets(self, instance):\n        \"\"\"\n        Args:\n            instance (dict): The current instance being published.\n\n        Returns:\n            list: The camera export presets to use.\n        \"\"\"\n        write_geo_knobs = [\n            (\"writeGeometries\", False),\n            (\"writePointClouds\", False),\n            (\"writeAxes\", False)\n        ]\n\n        publish_settings = get_publish_config()\n        extract_camera_settings = publish_settings.get(\"ExtractCameraFormat\", {})\n        export_camera_settings = extract_camera_settings.get(\"export_camera_format\", \"abc\")\n\n        if export_camera_settings == \"abc\":\n            write_geo_knobs.insert(0, (\"file_type\", \"abc\"))\n            write_geo_knobs.append(((\"storageFormat\", \"Ogawa\")))\n\n        elif export_camera_settings == \"fbx\":\n            write_geo_knobs.insert(0, (\"file_type\", \"fbx\"))\n            write_geo_knobs.append((\"writeLights\", False))\n\n        else:\n            raise ValueError(\n                f\"Invalid Camera export format: {export_camera_settings}\"\n            )\n\n        return write_geo_knobs\n\n    def process(self, instance):\n\n        # pass staging dir data\n        staging_dir = instance.data.get(\"stagingDir\")\n        if not staging_dir:\n            staging_dir = os.path.normpath(\n                os.path.dirname(instance.data[\"path\"]))\n            instance.data[\"stagingDir\"] = staging_dir\n\n        camera_node = instance.data[\"transientData\"][\"node\"]\n        handle_start = instance.context.data[\"handleStart\"]\n        handle_end = instance.context.data[\"handleEnd\"]\n        first_frame = int(nuke.root()[\"first_frame\"].getValue())\n        last_frame = int(nuke.root()[\"last_frame\"].getValue())\n        step = 1\n        output_range = str(nuke.FrameRange(first_frame, last_frame, step))\n\n        rm_nodes = []\n        self.log.debug(\"Creating additional nodes for 3D Camera Extractor\")\n        product_name = instance.data[\"productName\"]\n\n        # get extension form preset\n        export_presets = self._get_camera_export_presets(instance)\n        extension = next((k[1] for k in export_presets\n                          if k[0] == \"file_type\"), None)\n        if not extension:\n            raise RuntimeError(\n                \"Bad config for extension in presets. \"\n                \"Talk to your supervisor or pipeline admin\")\n\n        # create file name and path\n        filename = product_name + \".{}\".format(extension)\n        file_path = os.path.join(staging_dir, filename).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            # bake camera with axeses onto word coordinate XYZ\n            rm_n = bakeCameraWithAxeses(\n                camera_node, output_range)\n            rm_nodes.append(rm_n)\n\n            # create scene node\n            rm_n = nuke.createNode(\"Scene\")\n            rm_nodes.append(rm_n)\n\n            # create write geo node\n            wg_n = nuke.createNode(\"WriteGeo\")\n            wg_n[\"file\"].setValue(file_path)\n            # add path to write to\n            for k, v in export_presets:\n                wg_n[k].setValue(v)\n            rm_nodes.append(wg_n)\n\n            # write out camera\n            nuke.execute(\n                wg_n,\n                int(first_frame),\n                int(last_frame)\n            )\n            # erase additional nodes\n            for n in rm_nodes:\n                nuke.delete(n)\n\n        # create representation data\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        representation = {\n            'name': extension,\n            'ext': extension,\n            'files': filename,\n            \"stagingDir\": staging_dir,\n            \"frameStart\": first_frame,\n            \"frameEnd\": last_frame\n        }\n        instance.data[\"representations\"].append(representation)\n\n        instance.data.update({\n            \"path\": file_path,\n            \"outputDir\": staging_dir,\n            \"ext\": extension,\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"frameStart\": first_frame + handle_start,\n            \"frameEnd\": last_frame - handle_end,\n            \"frameStartHandle\": first_frame,\n            \"frameEndHandle\": last_frame,\n        })\n\n        self.log.debug(\"Extracted instance '{0}' to: {1}\".format(\n            instance.name, file_path))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_camera.html#client.ayon_nuke.plugins.publish.extract_camera.bakeCameraWithAxeses","title":"<code>bakeCameraWithAxeses(camera_node, output_range)</code>","text":"<p>Baking all perent hierarchy of axeses into camera with transposition onto word XYZ coordinance</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_camera.py</code> <pre><code>def bakeCameraWithAxeses(camera_node, output_range):\n    \"\"\" Baking all perent hierarchy of axeses into camera\n    with transposition onto word XYZ coordinance\n    \"\"\"\n    bakeFocal = False\n    bakeHaperture = False\n    bakeVaperture = False\n\n    camera_matrix = camera_node['world_matrix']\n\n    new_cam_n = nuke.createNode(\"Camera2\")\n    new_cam_n.setInput(0, None)\n    new_cam_n['rotate'].setAnimated()\n    new_cam_n['translate'].setAnimated()\n\n    old_focal = camera_node['focal']\n    if old_focal.isAnimated() and not (old_focal.animation(0).constant()):\n        new_cam_n['focal'].setAnimated()\n        bakeFocal = True\n    else:\n        new_cam_n['focal'].setValue(old_focal.value())\n\n    old_haperture = camera_node['haperture']\n    if old_haperture.isAnimated() and not (\n            old_haperture.animation(0).constant()):\n        new_cam_n['haperture'].setAnimated()\n        bakeHaperture = True\n    else:\n        new_cam_n['haperture'].setValue(old_haperture.value())\n\n    old_vaperture = camera_node['vaperture']\n    if old_vaperture.isAnimated() and not (\n            old_vaperture.animation(0).constant()):\n        new_cam_n['vaperture'].setAnimated()\n        bakeVaperture = True\n    else:\n        new_cam_n['vaperture'].setValue(old_vaperture.value())\n\n    new_cam_n['win_translate'].setValue(camera_node['win_translate'].value())\n    new_cam_n['win_scale'].setValue(camera_node['win_scale'].value())\n\n    for x in nuke.FrameRange(output_range):\n        math_matrix = nuke.math.Matrix4()\n        for y in range(camera_matrix.height()):\n            for z in range(camera_matrix.width()):\n                matrix_pointer = z + (y * camera_matrix.width())\n                math_matrix[matrix_pointer] = camera_matrix.getValueAt(\n                    x, (y + (z * camera_matrix.width())))\n\n        rot_matrix = nuke.math.Matrix4(math_matrix)\n        rot_matrix.rotationOnly()\n        rot = rot_matrix.rotationsZXY()\n\n        new_cam_n['rotate'].setValueAt(math.degrees(rot[0]), x, 0)\n        new_cam_n['rotate'].setValueAt(math.degrees(rot[1]), x, 1)\n        new_cam_n['rotate'].setValueAt(math.degrees(rot[2]), x, 2)\n        new_cam_n['translate'].setValueAt(\n            camera_matrix.getValueAt(x, 3), x, 0)\n        new_cam_n['translate'].setValueAt(\n            camera_matrix.getValueAt(x, 7), x, 1)\n        new_cam_n['translate'].setValueAt(\n            camera_matrix.getValueAt(x, 11), x, 2)\n\n        if bakeFocal:\n            new_cam_n['focal'].setValueAt(old_focal.getValueAt(x), x)\n        if bakeHaperture:\n            new_cam_n['haperture'].setValueAt(old_haperture.getValueAt(x), x)\n        if bakeVaperture:\n            new_cam_n['vaperture'].setValueAt(old_vaperture.getValueAt(x), x)\n\n    return new_cam_n\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_gizmo.html","title":"extract_gizmo","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_gizmo.html#client.ayon_nuke.plugins.publish.extract_gizmo.ExtractGizmo","title":"<code>ExtractGizmo</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>Extracting Gizmo (Group) node</p> <p>Will create nuke script only with the Gizmo node.</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_gizmo.py</code> <pre><code>class ExtractGizmo(publish.Extractor):\n    \"\"\"Extracting Gizmo (Group) node\n\n    Will create nuke script only with the Gizmo node.\n    \"\"\"\n\n    order = pyblish.api.ExtractorOrder\n    label = \"Extract Gizmo (group)\"\n    hosts = [\"nuke\"]\n    families = [\"gizmo\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        tmp_nodes = []\n        orig_grpn = instance.data[\"transientData\"][\"node\"]\n\n        # Define extract output file path\n        stagingdir = self.staging_dir(instance)\n        filename = \"{0}.nk\".format(instance.name)\n        path = os.path.join(stagingdir, filename)\n\n        # maintain selection\n        with maintained_selection():\n            orig_grpn_name = orig_grpn.name()\n            tmp_grpn_name = orig_grpn_name + \"_tmp\"\n            # select original group node\n            select_nodes([orig_grpn])\n\n            # copy to clipboard\n            nuke.nodeCopy(\"%clipboard%\")\n\n            # reset selection to none\n            reset_selection()\n\n            # paste clipboard\n            nuke.nodePaste(\"%clipboard%\")\n\n            # assign pasted node\n            copy_grpn = nuke.selectedNode()\n            copy_grpn.setXYpos((orig_grpn.xpos() + 120), orig_grpn.ypos())\n\n            # convert gizmos to groups\n            pnutils.bake_gizmos_recursively(copy_grpn)\n\n            # add to temporary nodes\n            tmp_nodes.append(copy_grpn)\n\n            # swap names\n            orig_grpn.setName(tmp_grpn_name)\n            copy_grpn.setName(orig_grpn_name)\n\n            # create tmp nk file\n            # save file to the path\n            nuke.nodeCopy(path)\n\n            # Clean up\n            for tn in tmp_nodes:\n                nuke.delete(tn)\n\n            # rename back to original\n            orig_grpn.setName(orig_grpn_name)\n\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        # create representation\n        representation = {\n            'name': 'gizmo',\n            'ext': 'nk',\n            'files': filename,\n            \"stagingDir\": stagingdir\n        }\n        instance.data[\"representations\"].append(representation)\n\n        self.log.debug(\"Extracted instance '{}' to: {}\".format(\n            instance.name, path))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_headless_farm.html","title":"extract_headless_farm","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_headless_farm.html#client.ayon_nuke.plugins.publish.extract_headless_farm.ExtractRenderOnFarm","title":"<code>ExtractRenderOnFarm</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Copy the workfile to a timestamped copy.</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_headless_farm.py</code> <pre><code>class ExtractRenderOnFarm(pyblish.api.InstancePlugin):\n    \"\"\"Copy the workfile to a timestamped copy.\"\"\"\n\n    order = pyblish.api.ExtractorOrder + 0.499\n    label = \"Extract Render On Farm\"\n    hosts = [\"nuke\"]\n    families = [\"render_on_farm\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        if not instance.context.data.get(\"render_on_farm\", False):\n            return\n\n        host = registered_host()\n        current_datetime = datetime.now()\n        formatted_timestamp = current_datetime.strftime(\"%Y%m%d%H%M%S\")\n        base, ext = os.path.splitext(host.get_current_workfile())\n\n        directory = os.path.join(os.path.dirname(base), \"farm_submissions\")\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n\n        filename = \"{}_{}{}\".format(\n            os.path.basename(base), formatted_timestamp, ext\n        )\n        path = os.path.join(directory, filename).replace(\"\\\\\", \"/\")\n        instance.context.data[\"currentFile\"] = path\n        shutil.copy(host.get_current_workfile(), path)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_model.html","title":"extract_model","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_model.html#client.ayon_nuke.plugins.publish.extract_model.ExtractModel","title":"<code>ExtractModel</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>3D model extractor</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_model.py</code> <pre><code>class ExtractModel(publish.Extractor):\n    \"\"\" 3D model extractor\n    \"\"\"\n    label = 'Extract Model'\n    order = pyblish.api.ExtractorOrder\n    families = [\"model\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    # presets\n    write_geo_knobs = [\n        (\"file_type\", \"abc\"),\n        (\"storageFormat\", \"Ogawa\"),\n        (\"writeGeometries\", True),\n        (\"writePointClouds\", False),\n        (\"writeAxes\", False)\n    ]\n\n    def process(self, instance):\n        handle_start = instance.context.data[\"handleStart\"]\n        handle_end = instance.context.data[\"handleEnd\"]\n        first_frame = int(nuke.root()[\"first_frame\"].getValue())\n        last_frame = int(nuke.root()[\"last_frame\"].getValue())\n\n        self.log.debug(\"instance.data: `{}`\".format(\n            pformat(instance.data)))\n\n        rm_nodes = []\n        model_node = instance.data[\"transientData\"][\"node\"]\n\n        self.log.debug(\"Creating additional nodes for Extract Model\")\n        product_name = instance.data[\"productName\"]\n        staging_dir = self.staging_dir(instance)\n\n        extension = next((k[1] for k in self.write_geo_knobs\n                          if k[0] == \"file_type\"), None)\n        if not extension:\n            raise RuntimeError(\n                \"Bad config for extension in presets. \"\n                \"Talk to your supervisor or pipeline admin\")\n\n        # create file name and path\n        filename = product_name + \".{}\".format(extension)\n        file_path = os.path.join(staging_dir, filename).replace(\"\\\\\", \"/\")\n\n        with maintained_selection():\n            # select model node\n            select_nodes([model_node])\n\n            # create write geo node\n            wg_n = nuke.createNode(\"WriteGeo\")\n            wg_n[\"file\"].setValue(file_path)\n            # add path to write to\n            for k, v in self.write_geo_knobs:\n                wg_n[k].setValue(v)\n            rm_nodes.append(wg_n)\n\n            # write out model\n            nuke.execute(\n                wg_n,\n                int(first_frame),\n                int(last_frame)\n            )\n            # erase additional nodes\n            for n in rm_nodes:\n                nuke.delete(n)\n\n            self.log.debug(\"Filepath: {}\".format(file_path))\n\n        # create representation data\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        representation = {\n            'name': extension,\n            'ext': extension,\n            'files': filename,\n            \"stagingDir\": staging_dir,\n            \"frameStart\": first_frame,\n            \"frameEnd\": last_frame\n        }\n        instance.data[\"representations\"].append(representation)\n\n        instance.data.update({\n            \"path\": file_path,\n            \"outputDir\": staging_dir,\n            \"ext\": extension,\n            \"handleStart\": handle_start,\n            \"handleEnd\": handle_end,\n            \"frameStart\": first_frame + handle_start,\n            \"frameEnd\": last_frame - handle_end,\n            \"frameStartHandle\": first_frame,\n            \"frameEndHandle\": last_frame,\n        })\n\n        self.log.debug(\"Extracted instance '{0}' to: {1}\".format(\n            instance.name, file_path))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_ouput_node.html","title":"extract_ouput_node","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_ouput_node.html#client.ayon_nuke.plugins.publish.extract_ouput_node.CreateOutputNode","title":"<code>CreateOutputNode</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Adding output node for each output write node So when latly user will want to Load .nk as LifeGroup or Precomp Nuke will not complain about missing Output node</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_ouput_node.py</code> <pre><code>class CreateOutputNode(pyblish.api.ContextPlugin):\n    \"\"\"Adding output node for each output write node\n    So when latly user will want to Load .nk as LifeGroup or Precomp\n    Nuke will not complain about missing Output node\n    \"\"\"\n    label = 'Output Node Create'\n    order = pyblish.api.ExtractorOrder + 0.4\n    families = [\"workfile\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, context):\n        # capture selection state\n        with maintained_selection():\n\n            active_node = [\n                inst.data.get(\"transientData\", {}).get(\"node\")\n                for inst in context\n                if inst.data.get(\"transientData\", {}).get(\"node\")\n                if inst.data.get(\n                    \"transientData\", {}).get(\"node\").Class() != \"Root\"\n            ]\n\n            if active_node:\n                active_node = active_node.pop()\n                self.log.debug(\"Active node: {}\".format(active_node))\n                active_node['selected'].setValue(True)\n\n            # select only instance render node\n            output_node = nuke.createNode(\"Output\")\n\n            # deselect all and select the original selection\n            output_node['selected'].setValue(False)\n\n            # save script\n            nuke.scriptSave()\n\n            # add node to instance node list\n            context.data[\"outputNode\"] = output_node\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_output_directory.html","title":"extract_output_directory","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_output_directory.html#client.ayon_nuke.plugins.publish.extract_output_directory.ExtractOutputDirectory","title":"<code>ExtractOutputDirectory</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Extracts the output path for any collection or single output_path.</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_output_directory.py</code> <pre><code>class ExtractOutputDirectory(pyblish.api.InstancePlugin):\n    \"\"\"Extracts the output path for any collection or single output_path.\"\"\"\n\n    order = pyblish.api.ExtractorOrder - 0.05\n    label = \"Output Directory\"\n    optional = True\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n\n        path = None\n\n        if \"output_path\" in instance.data.keys():\n            path = instance.data[\"path\"]\n\n        if not path:\n            return\n\n        if not os.path.exists(os.path.dirname(path)):\n            os.makedirs(os.path.dirname(path))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_render_local.html","title":"extract_render_local","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_render_local.html#client.ayon_nuke.plugins.publish.extract_render_local.NukeRenderLocal","title":"<code>NukeRenderLocal</code>","text":"<p>               Bases: <code>Extractor</code>, <code>ColormanagedPyblishPluginMixin</code></p> <p>Render the current Nuke composition locally.</p> <p>Extract the result of savers by starting a comp render This will run the local render of Nuke.</p> <p>Allows to use last published frames and overwrite only specific ones (set in instance.data.get(\"frames_to_fix\"))</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_render_local.py</code> <pre><code>class NukeRenderLocal(publish.Extractor,\n                      publish.ColormanagedPyblishPluginMixin):\n    \"\"\"Render the current Nuke composition locally.\n\n    Extract the result of savers by starting a comp render\n    This will run the local render of Nuke.\n\n    Allows to use last published frames and overwrite only specific ones\n    (set in instance.data.get(\"frames_to_fix\"))\n    \"\"\"\n\n    order = pyblish.api.ExtractorOrder\n    label = \"Render Local\"\n    hosts = [\"nuke\"]\n    families = [\"render.local\", \"prerender.local\", \"image.local\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        child_nodes = (\n            instance.data.get(\"transientData\", {}).get(\"childNodes\")\n            or instance\n        )\n\n        node = None\n        for x in child_nodes:\n            if x.Class() == \"Write\":\n                node = x\n\n        self.log.debug(\"instance collected: {}\".format(instance.data))\n\n        node_product_name = instance.data.get(\"name\", None)\n\n        first_frame = instance.data.get(\"frameStartHandle\", None)\n        last_frame = instance.data.get(\"frameEndHandle\", None)\n\n        filenames = []\n        node_file = node[\"file\"]\n        # Collect expected filepaths for each frame\n        # - for cases that output is still image is first created set of\n        #   paths which is then sorted and converted to list\n        expected_paths = list(sorted({\n            node_file.evaluate(frame)\n            for frame in range(first_frame, last_frame + 1)\n        }))\n        # Extract only filenames for representation\n        filenames.extend([\n            os.path.basename(filepath)\n            for filepath in expected_paths\n        ])\n\n        # Ensure output directory exists.\n        out_dir = os.path.dirname(expected_paths[0])\n        if not os.path.exists(out_dir):\n            os.makedirs(out_dir)\n\n        frames_to_render = [(first_frame, last_frame)]\n\n        frames_to_fix = instance.data.get(\"frames_to_fix\")\n        if instance.data.get(\"last_version_published_files\") and frames_to_fix:\n            frames_to_render = self._get_frames_to_render(frames_to_fix)\n            anatomy = instance.context.data[\"anatomy\"]\n            self._copy_last_published(anatomy, instance, out_dir,\n                                      filenames)\n\n        for render_first_frame, render_last_frame in frames_to_render:\n\n            self.log.info(\"Starting render\")\n            self.log.info(\"Start frame: {}\".format(render_first_frame))\n            self.log.info(\"End frame: {}\".format(render_last_frame))\n\n            # Render frames\n            try:\n                nuke.execute(\n                    str(node_product_name),\n                    int(render_first_frame),\n                    int(render_last_frame)\n                )\n            except RuntimeError as exc:\n                raise publish.PublishError(\n                    title=\"Render Failed\",\n                    message=f\"Failed to render {node_product_name}\",\n                    description=\"Check Nuke console for more information.\",\n                    detail=str(exc),\n                ) from exc\n\n        # Determine defined file type\n        path = node[\"file\"].value()\n        ext = os.path.splitext(path)[1].lstrip(\".\")\n\n        colorspace = napi.get_colorspace_from_node(node)\n\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        if len(filenames) == 1:\n            repre = {\n                'name': ext,\n                'ext': ext,\n                'files': filenames[0],\n                \"stagingDir\": out_dir\n            }\n        else:\n            repre = {\n                'name': ext,\n                'ext': ext,\n                'frameStart': (\n                    \"{{:0&gt;{}}}\"\n                    .format(len(str(last_frame)))\n                    .format(first_frame)\n                ),\n                'files': filenames,\n                \"stagingDir\": out_dir\n            }\n\n        # inject colorspace data\n        self.set_representation_colorspace(\n            repre, instance.context,\n            colorspace=colorspace\n        )\n\n        instance.data[\"representations\"].append(repre)\n\n        self.log.debug(\"Extracted instance '{0}' to: {1}\".format(\n            instance.name,\n            out_dir\n        ))\n\n        families = instance.data[\"families\"]\n        # redefinition of families\n        if \"render.local\" in families:\n            families.remove(\"render.local\")\n            families.insert(0, \"render2d\")\n        elif \"prerender.local\" in families:\n            families.remove(\"prerender.local\")\n            families.insert(0, \"prerender\")\n        elif \"image.local\" in families:\n            families.remove(\"image.local\")\n        instance.data[\"families\"] = families\n\n        collections, remainder = clique.assemble(filenames)\n        self.log.debug('collections: {}'.format(str(collections)))\n\n        if collections:\n            collection = collections[0]\n            instance.data['collection'] = collection\n\n        self.log.info('Finished render')\n\n        self.log.debug(\"_ instance.data: {}\".format(instance.data))\n\n    def _copy_last_published(self, anatomy, instance, out_dir,\n                             expected_filenames):\n        \"\"\"Copies last published files to temporary out_dir.\n\n        These are base of files which will be extended/fixed for specific\n        frames.\n        Renames published file to expected file name based on frame, eg.\n        test_project_test_asset_product_v005.1001.exr &gt; new_render.1001.exr\n        \"\"\"\n        last_published = instance.data[\"last_version_published_files\"]\n        last_published_and_frames = collect_frames(last_published)\n\n        expected_and_frames = collect_frames(expected_filenames)\n        frames_and_expected = {v: k for k, v in expected_and_frames.items()}\n        for file_path, frame in last_published_and_frames.items():\n            file_path = anatomy.fill_root(file_path)\n            if not os.path.exists(file_path):\n                continue\n            target_file_name = frames_and_expected.get(frame)\n            if not target_file_name:\n                continue\n\n            out_path = os.path.join(out_dir, target_file_name)\n            self.log.debug(\"Copying '{}' -&gt; '{}'\".format(file_path, out_path))\n            shutil.copy(file_path, out_path)\n\n            # TODO shouldn't this be uncommented\n            # instance.context.data[\"cleanupFullPaths\"].append(out_path)\n\n    def _get_frames_to_render(self, frames_to_fix):\n        \"\"\"Return list of frame range tuples to render\n\n        Args:\n            frames_to_fix (str): specific or range of frames to be rerendered\n             (1005, 1009-1010)\n        Returns:\n            (list): [(1005, 1005), (1009-1010)]\n        \"\"\"\n        frames_to_render = []\n\n        for frame_range in frames_to_fix.split(\",\"):\n            if frame_range.isdigit():\n                render_first_frame = frame_range\n                render_last_frame = frame_range\n            elif '-' in frame_range:\n                frames = frame_range.split('-')\n                render_first_frame = int(frames[0])\n                render_last_frame = int(frames[1])\n            else:\n                raise ValueError(\"Wrong format of frames to fix {}\"\n                                 .format(frames_to_fix))\n            frames_to_render.append((render_first_frame,\n                                     render_last_frame))\n        return frames_to_render\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_review_data.html","title":"extract_review_data","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_review_data.html#client.ayon_nuke.plugins.publish.extract_review_data.ExtractReviewData","title":"<code>ExtractReviewData</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>Extracts review tag into available representation</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_review_data.py</code> <pre><code>class ExtractReviewData(publish.Extractor):\n    \"\"\"Extracts review tag into available representation\n    \"\"\"\n\n    order = pyblish.api.ExtractorOrder + 0.01\n    # order = pyblish.api.CollectorOrder + 0.499\n    label = \"Extract Review Data\"\n\n    families = [\"review\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        fpath = instance.data[\"path\"]\n        ext = os.path.splitext(fpath)[-1][1:]\n\n        representations = instance.data.get(\"representations\", [])\n\n        # review can be removed since `ProcessSubmittedJobOnFarm` will create\n        # reviewable representation if needed\n        if (\n            instance.data.get(\"farm\")\n            and \"review\" in instance.data[\"families\"]\n        ):\n            instance.data[\"families\"].remove(\"review\")\n\n        # iterate representations and add `review` tag\n        for repre in representations:\n            if ext != repre[\"ext\"]:\n                continue\n\n            if not repre.get(\"tags\"):\n                repre[\"tags\"] = []\n\n            if \"review\" not in repre[\"tags\"]:\n                repre[\"tags\"].append(\"review\")\n\n            self.log.debug(\"Matching representation: {}\".format(\n                pformat(repre)\n            ))\n\n        instance.data[\"representations\"] = representations\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_review_intermediates.html","title":"extract_review_intermediates","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_review_intermediates.html#client.ayon_nuke.plugins.publish.extract_review_intermediates.ExtractReviewIntermediates","title":"<code>ExtractReviewIntermediates</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>Extracting intermediate videos or sequences with thumbnail for transcoding.</p> <p>must be run after extract_render_local.py</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_review_intermediates.py</code> <pre><code>class ExtractReviewIntermediates(publish.Extractor):\n    \"\"\"Extracting intermediate videos or sequences with\n    thumbnail for transcoding.\n\n    must be run after extract_render_local.py\n\n    \"\"\"\n\n    order = pyblish.api.ExtractorOrder + 0.01\n    label = \"Extract Review Intermediates\"\n\n    families = [\"review\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    # presets\n    viewer_lut_raw = None\n    outputs = {}\n\n    def process(self, instance):\n        # TODO 'families' should not be included for filtering of outputs\n        families = set(instance.data[\"families\"])\n\n        # Add product type to families\n        families.add(instance.data[\"productBaseType\"])\n\n        task_type = instance.context.data[\"taskType\"]\n        product_name = instance.data[\"productName\"]\n\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        # use instance's stagingDir only if explicitly custom\n        if not instance.data.get(\"stagingDir_is_custom\"):\n            instance.data[\"stagingDir\"] = os.path.normpath(\n                os.path.dirname(instance.data[\"path\"]))\n\n        self.log.debug(\n            \"StagingDir `{0}`...\".format(instance.data[\"stagingDir\"]))\n\n        self.log.debug(\"Outputs: {}\".format(self.outputs))\n\n        # generate data\n        with maintained_selection():\n            generated_repres = []\n            for o_data in self.outputs:\n                o_name = o_data[\"name\"]\n                self.log.debug(\n                    \"o_name: {}, o_data: {}\".format(o_name, pformat(o_data)))\n                f_product_base_types = o_data[\"filter\"][\"product_base_types\"]\n                f_task_types = o_data[\"filter\"][\"task_types\"]\n                product_names = o_data[\"filter\"][\"product_names\"]\n\n                self.log.debug(\n                    \"f_product_base_types `{}` &gt; families: {}\".format(\n                        f_product_base_types, families))\n\n                self.log.debug(\n                    \"f_task_types `{}` &gt; task_type: {}\".format(\n                        f_task_types, task_type))\n\n                self.log.debug(\n                    \"product_names `{}` &gt; product: {}\".format(\n                        product_names, product_name))\n\n                # test if family found in context\n                # using intersection to make sure all defined\n                # families are present in combination\n                if (\n                    f_product_base_types\n                    and not families.intersection(f_product_base_types)\n                ):\n                    continue\n\n                # test task types from filter\n                if f_task_types and task_type not in f_task_types:\n                    continue\n\n                # test products from filter\n                if product_names and not any(\n                    re.search(p, product_name) for p in product_names\n                ):\n                    continue\n\n                self.log.debug(\n                    \"Baking output `{}` with settings: {}\".format(\n                        o_name, o_data)\n                )\n\n                # check if settings have more then one preset\n                # so we dont need to add outputName to representation\n                # in case there is only one preset\n                multiple_presets = len(self.outputs) &gt; 1\n\n                # adding bake presets to instance data for other plugins\n                if not instance.data.get(\"bakePresets\"):\n                    instance.data[\"bakePresets\"] = {}\n                # add preset to bakePresets\n                instance.data[\"bakePresets\"][o_name] = o_data\n\n                # create exporter instance\n                exporter = plugin.ExporterReviewMov(\n                    self, instance, o_name, o_data[\"extension\"],\n                    multiple_presets)\n\n                delete = not o_data.get(\"publish\", False)\n\n                if instance.data.get(\"farm\"):\n                    if \"review\" in instance.data[\"families\"]:\n                        instance.data[\"families\"].remove(\"review\")\n\n                    data = exporter.generate_mov(\n                        farm=True, delete=delete, **o_data\n                    )\n\n                    self.log.debug(\n                        \"_ data: {}\".format(data))\n\n                    if not instance.data.get(\"bakingNukeScripts\"):\n                        instance.data[\"bakingNukeScripts\"] = []\n\n                    instance.data[\"bakingNukeScripts\"].append({\n                        \"bakeRenderPath\": data.get(\"bakeRenderPath\"),\n                        \"bakeScriptPath\": data.get(\"bakeScriptPath\"),\n                        \"bakeWriteNodeName\": data.get(\"bakeWriteNodeName\")\n                    })\n                else:\n                    data = exporter.generate_mov(delete=delete, **o_data)\n\n                # add representation generated by exporter\n                generated_repres.extend(data[\"representations\"])\n                self.log.debug(\n                    \"__ generated_repres: {}\".format(generated_repres))\n\n        if generated_repres:\n            # assign to representations\n            instance.data[\"representations\"] += generated_repres\n            instance.data[\"useSequenceForReview\"] = False\n        else:\n            instance.data[\"families\"].remove(\"review\")\n            self.log.debug(\n                \"Removing `review` from families. \"\n                \"Not available baking profile.\"\n            )\n            self.log.debug(instance.data[\"families\"])\n\n        self.log.debug(\n            \"_ representations: {}\".format(\n                instance.data[\"representations\"]))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_script_save.html","title":"extract_script_save","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_script_save.html#client.ayon_nuke.plugins.publish.extract_script_save.ExtractScriptSave","title":"<code>ExtractScriptSave</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Save current Nuke workfile script</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_script_save.py</code> <pre><code>class ExtractScriptSave(pyblish.api.InstancePlugin):\n    \"\"\"Save current Nuke workfile script\"\"\"\n    label = 'Script Save'\n    order = pyblish.api.ExtractorOrder - 0.1\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n\n        self.log.debug('Saving current script')\n        nuke.scriptSave()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_slate_frame.html","title":"extract_slate_frame","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_slate_frame.html#client.ayon_nuke.plugins.publish.extract_slate_frame.ExtractSlateFrame","title":"<code>ExtractSlateFrame</code>","text":"<p>               Bases: <code>Extractor</code></p> <p>Extracts movie and thumbnail with baked in luts</p> <p>must be run after extract_render_local.py</p> Source code in <code>client/ayon_nuke/plugins/publish/extract_slate_frame.py</code> <pre><code>class ExtractSlateFrame(publish.Extractor):\n    \"\"\"Extracts movie and thumbnail with baked in luts\n\n    must be run after extract_render_local.py\n\n    \"\"\"\n\n    order = pyblish.api.ExtractorOrder + 0.011\n    label = \"Extract Slate Frame\"\n\n    families = [\"slate\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    # Settings values\n    key_value_mapping = {\n        \"f_submission_note\": {\n            \"enabled\": True, \"template\": \"{comment}\"\n        },\n        \"f_submitting_for\": {\n            \"enabled\": True, \"template\": \"{intent[value]}\"\n        },\n        \"f_vfx_scope_of_work\": {\n            \"enabled\": False, \"template\": \"\"\n        }\n    }\n\n    def process(self, instance):\n\n        if \"representations\" not in instance.data:\n            instance.data[\"representations\"] = []\n\n        self._create_staging_dir(instance)\n\n        with maintained_selection():\n            self.log.debug(\"instance: {}\".format(instance))\n            self.log.debug(\"instance.data[families]: {}\".format(\n                instance.data[\"families\"]))\n\n            if instance.data.get(\"bakePresets\"):\n                for o_name, o_data in instance.data[\"bakePresets\"].items():\n                    self.log.debug(\"_ o_name: {}, o_data: {}\".format(\n                        o_name, pformat(o_data)))\n                    self.render_slate(\n                        instance,\n                        o_name,\n                        o_data[\"bake_viewer_process\"],\n                        o_data[\"bake_viewer_input_process\"]\n                    )\n            else:\n                # backward compatibility\n                self.render_slate(instance)\n\n            # also render image to sequence\n            self._render_slate_to_sequence(instance)\n\n    def _create_staging_dir(self, instance):\n\n        self.log.debug(\"Creating staging dir...\")\n\n        staging_dir = os.path.normpath(\n            os.path.dirname(instance.data[\"path\"]))\n\n        instance.data[\"stagingDir\"] = staging_dir\n\n        self.log.debug(\n            \"StagingDir `{0}`...\".format(instance.data[\"stagingDir\"]))\n\n    def _check_frames_exists(self, instance):\n        # rendering path from group write node\n        fpath = instance.data[\"path\"]\n\n        # instance frame range with handles\n        first = instance.data[\"frameStartHandle\"]\n        last = instance.data[\"frameEndHandle\"]\n\n        padding = fpath.count('#')\n\n        test_path_template = fpath\n        if padding:\n            repl_string = \"#\" * padding\n            test_path_template = fpath.replace(\n                repl_string, \"%0{}d\".format(padding))\n\n        for frame in range(first, last + 1):\n            test_file = test_path_template % frame\n            if not os.path.exists(test_file):\n                self.log.debug(\"__ test_file: `{}`\".format(test_file))\n                return None\n\n        return True\n\n    def render_slate(\n        self,\n        instance,\n        output_name=None,\n        bake_viewer_process=True,\n        bake_viewer_input_process=True\n    ):\n        \"\"\"Slate frame renderer\n\n        Args:\n            instance (PyblishInstance): Pyblish instance with product data\n            output_name (str, optional):\n                Slate variation name. Defaults to None.\n            bake_viewer_process (bool, optional):\n                Switch for viewer profile baking. Defaults to True.\n            bake_viewer_input_process (bool, optional):\n                Switch for input process node baking. Defaults to True.\n        \"\"\"\n        slate_node = instance.data[\"slateNode\"]\n\n        # rendering path from group write node\n        fpath = instance.data[\"path\"]\n\n        # instance frame range with handles\n        first_frame = instance.data[\"frameStartHandle\"]\n        last_frame = instance.data[\"frameEndHandle\"]\n\n        # fill slate node with comments\n        self.add_comment_slate_node(instance, slate_node)\n\n        # solve output name if any is set\n        _output_name = output_name or \"\"\n        if _output_name:\n            _output_name = \"_\" + _output_name\n\n        slate_first_frame = first_frame - 1\n\n        collection = instance.data.get(\"collection\", None)\n\n        if collection:\n            # get path\n            fname = os.path.basename(collection.format(\n                \"{head}{padding}{tail}\"))\n            fhead = collection.format(\"{head}\")\n        else:\n            fname = os.path.basename(fpath)\n            fhead = os.path.splitext(fname)[0] + \".\"\n\n        if \"#\" in fhead:\n            fhead = fhead.replace(\"#\", \"\")[:-1]\n\n        self.log.debug(\"__ first_frame: {}\".format(first_frame))\n        self.log.debug(\"__ slate_first_frame: {}\".format(slate_first_frame))\n\n        above_slate_node = slate_node.dependencies().pop()\n        # fallback if files does not exists\n        if self._check_frames_exists(instance):\n            # Read node\n            r_node = nuke.createNode(\"Read\")\n            r_node[\"file\"].setValue(fpath)\n            r_node[\"first\"].setValue(first_frame)\n            r_node[\"origfirst\"].setValue(first_frame)\n            r_node[\"last\"].setValue(last_frame)\n            r_node[\"origlast\"].setValue(last_frame)\n            r_node[\"colorspace\"].setValue(instance.data[\"colorspace\"])\n            previous_node = r_node\n            temporary_nodes = [previous_node]\n\n            # adding copy metadata node for correct frame metadata\n            cm_node = nuke.createNode(\"CopyMetaData\")\n            cm_node.setInput(0, previous_node)\n            cm_node.setInput(1, above_slate_node)\n            previous_node = cm_node\n            temporary_nodes.append(cm_node)\n\n        else:\n            previous_node = above_slate_node\n            temporary_nodes = []\n\n        # only create colorspace baking if toggled on\n        if bake_viewer_process:\n            if bake_viewer_input_process:\n                # get input process and connect it to baking\n                ipn = get_view_process_node()\n                if ipn is not None:\n                    ipn.setInput(0, previous_node)\n                    previous_node = ipn\n                    temporary_nodes.append(ipn)\n\n            # add duplicate slate node and connect to previous\n            duply_slate_node = duplicate_node(slate_node)\n            duply_slate_node.setInput(0, previous_node)\n            previous_node = duply_slate_node\n            temporary_nodes.append(duply_slate_node)\n\n            # add viewer display transformation node\n            dag_node = nuke.createNode(\"OCIODisplay\")\n            dag_node.setInput(0, previous_node)\n            previous_node = dag_node\n            temporary_nodes.append(dag_node)\n\n        else:\n            # add duplicate slate node and connect to previous\n            duply_slate_node = duplicate_node(slate_node)\n            duply_slate_node.setInput(0, previous_node)\n            previous_node = duply_slate_node\n            temporary_nodes.append(duply_slate_node)\n\n        # create write node\n        write_node = nuke.createNode(\"Write\")\n        file = fhead[:-1] + _output_name + \"_slate.png\"\n        path = os.path.join(\n            instance.data[\"stagingDir\"], file).replace(\"\\\\\", \"/\")\n\n        # add slate path to `slateFrames` instance data attr\n        if not instance.data.get(\"slateFrames\"):\n            instance.data[\"slateFrames\"] = {}\n\n        instance.data[\"slateFrames\"][output_name or \"*\"] = path\n\n        # create write node\n        write_node[\"file\"].setValue(path)\n        write_node[\"file_type\"].setValue(\"png\")\n        write_node[\"raw\"].setValue(1)\n        write_node.setInput(0, previous_node)\n        temporary_nodes.append(write_node)\n\n        # Render frames\n        nuke.execute(\n            write_node.name(), int(slate_first_frame), int(slate_first_frame))\n\n        # Clean up\n        for node in temporary_nodes:\n            nuke.delete(node)\n\n    def _render_slate_to_sequence(self, instance):\n        # set slate frame\n        first_frame = instance.data[\"frameStartHandle\"]\n        last_frame = instance.data[\"frameEndHandle\"]\n        slate_first_frame = first_frame - 1\n\n        # - get write node\n        write_node = instance.data[\"transientData\"][\"writeNode\"]\n\n        # termporarily turn off frame range limit\n        limit_on = False\n        if \"use_limit\" in write_node.knobs():\n            if bool(write_node[\"use_limit\"].value()):\n                limit_on = True\n                # turn limit off for rendering the slate\n                write_node[\"use_limit\"].setValue(0)\n                self.log.debug(\"__Setting render node limit\")\n\n        # render slate as sequence frame\n        nuke.execute(\n            instance.data[\"name\"],\n            int(slate_first_frame),\n            int(slate_first_frame)\n        )\n\n        # turn the frame range limit back on\n        if limit_on:\n            write_node[\"use_limit\"].setValue(1)\n\n        # Add file to representation files\n        # - evaluate filepaths for first frame and slate frame\n        first_filename = os.path.basename(\n            write_node[\"file\"].evaluate(first_frame))\n        slate_filename = os.path.basename(\n            write_node[\"file\"].evaluate(slate_first_frame))\n\n        # Find matching representation based on first filename\n        matching_repre = None\n        is_sequence = None\n        for repre in instance.data[\"representations\"]:\n            files = repre[\"files\"]\n            if (\n                not isinstance(files, str)\n                and first_filename in files\n            ):\n                matching_repre = repre\n                is_sequence = True\n                break\n\n            elif files == first_filename:\n                matching_repre = repre\n                is_sequence = False\n                break\n\n        if not matching_repre:\n            self.log.info(\n                \"Matching representation was not found.\"\n                \" Representation files were not filled with slate.\"\n            )\n            return\n\n        # Add frame to matching representation files\n        if not is_sequence:\n            matching_repre[\"files\"] = [first_filename, slate_filename]\n        elif slate_filename not in matching_repre[\"files\"]:\n            matching_repre[\"files\"].insert(0, slate_filename)\n            matching_repre[\"frameStart\"] = (\n                \"{{:0&gt;{}}}\"\n                .format(len(str(last_frame)))\n                .format(slate_first_frame)\n            )\n            self.log.debug(\n                \"__ matching_repre: {}\".format(pformat(matching_repre)))\n\n        data = matching_repre.get(\"data\", {})\n        data[\"slateFrames\"] = 1\n        matching_repre[\"data\"] = data\n\n        self.log.info(\"Added slate frame to representation files\")\n\n    def add_comment_slate_node(self, instance, node):\n\n        comment = instance.data[\"comment\"]\n        intent = instance.context.data.get(\"intent\")\n        if not isinstance(intent, dict):\n            intent = {\n                \"label\": intent,\n                \"value\": intent\n            }\n\n        fill_data = copy.deepcopy(instance.data[\"anatomyData\"])\n        fill_data.update({\n            \"custom\": copy.deepcopy(\n                instance.data.get(\"customData\") or {}\n            ),\n            \"comment\": comment,\n            \"intent\": intent\n        })\n\n        for key, _values in self.key_value_mapping.items():\n            if not _values[\"enabled\"]:\n                self.log.debug(\"Key \\\"{}\\\" is disabled\".format(key))\n                continue\n\n            template = _values[\"template\"]\n            try:\n                value = template.format(**fill_data)\n\n            except ValueError:\n                self.log.warning(\n                    \"Couldn't fill template \\\"{}\\\" with data: {}\".format(\n                        template, fill_data\n                    ),\n                    exc_info=True\n                )\n                continue\n\n            except KeyError:\n                self.log.warning(\n                    (\n                        \"Template contains unknown key.\"\n                        \" Template \\\"{}\\\" Data: {}\"\n                    ).format(template, fill_data),\n                    exc_info=True\n                )\n                continue\n\n            try:\n                node[key].setValue(value)\n                self.log.debug(\"Change key \\\"{}\\\" to value \\\"{}\\\"\".format(\n                    key, value\n                ))\n            except NameError:\n                self.log.warning((\n                    \"Failed to set value \\\"{0}\\\" on node attribute \\\"{0}\\\"\"\n                ).format(value))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/extract_slate_frame.html#client.ayon_nuke.plugins.publish.extract_slate_frame.ExtractSlateFrame.render_slate","title":"<code>render_slate(instance, output_name=None, bake_viewer_process=True, bake_viewer_input_process=True)</code>","text":"<p>Slate frame renderer</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>PyblishInstance</code> <p>Pyblish instance with product data</p> required <code>output_name</code> <code>str</code> <p>Slate variation name. Defaults to None.</p> <code>None</code> <code>bake_viewer_process</code> <code>bool</code> <p>Switch for viewer profile baking. Defaults to True.</p> <code>True</code> <code>bake_viewer_input_process</code> <code>bool</code> <p>Switch for input process node baking. Defaults to True.</p> <code>True</code> Source code in <code>client/ayon_nuke/plugins/publish/extract_slate_frame.py</code> <pre><code>def render_slate(\n    self,\n    instance,\n    output_name=None,\n    bake_viewer_process=True,\n    bake_viewer_input_process=True\n):\n    \"\"\"Slate frame renderer\n\n    Args:\n        instance (PyblishInstance): Pyblish instance with product data\n        output_name (str, optional):\n            Slate variation name. Defaults to None.\n        bake_viewer_process (bool, optional):\n            Switch for viewer profile baking. Defaults to True.\n        bake_viewer_input_process (bool, optional):\n            Switch for input process node baking. Defaults to True.\n    \"\"\"\n    slate_node = instance.data[\"slateNode\"]\n\n    # rendering path from group write node\n    fpath = instance.data[\"path\"]\n\n    # instance frame range with handles\n    first_frame = instance.data[\"frameStartHandle\"]\n    last_frame = instance.data[\"frameEndHandle\"]\n\n    # fill slate node with comments\n    self.add_comment_slate_node(instance, slate_node)\n\n    # solve output name if any is set\n    _output_name = output_name or \"\"\n    if _output_name:\n        _output_name = \"_\" + _output_name\n\n    slate_first_frame = first_frame - 1\n\n    collection = instance.data.get(\"collection\", None)\n\n    if collection:\n        # get path\n        fname = os.path.basename(collection.format(\n            \"{head}{padding}{tail}\"))\n        fhead = collection.format(\"{head}\")\n    else:\n        fname = os.path.basename(fpath)\n        fhead = os.path.splitext(fname)[0] + \".\"\n\n    if \"#\" in fhead:\n        fhead = fhead.replace(\"#\", \"\")[:-1]\n\n    self.log.debug(\"__ first_frame: {}\".format(first_frame))\n    self.log.debug(\"__ slate_first_frame: {}\".format(slate_first_frame))\n\n    above_slate_node = slate_node.dependencies().pop()\n    # fallback if files does not exists\n    if self._check_frames_exists(instance):\n        # Read node\n        r_node = nuke.createNode(\"Read\")\n        r_node[\"file\"].setValue(fpath)\n        r_node[\"first\"].setValue(first_frame)\n        r_node[\"origfirst\"].setValue(first_frame)\n        r_node[\"last\"].setValue(last_frame)\n        r_node[\"origlast\"].setValue(last_frame)\n        r_node[\"colorspace\"].setValue(instance.data[\"colorspace\"])\n        previous_node = r_node\n        temporary_nodes = [previous_node]\n\n        # adding copy metadata node for correct frame metadata\n        cm_node = nuke.createNode(\"CopyMetaData\")\n        cm_node.setInput(0, previous_node)\n        cm_node.setInput(1, above_slate_node)\n        previous_node = cm_node\n        temporary_nodes.append(cm_node)\n\n    else:\n        previous_node = above_slate_node\n        temporary_nodes = []\n\n    # only create colorspace baking if toggled on\n    if bake_viewer_process:\n        if bake_viewer_input_process:\n            # get input process and connect it to baking\n            ipn = get_view_process_node()\n            if ipn is not None:\n                ipn.setInput(0, previous_node)\n                previous_node = ipn\n                temporary_nodes.append(ipn)\n\n        # add duplicate slate node and connect to previous\n        duply_slate_node = duplicate_node(slate_node)\n        duply_slate_node.setInput(0, previous_node)\n        previous_node = duply_slate_node\n        temporary_nodes.append(duply_slate_node)\n\n        # add viewer display transformation node\n        dag_node = nuke.createNode(\"OCIODisplay\")\n        dag_node.setInput(0, previous_node)\n        previous_node = dag_node\n        temporary_nodes.append(dag_node)\n\n    else:\n        # add duplicate slate node and connect to previous\n        duply_slate_node = duplicate_node(slate_node)\n        duply_slate_node.setInput(0, previous_node)\n        previous_node = duply_slate_node\n        temporary_nodes.append(duply_slate_node)\n\n    # create write node\n    write_node = nuke.createNode(\"Write\")\n    file = fhead[:-1] + _output_name + \"_slate.png\"\n    path = os.path.join(\n        instance.data[\"stagingDir\"], file).replace(\"\\\\\", \"/\")\n\n    # add slate path to `slateFrames` instance data attr\n    if not instance.data.get(\"slateFrames\"):\n        instance.data[\"slateFrames\"] = {}\n\n    instance.data[\"slateFrames\"][output_name or \"*\"] = path\n\n    # create write node\n    write_node[\"file\"].setValue(path)\n    write_node[\"file_type\"].setValue(\"png\")\n    write_node[\"raw\"].setValue(1)\n    write_node.setInput(0, previous_node)\n    temporary_nodes.append(write_node)\n\n    # Render frames\n    nuke.execute(\n        write_node.name(), int(slate_first_frame), int(slate_first_frame))\n\n    # Clean up\n    for node in temporary_nodes:\n        nuke.delete(node)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/increment_script_version.html","title":"increment_script_version","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/increment_script_version.html#client.ayon_nuke.plugins.publish.increment_script_version.IncrementScriptVersion","title":"<code>IncrementScriptVersion</code>","text":"<p>               Bases: <code>ContextPlugin</code>, <code>OptionalPyblishPluginMixin</code></p> <p>Increment current script version.</p> Source code in <code>client/ayon_nuke/plugins/publish/increment_script_version.py</code> <pre><code>class IncrementScriptVersion(pyblish.api.ContextPlugin,\n                             OptionalPyblishPluginMixin):\n    \"\"\"Increment current script version.\"\"\"\n\n    order = pyblish.api.IntegratorOrder + 0.9\n    label = \"Increment Script Version\"\n    optional = True\n    families = [\"workfile\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, context):\n        if not self.is_active(context.data):\n            return\n\n        if not context.data.get(\"increment_script_version\", True):\n            return\n\n        assert all(result[\"success\"] for result in context.data[\"results\"]), (\n            \"Publishing not successful so version is not increased.\")\n\n        current_filepath = context.data[\"currentFile\"]\n        host: IWorkfileHost = registered_host()\n        try:\n            # Function 'save_next_version' was introduced in ayon-core 1.5.0\n            from ayon_core.pipeline.workfile import save_next_version\n            from ayon_core.host.interfaces import SaveWorkfileOptionalData\n\n            current_filename = os.path.basename(current_filepath)\n            save_next_version(\n                description=(\n                    f\"Incremented by publishing from {current_filename}\"\n                ),\n                # Optimize the save by reducing needed queries for context\n                prepared_data=SaveWorkfileOptionalData(\n                    project_entity=context.data[\"projectEntity\"],\n                    project_settings=context.data[\"project_settings\"],\n                    anatomy=context.data[\"anatomy\"],\n                )\n            )\n        except ImportError:\n            # Backwards compatibility before ayon-core 1.5.0\n            self.log.debug(\n                \"Using legacy `version_up`. Update AYON core addon to \"\n                \"use newer `save_next_version` function.\"\n            )\n            new_filepath = version_up(current_filepath)\n            host.save_workfile(new_filepath)\n\n        new_filepath = host.get_current_workfile()\n        self.log.debug(f\"Incremented script version to: {new_filepath}\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/increment_write_node.html","title":"increment_write_node","text":"<p>Increments render path in write node with actual workfile version</p>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/increment_write_node.html#client.ayon_nuke.plugins.publish.increment_write_node.IncrementWriteNodePathPostSubmit","title":"<code>IncrementWriteNodePathPostSubmit</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>OptionalPyblishPluginMixin</code></p> <p>Increments render path in write node with actual workfile version after workfile has been incremented.</p> <p>This allows users to manually trigger a local render being sure the render output paths are updated.</p> Source code in <code>client/ayon_nuke/plugins/publish/increment_write_node.py</code> <pre><code>class IncrementWriteNodePathPostSubmit(\n    pyblish.api.InstancePlugin, OptionalPyblishPluginMixin\n):\n    \"\"\"Increments render path in write node with actual workfile version after\n    workfile has been incremented.\n\n    This allows users to manually trigger a local render being sure\n    the render output paths are updated.\n    \"\"\"\n\n    order = pyblish.api.IntegratorOrder + 10\n    label = \"Update path in Write node - Post Version-Up\"\n    hosts = [\"nuke\", \"nukeassist\"]\n    families = [\"render\", \"prerender\", \"image\"]\n\n    settings_category = \"nuke\"\n    optional = True\n    active = True\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        if not instance.data.get(\"stagingDir_is_custom\"):\n            self.log.info(\n                f\"'{instance}' instance doesn't have custom staging dir.\"\n            )\n            return\n\n        write_node = instance.data[\"transientData\"].get(\"writeNode\")\n        if write_node is None:\n            group_node = instance.data[\"transientData\"][\"node\"]\n            self.log.info(\n                f\"Instance '{group_node.name()}' is missing write node!\"\n            )\n            return\n\n        render_target = instance.data[\"render_target\"]\n        if render_target in [\"frames\", \"frames_farm\"]:\n            self.log.info(\n                \"Instance reuses existing frames, not updating path\"\n            )\n            return\n\n        writes_version_sync(write_node, self.log)\n        nuke.scriptSave()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/remove_ouput_node.html","title":"remove_ouput_node","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/remove_ouput_node.html#client.ayon_nuke.plugins.publish.remove_ouput_node.RemoveOutputNode","title":"<code>RemoveOutputNode</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Removing output node for each output write node</p> Source code in <code>client/ayon_nuke/plugins/publish/remove_ouput_node.py</code> <pre><code>class RemoveOutputNode(pyblish.api.ContextPlugin):\n    \"\"\"Removing output node for each output write node\n\n    \"\"\"\n    label = 'Output Node Remove'\n    order = pyblish.api.IntegratorOrder + 0.4\n    families = [\"workfile\"]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    def process(self, context):\n        try:\n            output_node = context.data[\"outputNode\"]\n            name = output_node[\"name\"].value()\n            self.log.info(\"Removing output node: '{}'\".format(name))\n\n            nuke.delete(output_node)\n        except Exception:\n            return\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_asset_context.html","title":"validate_asset_context","text":"<p>Validate if instance folder is the same as context folder.</p>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_asset_context.html#client.ayon_nuke.plugins.publish.validate_asset_context.ValidateCorrectAssetContext","title":"<code>ValidateCorrectAssetContext</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>OptionalPyblishPluginMixin</code></p> <p>Validator to check if instance folder context match context folder.</p> <p>When working in per-shot style you always publish data in context of current folder (shot). This validator checks if this is so. It is optional so it can be disabled when needed.</p> <p>Checking <code>folderPath</code> and <code>task</code> keys.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_asset_context.py</code> <pre><code>class ValidateCorrectAssetContext(\n    pyblish.api.InstancePlugin,\n    OptionalPyblishPluginMixin\n):\n    \"\"\"Validator to check if instance folder context match context folder.\n\n    When working in per-shot style you always publish data in context of\n    current folder (shot). This validator checks if this is so. It is optional\n    so it can be disabled when needed.\n\n    Checking `folderPath` and `task` keys.\n    \"\"\"\n    order = ValidateContentsOrder\n    label = \"Validate Folder context\"\n    hosts = [\"nuke\"]\n    actions = [\n        RepairAction,\n        SelectInstanceNodeAction\n    ]\n    optional = True\n\n    settings_category = \"nuke\"\n\n    @classmethod\n    def apply_settings(cls, project_settings):\n        \"\"\"Apply deprecated settings from project settings.\n        \"\"\"\n        nuke_publish = project_settings[\"nuke\"][\"publish\"]\n        if \"ValidateCorrectAssetName\" in nuke_publish:\n            settings = nuke_publish[\"ValidateCorrectAssetName\"]\n        else:\n            settings = nuke_publish[\"ValidateCorrectAssetContext\"]\n\n        cls.enabled = settings[\"enabled\"]\n        cls.optional = settings[\"optional\"]\n        cls.active = settings[\"active\"]\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        invalid_keys = self.get_invalid(instance)\n\n        if not invalid_keys:\n            return\n\n        message_values = {\n            \"node_name\": instance.data[\"transientData\"][\"node\"].name(),\n            \"correct_values\": \", \".join([\n                \"{} &gt; {}\".format(_key, instance.context.data[_key])\n                for _key in invalid_keys\n            ]),\n            \"wrong_values\": \", \".join([\n                \"{} &gt; {}\".format(_key, instance.data.get(_key))\n                for _key in invalid_keys\n            ])\n        }\n\n        msg = (\n            \"Instance `{node_name}` has wrong context keys:\\n\"\n            \"Correct: `{correct_values}` | Wrong: `{wrong_values}`\").format(\n                **message_values)\n\n        self.log.debug(msg)\n\n        raise PublishXmlValidationError(\n            self, msg, formatting_data=message_values\n        )\n\n    @classmethod\n    def get_invalid(cls, instance):\n        \"\"\"Get invalid keys from instance data and context data.\"\"\"\n\n        invalid_keys = []\n        testing_keys = [\"folderPath\", \"task\"]\n        for _key in testing_keys:\n            if _key not in instance.data:\n                invalid_keys.append(_key)\n                continue\n            if instance.data[_key] != instance.context.data[_key]:\n                invalid_keys.append(_key)\n\n        return invalid_keys\n\n    @classmethod\n    def repair(cls, instance):\n        \"\"\"Repair instance data with context data.\"\"\"\n        invalid_keys = cls.get_invalid(instance)\n\n        create_context = instance.context.data[\"create_context\"]\n\n        instance_id = instance.data.get(\"instance_id\")\n        created_instance = create_context.get_instance_by_id(\n            instance_id\n        )\n        for _key in invalid_keys:\n            created_instance[_key] = instance.context.data[_key]\n\n        create_context.save_changes()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_asset_context.html#client.ayon_nuke.plugins.publish.validate_asset_context.ValidateCorrectAssetContext.apply_settings","title":"<code>apply_settings(project_settings)</code>  <code>classmethod</code>","text":"<p>Apply deprecated settings from project settings.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_asset_context.py</code> <pre><code>@classmethod\ndef apply_settings(cls, project_settings):\n    \"\"\"Apply deprecated settings from project settings.\n    \"\"\"\n    nuke_publish = project_settings[\"nuke\"][\"publish\"]\n    if \"ValidateCorrectAssetName\" in nuke_publish:\n        settings = nuke_publish[\"ValidateCorrectAssetName\"]\n    else:\n        settings = nuke_publish[\"ValidateCorrectAssetContext\"]\n\n    cls.enabled = settings[\"enabled\"]\n    cls.optional = settings[\"optional\"]\n    cls.active = settings[\"active\"]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_asset_context.html#client.ayon_nuke.plugins.publish.validate_asset_context.ValidateCorrectAssetContext.get_invalid","title":"<code>get_invalid(instance)</code>  <code>classmethod</code>","text":"<p>Get invalid keys from instance data and context data.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_asset_context.py</code> <pre><code>@classmethod\ndef get_invalid(cls, instance):\n    \"\"\"Get invalid keys from instance data and context data.\"\"\"\n\n    invalid_keys = []\n    testing_keys = [\"folderPath\", \"task\"]\n    for _key in testing_keys:\n        if _key not in instance.data:\n            invalid_keys.append(_key)\n            continue\n        if instance.data[_key] != instance.context.data[_key]:\n            invalid_keys.append(_key)\n\n    return invalid_keys\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_asset_context.html#client.ayon_nuke.plugins.publish.validate_asset_context.ValidateCorrectAssetContext.repair","title":"<code>repair(instance)</code>  <code>classmethod</code>","text":"<p>Repair instance data with context data.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_asset_context.py</code> <pre><code>@classmethod\ndef repair(cls, instance):\n    \"\"\"Repair instance data with context data.\"\"\"\n    invalid_keys = cls.get_invalid(instance)\n\n    create_context = instance.context.data[\"create_context\"]\n\n    instance_id = instance.data.get(\"instance_id\")\n    created_instance = create_context.get_instance_by_id(\n        instance_id\n    )\n    for _key in invalid_keys:\n        created_instance[_key] = instance.context.data[_key]\n\n    create_context.save_changes()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_backdrop.html","title":"validate_backdrop","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_backdrop.html#client.ayon_nuke.plugins.publish.validate_backdrop.SelectCenterInNodeGraph","title":"<code>SelectCenterInNodeGraph</code>","text":"<p>               Bases: <code>Action</code></p> <p>Centering failed instance node in node grap</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_backdrop.py</code> <pre><code>class SelectCenterInNodeGraph(pyblish.api.Action):\n    \"\"\"\n    Centering failed instance node in node grap\n    \"\"\"\n\n    label = \"Center node in node graph\"\n    icon = \"wrench\"\n    on = \"failed\"\n\n    def process(self, context, plugin):\n\n        # Get the errored instances\n        failed = []\n        for result in context.data[\"results\"]:\n            if (result[\"error\"] is not None and result[\"instance\"] is not None\n               and result[\"instance\"] not in failed):\n                failed.append(result[\"instance\"])\n\n        # Apply pyblish.logic to get the instances for the plug-in\n        instances = pyblish.api.instances_by_plugin(failed, plugin)\n\n        all_xC = []\n        all_yC = []\n\n        # maintain selection\n        with napi.maintained_selection():\n            # collect all failed nodes xpos and ypos\n            for instance in instances:\n                bdn = instance.data[\"transientData\"][\"node\"]\n                xC = bdn.xpos() + bdn.screenWidth() / 2\n                yC = bdn.ypos() + bdn.screenHeight() / 2\n\n                all_xC.append(xC)\n                all_yC.append(yC)\n\n        self.log.debug(\"all_xC: `{}`\".format(all_xC))\n        self.log.debug(\"all_yC: `{}`\".format(all_yC))\n\n        # zoom to nodes in node graph\n        nuke.zoom(2, [min(all_xC), min(all_yC)])\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_backdrop.html#client.ayon_nuke.plugins.publish.validate_backdrop.ValidateBackdrop","title":"<code>ValidateBackdrop</code>","text":"<p>               Bases: <code>InstancePlugin</code>, <code>OptionalPyblishPluginMixin</code></p> <p>Validate amount of nodes on backdrop node in case user forgotten to add nodes above the publishing backdrop node.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_backdrop.py</code> <pre><code>class ValidateBackdrop(\n    pyblish.api.InstancePlugin,\n    OptionalPyblishPluginMixin\n):\n    \"\"\" Validate amount of nodes on backdrop node in case user\n    forgotten to add nodes above the publishing backdrop node.\n    \"\"\"\n\n    order = ValidateContentsOrder\n    optional = True\n    families = [\"nukenodes\"]\n    label = \"Validate Backdrop\"\n    hosts = [\"nuke\"]\n    actions = [SelectCenterInNodeGraph]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        child_nodes = instance.data[\"transientData\"][\"childNodes\"]\n        connections_out = instance.data[\"transientData\"][\"nodeConnectionsOut\"]\n\n        msg_multiple_outputs = (\n            \"Only one outcoming connection from \"\n            \"\\\"{}\\\" is allowed\").format(instance.data[\"name\"])\n\n        if len(connections_out.keys()) &gt; 1:\n            raise PublishXmlValidationError(\n                self,\n                msg_multiple_outputs,\n                \"multiple_outputs\"\n            )\n\n        msg_no_nodes = \"No content on backdrop node: \\\"{}\\\"\".format(\n            instance.data[\"name\"])\n\n        self.log.debug(\n            \"Amount of nodes on instance: {}\".format(\n                len(child_nodes))\n        )\n\n        if child_nodes == []:\n            raise PublishXmlValidationError(\n                self,\n                msg_no_nodes,\n                \"no_nodes\"\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_exposed_knobs.html","title":"validate_exposed_knobs","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_exposed_knobs.html#client.ayon_nuke.plugins.publish.validate_exposed_knobs.ValidateExposedKnobs","title":"<code>ValidateExposedKnobs</code>","text":"<p>               Bases: <code>OptionalPyblishPluginMixin</code>, <code>InstancePlugin</code></p> <p>Validate write node exposed knobs.</p> <p>Compare exposed linked knobs to settings.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_exposed_knobs.py</code> <pre><code>class ValidateExposedKnobs(\n    OptionalPyblishPluginMixin,\n    pyblish.api.InstancePlugin\n):\n    \"\"\" Validate write node exposed knobs.\n\n    Compare exposed linked knobs to settings.\n    \"\"\"\n\n    order = pyblish.api.ValidatorOrder\n    optional = True\n    families = [\"render\", \"prerender\", \"image\"]\n    label = \"Validate Exposed Knobs\"\n    actions = [RepairExposedKnobs]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    product_base_types_mapping = {\n        \"render\": \"CreateWriteRender\",\n        \"prerender\": \"CreateWritePrerender\",\n        \"image\": \"CreateWriteImage\"\n    }\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        product_base_type = instance.data[\"productBaseType\"]\n        plugin = self.product_base_types_mapping[product_base_type]\n        group_node = instance.data[\"transientData\"][\"node\"]\n        nuke_settings = instance.context.data[\"project_settings\"][\"nuke\"]\n        create_settings = nuke_settings[\"create\"][plugin]\n        exposed_knobs = create_settings.get(\"exposed_knobs\", [])\n        unexposed_knobs = []\n        for knob in exposed_knobs:\n            if knob not in group_node.knobs():\n                unexposed_knobs.append(knob)\n\n        if unexposed_knobs:\n            raise PublishValidationError(\n                \"Missing exposed knobs: {}\".format(unexposed_knobs)\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_gizmo.html","title":"validate_gizmo","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_gizmo.html#client.ayon_nuke.plugins.publish.validate_gizmo.OpenFailedGroupNode","title":"<code>OpenFailedGroupNode</code>","text":"<p>               Bases: <code>Action</code></p> <p>Centering failed instance node in node grap</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_gizmo.py</code> <pre><code>class OpenFailedGroupNode(pyblish.api.Action):\n    \"\"\"\n    Centering failed instance node in node grap\n    \"\"\"\n\n    label = \"Open Group\"\n    icon = \"wrench\"\n    on = \"failed\"\n\n    def process(self, context, plugin):\n\n        # Get the errored instances\n        failed = []\n        for result in context.data[\"results\"]:\n            if (result[\"error\"] is not None and result[\"instance\"] is not None\n                    and result[\"instance\"] not in failed):\n                failed.append(result[\"instance\"])\n\n        # Apply pyblish.logic to get the instances for the plug-in\n        instances = pyblish.api.instances_by_plugin(failed, plugin)\n\n        # maintain selection\n        with napi.maintained_selection():\n            # collect all failed nodes xpos and ypos\n            for instance in instances:\n                grpn = instance.data[\"transientData\"][\"node\"]\n                nuke.showDag(grpn)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_gizmo.html#client.ayon_nuke.plugins.publish.validate_gizmo.ValidateGizmo","title":"<code>ValidateGizmo</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Validate amount of output nodes in gizmo (group) node</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_gizmo.py</code> <pre><code>class ValidateGizmo(pyblish.api.InstancePlugin):\n    \"\"\"Validate amount of output nodes in gizmo (group) node\"\"\"\n\n    order = pyblish.api.ValidatorOrder\n    optional = True\n    families = [\"gizmo\"]\n    label = \"Validate Gizmo (group)\"\n    hosts = [\"nuke\"]\n    actions = [OpenFailedGroupNode]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        grpn = instance.data[\"transientData\"][\"node\"]\n\n        with grpn:\n            connections_out = nuke.allNodes('Output')\n            if len(connections_out) &gt; 1:\n                msg_multiple_outputs = (\n                    \"Only one outcoming connection from \"\n                    \"\\\"{}\\\" is allowed\").format(instance.data[\"name\"])\n\n                raise PublishXmlValidationError(\n                    self, msg_multiple_outputs, \"multiple_outputs\",\n                    {\"node_name\": grpn[\"name\"].value()}\n                )\n\n            connections_in = nuke.allNodes('Input')\n            if len(connections_in) == 0:\n                msg_missing_inputs = (\n                    \"At least one Input node has to be inside Group: \"\n                    \"\\\"{}\\\"\").format(instance.data[\"name\"])\n\n                raise PublishXmlValidationError(\n                    self, msg_missing_inputs, \"no_inputs\",\n                    {\"node_name\": grpn[\"name\"].value()}\n                )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_knobs.html","title":"validate_knobs","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_knobs.html#client.ayon_nuke.plugins.publish.validate_knobs.ValidateKnobs","title":"<code>ValidateKnobs</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Ensure knobs are consistent.</p> <p>Knobs to validate and their values comes from the</p> Controlled by plugin settings that require json in following structure <p>\"ValidateKnobs\": {     \"enabled\": true,     \"knobs\": {         \"family\": {             \"knob_name\": knob_value             }         }     }</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_knobs.py</code> <pre><code>class ValidateKnobs(pyblish.api.ContextPlugin):\n    \"\"\"Ensure knobs are consistent.\n\n    Knobs to validate and their values comes from the\n\n    Controlled by plugin settings that require json in following structure:\n        \"ValidateKnobs\": {\n            \"enabled\": true,\n            \"knobs\": {\n                \"family\": {\n                    \"knob_name\": knob_value\n                    }\n                }\n            }\n    \"\"\"\n\n    order = pyblish.api.ValidatorOrder\n    label = \"Validate Knobs\"\n    hosts = [\"nuke\"]\n    actions = [RepairContextAction]\n    optional = True\n\n    settings_category = \"nuke\"\n\n    knobs = \"{}\"\n\n    def process(self, context):\n        invalid = self.get_invalid(context, compute=True)\n        if invalid:\n            invalid_items = [\n                (\n                    \"Node __{node_name}__ with knob _{label}_ \"\n                    \"expecting _{expected}_, \"\n                    \"but is set to _{current}_\"\n                ).format(**i)\n                for i in invalid\n            ]\n            raise PublishXmlValidationError(\n                self,\n                \"Found knobs with invalid values:\\n{}\".format(invalid),\n                formatting_data={\n                    \"invalid_items\": \"\\n\".join(invalid_items)}\n            )\n\n    @classmethod\n    def get_invalid(cls, context, compute=False):\n        invalid = context.data.get(\"invalid_knobs\", [])\n        if compute:\n            invalid = cls.get_invalid_knobs(context)\n\n        return invalid\n\n    @classmethod\n    def get_invalid_knobs(cls, context):\n        invalid_knobs = []\n\n        for instance in context:\n            # Load fresh knobs data for each instance\n            settings_knobs = json.loads(cls.knobs)\n\n            # Filter families.\n            families = [instance.data[\"productBaseType\"]]\n            families += instance.data.get(\"families\", [])\n\n            # Get all knobs to validate.\n            knobs = {}\n            for family in families:\n                # check if dot in family\n                if \".\" in family:\n                    family = family.split(\".\")[0]\n\n                # avoid families not in settings\n                if family not in settings_knobs:\n                    continue\n\n                # get presets of knobs\n                for preset in settings_knobs[family]:\n                    knobs[preset] = settings_knobs[family][preset]\n\n            # Get invalid knobs.\n            nodes = []\n\n            for node in nuke.allNodes():\n                nodes.append(node)\n                if node.Class() == \"Group\":\n                    node.begin()\n                    nodes.extend(iter(nuke.allNodes()))\n                    node.end()\n\n            for node in nodes:\n                for knob in node.knobs():\n                    if knob not in knobs.keys():\n                        continue\n\n                    expected = knobs[knob]\n                    if node[knob].value() != expected:\n                        invalid_knobs.append(\n                            {\n                                \"node_name\": node.name(),\n                                \"knob\": node[knob],\n                                \"name\": node[knob].name(),\n                                \"label\": node[knob].label(),\n                                \"expected\": expected,\n                                \"current\": node[knob].value()\n                            }\n                        )\n\n        context.data[\"invalid_knobs\"] = invalid_knobs\n        return invalid_knobs\n\n    @classmethod\n    def repair(cls, instance):\n        invalid = cls.get_invalid(instance)\n        for data in invalid:\n            # TODO: will need to improve type definitions\n            # with the new settings for knob types\n            if isinstance(data[\"expected\"], str):\n                data[\"knob\"].setValue(str(data[\"expected\"]))\n                continue\n\n            data[\"knob\"].setValue(data[\"expected\"])\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_output_resolution.html","title":"validate_output_resolution","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_output_resolution.html#client.ayon_nuke.plugins.publish.validate_output_resolution.ValidateOutputResolution","title":"<code>ValidateOutputResolution</code>","text":"<p>               Bases: <code>OptionalPyblishPluginMixin</code>, <code>InstancePlugin</code></p> <p>Validates Output Resolution.</p> <p>It is making sure the resolution of write's input is the same as Format definition of script in Root node.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_output_resolution.py</code> <pre><code>class ValidateOutputResolution(\n    OptionalPyblishPluginMixin,\n    pyblish.api.InstancePlugin\n):\n    \"\"\"Validates Output Resolution.\n\n    It is making sure the resolution of write's input is the same as\n    Format definition of script in Root node.\n    \"\"\"\n\n    order = pyblish.api.ValidatorOrder\n    optional = True\n    families = [\"render\"]\n    label = \"Validate Write resolution\"\n    hosts = [\"nuke\"]\n    actions = [RepairAction]\n\n    settings_category = \"nuke\"\n\n    missing_msg = \"Missing Reformat node in render group node\"\n    resolution_msg = \"Reformat is set to wrong format\"\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        invalid = self.get_invalid(instance)\n        if invalid:\n            raise PublishXmlValidationError(self, invalid)\n\n    @classmethod\n    def get_reformat(cls, instance):\n        child_nodes = (\n            instance.data.get(\"transientData\", {}).get(\"childNodes\")\n            or instance\n        )\n\n        reformat = None\n        for inode in child_nodes:\n            if inode.Class() != \"Reformat\":\n                continue\n            reformat = inode\n\n        return reformat\n\n    @classmethod\n    def get_invalid(cls, instance):\n        def _check_resolution(instance, reformat):\n            root_width = instance.data[\"resolutionWidth\"]\n            root_height = instance.data[\"resolutionHeight\"]\n\n            write_width = reformat.format().width()\n            write_height = reformat.format().height()\n\n            if (root_width != write_width) or (root_height != write_height):\n                return None\n            else:\n                return True\n\n        # check if reformat is in render node\n        reformat = cls.get_reformat(instance)\n        if not reformat:\n            return cls.missing_msg\n\n        # check if reformat is set to correct root format\n        correct_format = _check_resolution(instance, reformat)\n        if not correct_format:\n            return cls.resolution_msg\n\n    @classmethod\n    def repair(cls, instance):\n        child_nodes = (\n            instance.data.get(\"transientData\", {}).get(\"childNodes\")\n            or instance\n        )\n\n        invalid = cls.get_invalid(instance)\n        grp_node = instance.data[\"transientData\"][\"node\"]\n\n        if cls.missing_msg == invalid:\n            # make sure we are inside of the group node\n            with grp_node:\n                # find input node and select it\n                _input = None\n                for inode in child_nodes:\n                    if inode.Class() != \"Input\":\n                        continue\n                    _input = inode\n\n                # add reformat node under it\n                with napi.maintained_selection():\n                    _input['selected'].setValue(True)\n                    _rfn = nuke.createNode(\"Reformat\", \"name Reformat01\")\n                    _rfn[\"resize\"].setValue(0)\n                    _rfn[\"black_outside\"].setValue(1)\n\n                cls.log.info(\"Adding reformat node\")\n\n        if cls.resolution_msg == invalid:\n            reformat = cls.get_reformat(instance)\n            reformat[\"format\"].setValue(nuke.root()[\"format\"].value())\n            cls.log.info(\"Fixing reformat to root.format\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_proxy_mode.html","title":"validate_proxy_mode","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_proxy_mode.html#client.ayon_nuke.plugins.publish.validate_proxy_mode.FixProxyMode","title":"<code>FixProxyMode</code>","text":"<p>               Bases: <code>Action</code></p> <p>Togger off proxy switch OFF</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_proxy_mode.py</code> <pre><code>class FixProxyMode(pyblish.api.Action):\n    \"\"\"\n    Togger off proxy switch OFF\n    \"\"\"\n\n    label = \"Repair\"\n    icon = \"wrench\"\n    on = \"failed\"\n\n    def process(self, context, plugin):\n        rootNode = nuke.root()\n        rootNode[\"proxy\"].setValue(False)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_proxy_mode.html#client.ayon_nuke.plugins.publish.validate_proxy_mode.ValidateProxyMode","title":"<code>ValidateProxyMode</code>","text":"<p>               Bases: <code>ContextPlugin</code></p> <p>Validate active proxy mode</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_proxy_mode.py</code> <pre><code>class ValidateProxyMode(pyblish.api.ContextPlugin):\n    \"\"\"Validate active proxy mode\"\"\"\n\n    order = pyblish.api.ValidatorOrder\n    label = \"Validate Proxy Mode\"\n    hosts = [\"nuke\"]\n    actions = [FixProxyMode]\n\n    settings_category = \"nuke\"\n\n    def process(self, context):\n\n        rootNode = nuke.root()\n        isProxy = rootNode[\"proxy\"].value()\n\n        if isProxy:\n            raise PublishXmlValidationError(\n                self, \"Proxy mode should be toggled OFF\"\n            )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_rendered_frames.html","title":"validate_rendered_frames","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_rendered_frames.html#client.ayon_nuke.plugins.publish.validate_rendered_frames.ValidateRenderedFrames","title":"<code>ValidateRenderedFrames</code>","text":"<p>               Bases: <code>InstancePlugin</code></p> <p>Validates file output.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_rendered_frames.py</code> <pre><code>class ValidateRenderedFrames(pyblish.api.InstancePlugin):\n    \"\"\" Validates file output. \"\"\"\n\n    order = pyblish.api.ValidatorOrder + 0.1\n    families = [\"render\", \"prerender\", \"still\"]\n\n    label = \"Validate rendered frame\"\n    hosts = [\"nuke\", \"nukestudio\"]\n    actions = [RepairCollectionActionToLocal, RepairCollectionActionToFarm]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        node = instance.data[\"transientData\"][\"node\"]\n\n        f_data = {\n            \"node_name\": node.name()\n        }\n\n        for repre in instance.data[\"representations\"]:\n\n            if not repre.get(\"files\"):\n                msg = (\"no frames were collected, \"\n                       \"you need to render them.\\n\"\n                       \"Check properties of write node (group) and\"\n                       \"select 'Local' option in 'Publish' dropdown.\")\n                self.log.error(msg)\n                raise PublishXmlValidationError(\n                    self, msg, formatting_data=f_data)\n\n            if isinstance(repre[\"files\"], str):\n                return\n\n            collections, remainder = clique.assemble(repre[\"files\"])\n            self.log.debug(\"collections: {}\".format(str(collections)))\n            self.log.debug(\"remainder: {}\".format(str(remainder)))\n\n            collection = collections[0]\n\n            f_start_h = instance.data[\"frameStartHandle\"]\n            f_end_h = instance.data[\"frameEndHandle\"]\n\n            frame_length = int(f_end_h - f_start_h + 1)\n\n            if frame_length != 1:\n                if len(collections) != 1:\n                    msg = \"There are multiple collections in the folder\"\n                    self.log.error(msg)\n                    raise PublishXmlValidationError(\n                        self, msg, formatting_data=f_data)\n\n                if not collection.is_contiguous():\n                    msg = \"Some frames appear to be missing\"\n                    self.log.error(msg)\n                    raise PublishXmlValidationError(\n                        self, msg, formatting_data=f_data)\n\n            collected_frames_len = len(collection.indexes)\n            coll_start = min(collection.indexes)\n            coll_end = max(collection.indexes)\n\n            self.log.debug(\"frame_length: {}\".format(frame_length))\n            self.log.debug(\"collected_frames_len: {}\".format(\n                collected_frames_len))\n            self.log.debug(\"f_start_h-f_end_h: {}-{}\".format(\n                f_start_h, f_end_h))\n            self.log.debug(\n                \"coll_start-coll_end: {}-{}\".format(coll_start, coll_end))\n\n            self.log.debug(\n                \"len(collection.indexes): {}\".format(collected_frames_len)\n            )\n\n            if (\"slate\" in instance.data[\"families\"]) \\\n                    and (frame_length != collected_frames_len):\n                collected_frames_len -= 1\n                f_start_h += 1\n\n            if (\n                collected_frames_len != frame_length\n                and coll_start &lt;= f_start_h\n                and coll_end &gt;= f_end_h\n            ):\n                raise PublishXmlValidationError(\n                    self, (\n                        \"{} missing frames. Use repair to \"\n                        \"render all frames\"\n                    ).format(__name__), formatting_data=f_data\n                )\n\n            instance.data[\"collection\"] = collection\n\n            return\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_script_attributes.html","title":"validate_script_attributes","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_script_attributes.html#client.ayon_nuke.plugins.publish.validate_script_attributes.ValidateScriptAttributes","title":"<code>ValidateScriptAttributes</code>","text":"<p>               Bases: <code>OptionalPyblishPluginMixin</code>, <code>InstancePlugin</code></p> <p>Validates file output.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_script_attributes.py</code> <pre><code>class ValidateScriptAttributes(\n    OptionalPyblishPluginMixin,\n    pyblish.api.InstancePlugin\n):\n    \"\"\" Validates file output. \"\"\"\n\n    order = pyblish.api.ValidatorOrder + 0.1\n    families = [\"workfile\"]\n    label = \"Validate script attributes\"\n    hosts = [\"nuke\"]\n    optional = True\n    actions = [RepairAction]\n\n    settings_category = \"nuke\"\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        script_data = deepcopy(instance.context.data[\"scriptData\"])\n\n        # Task may be optional for an instance\n        task_entity = instance.data.get(\"taskEntity\")\n        if task_entity:\n            src_attributes = task_entity[\"attrib\"]\n        else:\n            src_attributes = instance.data[\"folderEntity\"][\"attrib\"]\n\n        # These attributes will be checked\n        attributes = [\n            \"fps\",\n            \"frameStart\",\n            \"frameEnd\",\n            \"resolutionWidth\",\n            \"resolutionHeight\",\n            \"handleStart\",\n            \"handleEnd\"\n        ]\n\n        # get only defined attributes from folder or task data\n        check_attributes = {\n            attr: src_attributes[attr]\n            for attr in attributes\n            if attr in src_attributes\n        }\n        # fix frame values to include handles\n        check_attributes[\"fps\"] = float(\"{0:.4f}\".format(\n            check_attributes[\"fps\"]))\n        script_data[\"fps\"] = float(\"{0:.4f}\".format(\n            script_data[\"fps\"]))\n\n        # Compare folder's values Nukescript X Database\n        not_matching = []\n        for attr in attributes:\n            self.log.debug(\n                \"Task vs Script attribute \\\"{}\\\": {}, {}\".format(\n                    attr,\n                    check_attributes[attr],\n                    script_data[attr]\n                )\n            )\n            if check_attributes[attr] != script_data[attr]:\n                not_matching.append({\n                    \"name\": attr,\n                    \"expected\": check_attributes[attr],\n                    \"actual\": script_data[attr]\n                })\n\n        # Raise error if not matching\n        if not_matching:\n            msg = \"Following attributes are not set correctly: \\n{}\"\n            attrs_wrong_str = \"\\n\".join([\n                (\n                    \"`{0}` is set to `{1}`, \"\n                    \"but should be set to `{2}`\"\n                ).format(at[\"name\"], at[\"actual\"], at[\"expected\"])\n                for at in not_matching\n            ])\n            attrs_wrong_html = \"&lt;br/&gt;\".join([\n                (\n                    \"-- __{0}__ is set to __{1}__, \"\n                    \"but should be set to __{2}__\"\n                ).format(at[\"name\"], at[\"actual\"], at[\"expected\"])\n                for at in not_matching\n            ])\n            raise PublishXmlValidationError(\n                self, msg.format(attrs_wrong_str),\n                formatting_data={\n                    \"failed_attributes\": attrs_wrong_html\n                }\n            )\n\n    @classmethod\n    def repair(cls, instance):\n        cls.log.debug(\"__ repairing instance: {}\".format(instance))\n        WorkfileSettings().set_context_settings()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_write_nodes.html","title":"validate_write_nodes","text":""},{"location":"autoapi/client/ayon_nuke/plugins/publish/validate_write_nodes.html#client.ayon_nuke.plugins.publish.validate_write_nodes.ValidateNukeWriteNode","title":"<code>ValidateNukeWriteNode</code>","text":"<p>               Bases: <code>OptionalPyblishPluginMixin</code>, <code>InstancePlugin</code></p> <p>Validate Write node's knobs.</p> <p>Compare knobs on write node inside the render group with settings. At the moment supporting only <code>file</code> knob.</p> Source code in <code>client/ayon_nuke/plugins/publish/validate_write_nodes.py</code> <pre><code>class ValidateNukeWriteNode(\n    OptionalPyblishPluginMixin,\n    pyblish.api.InstancePlugin\n):\n    \"\"\" Validate Write node's knobs.\n\n    Compare knobs on write node inside the render group\n    with settings. At the moment supporting only `file` knob.\n    \"\"\"\n\n    order = pyblish.api.ValidatorOrder\n    optional = True\n    families = [\"render\"]\n    label = \"Validate write node\"\n    actions = [RepairNukeWriteNodeAction]\n    hosts = [\"nuke\"]\n\n    settings_category = \"nuke\"\n\n    product_base_types_mapping = {\n        \"render\": \"CreateWriteRender\",\n        \"prerender\": \"CreateWritePrerender\",\n        \"image\": \"CreateWriteImage\"\n    }\n\n    def process(self, instance):\n        if not self.is_active(instance.data):\n            return\n\n        child_nodes = (\n            instance.data.get(\"transientData\", {}).get(\"childNodes\")\n            or instance\n        )\n\n        write_group_node = instance.data[\"transientData\"][\"node\"]\n\n        # get write node from inside of group\n        write_node = None\n        for x in child_nodes:\n            if x.Class() == \"Write\":\n                write_node = x\n\n        if write_node is None:\n            return\n\n        # gather exposed knobs to remove them from knobs check.\n        nuke_settings = instance.context.data[\"project_settings\"][\"nuke\"]\n        product_base_type: str = instance.data[\"productBaseType\"]\n        plugin = self.product_base_types_mapping[product_base_type]\n        create_settings = nuke_settings[\"create\"][plugin]\n        exposed_knobs = set(create_settings.get(\"exposed_knobs\", []))\n\n        correct_data = get_write_node_template_attr(write_group_node)\n\n        check = []\n\n        # Collect key values of same type in a list.\n        values_by_name = defaultdict(list)\n        for knob_data in correct_data[\"knobs\"]:\n            knob_type = knob_data[\"type\"]\n            knob_value = knob_data[knob_type]\n\n            values_by_name[knob_data[\"name\"]].append(knob_value)\n\n        for knob_data in correct_data[\"knobs\"]:\n            knob_type = knob_data[\"type\"]\n\n            if (\n                knob_type == \"__legacy__\"\n            ):\n                raise PublishXmlValidationError(\n                    self, (\n                        \"Please update data in settings 'project_settings\"\n                        \"/nuke/imageio/nodes/required_nodes'\"\n                    ),\n                    key=\"legacy\"\n                )\n\n            key = knob_data[\"name\"]\n            if key in exposed_knobs or key in (\"file\", \"tile_color\"):\n                # This is not a knob we need to validate as it is likely\n                # not matching default value but edited by user.\n                continue\n\n            values = values_by_name[key]\n\n            try:\n                node_value = write_node[key].value()\n\n            except NameError:\n                self.log.warning(\"Missing knob %s in write node.\", key)\n                continue\n\n            # fix type differences\n            fixed_values = []\n            for value in values:\n                if type(node_value) in (int, float):\n                    try:\n                        if isinstance(value, list):\n                            value = color_gui_to_int(value)\n                        else:\n                            value = float(value)\n                            node_value = float(node_value)\n                    except ValueError:\n                        value = str(value)\n                else:\n                    value = str(value)\n                    node_value = str(node_value)\n\n                fixed_values.append(value)\n\n            if node_value not in fixed_values:\n                check.append([key, fixed_values, write_node[key].value()])\n\n        if check:\n            self._make_error(check)\n\n    def _make_error(self, check):\n        # sourcery skip: merge-assign-and-aug-assign, move-assign-in-block\n        dbg_msg = \"Write node's knobs values are not correct!\\n\"\n        msg_add = \"Knob '{0}' &gt; Expected: `{1}` &gt; Current: `{2}`\"\n\n        details = [\n            msg_add.format(item[0], item[1], item[2])\n            for item in check\n        ]\n        xml_msg = \"&lt;br/&gt;\".join(details)\n        dbg_msg += \"\\n\\t\".join(details)\n\n        raise PublishXmlValidationError(\n            self, dbg_msg, formatting_data={\"xml_msg\": xml_msg}\n        )\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/index.html","title":"workfile_build","text":""},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/create_placeholder.html","title":"create_placeholder","text":""},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/create_placeholder.html#client.ayon_nuke.plugins.workfile_build.create_placeholder.NukePlaceholderCreatePlugin","title":"<code>NukePlaceholderCreatePlugin</code>","text":"<p>               Bases: <code>NukePlaceholderPlugin</code>, <code>PlaceholderCreateMixin</code></p> Source code in <code>client/ayon_nuke/plugins/workfile_build/create_placeholder.py</code> <pre><code>class NukePlaceholderCreatePlugin(\n    NukePlaceholderPlugin, PlaceholderCreateMixin\n):\n    identifier = \"nuke.create\"\n    label = \"Nuke create\"\n\n    def _parse_placeholder_node_data(self, node):\n        placeholder_data = super(\n            NukePlaceholderCreatePlugin, self\n        )._parse_placeholder_node_data(node)\n\n        node_knobs = node.knobs()\n        nb_children = 0\n        if \"nb_children\" in node_knobs:\n            nb_children = int(node_knobs[\"nb_children\"].getValue())\n        placeholder_data[\"nb_children\"] = nb_children\n\n        siblings = []\n        if \"siblings\" in node_knobs:\n            siblings = node_knobs[\"siblings\"].values()\n        placeholder_data[\"siblings\"] = siblings\n\n        node_full_name = node.fullName()\n        placeholder_data[\"group_name\"] = node_full_name.rpartition(\".\")[0]\n        placeholder_data[\"last_loaded\"] = []\n        placeholder_data[\"delete\"] = False\n        return placeholder_data\n\n    def _before_instance_create(self, placeholder):\n        placeholder.data[\"nodes_init\"] = nuke.allNodes()\n\n    def collect_placeholders(self):\n        output = []\n        scene_placeholders = self._collect_scene_placeholders()\n        for node_name, node in scene_placeholders.items():\n            plugin_identifier_knob = node.knob(\"plugin_identifier\")\n            if (\n                plugin_identifier_knob is None\n                or plugin_identifier_knob.getValue() != self.identifier\n            ):\n                continue\n\n            placeholder_data = self._parse_placeholder_node_data(node)\n\n            output.append(\n                CreatePlaceholderItem(node_name, placeholder_data, self)\n            )\n\n        return output\n\n    def populate_placeholder(self, placeholder):\n        self.populate_create_placeholder(placeholder)\n\n    def repopulate_placeholder(self, placeholder):\n        self.populate_create_placeholder(placeholder)\n\n    def get_placeholder_options(self, options=None):\n        return self.get_create_plugin_options(options)\n\n    def post_placeholder_process(self, placeholder, failed):\n        \"\"\"Cleanup placeholder after load of its corresponding representations.\n\n        Args:\n            placeholder (PlaceholderItem): Item which was just used to load\n                representation.\n            failed (bool): Loading of representation failed.\n        \"\"\"\n        # deselect all selected nodes\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n\n        # getting the latest nodes added\n        nodes_init = placeholder.data[\"nodes_init\"]\n        nodes_created = list(set(nuke.allNodes()) - set(nodes_init))\n        self.log.debug(\"Created nodes: {}\".format(nodes_created))\n        if not nodes_created:\n            return\n\n        placeholder.data[\"delete\"] = True\n\n        nodes_created = self._move_to_placeholder_group(\n            placeholder, nodes_created\n        )\n        placeholder.data[\"last_created\"] = nodes_created\n        refresh_nodes(nodes_created)\n\n        # positioning of the created nodes\n        min_x, min_y, _, _ = get_extreme_positions(nodes_created)\n        for node in nodes_created:\n            xpos = (node.xpos() - min_x) + placeholder_node.xpos()\n            ypos = (node.ypos() - min_y) + placeholder_node.ypos()\n            node.setXYpos(xpos, ypos)\n        refresh_nodes(nodes_created)\n\n        # fix the problem of z_order for backdrops\n        self._fix_z_order(placeholder)\n\n        if placeholder.data.get(\"keep_placeholder\"):\n            self._imprint_siblings(placeholder)\n\n        if placeholder.data[\"nb_children\"] == 0:\n            # save initial nodes positions and dimensions, update them\n            # and set inputs and outputs of created nodes\n\n            if placeholder.data.get(\"keep_placeholder\"):\n                self._imprint_inits()\n                self._update_nodes(placeholder, nuke.allNodes(), nodes_created)\n\n            self._set_created_connections(placeholder)\n\n        elif placeholder.data[\"siblings\"]:\n            # create copies of placeholder siblings for the new created nodes,\n            # set their inputs and outputs and update all nodes positions and\n            # dimensions and siblings names\n\n            siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n            refresh_nodes(siblings)\n            copies = self._create_sib_copies(placeholder)\n            new_nodes = list(copies.values())  # copies nodes\n            self._update_nodes(new_nodes, nodes_created)\n            placeholder_node.removeKnob(placeholder_node.knob(\"siblings\"))\n            new_nodes_name = get_names_from_nodes(new_nodes)\n            imprint(placeholder_node, {\"siblings\": new_nodes_name})\n            self._set_copies_connections(placeholder, copies)\n\n            self._update_nodes(\n                nuke.allNodes(),\n                new_nodes + nodes_created,\n                20\n            )\n\n            new_siblings = get_names_from_nodes(new_nodes)\n            placeholder.data[\"siblings\"] = new_siblings\n\n        else:\n            # if the placeholder doesn't have siblings, the created\n            # nodes will be placed in a free space\n\n            xpointer, ypointer = find_free_space_to_paste_nodes(\n                nodes_created, direction=\"bottom\", offset=200\n            )\n            node = nuke.createNode(\"NoOp\")\n            reset_selection()\n            nuke.delete(node)\n            for node in nodes_created:\n                xpos = (node.xpos() - min_x) + xpointer\n                ypos = (node.ypos() - min_y) + ypointer\n                node.setXYpos(xpos, ypos)\n\n        placeholder.data[\"nb_children\"] += 1\n        reset_selection()\n\n        # go back to root group\n        nuke.root().begin()\n\n    def _move_to_placeholder_group(self, placeholder, nodes_created):\n        \"\"\"\n        opening the placeholder's group and copying created nodes in it.\n\n        Returns :\n            nodes_created (list): the new list of pasted nodes\n        \"\"\"\n        groups_name = placeholder.data[\"group_name\"]\n        reset_selection()\n        select_nodes(nodes_created)\n        if groups_name:\n            with node_tempfile() as filepath:\n                nuke.nodeCopy(filepath)\n                for node in nuke.selectedNodes():\n                    nuke.delete(node)\n                group = nuke.toNode(groups_name)\n                group.begin()\n                nuke.nodePaste(filepath)\n                nodes_created = nuke.selectedNodes()\n        return nodes_created\n\n    def _fix_z_order(self, placeholder):\n        \"\"\"Fix the problem of z_order when a backdrop is create.\"\"\"\n\n        nodes_created = placeholder.data[\"last_created\"]\n        created_backdrops = []\n        bd_orders = set()\n        for node in nodes_created:\n            if isinstance(node, nuke.BackdropNode):\n                created_backdrops.append(node)\n                bd_orders.add(node.knob(\"z_order\").getValue())\n\n        if not bd_orders:\n            return\n\n        sib_orders = set()\n        for node_name in placeholder.data[\"siblings\"]:\n            node = nuke.toNode(node_name)\n            if isinstance(node, nuke.BackdropNode):\n                sib_orders.add(node.knob(\"z_order\").getValue())\n\n        if not sib_orders:\n            return\n\n        min_order = min(bd_orders)\n        max_order = max(sib_orders)\n        for backdrop_node in created_backdrops:\n            z_order = backdrop_node.knob(\"z_order\").getValue()\n            backdrop_node.knob(\"z_order\").setValue(\n                z_order + max_order - min_order + 1)\n\n    def _imprint_siblings(self, placeholder):\n        \"\"\"\n        - add siblings names to placeholder attributes (nodes created with it)\n        - add Id to the attributes of all the other nodes\n        \"\"\"\n\n        created_nodes = placeholder.data[\"last_created\"]\n        created_nodes_set = set(created_nodes)\n\n        for node in created_nodes:\n            node_knobs = node.knobs()\n\n            if (\n                \"is_placeholder\" not in node_knobs\n                or (\n                    \"is_placeholder\" in node_knobs\n                    and node.knob(\"is_placeholder\").value()\n                )\n            ):\n                siblings = list(created_nodes_set - {node})\n                siblings_name = get_names_from_nodes(siblings)\n                siblings = {\"siblings\": siblings_name}\n                imprint(node, siblings)\n\n    def _imprint_inits(self):\n        \"\"\"Add initial positions and dimensions to the attributes\"\"\"\n\n        for node in nuke.allNodes():\n            refresh_node(node)\n            imprint(node, {\"x_init\": node.xpos(), \"y_init\": node.ypos()})\n            node.knob(\"x_init\").setVisible(False)\n            node.knob(\"y_init\").setVisible(False)\n            width = node.screenWidth()\n            height = node.screenHeight()\n            if \"bdwidth\" in node.knobs():\n                imprint(node, {\"w_init\": width, \"h_init\": height})\n                node.knob(\"w_init\").setVisible(False)\n                node.knob(\"h_init\").setVisible(False)\n            refresh_node(node)\n\n    def _update_nodes(\n        self, placeholder, nodes, considered_nodes, offset_y=None\n    ):\n        \"\"\"Adjust backdrop nodes dimensions and positions.\n\n        Considering some nodes sizes.\n\n        Args:\n            nodes (list): list of nodes to update\n            considered_nodes (list): list of nodes to consider while updating\n                positions and dimensions\n            offset (int): distance between copies\n        \"\"\"\n\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n\n        min_x, min_y, max_x, max_y = get_extreme_positions(considered_nodes)\n\n        diff_x = diff_y = 0\n        contained_nodes = []  # for backdrops\n\n        if offset_y is None:\n            width_ph = placeholder_node.screenWidth()\n            height_ph = placeholder_node.screenHeight()\n            diff_y = max_y - min_y - height_ph\n            diff_x = max_x - min_x - width_ph\n            contained_nodes = [placeholder_node]\n            min_x = placeholder_node.xpos()\n            min_y = placeholder_node.ypos()\n        else:\n            siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n            minX, _, maxX, _ = get_extreme_positions(siblings)\n            diff_y = max_y - min_y + 20\n            diff_x = abs(max_x - min_x - maxX + minX)\n            contained_nodes = considered_nodes\n\n        if diff_y &lt;= 0 and diff_x &lt;= 0:\n            return\n\n        for node in nodes:\n            refresh_node(node)\n\n            if (\n                node == placeholder_node\n                or node in considered_nodes\n            ):\n                continue\n\n            if (\n                not isinstance(node, nuke.BackdropNode)\n                or (\n                    isinstance(node, nuke.BackdropNode)\n                    and not set(contained_nodes) &lt;= set(node.getNodes())\n                )\n            ):\n                if offset_y is None and node.xpos() &gt;= min_x:\n                    node.setXpos(node.xpos() + diff_x)\n\n                if node.ypos() &gt;= min_y:\n                    node.setYpos(node.ypos() + diff_y)\n\n            else:\n                width = node.screenWidth()\n                height = node.screenHeight()\n                node.knob(\"bdwidth\").setValue(width + diff_x)\n                node.knob(\"bdheight\").setValue(height + diff_y)\n\n            refresh_node(node)\n\n    def _set_created_connections(self, placeholder):\n        \"\"\"\n        set inputs and outputs of created nodes\"\"\"\n\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n        input_node, output_node = get_group_io_nodes(\n            placeholder.data[\"last_created\"]\n        )\n        for node in placeholder_node.dependent():\n            for idx in range(node.inputs()):\n                if node.input(idx) == placeholder_node and output_node:\n                    node.setInput(idx, output_node)\n\n        for node in placeholder_node.dependencies():\n            for idx in range(placeholder_node.inputs()):\n                if placeholder_node.input(idx) == node and input_node:\n                    input_node.setInput(0, node)\n\n    def _create_sib_copies(self, placeholder):\n        \"\"\" creating copies of the palce_holder siblings (the ones who were\n        created with it) for the new nodes added\n\n        Returns :\n            copies (dict) : with copied nodes names and their copies\n        \"\"\"\n\n        copies = {}\n        siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n        for node in siblings:\n            new_node = duplicate_node(node)\n\n            x_init = int(new_node.knob(\"x_init\").getValue())\n            y_init = int(new_node.knob(\"y_init\").getValue())\n            new_node.setXYpos(x_init, y_init)\n            if isinstance(new_node, nuke.BackdropNode):\n                w_init = new_node.knob(\"w_init\").getValue()\n                h_init = new_node.knob(\"h_init\").getValue()\n                new_node.knob(\"bdwidth\").setValue(w_init)\n                new_node.knob(\"bdheight\").setValue(h_init)\n                refresh_node(node)\n\n            if \"repre_id\" in node.knobs().keys():\n                node.removeKnob(node.knob(\"repre_id\"))\n            copies[node.name()] = new_node\n        return copies\n\n    def _set_copies_connections(self, placeholder, copies):\n        \"\"\"Set inputs and outputs of the copies.\n\n        Args:\n            copies (dict): Copied nodes by their names.\n        \"\"\"\n\n        last_input, last_output = get_group_io_nodes(\n            placeholder.data[\"last_created\"]\n        )\n        siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n        siblings_input, siblings_output = get_group_io_nodes(siblings)\n        copy_input = copies[siblings_input.name()]\n        copy_output = copies[siblings_output.name()]\n\n        for node_init in siblings:\n            if node_init == siblings_output:\n                continue\n\n            node_copy = copies[node_init.name()]\n            for node in node_init.dependent():\n                for idx in range(node.inputs()):\n                    if node.input(idx) != node_init:\n                        continue\n\n                    if node in siblings:\n                        copies[node.name()].setInput(idx, node_copy)\n                    else:\n                        last_input.setInput(0, node_copy)\n\n            for node in node_init.dependencies():\n                for idx in range(node_init.inputs()):\n                    if node_init.input(idx) != node:\n                        continue\n\n                    if node_init == siblings_input:\n                        copy_input.setInput(idx, node)\n                    elif node in siblings:\n                        node_copy.setInput(idx, copies[node.name()])\n                    else:\n                        node_copy.setInput(idx, last_output)\n\n        siblings_input.setInput(0, copy_output)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/create_placeholder.html#client.ayon_nuke.plugins.workfile_build.create_placeholder.NukePlaceholderCreatePlugin.post_placeholder_process","title":"<code>post_placeholder_process(placeholder, failed)</code>","text":"<p>Cleanup placeholder after load of its corresponding representations.</p> <p>Parameters:</p> Name Type Description Default <code>placeholder</code> <code>PlaceholderItem</code> <p>Item which was just used to load representation.</p> required <code>failed</code> <code>bool</code> <p>Loading of representation failed.</p> required Source code in <code>client/ayon_nuke/plugins/workfile_build/create_placeholder.py</code> <pre><code>def post_placeholder_process(self, placeholder, failed):\n    \"\"\"Cleanup placeholder after load of its corresponding representations.\n\n    Args:\n        placeholder (PlaceholderItem): Item which was just used to load\n            representation.\n        failed (bool): Loading of representation failed.\n    \"\"\"\n    # deselect all selected nodes\n    placeholder_node = nuke.toNode(placeholder.scene_identifier)\n\n    # getting the latest nodes added\n    nodes_init = placeholder.data[\"nodes_init\"]\n    nodes_created = list(set(nuke.allNodes()) - set(nodes_init))\n    self.log.debug(\"Created nodes: {}\".format(nodes_created))\n    if not nodes_created:\n        return\n\n    placeholder.data[\"delete\"] = True\n\n    nodes_created = self._move_to_placeholder_group(\n        placeholder, nodes_created\n    )\n    placeholder.data[\"last_created\"] = nodes_created\n    refresh_nodes(nodes_created)\n\n    # positioning of the created nodes\n    min_x, min_y, _, _ = get_extreme_positions(nodes_created)\n    for node in nodes_created:\n        xpos = (node.xpos() - min_x) + placeholder_node.xpos()\n        ypos = (node.ypos() - min_y) + placeholder_node.ypos()\n        node.setXYpos(xpos, ypos)\n    refresh_nodes(nodes_created)\n\n    # fix the problem of z_order for backdrops\n    self._fix_z_order(placeholder)\n\n    if placeholder.data.get(\"keep_placeholder\"):\n        self._imprint_siblings(placeholder)\n\n    if placeholder.data[\"nb_children\"] == 0:\n        # save initial nodes positions and dimensions, update them\n        # and set inputs and outputs of created nodes\n\n        if placeholder.data.get(\"keep_placeholder\"):\n            self._imprint_inits()\n            self._update_nodes(placeholder, nuke.allNodes(), nodes_created)\n\n        self._set_created_connections(placeholder)\n\n    elif placeholder.data[\"siblings\"]:\n        # create copies of placeholder siblings for the new created nodes,\n        # set their inputs and outputs and update all nodes positions and\n        # dimensions and siblings names\n\n        siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n        refresh_nodes(siblings)\n        copies = self._create_sib_copies(placeholder)\n        new_nodes = list(copies.values())  # copies nodes\n        self._update_nodes(new_nodes, nodes_created)\n        placeholder_node.removeKnob(placeholder_node.knob(\"siblings\"))\n        new_nodes_name = get_names_from_nodes(new_nodes)\n        imprint(placeholder_node, {\"siblings\": new_nodes_name})\n        self._set_copies_connections(placeholder, copies)\n\n        self._update_nodes(\n            nuke.allNodes(),\n            new_nodes + nodes_created,\n            20\n        )\n\n        new_siblings = get_names_from_nodes(new_nodes)\n        placeholder.data[\"siblings\"] = new_siblings\n\n    else:\n        # if the placeholder doesn't have siblings, the created\n        # nodes will be placed in a free space\n\n        xpointer, ypointer = find_free_space_to_paste_nodes(\n            nodes_created, direction=\"bottom\", offset=200\n        )\n        node = nuke.createNode(\"NoOp\")\n        reset_selection()\n        nuke.delete(node)\n        for node in nodes_created:\n            xpos = (node.xpos() - min_x) + xpointer\n            ypos = (node.ypos() - min_y) + ypointer\n            node.setXYpos(xpos, ypos)\n\n    placeholder.data[\"nb_children\"] += 1\n    reset_selection()\n\n    # go back to root group\n    nuke.root().begin()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/load_placeholder.html","title":"load_placeholder","text":""},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/load_placeholder.html#client.ayon_nuke.plugins.workfile_build.load_placeholder.NukePlaceholderLoadPlugin","title":"<code>NukePlaceholderLoadPlugin</code>","text":"<p>               Bases: <code>NukePlaceholderPlugin</code>, <code>PlaceholderLoadMixin</code></p> Source code in <code>client/ayon_nuke/plugins/workfile_build/load_placeholder.py</code> <pre><code>class NukePlaceholderLoadPlugin(NukePlaceholderPlugin, PlaceholderLoadMixin):\n    identifier = \"nuke.load\"\n    label = \"Nuke load\"\n\n    def _parse_placeholder_node_data(self, node):\n        placeholder_data = super(\n            NukePlaceholderLoadPlugin, self\n        )._parse_placeholder_node_data(node)\n\n        node_knobs = node.knobs()\n        nb_children = 0\n        if \"nb_children\" in node_knobs:\n            nb_children = int(node_knobs[\"nb_children\"].getValue())\n        placeholder_data[\"nb_children\"] = nb_children\n\n        siblings = []\n        if \"siblings\" in node_knobs:\n            siblings = node_knobs[\"siblings\"].values()\n        placeholder_data[\"siblings\"] = siblings\n\n        node_full_name = node.fullName()\n        placeholder_data[\"group_name\"] = node_full_name.rpartition(\".\")[0]\n        placeholder_data[\"last_loaded\"] = []\n        placeholder_data[\"delete\"] = False\n        return placeholder_data\n\n    def _get_loaded_repre_ids(self):\n        loaded_representation_ids = self.builder.get_shared_populate_data(\n            \"loaded_representation_ids\"\n        )\n        if loaded_representation_ids is None:\n            loaded_representation_ids = set()\n            for node in nuke.allNodes():\n                if \"repre_id\" in node.knobs():\n                    loaded_representation_ids.add(\n                        node.knob(\"repre_id\").getValue()\n                    )\n\n            self.builder.set_shared_populate_data(\n                \"loaded_representation_ids\", loaded_representation_ids\n            )\n        return loaded_representation_ids\n\n    def _before_placeholder_load(self, placeholder):\n        placeholder.data[\"nodes_init\"] = nuke.allNodes()\n\n    def _before_repre_load(self, placeholder, representation):\n        placeholder.data[\"last_repre_id\"] = representation[\"id\"]\n\n    def collect_placeholders(self):\n        output = []\n        scene_placeholders = self._collect_scene_placeholders()\n        for node_name, node in scene_placeholders.items():\n            plugin_identifier_knob = node.knob(\"plugin_identifier\")\n            if (\n                plugin_identifier_knob is None\n                or plugin_identifier_knob.getValue() != self.identifier\n            ):\n                continue\n\n            placeholder_data = self._parse_placeholder_node_data(node)\n            # TODO do data validations and maybe updgrades if are invalid\n            output.append(\n                LoadPlaceholderItem(node_name, placeholder_data, self)\n            )\n\n        return output\n\n    def populate_placeholder(self, placeholder):\n        self.populate_load_placeholder(placeholder)\n\n    def repopulate_placeholder(self, placeholder):\n        repre_ids = self._get_loaded_repre_ids()\n        self.populate_load_placeholder(placeholder, repre_ids)\n\n    def get_placeholder_options(self, options=None):\n        return self.get_load_plugin_options(options)\n\n    def post_placeholder_process(self, placeholder, failed):\n        \"\"\"Cleanup placeholder after load of its corresponding representations.\n\n        Args:\n            placeholder (PlaceholderItem): Item which was just used to load\n                representation.\n            failed (bool): Loading of representation failed.\n        \"\"\"\n        # deselect all selected nodes\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n\n        # getting the latest nodes added\n        # TODO get from shared populate data!\n        nodes_init = placeholder.data[\"nodes_init\"]\n        nodes_loaded = list(set(nuke.allNodes()) - set(nodes_init))\n        self.log.debug(\"Loaded nodes: {}\".format(nodes_loaded))\n        if not nodes_loaded:\n            return\n\n        placeholder.data[\"delete\"] = True\n\n        nodes_loaded = self._move_to_placeholder_group(\n            placeholder, nodes_loaded\n        )\n        placeholder.data[\"last_loaded\"] = nodes_loaded\n        refresh_nodes(nodes_loaded)\n\n        # positioning of the loaded nodes\n        min_x, min_y, _, _ = get_extreme_positions(nodes_loaded)\n        for node in nodes_loaded:\n            xpos = (node.xpos() - min_x) + placeholder_node.xpos()\n            ypos = (node.ypos() - min_y) + placeholder_node.ypos()\n            node.setXYpos(xpos, ypos)\n        refresh_nodes(nodes_loaded)\n\n        # fix the problem of z_order for backdrops\n        self._fix_z_order(placeholder)\n\n        if placeholder.data.get(\"keep_placeholder\"):\n            self._imprint_siblings(placeholder)\n\n        if placeholder.data[\"nb_children\"] == 0:\n            # save initial nodes positions and dimensions, update them\n            # and set inputs and outputs of loaded nodes\n            if placeholder.data.get(\"keep_placeholder\"):\n                self._imprint_inits()\n                self._update_nodes(placeholder, nuke.allNodes(), nodes_loaded)\n\n            self._set_loaded_connections(placeholder)\n\n        elif placeholder.data[\"siblings\"]:\n            # create copies of placeholder siblings for the new loaded nodes,\n            # set their inputs and outputs and update all nodes positions and\n            # dimensions and siblings names\n\n            siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n            refresh_nodes(siblings)\n            copies = self._create_sib_copies(placeholder)\n            new_nodes = list(copies.values())  # copies nodes\n            self._update_nodes(new_nodes, nodes_loaded)\n            placeholder_node.removeKnob(placeholder_node.knob(\"siblings\"))\n            new_nodes_name = get_names_from_nodes(new_nodes)\n            imprint(placeholder_node, {\"siblings\": new_nodes_name})\n            self._set_copies_connections(placeholder, copies)\n\n            self._update_nodes(\n                nuke.allNodes(),\n                new_nodes + nodes_loaded,\n                20\n            )\n\n            new_siblings = get_names_from_nodes(new_nodes)\n            placeholder.data[\"siblings\"] = new_siblings\n\n        else:\n            # if the placeholder doesn't have siblings, the loaded\n            # nodes will be placed in a free space\n\n            xpointer, ypointer = find_free_space_to_paste_nodes(\n                nodes_loaded, direction=\"bottom\", offset=200\n            )\n            node = nuke.createNode(\"NoOp\")\n            reset_selection()\n            nuke.delete(node)\n            for node in nodes_loaded:\n                xpos = (node.xpos() - min_x) + xpointer\n                ypos = (node.ypos() - min_y) + ypointer\n                node.setXYpos(xpos, ypos)\n\n        placeholder.data[\"nb_children\"] += 1\n        reset_selection()\n\n        # go back to root group\n        nuke.root().begin()\n\n    def _move_to_placeholder_group(self, placeholder, nodes_loaded):\n        \"\"\"\n        opening the placeholder's group and copying loaded nodes in it.\n\n        Returns :\n            nodes_loaded (list): the new list of pasted nodes\n        \"\"\"\n\n        groups_name = placeholder.data[\"group_name\"]\n        reset_selection()\n        select_nodes(nodes_loaded)\n        if groups_name:\n            with node_tempfile() as filepath:\n                nuke.nodeCopy(filepath)\n                for node in nuke.selectedNodes():\n                    nuke.delete(node)\n                group = nuke.toNode(groups_name)\n                group.begin()\n                nuke.nodePaste(filepath)\n                nodes_loaded = nuke.selectedNodes()\n        return nodes_loaded\n\n    def _fix_z_order(self, placeholder):\n        \"\"\"Fix the problem of z_order when a backdrop is loaded.\"\"\"\n\n        nodes_loaded = placeholder.data[\"last_loaded\"]\n        loaded_backdrops = []\n        bd_orders = set()\n        for node in nodes_loaded:\n            if isinstance(node, nuke.BackdropNode):\n                loaded_backdrops.append(node)\n                bd_orders.add(node.knob(\"z_order\").getValue())\n\n        if not bd_orders:\n            return\n\n        sib_orders = set()\n        for node_name in placeholder.data[\"siblings\"]:\n            node = nuke.toNode(node_name)\n            if isinstance(node, nuke.BackdropNode):\n                sib_orders.add(node.knob(\"z_order\").getValue())\n\n        if not sib_orders:\n            return\n\n        min_order = min(bd_orders)\n        max_order = max(sib_orders)\n        for backdrop_node in loaded_backdrops:\n            z_order = backdrop_node.knob(\"z_order\").getValue()\n            backdrop_node.knob(\"z_order\").setValue(\n                z_order + max_order - min_order + 1)\n\n    def _imprint_siblings(self, placeholder):\n        \"\"\"\n        - add siblings names to placeholder attributes (nodes loaded with it)\n        - add Id to the attributes of all the other nodes\n        \"\"\"\n\n        loaded_nodes = placeholder.data[\"last_loaded\"]\n        loaded_nodes_set = set(loaded_nodes)\n        data = {\"repre_id\": str(placeholder.data[\"last_repre_id\"])}\n\n        for node in loaded_nodes:\n            node_knobs = node.knobs()\n            if \"builder_type\" not in node_knobs:\n                # save the id of representation for all imported nodes\n                imprint(node, data)\n                node.knob(\"repre_id\").setVisible(False)\n                refresh_node(node)\n                continue\n\n            if (\n                \"is_placeholder\" not in node_knobs\n                or (\n                    \"is_placeholder\" in node_knobs\n                    and node.knob(\"is_placeholder\").value()\n                )\n            ):\n                siblings = list(loaded_nodes_set - {node})\n                siblings_name = get_names_from_nodes(siblings)\n                siblings = {\"siblings\": siblings_name}\n                imprint(node, siblings)\n\n    def _imprint_inits(self):\n        \"\"\"Add initial positions and dimensions to the attributes\"\"\"\n\n        for node in nuke.allNodes():\n            refresh_node(node)\n            imprint(node, {\"x_init\": node.xpos(), \"y_init\": node.ypos()})\n            node.knob(\"x_init\").setVisible(False)\n            node.knob(\"y_init\").setVisible(False)\n            width = node.screenWidth()\n            height = node.screenHeight()\n            if \"bdwidth\" in node.knobs():\n                imprint(node, {\"w_init\": width, \"h_init\": height})\n                node.knob(\"w_init\").setVisible(False)\n                node.knob(\"h_init\").setVisible(False)\n            refresh_node(node)\n\n    def _update_nodes(\n        self, placeholder, nodes, considered_nodes, offset_y=None\n    ):\n        \"\"\"Adjust backdrop nodes dimensions and positions.\n\n        Considering some nodes sizes.\n\n        Args:\n            nodes (list): list of nodes to update\n            considered_nodes (list): list of nodes to consider while updating\n                positions and dimensions\n            offset (int): distance between copies\n        \"\"\"\n\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n\n        min_x, min_y, max_x, max_y = get_extreme_positions(considered_nodes)\n\n        diff_x = diff_y = 0\n        contained_nodes = []  # for backdrops\n\n        if offset_y is None:\n            width_ph = placeholder_node.screenWidth()\n            height_ph = placeholder_node.screenHeight()\n            diff_y = max_y - min_y - height_ph\n            diff_x = max_x - min_x - width_ph\n            contained_nodes = [placeholder_node]\n            min_x = placeholder_node.xpos()\n            min_y = placeholder_node.ypos()\n        else:\n            siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n            minX, _, maxX, _ = get_extreme_positions(siblings)\n            diff_y = max_y - min_y + 20\n            diff_x = abs(max_x - min_x - maxX + minX)\n            contained_nodes = considered_nodes\n\n        if diff_y &lt;= 0 and diff_x &lt;= 0:\n            return\n\n        for node in nodes:\n            refresh_node(node)\n\n            if (\n                node == placeholder_node\n                or node in considered_nodes\n            ):\n                continue\n\n            if (\n                not isinstance(node, nuke.BackdropNode)\n                or (\n                    isinstance(node, nuke.BackdropNode)\n                    and not set(contained_nodes) &lt;= set(node.getNodes())\n                )\n            ):\n                if offset_y is None and node.xpos() &gt;= min_x:\n                    node.setXpos(node.xpos() + diff_x)\n\n                if node.ypos() &gt;= min_y:\n                    node.setYpos(node.ypos() + diff_y)\n\n            else:\n                width = node.screenWidth()\n                height = node.screenHeight()\n                node.knob(\"bdwidth\").setValue(width + diff_x)\n                node.knob(\"bdheight\").setValue(height + diff_y)\n\n            refresh_node(node)\n\n    def _set_loaded_connections(self, placeholder):\n        \"\"\"\n        set inputs and outputs of loaded nodes\"\"\"\n\n        placeholder_node = nuke.toNode(placeholder.scene_identifier)\n        input_node, output_node = get_group_io_nodes(\n            placeholder.data[\"last_loaded\"]\n        )\n        for node in placeholder_node.dependent():\n            for idx in range(node.inputs()):\n                if node.input(idx) == placeholder_node and output_node:\n                    node.setInput(idx, output_node)\n\n        for node in placeholder_node.dependencies():\n            for idx in range(placeholder_node.inputs()):\n                if placeholder_node.input(idx) == node and input_node:\n                    input_node.setInput(0, node)\n\n    def _create_sib_copies(self, placeholder):\n        \"\"\" creating copies of the palce_holder siblings (the ones who were\n        loaded with it) for the new nodes added\n\n        Returns :\n            copies (dict) : with copied nodes names and their copies\n        \"\"\"\n\n        copies = {}\n        siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n        for node in siblings:\n            new_node = duplicate_node(node)\n\n            x_init = int(new_node.knob(\"x_init\").getValue())\n            y_init = int(new_node.knob(\"y_init\").getValue())\n            new_node.setXYpos(x_init, y_init)\n            if isinstance(new_node, nuke.BackdropNode):\n                w_init = new_node.knob(\"w_init\").getValue()\n                h_init = new_node.knob(\"h_init\").getValue()\n                new_node.knob(\"bdwidth\").setValue(w_init)\n                new_node.knob(\"bdheight\").setValue(h_init)\n                refresh_node(node)\n\n            if \"repre_id\" in node.knobs().keys():\n                node.removeKnob(node.knob(\"repre_id\"))\n            copies[node.name()] = new_node\n        return copies\n\n    def _set_copies_connections(self, placeholder, copies):\n        \"\"\"Set inputs and outputs of the copies.\n\n        Args:\n            copies (dict): Copied nodes by their names.\n        \"\"\"\n\n        last_input, last_output = get_group_io_nodes(\n            placeholder.data[\"last_loaded\"]\n        )\n        siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n        siblings_input, siblings_output = get_group_io_nodes(siblings)\n        copy_input = copies[siblings_input.name()]\n        copy_output = copies[siblings_output.name()]\n\n        for node_init in siblings:\n            if node_init == siblings_output:\n                continue\n\n            node_copy = copies[node_init.name()]\n            for node in node_init.dependent():\n                for idx in range(node.inputs()):\n                    if node.input(idx) != node_init:\n                        continue\n\n                    if node in siblings:\n                        copies[node.name()].setInput(idx, node_copy)\n                    else:\n                        last_input.setInput(0, node_copy)\n\n            for node in node_init.dependencies():\n                for idx in range(node_init.inputs()):\n                    if node_init.input(idx) != node:\n                        continue\n\n                    if node_init == siblings_input:\n                        copy_input.setInput(idx, node)\n                    elif node in siblings:\n                        node_copy.setInput(idx, copies[node.name()])\n                    else:\n                        node_copy.setInput(idx, last_output)\n\n        siblings_input.setInput(0, copy_output)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/plugins/workfile_build/load_placeholder.html#client.ayon_nuke.plugins.workfile_build.load_placeholder.NukePlaceholderLoadPlugin.post_placeholder_process","title":"<code>post_placeholder_process(placeholder, failed)</code>","text":"<p>Cleanup placeholder after load of its corresponding representations.</p> <p>Parameters:</p> Name Type Description Default <code>placeholder</code> <code>PlaceholderItem</code> <p>Item which was just used to load representation.</p> required <code>failed</code> <code>bool</code> <p>Loading of representation failed.</p> required Source code in <code>client/ayon_nuke/plugins/workfile_build/load_placeholder.py</code> <pre><code>def post_placeholder_process(self, placeholder, failed):\n    \"\"\"Cleanup placeholder after load of its corresponding representations.\n\n    Args:\n        placeholder (PlaceholderItem): Item which was just used to load\n            representation.\n        failed (bool): Loading of representation failed.\n    \"\"\"\n    # deselect all selected nodes\n    placeholder_node = nuke.toNode(placeholder.scene_identifier)\n\n    # getting the latest nodes added\n    # TODO get from shared populate data!\n    nodes_init = placeholder.data[\"nodes_init\"]\n    nodes_loaded = list(set(nuke.allNodes()) - set(nodes_init))\n    self.log.debug(\"Loaded nodes: {}\".format(nodes_loaded))\n    if not nodes_loaded:\n        return\n\n    placeholder.data[\"delete\"] = True\n\n    nodes_loaded = self._move_to_placeholder_group(\n        placeholder, nodes_loaded\n    )\n    placeholder.data[\"last_loaded\"] = nodes_loaded\n    refresh_nodes(nodes_loaded)\n\n    # positioning of the loaded nodes\n    min_x, min_y, _, _ = get_extreme_positions(nodes_loaded)\n    for node in nodes_loaded:\n        xpos = (node.xpos() - min_x) + placeholder_node.xpos()\n        ypos = (node.ypos() - min_y) + placeholder_node.ypos()\n        node.setXYpos(xpos, ypos)\n    refresh_nodes(nodes_loaded)\n\n    # fix the problem of z_order for backdrops\n    self._fix_z_order(placeholder)\n\n    if placeholder.data.get(\"keep_placeholder\"):\n        self._imprint_siblings(placeholder)\n\n    if placeholder.data[\"nb_children\"] == 0:\n        # save initial nodes positions and dimensions, update them\n        # and set inputs and outputs of loaded nodes\n        if placeholder.data.get(\"keep_placeholder\"):\n            self._imprint_inits()\n            self._update_nodes(placeholder, nuke.allNodes(), nodes_loaded)\n\n        self._set_loaded_connections(placeholder)\n\n    elif placeholder.data[\"siblings\"]:\n        # create copies of placeholder siblings for the new loaded nodes,\n        # set their inputs and outputs and update all nodes positions and\n        # dimensions and siblings names\n\n        siblings = get_nodes_by_names(placeholder.data[\"siblings\"])\n        refresh_nodes(siblings)\n        copies = self._create_sib_copies(placeholder)\n        new_nodes = list(copies.values())  # copies nodes\n        self._update_nodes(new_nodes, nodes_loaded)\n        placeholder_node.removeKnob(placeholder_node.knob(\"siblings\"))\n        new_nodes_name = get_names_from_nodes(new_nodes)\n        imprint(placeholder_node, {\"siblings\": new_nodes_name})\n        self._set_copies_connections(placeholder, copies)\n\n        self._update_nodes(\n            nuke.allNodes(),\n            new_nodes + nodes_loaded,\n            20\n        )\n\n        new_siblings = get_names_from_nodes(new_nodes)\n        placeholder.data[\"siblings\"] = new_siblings\n\n    else:\n        # if the placeholder doesn't have siblings, the loaded\n        # nodes will be placed in a free space\n\n        xpointer, ypointer = find_free_space_to_paste_nodes(\n            nodes_loaded, direction=\"bottom\", offset=200\n        )\n        node = nuke.createNode(\"NoOp\")\n        reset_selection()\n        nuke.delete(node)\n        for node in nodes_loaded:\n            xpos = (node.xpos() - min_x) + xpointer\n            ypos = (node.ypos() - min_y) + ypointer\n            node.setXYpos(xpos, ypos)\n\n    placeholder.data[\"nb_children\"] += 1\n    reset_selection()\n\n    # go back to root group\n    nuke.root().begin()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/startup/index.html","title":"startup","text":""},{"location":"autoapi/client/ayon_nuke/startup/clear_rendered.html","title":"clear_rendered","text":""},{"location":"autoapi/client/ayon_nuke/startup/custom_write_node.html","title":"custom_write_node","text":"<p>AYON custom script for setting up write nodes for non-publish</p>"},{"location":"autoapi/client/ayon_nuke/startup/custom_write_node.html#client.ayon_nuke.startup.custom_write_node.WriteNodeKnobSettingPanel","title":"<code>WriteNodeKnobSettingPanel</code>","text":"<p>               Bases: <code>PythonPanel</code></p> <p>Write Node's Knobs Settings Panel</p> Source code in <code>client/ayon_nuke/startup/custom_write_node.py</code> <pre><code>class WriteNodeKnobSettingPanel(nukescripts.PythonPanel):\n    \"\"\" Write Node's Knobs Settings Panel \"\"\"\n    def __init__(self):\n        nukescripts.PythonPanel.__init__(self, \"Set Knobs Value(Write Node)\")\n\n        preset_names, _ = self.get_node_knobs_setting()\n        # create knobs\n\n        self.selected_preset_name = nuke.Enumeration_Knob(\n            'preset_selector', 'presets', preset_names)\n        # add knobs to panel\n        self.addKnob(self.selected_preset_name)\n\n    def process(self):\n        \"\"\" Process the panel values. \"\"\"\n        write_selected_nodes = [\n            selected_nodes for selected_nodes in nuke.selectedNodes()\n            if selected_nodes.Class() == \"Write\"]\n\n        selected_preset = self.selected_preset_name.value()\n        ext = None\n        knobs = knobs_setting[\"knobs\"]\n        preset_name, node_knobs_presets = (\n            self.get_node_knobs_setting(selected_preset)\n        )\n\n        if selected_preset and preset_name:\n            if not node_knobs_presets:\n                nuke.message(\n                    \"No knobs value found in subset group..\"\n                    \"\\nDefault setting will be used..\")\n            else:\n                knobs = node_knobs_presets\n\n        knob_names = {knob[\"name\"]: knob for knob in knobs}\n\n        if \"ext\" in knob_names:\n            ext = knob_names[\"ext\"][\"value\"]\n        elif \"file_type\" in knob_names:\n            ext = knob_names[\"ext\"][\"value\"]\n        else:\n            nuke.message(\n                \"ERROR: No 'file_type' nor 'ext' found in the product's knobs.\"\n                \"\\nPlease add one to complete setting up the node\")\n            return\n\n        anatomy = Anatomy(get_current_project_name())\n\n        project_settings = get_current_project_settings()\n        write_settings = project_settings[\"nuke\"][\"create\"][\"CreateWriteRender\"]\n        temp_rendering_path_template = write_settings[\"temp_rendering_path_template\"]\n\n        frame_padding = anatomy.templates_obj.frame_padding\n        for write_node in write_selected_nodes:\n            # data for mapping the path\n            # TODO add more fill data\n            product_name = write_node[\"name\"].value()\n            data = {\n                \"work\": os.getenv(\"AYON_WORKDIR\"),\n                \"product\": {\n                    \"name\": product_name,\n                },\n                \"frame\": \"#\" * frame_padding,\n                \"ext\": ext\n            }\n            file_path = temp_rendering_path_template.format(**data)\n            file_path = file_path.replace(\"\\\\\", \"/\")\n            write_node[\"file\"].setValue(file_path)\n            set_node_knobs_from_settings(write_node, knobs)\n\n    def get_node_knobs_setting(self, selected_preset=None):\n        preset_names = []\n        knobs_nodes = []\n\n        settings = [\n            node_settings for node_settings\n            in get_nuke_imageio_settings()[\"nodes\"][\"override_nodes\"]\n            if (\n                    node_settings[\"nuke_node_class\"] == \"Write\" or\n                    node_settings[\"custom_class\"] == \"Write\"\n               )\n            and node_settings.get(\"product_names\", [])\n        ]\n        if not settings:\n            return [], []\n\n        for i, _ in enumerate(settings):\n            if selected_preset in settings[i][\"product_names\"]:\n                knobs_nodes = settings[i][\"knobs\"]\n\n        for setting in settings:\n            product_names = setting.get(\"product_names\", [])\n            preset_names.extend(iter(product_names))\n        return preset_names, knobs_nodes\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/startup/custom_write_node.html#client.ayon_nuke.startup.custom_write_node.WriteNodeKnobSettingPanel.process","title":"<code>process()</code>","text":"<p>Process the panel values.</p> Source code in <code>client/ayon_nuke/startup/custom_write_node.py</code> <pre><code>def process(self):\n    \"\"\" Process the panel values. \"\"\"\n    write_selected_nodes = [\n        selected_nodes for selected_nodes in nuke.selectedNodes()\n        if selected_nodes.Class() == \"Write\"]\n\n    selected_preset = self.selected_preset_name.value()\n    ext = None\n    knobs = knobs_setting[\"knobs\"]\n    preset_name, node_knobs_presets = (\n        self.get_node_knobs_setting(selected_preset)\n    )\n\n    if selected_preset and preset_name:\n        if not node_knobs_presets:\n            nuke.message(\n                \"No knobs value found in subset group..\"\n                \"\\nDefault setting will be used..\")\n        else:\n            knobs = node_knobs_presets\n\n    knob_names = {knob[\"name\"]: knob for knob in knobs}\n\n    if \"ext\" in knob_names:\n        ext = knob_names[\"ext\"][\"value\"]\n    elif \"file_type\" in knob_names:\n        ext = knob_names[\"ext\"][\"value\"]\n    else:\n        nuke.message(\n            \"ERROR: No 'file_type' nor 'ext' found in the product's knobs.\"\n            \"\\nPlease add one to complete setting up the node\")\n        return\n\n    anatomy = Anatomy(get_current_project_name())\n\n    project_settings = get_current_project_settings()\n    write_settings = project_settings[\"nuke\"][\"create\"][\"CreateWriteRender\"]\n    temp_rendering_path_template = write_settings[\"temp_rendering_path_template\"]\n\n    frame_padding = anatomy.templates_obj.frame_padding\n    for write_node in write_selected_nodes:\n        # data for mapping the path\n        # TODO add more fill data\n        product_name = write_node[\"name\"].value()\n        data = {\n            \"work\": os.getenv(\"AYON_WORKDIR\"),\n            \"product\": {\n                \"name\": product_name,\n            },\n            \"frame\": \"#\" * frame_padding,\n            \"ext\": ext\n        }\n        file_path = temp_rendering_path_template.format(**data)\n        file_path = file_path.replace(\"\\\\\", \"/\")\n        write_node[\"file\"].setValue(file_path)\n        set_node_knobs_from_settings(write_node, knobs)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/startup/frame_setting_for_read_nodes.html","title":"frame_setting_for_read_nodes","text":"<p>AYON custom script for resetting read nodes start frame values</p>"},{"location":"autoapi/client/ayon_nuke/startup/frame_setting_for_read_nodes.html#client.ayon_nuke.startup.frame_setting_for_read_nodes.FrameSettingsPanel","title":"<code>FrameSettingsPanel</code>","text":"<p>               Bases: <code>PythonPanel</code></p> <p>Frame Settings Panel</p> Source code in <code>client/ayon_nuke/startup/frame_setting_for_read_nodes.py</code> <pre><code>class FrameSettingsPanel(nukescripts.PythonPanel):\n    \"\"\" Frame Settings Panel \"\"\"\n    def __init__(self):\n        nukescripts.PythonPanel.__init__(self, \"Set Frame Start (Read Node)\")\n\n        # create knobs\n        self.frame = nuke.Int_Knob(\n            'frame', 'Frame Number')\n        self.selected = nuke.Boolean_Knob(\"selection\")\n        # add knobs to panel\n        self.addKnob(self.selected)\n        self.addKnob(self.frame)\n\n        # set values\n        self.selected.setValue(False)\n        self.frame.setValue(nuke.root().firstFrame())\n\n    def process(self):\n        \"\"\" Process the panel values. \"\"\"\n        # get values\n        frame = self.frame.value()\n        if self.selected.value():\n            # selected nodes processing\n            if not nuke.selectedNodes():\n                return\n            for rn_ in nuke.selectedNodes():\n                if rn_.Class() != \"Read\":\n                    continue\n                rn_[\"frame_mode\"].setValue(\"start_at\")\n                rn_[\"frame\"].setValue(str(frame))\n        else:\n            # all nodes processing\n            for rn_ in nuke.allNodes(filter=\"Read\"):\n                rn_[\"frame_mode\"].setValue(\"start_at\")\n                rn_[\"frame\"].setValue(str(frame))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/startup/frame_setting_for_read_nodes.html#client.ayon_nuke.startup.frame_setting_for_read_nodes.FrameSettingsPanel.process","title":"<code>process()</code>","text":"<p>Process the panel values.</p> Source code in <code>client/ayon_nuke/startup/frame_setting_for_read_nodes.py</code> <pre><code>def process(self):\n    \"\"\" Process the panel values. \"\"\"\n    # get values\n    frame = self.frame.value()\n    if self.selected.value():\n        # selected nodes processing\n        if not nuke.selectedNodes():\n            return\n        for rn_ in nuke.selectedNodes():\n            if rn_.Class() != \"Read\":\n                continue\n            rn_[\"frame_mode\"].setValue(\"start_at\")\n            rn_[\"frame\"].setValue(str(frame))\n    else:\n        # all nodes processing\n        for rn_ in nuke.allNodes(filter=\"Read\"):\n            rn_[\"frame_mode\"].setValue(\"start_at\")\n            rn_[\"frame\"].setValue(str(frame))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/startup/menu.html","title":"menu","text":""},{"location":"autoapi/client/ayon_nuke/startup/write_to_read.html","title":"write_to_read","text":""},{"location":"autoapi/client/ayon_nuke/vendor/index.html","title":"vendor","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/index.html","title":"google","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/index.html","title":"protobuf","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/any_pb2.html","title":"any_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/api_pb2.html","title":"api_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html","title":"descriptor","text":"<p>Descriptors essentially contain exactly the information found in a .proto file, in types that make this information accessible in Python.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.Descriptor","title":"<code>Descriptor</code>","text":"<p>               Bases: <code>_NestedDescriptorBase</code></p> <p>Descriptor for a protocol message type.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of this protocol message type.</p> <code>full_name</code> <code>str</code> <p>Fully-qualified name of this protocol message type, which will include protocol \"package\" name and the name of any enclosing types.</p> <code>containing_type</code> <code>Descriptor</code> <p>Reference to the descriptor of the type containing us, or None if this is top-level.</p> <code>fields</code> <code>list[FieldDescriptor]</code> <p>Field descriptors for all fields in this type.</p> <code>fields_by_number</code> <code>dict(int, FieldDescriptor</code> <p>Same :class:<code>FieldDescriptor</code> objects as in :attr:<code>fields</code>, but indexed by \"number\" attribute in each FieldDescriptor.</p> <code>fields_by_name</code> <code>dict(str, FieldDescriptor</code> <p>Same :class:<code>FieldDescriptor</code> objects as in :attr:<code>fields</code>, but indexed by \"name\" attribute in each :class:<code>FieldDescriptor</code>.</p> <code>nested_types</code> <code>list[Descriptor]</code> <p>Descriptor references for all protocol message types nested within this one.</p> <code>nested_types_by_name</code> <code>dict(str, Descriptor</code> <p>Same Descriptor objects as in :attr:<code>nested_types</code>, but indexed by \"name\" attribute in each Descriptor.</p> <code>enum_types</code> <code>list[EnumDescriptor]</code> <p>:class:<code>EnumDescriptor</code> references for all enums contained within this type.</p> <code>enum_types_by_name</code> <code>dict(str, EnumDescriptor</code> <p>Same :class:<code>EnumDescriptor</code> objects as in :attr:<code>enum_types</code>, but indexed by \"name\" attribute in each EnumDescriptor.</p> <code>enum_values_by_name</code> <code>dict(str, EnumValueDescriptor</code> <p>Dict mapping from enum value name to :class:<code>EnumValueDescriptor</code> for that value.</p> <code>extensions</code> <code>list[FieldDescriptor]</code> <p>All extensions defined directly within this message type (NOT within a nested type).</p> <code>extensions_by_name</code> <code>dict(str, FieldDescriptor</code> <p>Same FieldDescriptor objects as :attr:<code>extensions</code>, but indexed by \"name\" attribute of each FieldDescriptor.</p> <code>is_extendable</code> <code>bool</code> <p>Does this type define any extension ranges?</p> <code>oneofs</code> <code>list[OneofDescriptor]</code> <p>The list of descriptors for oneof fields in this message.</p> <code>oneofs_by_name</code> <code>dict(str, OneofDescriptor</code> <p>Same objects as in :attr:<code>oneofs</code>, but indexed by \"name\" attribute.</p> <code>file</code> <code>FileDescriptor</code> <p>Reference to file descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class Descriptor(_NestedDescriptorBase):\n\n  \"\"\"Descriptor for a protocol message type.\n\n  Attributes:\n      name (str): Name of this protocol message type.\n      full_name (str): Fully-qualified name of this protocol message type,\n          which will include protocol \"package\" name and the name of any\n          enclosing types.\n      containing_type (Descriptor): Reference to the descriptor of the type\n          containing us, or None if this is top-level.\n      fields (list[FieldDescriptor]): Field descriptors for all fields in\n          this type.\n      fields_by_number (dict(int, FieldDescriptor)): Same\n          :class:`FieldDescriptor` objects as in :attr:`fields`, but indexed\n          by \"number\" attribute in each FieldDescriptor.\n      fields_by_name (dict(str, FieldDescriptor)): Same\n          :class:`FieldDescriptor` objects as in :attr:`fields`, but indexed by\n          \"name\" attribute in each :class:`FieldDescriptor`.\n      nested_types (list[Descriptor]): Descriptor references\n          for all protocol message types nested within this one.\n      nested_types_by_name (dict(str, Descriptor)): Same Descriptor\n          objects as in :attr:`nested_types`, but indexed by \"name\" attribute\n          in each Descriptor.\n      enum_types (list[EnumDescriptor]): :class:`EnumDescriptor` references\n          for all enums contained within this type.\n      enum_types_by_name (dict(str, EnumDescriptor)): Same\n          :class:`EnumDescriptor` objects as in :attr:`enum_types`, but\n          indexed by \"name\" attribute in each EnumDescriptor.\n      enum_values_by_name (dict(str, EnumValueDescriptor)): Dict mapping\n          from enum value name to :class:`EnumValueDescriptor` for that value.\n      extensions (list[FieldDescriptor]): All extensions defined directly\n          within this message type (NOT within a nested type).\n      extensions_by_name (dict(str, FieldDescriptor)): Same FieldDescriptor\n          objects as :attr:`extensions`, but indexed by \"name\" attribute of each\n          FieldDescriptor.\n      is_extendable (bool):  Does this type define any extension ranges?\n      oneofs (list[OneofDescriptor]): The list of descriptors for oneof fields\n          in this message.\n      oneofs_by_name (dict(str, OneofDescriptor)): Same objects as in\n          :attr:`oneofs`, but indexed by \"name\" attribute.\n      file (FileDescriptor): Reference to file descriptor.\n\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.Descriptor\n\n    def __new__(\n        cls,\n        name=None,\n        full_name=None,\n        filename=None,\n        containing_type=None,\n        fields=None,\n        nested_types=None,\n        enum_types=None,\n        extensions=None,\n        options=None,\n        serialized_options=None,\n        is_extendable=True,\n        extension_ranges=None,\n        oneofs=None,\n        file=None,  # pylint: disable=redefined-builtin\n        serialized_start=None,\n        serialized_end=None,\n        syntax=None,\n        create_key=None):\n      _message.Message._CheckCalledFromGeneratedFile()\n      return _message.default_pool.FindMessageTypeByName(full_name)\n\n  # NOTE(tmarek): The file argument redefining a builtin is nothing we can\n  # fix right now since we don't know how many clients already rely on the\n  # name of the argument.\n  def __init__(self, name, full_name, filename, containing_type, fields,\n               nested_types, enum_types, extensions, options=None,\n               serialized_options=None,\n               is_extendable=True, extension_ranges=None, oneofs=None,\n               file=None, serialized_start=None, serialized_end=None,  # pylint: disable=redefined-builtin\n               syntax=None, create_key=None):\n    \"\"\"Arguments to __init__() are as described in the description\n    of Descriptor fields above.\n\n    Note that filename is an obsolete argument, that is not used anymore.\n    Please use file.name to access this as an attribute.\n    \"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('Descriptor')\n\n    super(Descriptor, self).__init__(\n        options, 'MessageOptions', name, full_name, file,\n        containing_type, serialized_start=serialized_start,\n        serialized_end=serialized_end, serialized_options=serialized_options)\n\n    # We have fields in addition to fields_by_name and fields_by_number,\n    # so that:\n    #   1. Clients can index fields by \"order in which they're listed.\"\n    #   2. Clients can easily iterate over all fields with the terse\n    #      syntax: for f in descriptor.fields: ...\n    self.fields = fields\n    for field in self.fields:\n      field.containing_type = self\n    self.fields_by_number = dict((f.number, f) for f in fields)\n    self.fields_by_name = dict((f.name, f) for f in fields)\n    self._fields_by_camelcase_name = None\n\n    self.nested_types = nested_types\n    for nested_type in nested_types:\n      nested_type.containing_type = self\n    self.nested_types_by_name = dict((t.name, t) for t in nested_types)\n\n    self.enum_types = enum_types\n    for enum_type in self.enum_types:\n      enum_type.containing_type = self\n    self.enum_types_by_name = dict((t.name, t) for t in enum_types)\n    self.enum_values_by_name = dict(\n        (v.name, v) for t in enum_types for v in t.values)\n\n    self.extensions = extensions\n    for extension in self.extensions:\n      extension.extension_scope = self\n    self.extensions_by_name = dict((f.name, f) for f in extensions)\n    self.is_extendable = is_extendable\n    self.extension_ranges = extension_ranges\n    self.oneofs = oneofs if oneofs is not None else []\n    self.oneofs_by_name = dict((o.name, o) for o in self.oneofs)\n    for oneof in self.oneofs:\n      oneof.containing_type = self\n    self.syntax = syntax or \"proto2\"\n\n  @property\n  def fields_by_camelcase_name(self):\n    \"\"\"Same FieldDescriptor objects as in :attr:`fields`, but indexed by\n    :attr:`FieldDescriptor.camelcase_name`.\n    \"\"\"\n    if self._fields_by_camelcase_name is None:\n      self._fields_by_camelcase_name = dict(\n          (f.camelcase_name, f) for f in self.fields)\n    return self._fields_by_camelcase_name\n\n  def EnumValueName(self, enum, value):\n    \"\"\"Returns the string name of an enum value.\n\n    This is just a small helper method to simplify a common operation.\n\n    Args:\n      enum: string name of the Enum.\n      value: int, value of the enum.\n\n    Returns:\n      string name of the enum value.\n\n    Raises:\n      KeyError if either the Enum doesn't exist or the value is not a valid\n        value for the enum.\n    \"\"\"\n    return self.enum_types_by_name[enum].values_by_number[value].name\n\n  def CopyToProto(self, proto):\n    \"\"\"Copies this to a descriptor_pb2.DescriptorProto.\n\n    Args:\n      proto: An empty descriptor_pb2.DescriptorProto.\n    \"\"\"\n    # This function is overridden to give a better doc comment.\n    super(Descriptor, self).CopyToProto(proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.Descriptor.fields_by_camelcase_name","title":"<code>fields_by_camelcase_name</code>  <code>property</code>","text":"<p>Same FieldDescriptor objects as in :attr:<code>fields</code>, but indexed by :attr:<code>FieldDescriptor.camelcase_name</code>.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.Descriptor.CopyToProto","title":"<code>CopyToProto(proto)</code>","text":"<p>Copies this to a descriptor_pb2.DescriptorProto.</p> <p>Parameters:</p> Name Type Description Default <code>proto</code> <p>An empty descriptor_pb2.DescriptorProto.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def CopyToProto(self, proto):\n  \"\"\"Copies this to a descriptor_pb2.DescriptorProto.\n\n  Args:\n    proto: An empty descriptor_pb2.DescriptorProto.\n  \"\"\"\n  # This function is overridden to give a better doc comment.\n  super(Descriptor, self).CopyToProto(proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.Descriptor.EnumValueName","title":"<code>EnumValueName(enum, value)</code>","text":"<p>Returns the string name of an enum value.</p> <p>This is just a small helper method to simplify a common operation.</p> <p>Parameters:</p> Name Type Description Default <code>enum</code> <p>string name of the Enum.</p> required <code>value</code> <p>int, value of the enum.</p> required <p>Returns:</p> Type Description <p>string name of the enum value.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def EnumValueName(self, enum, value):\n  \"\"\"Returns the string name of an enum value.\n\n  This is just a small helper method to simplify a common operation.\n\n  Args:\n    enum: string name of the Enum.\n    value: int, value of the enum.\n\n  Returns:\n    string name of the enum value.\n\n  Raises:\n    KeyError if either the Enum doesn't exist or the value is not a valid\n      value for the enum.\n  \"\"\"\n  return self.enum_types_by_name[enum].values_by_number[value].name\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.Descriptor.__init__","title":"<code>__init__(name, full_name, filename, containing_type, fields, nested_types, enum_types, extensions, options=None, serialized_options=None, is_extendable=True, extension_ranges=None, oneofs=None, file=None, serialized_start=None, serialized_end=None, syntax=None, create_key=None)</code>","text":"<p>Arguments to init() are as described in the description of Descriptor fields above.</p> <p>Note that filename is an obsolete argument, that is not used anymore. Please use file.name to access this as an attribute.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self, name, full_name, filename, containing_type, fields,\n             nested_types, enum_types, extensions, options=None,\n             serialized_options=None,\n             is_extendable=True, extension_ranges=None, oneofs=None,\n             file=None, serialized_start=None, serialized_end=None,  # pylint: disable=redefined-builtin\n             syntax=None, create_key=None):\n  \"\"\"Arguments to __init__() are as described in the description\n  of Descriptor fields above.\n\n  Note that filename is an obsolete argument, that is not used anymore.\n  Please use file.name to access this as an attribute.\n  \"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('Descriptor')\n\n  super(Descriptor, self).__init__(\n      options, 'MessageOptions', name, full_name, file,\n      containing_type, serialized_start=serialized_start,\n      serialized_end=serialized_end, serialized_options=serialized_options)\n\n  # We have fields in addition to fields_by_name and fields_by_number,\n  # so that:\n  #   1. Clients can index fields by \"order in which they're listed.\"\n  #   2. Clients can easily iterate over all fields with the terse\n  #      syntax: for f in descriptor.fields: ...\n  self.fields = fields\n  for field in self.fields:\n    field.containing_type = self\n  self.fields_by_number = dict((f.number, f) for f in fields)\n  self.fields_by_name = dict((f.name, f) for f in fields)\n  self._fields_by_camelcase_name = None\n\n  self.nested_types = nested_types\n  for nested_type in nested_types:\n    nested_type.containing_type = self\n  self.nested_types_by_name = dict((t.name, t) for t in nested_types)\n\n  self.enum_types = enum_types\n  for enum_type in self.enum_types:\n    enum_type.containing_type = self\n  self.enum_types_by_name = dict((t.name, t) for t in enum_types)\n  self.enum_values_by_name = dict(\n      (v.name, v) for t in enum_types for v in t.values)\n\n  self.extensions = extensions\n  for extension in self.extensions:\n    extension.extension_scope = self\n  self.extensions_by_name = dict((f.name, f) for f in extensions)\n  self.is_extendable = is_extendable\n  self.extension_ranges = extension_ranges\n  self.oneofs = oneofs if oneofs is not None else []\n  self.oneofs_by_name = dict((o.name, o) for o in self.oneofs)\n  for oneof in self.oneofs:\n    oneof.containing_type = self\n  self.syntax = syntax or \"proto2\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.DescriptorBase","title":"<code>DescriptorBase</code>","text":"<p>Descriptors base class.</p> <p>This class is the base of all descriptor classes. It provides common options related functionality.</p> <p>Attributes:</p> Name Type Description <code>has_options</code> <p>True if the descriptor has non-default options.  Usually it   is not necessary to read this -- just call GetOptions() which will   happily return the default instance.  However, it's sometimes useful   for efficiency, and also useful inside the protobuf implementation to   avoid some bootstrapping issues.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class DescriptorBase(metaclass=DescriptorMetaclass):\n\n  \"\"\"Descriptors base class.\n\n  This class is the base of all descriptor classes. It provides common options\n  related functionality.\n\n  Attributes:\n    has_options:  True if the descriptor has non-default options.  Usually it\n        is not necessary to read this -- just call GetOptions() which will\n        happily return the default instance.  However, it's sometimes useful\n        for efficiency, and also useful inside the protobuf implementation to\n        avoid some bootstrapping issues.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    # The class, or tuple of classes, that are considered as \"virtual\n    # subclasses\" of this descriptor class.\n    _C_DESCRIPTOR_CLASS = ()\n\n  def __init__(self, options, serialized_options, options_class_name):\n    \"\"\"Initialize the descriptor given its options message and the name of the\n    class of the options message. The name of the class is required in case\n    the options message is None and has to be created.\n    \"\"\"\n    self._options = options\n    self._options_class_name = options_class_name\n    self._serialized_options = serialized_options\n\n    # Does this descriptor have non-default options?\n    self.has_options = (options is not None) or (serialized_options is not None)\n\n  def _SetOptions(self, options, options_class_name):\n    \"\"\"Sets the descriptor's options\n\n    This function is used in generated proto2 files to update descriptor\n    options. It must not be used outside proto2.\n    \"\"\"\n    self._options = options\n    self._options_class_name = options_class_name\n\n    # Does this descriptor have non-default options?\n    self.has_options = options is not None\n\n  def GetOptions(self):\n    \"\"\"Retrieves descriptor options.\n\n    This method returns the options set or creates the default options for the\n    descriptor.\n    \"\"\"\n    if self._options:\n      return self._options\n\n    from google.protobuf import descriptor_pb2\n    try:\n      options_class = getattr(descriptor_pb2,\n                              self._options_class_name)\n    except AttributeError:\n      raise RuntimeError('Unknown options class name %s!' %\n                         (self._options_class_name))\n\n    with _lock:\n      if self._serialized_options is None:\n        self._options = options_class()\n      else:\n        self._options = _ParseOptions(options_class(),\n                                      self._serialized_options)\n\n      return self._options\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.DescriptorBase.GetOptions","title":"<code>GetOptions()</code>","text":"<p>Retrieves descriptor options.</p> <p>This method returns the options set or creates the default options for the descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def GetOptions(self):\n  \"\"\"Retrieves descriptor options.\n\n  This method returns the options set or creates the default options for the\n  descriptor.\n  \"\"\"\n  if self._options:\n    return self._options\n\n  from google.protobuf import descriptor_pb2\n  try:\n    options_class = getattr(descriptor_pb2,\n                            self._options_class_name)\n  except AttributeError:\n    raise RuntimeError('Unknown options class name %s!' %\n                       (self._options_class_name))\n\n  with _lock:\n    if self._serialized_options is None:\n      self._options = options_class()\n    else:\n      self._options = _ParseOptions(options_class(),\n                                    self._serialized_options)\n\n    return self._options\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.DescriptorBase.__init__","title":"<code>__init__(options, serialized_options, options_class_name)</code>","text":"<p>Initialize the descriptor given its options message and the name of the class of the options message. The name of the class is required in case the options message is None and has to be created.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self, options, serialized_options, options_class_name):\n  \"\"\"Initialize the descriptor given its options message and the name of the\n  class of the options message. The name of the class is required in case\n  the options message is None and has to be created.\n  \"\"\"\n  self._options = options\n  self._options_class_name = options_class_name\n  self._serialized_options = serialized_options\n\n  # Does this descriptor have non-default options?\n  self.has_options = (options is not None) or (serialized_options is not None)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.EnumDescriptor","title":"<code>EnumDescriptor</code>","text":"<p>               Bases: <code>_NestedDescriptorBase</code></p> <p>Descriptor for an enum defined in a .proto file.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the enum type.</p> <code>full_name</code> <code>str</code> <p>Full name of the type, including package name and any enclosing type(s).</p> <code>values</code> <code>list[EnumValueDescriptor]</code> <p>List of the values in this enum.</p> <code>values_by_name</code> <code>dict(str, EnumValueDescriptor</code> <p>Same as :attr:<code>values</code>, but indexed by the \"name\" field of each EnumValueDescriptor.</p> <code>values_by_number</code> <code>dict(int, EnumValueDescriptor</code> <p>Same as :attr:<code>values</code>, but indexed by the \"number\" field of each EnumValueDescriptor.</p> <code>containing_type</code> <code>Descriptor</code> <p>Descriptor of the immediate containing type of this enum, or None if this is an enum defined at the top level in a .proto file.  Set by Descriptor's constructor if we're passed into one.</p> <code>file</code> <code>FileDescriptor</code> <p>Reference to file descriptor.</p> <code>options</code> <code>EnumOptions</code> <p>Enum options message or None to use default enum options.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class EnumDescriptor(_NestedDescriptorBase):\n\n  \"\"\"Descriptor for an enum defined in a .proto file.\n\n  Attributes:\n    name (str): Name of the enum type.\n    full_name (str): Full name of the type, including package name\n      and any enclosing type(s).\n\n    values (list[EnumValueDescriptor]): List of the values\n      in this enum.\n    values_by_name (dict(str, EnumValueDescriptor)): Same as :attr:`values`,\n      but indexed by the \"name\" field of each EnumValueDescriptor.\n    values_by_number (dict(int, EnumValueDescriptor)): Same as :attr:`values`,\n      but indexed by the \"number\" field of each EnumValueDescriptor.\n    containing_type (Descriptor): Descriptor of the immediate containing\n      type of this enum, or None if this is an enum defined at the\n      top level in a .proto file.  Set by Descriptor's constructor\n      if we're passed into one.\n    file (FileDescriptor): Reference to file descriptor.\n    options (descriptor_pb2.EnumOptions): Enum options message or\n      None to use default enum options.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.EnumDescriptor\n\n    def __new__(cls, name, full_name, filename, values,\n                containing_type=None, options=None,\n                serialized_options=None, file=None,  # pylint: disable=redefined-builtin\n                serialized_start=None, serialized_end=None, create_key=None):\n      _message.Message._CheckCalledFromGeneratedFile()\n      return _message.default_pool.FindEnumTypeByName(full_name)\n\n  def __init__(self, name, full_name, filename, values,\n               containing_type=None, options=None,\n               serialized_options=None, file=None,  # pylint: disable=redefined-builtin\n               serialized_start=None, serialized_end=None, create_key=None):\n    \"\"\"Arguments are as described in the attribute description above.\n\n    Note that filename is an obsolete argument, that is not used anymore.\n    Please use file.name to access this as an attribute.\n    \"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('EnumDescriptor')\n\n    super(EnumDescriptor, self).__init__(\n        options, 'EnumOptions', name, full_name, file,\n        containing_type, serialized_start=serialized_start,\n        serialized_end=serialized_end, serialized_options=serialized_options)\n\n    self.values = values\n    for value in self.values:\n      value.type = self\n    self.values_by_name = dict((v.name, v) for v in values)\n    # Values are reversed to ensure that the first alias is retained.\n    self.values_by_number = dict((v.number, v) for v in reversed(values))\n\n  def CopyToProto(self, proto):\n    \"\"\"Copies this to a descriptor_pb2.EnumDescriptorProto.\n\n    Args:\n      proto (descriptor_pb2.EnumDescriptorProto): An empty descriptor proto.\n    \"\"\"\n    # This function is overridden to give a better doc comment.\n    super(EnumDescriptor, self).CopyToProto(proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.EnumDescriptor.CopyToProto","title":"<code>CopyToProto(proto)</code>","text":"<p>Copies this to a descriptor_pb2.EnumDescriptorProto.</p> <p>Parameters:</p> Name Type Description Default <code>proto</code> <code>EnumDescriptorProto</code> <p>An empty descriptor proto.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def CopyToProto(self, proto):\n  \"\"\"Copies this to a descriptor_pb2.EnumDescriptorProto.\n\n  Args:\n    proto (descriptor_pb2.EnumDescriptorProto): An empty descriptor proto.\n  \"\"\"\n  # This function is overridden to give a better doc comment.\n  super(EnumDescriptor, self).CopyToProto(proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.EnumDescriptor.__init__","title":"<code>__init__(name, full_name, filename, values, containing_type=None, options=None, serialized_options=None, file=None, serialized_start=None, serialized_end=None, create_key=None)</code>","text":"<p>Arguments are as described in the attribute description above.</p> <p>Note that filename is an obsolete argument, that is not used anymore. Please use file.name to access this as an attribute.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self, name, full_name, filename, values,\n             containing_type=None, options=None,\n             serialized_options=None, file=None,  # pylint: disable=redefined-builtin\n             serialized_start=None, serialized_end=None, create_key=None):\n  \"\"\"Arguments are as described in the attribute description above.\n\n  Note that filename is an obsolete argument, that is not used anymore.\n  Please use file.name to access this as an attribute.\n  \"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('EnumDescriptor')\n\n  super(EnumDescriptor, self).__init__(\n      options, 'EnumOptions', name, full_name, file,\n      containing_type, serialized_start=serialized_start,\n      serialized_end=serialized_end, serialized_options=serialized_options)\n\n  self.values = values\n  for value in self.values:\n    value.type = self\n  self.values_by_name = dict((v.name, v) for v in values)\n  # Values are reversed to ensure that the first alias is retained.\n  self.values_by_number = dict((v.number, v) for v in reversed(values))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.EnumValueDescriptor","title":"<code>EnumValueDescriptor</code>","text":"<p>               Bases: <code>DescriptorBase</code></p> <p>Descriptor for a single value within an enum.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of this value.</p> <code>index</code> <code>int</code> <p>Dense, 0-indexed index giving the order that this value appears textually within its enum in the .proto file.</p> <code>number</code> <code>int</code> <p>Actual number assigned to this enum value.</p> <code>type</code> <code>EnumDescriptor</code> <p>:class:<code>EnumDescriptor</code> to which this value belongs.  Set by :class:<code>EnumDescriptor</code>'s constructor if we're passed into one.</p> <code>options</code> <code>EnumValueOptions</code> <p>Enum value options message or None to use default enum value options options.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class EnumValueDescriptor(DescriptorBase):\n\n  \"\"\"Descriptor for a single value within an enum.\n\n  Attributes:\n    name (str): Name of this value.\n    index (int): Dense, 0-indexed index giving the order that this\n      value appears textually within its enum in the .proto file.\n    number (int): Actual number assigned to this enum value.\n    type (EnumDescriptor): :class:`EnumDescriptor` to which this value\n      belongs.  Set by :class:`EnumDescriptor`'s constructor if we're\n      passed into one.\n    options (descriptor_pb2.EnumValueOptions): Enum value options message or\n      None to use default enum value options options.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.EnumValueDescriptor\n\n    def __new__(cls, name, index, number,\n                type=None,  # pylint: disable=redefined-builtin\n                options=None, serialized_options=None, create_key=None):\n      _message.Message._CheckCalledFromGeneratedFile()\n      # There is no way we can build a complete EnumValueDescriptor with the\n      # given parameters (the name of the Enum is not known, for example).\n      # Fortunately generated files just pass it to the EnumDescriptor()\n      # constructor, which will ignore it, so returning None is good enough.\n      return None\n\n  def __init__(self, name, index, number,\n               type=None,  # pylint: disable=redefined-builtin\n               options=None, serialized_options=None, create_key=None):\n    \"\"\"Arguments are as described in the attribute description above.\"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('EnumValueDescriptor')\n\n    super(EnumValueDescriptor, self).__init__(\n        options, serialized_options, 'EnumValueOptions')\n    self.name = name\n    self.index = index\n    self.number = number\n    self.type = type\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.EnumValueDescriptor.__init__","title":"<code>__init__(name, index, number, type=None, options=None, serialized_options=None, create_key=None)</code>","text":"<p>Arguments are as described in the attribute description above.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self, name, index, number,\n             type=None,  # pylint: disable=redefined-builtin\n             options=None, serialized_options=None, create_key=None):\n  \"\"\"Arguments are as described in the attribute description above.\"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('EnumValueDescriptor')\n\n  super(EnumValueDescriptor, self).__init__(\n      options, serialized_options, 'EnumValueOptions')\n  self.name = name\n  self.index = index\n  self.number = number\n  self.type = type\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.Error","title":"<code>Error</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base error for this module.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class Error(Exception):\n  \"\"\"Base error for this module.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FieldDescriptor","title":"<code>FieldDescriptor</code>","text":"<p>               Bases: <code>DescriptorBase</code></p> <p>Descriptor for a single field in a .proto file.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of this field, exactly as it appears in .proto.</p> <code>full_name</code> <code>str</code> <p>Name of this field, including containing scope.  This is particularly relevant for extensions.</p> <code>index</code> <code>int</code> <p>Dense, 0-indexed index giving the order that this field textually appears within its message in the .proto file.</p> <code>number</code> <code>int</code> <p>Tag number declared for this field in the .proto file.</p> <code>type</code> <code>int</code> <p>(One of the TYPE_* constants below) Declared type.</p> <code>cpp_type</code> <code>int</code> <p>(One of the CPPTYPE_* constants below) C++ type used to represent this field.</p> <code>label</code> <code>int</code> <p>(One of the LABEL_* constants below) Tells whether this field is optional, required, or repeated.</p> <code>has_default_value</code> <code>bool</code> <p>True if this field has a default value defined, otherwise false.</p> <code>default_value</code> <code>Varies</code> <p>Default value of this field.  Only meaningful for non-repeated scalar fields.  Repeated fields should always set this to [], and non-repeated composite fields should always set this to None.</p> <code>containing_type</code> <code>Descriptor</code> <p>Descriptor of the protocol message type that contains this field.  Set by the Descriptor constructor if we're passed into one. Somewhat confusingly, for extension fields, this is the descriptor of the EXTENDED message, not the descriptor of the message containing this field.  (See is_extension and extension_scope below).</p> <code>message_type</code> <code>Descriptor</code> <p>If a composite field, a descriptor of the message type contained in this field.  Otherwise, this is None.</p> <code>enum_type</code> <code>EnumDescriptor</code> <p>If this field contains an enum, a descriptor of that enum.  Otherwise, this is None.</p> <code>is_extension</code> <p>True iff this describes an extension field.</p> <code>extension_scope</code> <code>Descriptor</code> <p>Only meaningful if is_extension is True. Gives the message that immediately contains this extension field. Will be None iff we're a top-level (file-level) extension field.</p> <code>options</code> <code>FieldOptions</code> <p>Protocol message field options or None to use default field options.</p> <code>containing_oneof</code> <code>OneofDescriptor</code> <p>If the field is a member of a oneof union, contains its descriptor. Otherwise, None.</p> <code>file</code> <code>FileDescriptor</code> <p>Reference to file descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class FieldDescriptor(DescriptorBase):\n\n  \"\"\"Descriptor for a single field in a .proto file.\n\n  Attributes:\n    name (str): Name of this field, exactly as it appears in .proto.\n    full_name (str): Name of this field, including containing scope.  This is\n      particularly relevant for extensions.\n    index (int): Dense, 0-indexed index giving the order that this\n      field textually appears within its message in the .proto file.\n    number (int): Tag number declared for this field in the .proto file.\n\n    type (int): (One of the TYPE_* constants below) Declared type.\n    cpp_type (int): (One of the CPPTYPE_* constants below) C++ type used to\n      represent this field.\n\n    label (int): (One of the LABEL_* constants below) Tells whether this\n      field is optional, required, or repeated.\n    has_default_value (bool): True if this field has a default value defined,\n      otherwise false.\n    default_value (Varies): Default value of this field.  Only\n      meaningful for non-repeated scalar fields.  Repeated fields\n      should always set this to [], and non-repeated composite\n      fields should always set this to None.\n\n    containing_type (Descriptor): Descriptor of the protocol message\n      type that contains this field.  Set by the Descriptor constructor\n      if we're passed into one.\n      Somewhat confusingly, for extension fields, this is the\n      descriptor of the EXTENDED message, not the descriptor\n      of the message containing this field.  (See is_extension and\n      extension_scope below).\n    message_type (Descriptor): If a composite field, a descriptor\n      of the message type contained in this field.  Otherwise, this is None.\n    enum_type (EnumDescriptor): If this field contains an enum, a\n      descriptor of that enum.  Otherwise, this is None.\n\n    is_extension: True iff this describes an extension field.\n    extension_scope (Descriptor): Only meaningful if is_extension is True.\n      Gives the message that immediately contains this extension field.\n      Will be None iff we're a top-level (file-level) extension field.\n\n    options (descriptor_pb2.FieldOptions): Protocol message field options or\n      None to use default field options.\n\n    containing_oneof (OneofDescriptor): If the field is a member of a oneof\n      union, contains its descriptor. Otherwise, None.\n\n    file (FileDescriptor): Reference to file descriptor.\n  \"\"\"\n\n  # Must be consistent with C++ FieldDescriptor::Type enum in\n  # descriptor.h.\n  #\n  # TODO(robinson): Find a way to eliminate this repetition.\n  TYPE_DOUBLE         = 1\n  TYPE_FLOAT          = 2\n  TYPE_INT64          = 3\n  TYPE_UINT64         = 4\n  TYPE_INT32          = 5\n  TYPE_FIXED64        = 6\n  TYPE_FIXED32        = 7\n  TYPE_BOOL           = 8\n  TYPE_STRING         = 9\n  TYPE_GROUP          = 10\n  TYPE_MESSAGE        = 11\n  TYPE_BYTES          = 12\n  TYPE_UINT32         = 13\n  TYPE_ENUM           = 14\n  TYPE_SFIXED32       = 15\n  TYPE_SFIXED64       = 16\n  TYPE_SINT32         = 17\n  TYPE_SINT64         = 18\n  MAX_TYPE            = 18\n\n  # Must be consistent with C++ FieldDescriptor::CppType enum in\n  # descriptor.h.\n  #\n  # TODO(robinson): Find a way to eliminate this repetition.\n  CPPTYPE_INT32       = 1\n  CPPTYPE_INT64       = 2\n  CPPTYPE_UINT32      = 3\n  CPPTYPE_UINT64      = 4\n  CPPTYPE_DOUBLE      = 5\n  CPPTYPE_FLOAT       = 6\n  CPPTYPE_BOOL        = 7\n  CPPTYPE_ENUM        = 8\n  CPPTYPE_STRING      = 9\n  CPPTYPE_MESSAGE     = 10\n  MAX_CPPTYPE         = 10\n\n  _PYTHON_TO_CPP_PROTO_TYPE_MAP = {\n      TYPE_DOUBLE: CPPTYPE_DOUBLE,\n      TYPE_FLOAT: CPPTYPE_FLOAT,\n      TYPE_ENUM: CPPTYPE_ENUM,\n      TYPE_INT64: CPPTYPE_INT64,\n      TYPE_SINT64: CPPTYPE_INT64,\n      TYPE_SFIXED64: CPPTYPE_INT64,\n      TYPE_UINT64: CPPTYPE_UINT64,\n      TYPE_FIXED64: CPPTYPE_UINT64,\n      TYPE_INT32: CPPTYPE_INT32,\n      TYPE_SFIXED32: CPPTYPE_INT32,\n      TYPE_SINT32: CPPTYPE_INT32,\n      TYPE_UINT32: CPPTYPE_UINT32,\n      TYPE_FIXED32: CPPTYPE_UINT32,\n      TYPE_BYTES: CPPTYPE_STRING,\n      TYPE_STRING: CPPTYPE_STRING,\n      TYPE_BOOL: CPPTYPE_BOOL,\n      TYPE_MESSAGE: CPPTYPE_MESSAGE,\n      TYPE_GROUP: CPPTYPE_MESSAGE\n      }\n\n  # Must be consistent with C++ FieldDescriptor::Label enum in\n  # descriptor.h.\n  #\n  # TODO(robinson): Find a way to eliminate this repetition.\n  LABEL_OPTIONAL      = 1\n  LABEL_REQUIRED      = 2\n  LABEL_REPEATED      = 3\n  MAX_LABEL           = 3\n\n  # Must be consistent with C++ constants kMaxNumber, kFirstReservedNumber,\n  # and kLastReservedNumber in descriptor.h\n  MAX_FIELD_NUMBER = (1 &lt;&lt; 29) - 1\n  FIRST_RESERVED_FIELD_NUMBER = 19000\n  LAST_RESERVED_FIELD_NUMBER = 19999\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.FieldDescriptor\n\n    def __new__(cls, name, full_name, index, number, type, cpp_type, label,\n                default_value, message_type, enum_type, containing_type,\n                is_extension, extension_scope, options=None,\n                serialized_options=None,\n                has_default_value=True, containing_oneof=None, json_name=None,\n                file=None, create_key=None):  # pylint: disable=redefined-builtin\n      _message.Message._CheckCalledFromGeneratedFile()\n      if is_extension:\n        return _message.default_pool.FindExtensionByName(full_name)\n      else:\n        return _message.default_pool.FindFieldByName(full_name)\n\n  def __init__(self, name, full_name, index, number, type, cpp_type, label,\n               default_value, message_type, enum_type, containing_type,\n               is_extension, extension_scope, options=None,\n               serialized_options=None,\n               has_default_value=True, containing_oneof=None, json_name=None,\n               file=None, create_key=None):  # pylint: disable=redefined-builtin\n    \"\"\"The arguments are as described in the description of FieldDescriptor\n    attributes above.\n\n    Note that containing_type may be None, and may be set later if necessary\n    (to deal with circular references between message types, for example).\n    Likewise for extension_scope.\n    \"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('FieldDescriptor')\n\n    super(FieldDescriptor, self).__init__(\n        options, serialized_options, 'FieldOptions')\n    self.name = name\n    self.full_name = full_name\n    self.file = file\n    self._camelcase_name = None\n    if json_name is None:\n      self.json_name = _ToJsonName(name)\n    else:\n      self.json_name = json_name\n    self.index = index\n    self.number = number\n    self.type = type\n    self.cpp_type = cpp_type\n    self.label = label\n    self.has_default_value = has_default_value\n    self.default_value = default_value\n    self.containing_type = containing_type\n    self.message_type = message_type\n    self.enum_type = enum_type\n    self.is_extension = is_extension\n    self.extension_scope = extension_scope\n    self.containing_oneof = containing_oneof\n    if api_implementation.Type() == 'cpp':\n      if is_extension:\n        self._cdescriptor = _message.default_pool.FindExtensionByName(full_name)\n      else:\n        self._cdescriptor = _message.default_pool.FindFieldByName(full_name)\n    else:\n      self._cdescriptor = None\n\n  @property\n  def camelcase_name(self):\n    \"\"\"Camelcase name of this field.\n\n    Returns:\n      str: the name in CamelCase.\n    \"\"\"\n    if self._camelcase_name is None:\n      self._camelcase_name = _ToCamelCase(self.name)\n    return self._camelcase_name\n\n  @property\n  def has_presence(self):\n    \"\"\"Whether the field distinguishes between unpopulated and default values.\n\n    Raises:\n      RuntimeError: singular field that is not linked with message nor file.\n    \"\"\"\n    if self.label == FieldDescriptor.LABEL_REPEATED:\n      return False\n    if (self.cpp_type == FieldDescriptor.CPPTYPE_MESSAGE or\n        self.containing_oneof):\n      return True\n    if hasattr(self.file, 'syntax'):\n      return self.file.syntax == 'proto2'\n    if hasattr(self.message_type, 'syntax'):\n      return self.message_type.syntax == 'proto2'\n    raise RuntimeError(\n        'has_presence is not ready to use because field %s is not'\n        ' linked with message type nor file' % self.full_name)\n\n  @staticmethod\n  def ProtoTypeToCppProtoType(proto_type):\n    \"\"\"Converts from a Python proto type to a C++ Proto Type.\n\n    The Python ProtocolBuffer classes specify both the 'Python' datatype and the\n    'C++' datatype - and they're not the same. This helper method should\n    translate from one to another.\n\n    Args:\n      proto_type: the Python proto type (descriptor.FieldDescriptor.TYPE_*)\n    Returns:\n      int: descriptor.FieldDescriptor.CPPTYPE_*, the C++ type.\n    Raises:\n      TypeTransformationError: when the Python proto type isn't known.\n    \"\"\"\n    try:\n      return FieldDescriptor._PYTHON_TO_CPP_PROTO_TYPE_MAP[proto_type]\n    except KeyError:\n      raise TypeTransformationError('Unknown proto_type: %s' % proto_type)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FieldDescriptor.camelcase_name","title":"<code>camelcase_name</code>  <code>property</code>","text":"<p>Camelcase name of this field.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the name in CamelCase.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FieldDescriptor.has_presence","title":"<code>has_presence</code>  <code>property</code>","text":"<p>Whether the field distinguishes between unpopulated and default values.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>singular field that is not linked with message nor file.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FieldDescriptor.ProtoTypeToCppProtoType","title":"<code>ProtoTypeToCppProtoType(proto_type)</code>  <code>staticmethod</code>","text":"<p>Converts from a Python proto type to a C++ Proto Type.</p> <p>The Python ProtocolBuffer classes specify both the 'Python' datatype and the 'C++' datatype - and they're not the same. This helper method should translate from one to another.</p> <p>Parameters:</p> Name Type Description Default <code>proto_type</code> <p>the Python proto type (descriptor.FieldDescriptor.TYPE_*)</p> required <p>Returns:   int: descriptor.FieldDescriptor.CPPTYPE_*, the C++ type. Raises:   TypeTransformationError: when the Python proto type isn't known.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>@staticmethod\ndef ProtoTypeToCppProtoType(proto_type):\n  \"\"\"Converts from a Python proto type to a C++ Proto Type.\n\n  The Python ProtocolBuffer classes specify both the 'Python' datatype and the\n  'C++' datatype - and they're not the same. This helper method should\n  translate from one to another.\n\n  Args:\n    proto_type: the Python proto type (descriptor.FieldDescriptor.TYPE_*)\n  Returns:\n    int: descriptor.FieldDescriptor.CPPTYPE_*, the C++ type.\n  Raises:\n    TypeTransformationError: when the Python proto type isn't known.\n  \"\"\"\n  try:\n    return FieldDescriptor._PYTHON_TO_CPP_PROTO_TYPE_MAP[proto_type]\n  except KeyError:\n    raise TypeTransformationError('Unknown proto_type: %s' % proto_type)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FieldDescriptor.__init__","title":"<code>__init__(name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options=None, serialized_options=None, has_default_value=True, containing_oneof=None, json_name=None, file=None, create_key=None)</code>","text":"<p>The arguments are as described in the description of FieldDescriptor attributes above.</p> <p>Note that containing_type may be None, and may be set later if necessary (to deal with circular references between message types, for example). Likewise for extension_scope.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self, name, full_name, index, number, type, cpp_type, label,\n             default_value, message_type, enum_type, containing_type,\n             is_extension, extension_scope, options=None,\n             serialized_options=None,\n             has_default_value=True, containing_oneof=None, json_name=None,\n             file=None, create_key=None):  # pylint: disable=redefined-builtin\n  \"\"\"The arguments are as described in the description of FieldDescriptor\n  attributes above.\n\n  Note that containing_type may be None, and may be set later if necessary\n  (to deal with circular references between message types, for example).\n  Likewise for extension_scope.\n  \"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('FieldDescriptor')\n\n  super(FieldDescriptor, self).__init__(\n      options, serialized_options, 'FieldOptions')\n  self.name = name\n  self.full_name = full_name\n  self.file = file\n  self._camelcase_name = None\n  if json_name is None:\n    self.json_name = _ToJsonName(name)\n  else:\n    self.json_name = json_name\n  self.index = index\n  self.number = number\n  self.type = type\n  self.cpp_type = cpp_type\n  self.label = label\n  self.has_default_value = has_default_value\n  self.default_value = default_value\n  self.containing_type = containing_type\n  self.message_type = message_type\n  self.enum_type = enum_type\n  self.is_extension = is_extension\n  self.extension_scope = extension_scope\n  self.containing_oneof = containing_oneof\n  if api_implementation.Type() == 'cpp':\n    if is_extension:\n      self._cdescriptor = _message.default_pool.FindExtensionByName(full_name)\n    else:\n      self._cdescriptor = _message.default_pool.FindFieldByName(full_name)\n  else:\n    self._cdescriptor = None\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FileDescriptor","title":"<code>FileDescriptor</code>","text":"<p>               Bases: <code>DescriptorBase</code></p> <p>Descriptor for a file. Mimics the descriptor_pb2.FileDescriptorProto.</p> <p>Note that :attr:<code>enum_types_by_name</code>, :attr:<code>extensions_by_name</code>, and :attr:<code>dependencies</code> fields are only set by the :py:mod:<code>google.protobuf.message_factory</code> module, and not by the generated proto code.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of file, relative to root of source tree.</p> <code>package</code> <code>str</code> <p>Name of the package</p> <code>syntax</code> <code>str</code> <p>string indicating syntax of the file (can be \"proto2\" or \"proto3\")</p> <code>serialized_pb</code> <code>bytes</code> <p>Byte string of serialized :class:<code>descriptor_pb2.FileDescriptorProto</code>.</p> <code>dependencies</code> <code>list[FileDescriptor]</code> <p>List of other :class:<code>FileDescriptor</code> objects this :class:<code>FileDescriptor</code> depends on.</p> <code>public_dependencies</code> <code>list[FileDescriptor]</code> <p>A subset of :attr:<code>dependencies</code>, which were declared as \"public\".</p> <code>message_types_by_name</code> <code>dict(str, Descriptor</code> <p>Mapping from message names to their :class:<code>Descriptor</code>.</p> <code>enum_types_by_name</code> <code>dict(str, EnumDescriptor</code> <p>Mapping from enum names to their :class:<code>EnumDescriptor</code>.</p> <code>extensions_by_name</code> <code>dict(str, FieldDescriptor</code> <p>Mapping from extension names declared at file scope to their :class:<code>FieldDescriptor</code>.</p> <code>services_by_name</code> <code>dict(str, ServiceDescriptor</code> <p>Mapping from services' names to their :class:<code>ServiceDescriptor</code>.</p> <code>pool</code> <code>DescriptorPool</code> <p>The pool this descriptor belongs to.  When not passed to the constructor, the global default pool is used.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class FileDescriptor(DescriptorBase):\n  \"\"\"Descriptor for a file. Mimics the descriptor_pb2.FileDescriptorProto.\n\n  Note that :attr:`enum_types_by_name`, :attr:`extensions_by_name`, and\n  :attr:`dependencies` fields are only set by the\n  :py:mod:`google.protobuf.message_factory` module, and not by the generated\n  proto code.\n\n  Attributes:\n    name (str): Name of file, relative to root of source tree.\n    package (str): Name of the package\n    syntax (str): string indicating syntax of the file (can be \"proto2\" or\n      \"proto3\")\n    serialized_pb (bytes): Byte string of serialized\n      :class:`descriptor_pb2.FileDescriptorProto`.\n    dependencies (list[FileDescriptor]): List of other :class:`FileDescriptor`\n      objects this :class:`FileDescriptor` depends on.\n    public_dependencies (list[FileDescriptor]): A subset of\n      :attr:`dependencies`, which were declared as \"public\".\n    message_types_by_name (dict(str, Descriptor)): Mapping from message names\n      to their :class:`Descriptor`.\n    enum_types_by_name (dict(str, EnumDescriptor)): Mapping from enum names to\n      their :class:`EnumDescriptor`.\n    extensions_by_name (dict(str, FieldDescriptor)): Mapping from extension\n      names declared at file scope to their :class:`FieldDescriptor`.\n    services_by_name (dict(str, ServiceDescriptor)): Mapping from services'\n      names to their :class:`ServiceDescriptor`.\n    pool (DescriptorPool): The pool this descriptor belongs to.  When not\n      passed to the constructor, the global default pool is used.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.FileDescriptor\n\n    def __new__(cls, name, package, options=None,\n                serialized_options=None, serialized_pb=None,\n                dependencies=None, public_dependencies=None,\n                syntax=None, pool=None, create_key=None):\n      # FileDescriptor() is called from various places, not only from generated\n      # files, to register dynamic proto files and messages.\n      # pylint: disable=g-explicit-bool-comparison\n      if serialized_pb == b'':\n        # Cpp generated code must be linked in if serialized_pb is ''\n        try:\n          return _message.default_pool.FindFileByName(name)\n        except KeyError:\n          raise RuntimeError('Please link in cpp generated lib for %s' % (name))\n      elif serialized_pb:\n        return _message.default_pool.AddSerializedFile(serialized_pb)\n      else:\n        return super(FileDescriptor, cls).__new__(cls)\n\n  def __init__(self, name, package, options=None,\n               serialized_options=None, serialized_pb=None,\n               dependencies=None, public_dependencies=None,\n               syntax=None, pool=None, create_key=None):\n    \"\"\"Constructor.\"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('FileDescriptor')\n\n    super(FileDescriptor, self).__init__(\n        options, serialized_options, 'FileOptions')\n\n    if pool is None:\n      from google.protobuf import descriptor_pool\n      pool = descriptor_pool.Default()\n    self.pool = pool\n    self.message_types_by_name = {}\n    self.name = name\n    self.package = package\n    self.syntax = syntax or \"proto2\"\n    self.serialized_pb = serialized_pb\n\n    self.enum_types_by_name = {}\n    self.extensions_by_name = {}\n    self.services_by_name = {}\n    self.dependencies = (dependencies or [])\n    self.public_dependencies = (public_dependencies or [])\n\n  def CopyToProto(self, proto):\n    \"\"\"Copies this to a descriptor_pb2.FileDescriptorProto.\n\n    Args:\n      proto: An empty descriptor_pb2.FileDescriptorProto.\n    \"\"\"\n    proto.ParseFromString(self.serialized_pb)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FileDescriptor.CopyToProto","title":"<code>CopyToProto(proto)</code>","text":"<p>Copies this to a descriptor_pb2.FileDescriptorProto.</p> <p>Parameters:</p> Name Type Description Default <code>proto</code> <p>An empty descriptor_pb2.FileDescriptorProto.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def CopyToProto(self, proto):\n  \"\"\"Copies this to a descriptor_pb2.FileDescriptorProto.\n\n  Args:\n    proto: An empty descriptor_pb2.FileDescriptorProto.\n  \"\"\"\n  proto.ParseFromString(self.serialized_pb)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.FileDescriptor.__init__","title":"<code>__init__(name, package, options=None, serialized_options=None, serialized_pb=None, dependencies=None, public_dependencies=None, syntax=None, pool=None, create_key=None)</code>","text":"<p>Constructor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self, name, package, options=None,\n             serialized_options=None, serialized_pb=None,\n             dependencies=None, public_dependencies=None,\n             syntax=None, pool=None, create_key=None):\n  \"\"\"Constructor.\"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('FileDescriptor')\n\n  super(FileDescriptor, self).__init__(\n      options, serialized_options, 'FileOptions')\n\n  if pool is None:\n    from google.protobuf import descriptor_pool\n    pool = descriptor_pool.Default()\n  self.pool = pool\n  self.message_types_by_name = {}\n  self.name = name\n  self.package = package\n  self.syntax = syntax or \"proto2\"\n  self.serialized_pb = serialized_pb\n\n  self.enum_types_by_name = {}\n  self.extensions_by_name = {}\n  self.services_by_name = {}\n  self.dependencies = (dependencies or [])\n  self.public_dependencies = (public_dependencies or [])\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.MethodDescriptor","title":"<code>MethodDescriptor</code>","text":"<p>               Bases: <code>DescriptorBase</code></p> <p>Descriptor for a method in a service.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the method within the service.</p> <code>full_name</code> <code>str</code> <p>Full name of method.</p> <code>index</code> <code>int</code> <p>0-indexed index of the method inside the service.</p> <code>containing_service</code> <code>ServiceDescriptor</code> <p>The service that contains this method.</p> <code>input_type</code> <code>Descriptor</code> <p>The descriptor of the message that this method accepts.</p> <code>output_type</code> <code>Descriptor</code> <p>The descriptor of the message that this method returns.</p> <code>client_streaming</code> <code>bool</code> <p>Whether this method uses client streaming.</p> <code>server_streaming</code> <code>bool</code> <p>Whether this method uses server streaming.</p> <code>options</code> <code>MethodOptions or None</code> <p>Method options message, or None to use default method options.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class MethodDescriptor(DescriptorBase):\n\n  \"\"\"Descriptor for a method in a service.\n\n  Attributes:\n    name (str): Name of the method within the service.\n    full_name (str): Full name of method.\n    index (int): 0-indexed index of the method inside the service.\n    containing_service (ServiceDescriptor): The service that contains this\n      method.\n    input_type (Descriptor): The descriptor of the message that this method\n      accepts.\n    output_type (Descriptor): The descriptor of the message that this method\n      returns.\n    client_streaming (bool): Whether this method uses client streaming.\n    server_streaming (bool): Whether this method uses server streaming.\n    options (descriptor_pb2.MethodOptions or None): Method options message, or\n      None to use default method options.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.MethodDescriptor\n\n    def __new__(cls,\n                name,\n                full_name,\n                index,\n                containing_service,\n                input_type,\n                output_type,\n                client_streaming=False,\n                server_streaming=False,\n                options=None,\n                serialized_options=None,\n                create_key=None):\n      _message.Message._CheckCalledFromGeneratedFile()  # pylint: disable=protected-access\n      return _message.default_pool.FindMethodByName(full_name)\n\n  def __init__(self,\n               name,\n               full_name,\n               index,\n               containing_service,\n               input_type,\n               output_type,\n               client_streaming=False,\n               server_streaming=False,\n               options=None,\n               serialized_options=None,\n               create_key=None):\n    \"\"\"The arguments are as described in the description of MethodDescriptor\n    attributes above.\n\n    Note that containing_service may be None, and may be set later if necessary.\n    \"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('MethodDescriptor')\n\n    super(MethodDescriptor, self).__init__(\n        options, serialized_options, 'MethodOptions')\n    self.name = name\n    self.full_name = full_name\n    self.index = index\n    self.containing_service = containing_service\n    self.input_type = input_type\n    self.output_type = output_type\n    self.client_streaming = client_streaming\n    self.server_streaming = server_streaming\n\n  def CopyToProto(self, proto):\n    \"\"\"Copies this to a descriptor_pb2.MethodDescriptorProto.\n\n    Args:\n      proto (descriptor_pb2.MethodDescriptorProto): An empty descriptor proto.\n\n    Raises:\n      Error: If self couldn't be serialized, due to too few constructor\n        arguments.\n    \"\"\"\n    if self.containing_service is not None:\n      from google.protobuf import descriptor_pb2\n      service_proto = descriptor_pb2.ServiceDescriptorProto()\n      self.containing_service.CopyToProto(service_proto)\n      proto.CopyFrom(service_proto.method[self.index])\n    else:\n      raise Error('Descriptor does not contain a service.')\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.MethodDescriptor.CopyToProto","title":"<code>CopyToProto(proto)</code>","text":"<p>Copies this to a descriptor_pb2.MethodDescriptorProto.</p> <p>Parameters:</p> Name Type Description Default <code>proto</code> <code>MethodDescriptorProto</code> <p>An empty descriptor proto.</p> required <p>Raises:</p> Type Description <code>Error</code> <p>If self couldn't be serialized, due to too few constructor arguments.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def CopyToProto(self, proto):\n  \"\"\"Copies this to a descriptor_pb2.MethodDescriptorProto.\n\n  Args:\n    proto (descriptor_pb2.MethodDescriptorProto): An empty descriptor proto.\n\n  Raises:\n    Error: If self couldn't be serialized, due to too few constructor\n      arguments.\n  \"\"\"\n  if self.containing_service is not None:\n    from google.protobuf import descriptor_pb2\n    service_proto = descriptor_pb2.ServiceDescriptorProto()\n    self.containing_service.CopyToProto(service_proto)\n    proto.CopyFrom(service_proto.method[self.index])\n  else:\n    raise Error('Descriptor does not contain a service.')\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.MethodDescriptor.__init__","title":"<code>__init__(name, full_name, index, containing_service, input_type, output_type, client_streaming=False, server_streaming=False, options=None, serialized_options=None, create_key=None)</code>","text":"<p>The arguments are as described in the description of MethodDescriptor attributes above.</p> <p>Note that containing_service may be None, and may be set later if necessary.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(self,\n             name,\n             full_name,\n             index,\n             containing_service,\n             input_type,\n             output_type,\n             client_streaming=False,\n             server_streaming=False,\n             options=None,\n             serialized_options=None,\n             create_key=None):\n  \"\"\"The arguments are as described in the description of MethodDescriptor\n  attributes above.\n\n  Note that containing_service may be None, and may be set later if necessary.\n  \"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('MethodDescriptor')\n\n  super(MethodDescriptor, self).__init__(\n      options, serialized_options, 'MethodOptions')\n  self.name = name\n  self.full_name = full_name\n  self.index = index\n  self.containing_service = containing_service\n  self.input_type = input_type\n  self.output_type = output_type\n  self.client_streaming = client_streaming\n  self.server_streaming = server_streaming\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.OneofDescriptor","title":"<code>OneofDescriptor</code>","text":"<p>               Bases: <code>DescriptorBase</code></p> <p>Descriptor for a oneof field.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the oneof field.</p> <code>full_name</code> <code>str</code> <p>Full name of the oneof field, including package name.</p> <code>index</code> <code>int</code> <p>0-based index giving the order of the oneof field inside its containing type.</p> <code>containing_type</code> <code>Descriptor</code> <p>:class:<code>Descriptor</code> of the protocol message type that contains this field.  Set by the :class:<code>Descriptor</code> constructor if we're passed into one.</p> <code>fields</code> <code>list[FieldDescriptor]</code> <p>The list of field descriptors this oneof can contain.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class OneofDescriptor(DescriptorBase):\n  \"\"\"Descriptor for a oneof field.\n\n  Attributes:\n    name (str): Name of the oneof field.\n    full_name (str): Full name of the oneof field, including package name.\n    index (int): 0-based index giving the order of the oneof field inside\n      its containing type.\n    containing_type (Descriptor): :class:`Descriptor` of the protocol message\n      type that contains this field.  Set by the :class:`Descriptor` constructor\n      if we're passed into one.\n    fields (list[FieldDescriptor]): The list of field descriptors this\n      oneof can contain.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.OneofDescriptor\n\n    def __new__(\n        cls, name, full_name, index, containing_type, fields, options=None,\n        serialized_options=None, create_key=None):\n      _message.Message._CheckCalledFromGeneratedFile()\n      return _message.default_pool.FindOneofByName(full_name)\n\n  def __init__(\n      self, name, full_name, index, containing_type, fields, options=None,\n      serialized_options=None, create_key=None):\n    \"\"\"Arguments are as described in the attribute description above.\"\"\"\n    if create_key is not _internal_create_key:\n      _Deprecated('OneofDescriptor')\n\n    super(OneofDescriptor, self).__init__(\n        options, serialized_options, 'OneofOptions')\n    self.name = name\n    self.full_name = full_name\n    self.index = index\n    self.containing_type = containing_type\n    self.fields = fields\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.OneofDescriptor.__init__","title":"<code>__init__(name, full_name, index, containing_type, fields, options=None, serialized_options=None, create_key=None)</code>","text":"<p>Arguments are as described in the attribute description above.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def __init__(\n    self, name, full_name, index, containing_type, fields, options=None,\n    serialized_options=None, create_key=None):\n  \"\"\"Arguments are as described in the attribute description above.\"\"\"\n  if create_key is not _internal_create_key:\n    _Deprecated('OneofDescriptor')\n\n  super(OneofDescriptor, self).__init__(\n      options, serialized_options, 'OneofOptions')\n  self.name = name\n  self.full_name = full_name\n  self.index = index\n  self.containing_type = containing_type\n  self.fields = fields\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.ServiceDescriptor","title":"<code>ServiceDescriptor</code>","text":"<p>               Bases: <code>_NestedDescriptorBase</code></p> <p>Descriptor for a service.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the service.</p> <code>full_name</code> <code>str</code> <p>Full name of the service, including package name.</p> <code>index</code> <code>int</code> <p>0-indexed index giving the order that this services definition appears within the .proto file.</p> <code>methods</code> <code>list[MethodDescriptor]</code> <p>List of methods provided by this service.</p> <code>methods_by_name</code> <code>dict(str, MethodDescriptor</code> <p>Same :class:<code>MethodDescriptor</code> objects as in :attr:<code>methods_by_name</code>, but indexed by \"name\" attribute in each :class:<code>MethodDescriptor</code>.</p> <code>options</code> <code>ServiceOptions</code> <p>Service options message or None to use default service options.</p> <code>file</code> <code>FileDescriptor</code> <p>Reference to file info.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class ServiceDescriptor(_NestedDescriptorBase):\n\n  \"\"\"Descriptor for a service.\n\n  Attributes:\n    name (str): Name of the service.\n    full_name (str): Full name of the service, including package name.\n    index (int): 0-indexed index giving the order that this services\n      definition appears within the .proto file.\n    methods (list[MethodDescriptor]): List of methods provided by this\n      service.\n    methods_by_name (dict(str, MethodDescriptor)): Same\n      :class:`MethodDescriptor` objects as in :attr:`methods_by_name`, but\n      indexed by \"name\" attribute in each :class:`MethodDescriptor`.\n    options (descriptor_pb2.ServiceOptions): Service options message or\n      None to use default service options.\n    file (FileDescriptor): Reference to file info.\n  \"\"\"\n\n  if _USE_C_DESCRIPTORS:\n    _C_DESCRIPTOR_CLASS = _message.ServiceDescriptor\n\n    def __new__(\n        cls,\n        name=None,\n        full_name=None,\n        index=None,\n        methods=None,\n        options=None,\n        serialized_options=None,\n        file=None,  # pylint: disable=redefined-builtin\n        serialized_start=None,\n        serialized_end=None,\n        create_key=None):\n      _message.Message._CheckCalledFromGeneratedFile()  # pylint: disable=protected-access\n      return _message.default_pool.FindServiceByName(full_name)\n\n  def __init__(self, name, full_name, index, methods, options=None,\n               serialized_options=None, file=None,  # pylint: disable=redefined-builtin\n               serialized_start=None, serialized_end=None, create_key=None):\n    if create_key is not _internal_create_key:\n      _Deprecated('ServiceDescriptor')\n\n    super(ServiceDescriptor, self).__init__(\n        options, 'ServiceOptions', name, full_name, file,\n        None, serialized_start=serialized_start,\n        serialized_end=serialized_end, serialized_options=serialized_options)\n    self.index = index\n    self.methods = methods\n    self.methods_by_name = dict((m.name, m) for m in methods)\n    # Set the containing service for each method in this service.\n    for method in self.methods:\n      method.containing_service = self\n\n  def FindMethodByName(self, name):\n    \"\"\"Searches for the specified method, and returns its descriptor.\n\n    Args:\n      name (str): Name of the method.\n    Returns:\n      MethodDescriptor or None: the descriptor for the requested method, if\n      found.\n    \"\"\"\n    return self.methods_by_name.get(name, None)\n\n  def CopyToProto(self, proto):\n    \"\"\"Copies this to a descriptor_pb2.ServiceDescriptorProto.\n\n    Args:\n      proto (descriptor_pb2.ServiceDescriptorProto): An empty descriptor proto.\n    \"\"\"\n    # This function is overridden to give a better doc comment.\n    super(ServiceDescriptor, self).CopyToProto(proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.ServiceDescriptor.CopyToProto","title":"<code>CopyToProto(proto)</code>","text":"<p>Copies this to a descriptor_pb2.ServiceDescriptorProto.</p> <p>Parameters:</p> Name Type Description Default <code>proto</code> <code>ServiceDescriptorProto</code> <p>An empty descriptor proto.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def CopyToProto(self, proto):\n  \"\"\"Copies this to a descriptor_pb2.ServiceDescriptorProto.\n\n  Args:\n    proto (descriptor_pb2.ServiceDescriptorProto): An empty descriptor proto.\n  \"\"\"\n  # This function is overridden to give a better doc comment.\n  super(ServiceDescriptor, self).CopyToProto(proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.ServiceDescriptor.FindMethodByName","title":"<code>FindMethodByName(name)</code>","text":"<p>Searches for the specified method, and returns its descriptor.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of the method.</p> required <p>Returns:   MethodDescriptor or None: the descriptor for the requested method, if   found.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def FindMethodByName(self, name):\n  \"\"\"Searches for the specified method, and returns its descriptor.\n\n  Args:\n    name (str): Name of the method.\n  Returns:\n    MethodDescriptor or None: the descriptor for the requested method, if\n    found.\n  \"\"\"\n  return self.methods_by_name.get(name, None)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.TypeTransformationError","title":"<code>TypeTransformationError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Error transforming between python proto type and corresponding C++ type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>class TypeTransformationError(Error):\n  \"\"\"Error transforming between python proto type and corresponding C++ type.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor.html#client.ayon_nuke.vendor.google.protobuf.descriptor.MakeDescriptor","title":"<code>MakeDescriptor(desc_proto, package='', build_file_if_cpp=True, syntax=None)</code>","text":"<p>Make a protobuf Descriptor given a DescriptorProto protobuf.</p> <p>Handles nested descriptors. Note that this is limited to the scope of defining a message inside of another message. Composite fields can currently only be resolved if the message is defined in the same scope as the field.</p> <p>Parameters:</p> Name Type Description Default <code>desc_proto</code> <p>The descriptor_pb2.DescriptorProto protobuf message.</p> required <code>package</code> <p>Optional package name for the new message Descriptor (string).</p> <code>''</code> <code>build_file_if_cpp</code> <p>Update the C++ descriptor pool if api matches.                  Set to False on recursion, so no duplicates are created.</p> <code>True</code> <code>syntax</code> <p>The syntax/semantics that should be used.  Set to \"proto3\" to get       proto3 field presence semantics.</p> <code>None</code> <p>Returns:   A Descriptor for protobuf messages.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor.py</code> <pre><code>def MakeDescriptor(desc_proto, package='', build_file_if_cpp=True,\n                   syntax=None):\n  \"\"\"Make a protobuf Descriptor given a DescriptorProto protobuf.\n\n  Handles nested descriptors. Note that this is limited to the scope of defining\n  a message inside of another message. Composite fields can currently only be\n  resolved if the message is defined in the same scope as the field.\n\n  Args:\n    desc_proto: The descriptor_pb2.DescriptorProto protobuf message.\n    package: Optional package name for the new message Descriptor (string).\n    build_file_if_cpp: Update the C++ descriptor pool if api matches.\n                       Set to False on recursion, so no duplicates are created.\n    syntax: The syntax/semantics that should be used.  Set to \"proto3\" to get\n            proto3 field presence semantics.\n  Returns:\n    A Descriptor for protobuf messages.\n  \"\"\"\n  if api_implementation.Type() == 'cpp' and build_file_if_cpp:\n    # The C++ implementation requires all descriptors to be backed by the same\n    # definition in the C++ descriptor pool. To do this, we build a\n    # FileDescriptorProto with the same definition as this descriptor and build\n    # it into the pool.\n    from google.protobuf import descriptor_pb2\n    file_descriptor_proto = descriptor_pb2.FileDescriptorProto()\n    file_descriptor_proto.message_type.add().MergeFrom(desc_proto)\n\n    # Generate a random name for this proto file to prevent conflicts with any\n    # imported ones. We need to specify a file name so the descriptor pool\n    # accepts our FileDescriptorProto, but it is not important what that file\n    # name is actually set to.\n    proto_name = binascii.hexlify(os.urandom(16)).decode('ascii')\n\n    if package:\n      file_descriptor_proto.name = os.path.join(package.replace('.', '/'),\n                                                proto_name + '.proto')\n      file_descriptor_proto.package = package\n    else:\n      file_descriptor_proto.name = proto_name + '.proto'\n\n    _message.default_pool.Add(file_descriptor_proto)\n    result = _message.default_pool.FindFileByName(file_descriptor_proto.name)\n\n    if _USE_C_DESCRIPTORS:\n      return result.message_types_by_name[desc_proto.name]\n\n  full_message_name = [desc_proto.name]\n  if package: full_message_name.insert(0, package)\n\n  # Create Descriptors for enum types\n  enum_types = {}\n  for enum_proto in desc_proto.enum_type:\n    full_name = '.'.join(full_message_name + [enum_proto.name])\n    enum_desc = EnumDescriptor(\n        enum_proto.name, full_name, None, [\n            EnumValueDescriptor(enum_val.name, ii, enum_val.number,\n                                create_key=_internal_create_key)\n            for ii, enum_val in enumerate(enum_proto.value)],\n        create_key=_internal_create_key)\n    enum_types[full_name] = enum_desc\n\n  # Create Descriptors for nested types\n  nested_types = {}\n  for nested_proto in desc_proto.nested_type:\n    full_name = '.'.join(full_message_name + [nested_proto.name])\n    # Nested types are just those defined inside of the message, not all types\n    # used by fields in the message, so no loops are possible here.\n    nested_desc = MakeDescriptor(nested_proto,\n                                 package='.'.join(full_message_name),\n                                 build_file_if_cpp=False,\n                                 syntax=syntax)\n    nested_types[full_name] = nested_desc\n\n  fields = []\n  for field_proto in desc_proto.field:\n    full_name = '.'.join(full_message_name + [field_proto.name])\n    enum_desc = None\n    nested_desc = None\n    if field_proto.json_name:\n      json_name = field_proto.json_name\n    else:\n      json_name = None\n    if field_proto.HasField('type_name'):\n      type_name = field_proto.type_name\n      full_type_name = '.'.join(full_message_name +\n                                [type_name[type_name.rfind('.')+1:]])\n      if full_type_name in nested_types:\n        nested_desc = nested_types[full_type_name]\n      elif full_type_name in enum_types:\n        enum_desc = enum_types[full_type_name]\n      # Else type_name references a non-local type, which isn't implemented\n    field = FieldDescriptor(\n        field_proto.name, full_name, field_proto.number - 1,\n        field_proto.number, field_proto.type,\n        FieldDescriptor.ProtoTypeToCppProtoType(field_proto.type),\n        field_proto.label, None, nested_desc, enum_desc, None, False, None,\n        options=_OptionsOrNone(field_proto), has_default_value=False,\n        json_name=json_name, create_key=_internal_create_key)\n    fields.append(field)\n\n  desc_name = '.'.join(full_message_name)\n  return Descriptor(desc_proto.name, desc_name, None, None, fields,\n                    list(nested_types.values()), list(enum_types.values()), [],\n                    options=_OptionsOrNone(desc_proto),\n                    create_key=_internal_create_key)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_database.html","title":"descriptor_database","text":"<p>Provides a container for DescriptorProtos.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_database.html#client.ayon_nuke.vendor.google.protobuf.descriptor_database.DescriptorDatabase","title":"<code>DescriptorDatabase</code>","text":"<p>               Bases: <code>object</code></p> <p>A container accepting FileDescriptorProtos and maps DescriptorProtos.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_database.py</code> <pre><code>class DescriptorDatabase(object):\n  \"\"\"A container accepting FileDescriptorProtos and maps DescriptorProtos.\"\"\"\n\n  def __init__(self):\n    self._file_desc_protos_by_file = {}\n    self._file_desc_protos_by_symbol = {}\n\n  def Add(self, file_desc_proto):\n    \"\"\"Adds the FileDescriptorProto and its types to this database.\n\n    Args:\n      file_desc_proto: The FileDescriptorProto to add.\n    Raises:\n      DescriptorDatabaseConflictingDefinitionError: if an attempt is made to\n        add a proto with the same name but different definition than an\n        existing proto in the database.\n    \"\"\"\n    proto_name = file_desc_proto.name\n    if proto_name not in self._file_desc_protos_by_file:\n      self._file_desc_protos_by_file[proto_name] = file_desc_proto\n    elif self._file_desc_protos_by_file[proto_name] != file_desc_proto:\n      raise DescriptorDatabaseConflictingDefinitionError(\n          '%s already added, but with different descriptor.' % proto_name)\n    else:\n      return\n\n    # Add all the top-level descriptors to the index.\n    package = file_desc_proto.package\n    for message in file_desc_proto.message_type:\n      for name in _ExtractSymbols(message, package):\n        self._AddSymbol(name, file_desc_proto)\n    for enum in file_desc_proto.enum_type:\n      self._AddSymbol(('.'.join((package, enum.name))), file_desc_proto)\n      for enum_value in enum.value:\n        self._file_desc_protos_by_symbol[\n            '.'.join((package, enum_value.name))] = file_desc_proto\n    for extension in file_desc_proto.extension:\n      self._AddSymbol(('.'.join((package, extension.name))), file_desc_proto)\n    for service in file_desc_proto.service:\n      self._AddSymbol(('.'.join((package, service.name))), file_desc_proto)\n\n  def FindFileByName(self, name):\n    \"\"\"Finds the file descriptor proto by file name.\n\n    Typically the file name is a relative path ending to a .proto file. The\n    proto with the given name will have to have been added to this database\n    using the Add method or else an error will be raised.\n\n    Args:\n      name: The file name to find.\n\n    Returns:\n      The file descriptor proto matching the name.\n\n    Raises:\n      KeyError if no file by the given name was added.\n    \"\"\"\n\n    return self._file_desc_protos_by_file[name]\n\n  def FindFileContainingSymbol(self, symbol):\n    \"\"\"Finds the file descriptor proto containing the specified symbol.\n\n    The symbol should be a fully qualified name including the file descriptor's\n    package and any containing messages. Some examples:\n\n    'some.package.name.Message'\n    'some.package.name.Message.NestedEnum'\n    'some.package.name.Message.some_field'\n\n    The file descriptor proto containing the specified symbol must be added to\n    this database using the Add method or else an error will be raised.\n\n    Args:\n      symbol: The fully qualified symbol name.\n\n    Returns:\n      The file descriptor proto containing the symbol.\n\n    Raises:\n      KeyError if no file contains the specified symbol.\n    \"\"\"\n    try:\n      return self._file_desc_protos_by_symbol[symbol]\n    except KeyError:\n      # Fields, enum values, and nested extensions are not in\n      # _file_desc_protos_by_symbol. Try to find the top level\n      # descriptor. Non-existent nested symbol under a valid top level\n      # descriptor can also be found. The behavior is the same with\n      # protobuf C++.\n      top_level, _, _ = symbol.rpartition('.')\n      try:\n        return self._file_desc_protos_by_symbol[top_level]\n      except KeyError:\n        # Raise the original symbol as a KeyError for better diagnostics.\n        raise KeyError(symbol)\n\n  def FindFileContainingExtension(self, extendee_name, extension_number):\n    # TODO(jieluo): implement this API.\n    return None\n\n  def FindAllExtensionNumbers(self, extendee_name):\n    # TODO(jieluo): implement this API.\n    return []\n\n  def _AddSymbol(self, name, file_desc_proto):\n    if name in self._file_desc_protos_by_symbol:\n      warn_msg = ('Conflict register for file \"' + file_desc_proto.name +\n                  '\": ' + name +\n                  ' is already defined in file \"' +\n                  self._file_desc_protos_by_symbol[name].name + '\"')\n      warnings.warn(warn_msg, RuntimeWarning)\n    self._file_desc_protos_by_symbol[name] = file_desc_proto\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_database.html#client.ayon_nuke.vendor.google.protobuf.descriptor_database.DescriptorDatabase.Add","title":"<code>Add(file_desc_proto)</code>","text":"<p>Adds the FileDescriptorProto and its types to this database.</p> <p>Parameters:</p> Name Type Description Default <code>file_desc_proto</code> <p>The FileDescriptorProto to add.</p> required <p>Raises:   DescriptorDatabaseConflictingDefinitionError: if an attempt is made to     add a proto with the same name but different definition than an     existing proto in the database.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_database.py</code> <pre><code>def Add(self, file_desc_proto):\n  \"\"\"Adds the FileDescriptorProto and its types to this database.\n\n  Args:\n    file_desc_proto: The FileDescriptorProto to add.\n  Raises:\n    DescriptorDatabaseConflictingDefinitionError: if an attempt is made to\n      add a proto with the same name but different definition than an\n      existing proto in the database.\n  \"\"\"\n  proto_name = file_desc_proto.name\n  if proto_name not in self._file_desc_protos_by_file:\n    self._file_desc_protos_by_file[proto_name] = file_desc_proto\n  elif self._file_desc_protos_by_file[proto_name] != file_desc_proto:\n    raise DescriptorDatabaseConflictingDefinitionError(\n        '%s already added, but with different descriptor.' % proto_name)\n  else:\n    return\n\n  # Add all the top-level descriptors to the index.\n  package = file_desc_proto.package\n  for message in file_desc_proto.message_type:\n    for name in _ExtractSymbols(message, package):\n      self._AddSymbol(name, file_desc_proto)\n  for enum in file_desc_proto.enum_type:\n    self._AddSymbol(('.'.join((package, enum.name))), file_desc_proto)\n    for enum_value in enum.value:\n      self._file_desc_protos_by_symbol[\n          '.'.join((package, enum_value.name))] = file_desc_proto\n  for extension in file_desc_proto.extension:\n    self._AddSymbol(('.'.join((package, extension.name))), file_desc_proto)\n  for service in file_desc_proto.service:\n    self._AddSymbol(('.'.join((package, service.name))), file_desc_proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_database.html#client.ayon_nuke.vendor.google.protobuf.descriptor_database.DescriptorDatabase.FindFileByName","title":"<code>FindFileByName(name)</code>","text":"<p>Finds the file descriptor proto by file name.</p> <p>Typically the file name is a relative path ending to a .proto file. The proto with the given name will have to have been added to this database using the Add method or else an error will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>The file name to find.</p> required <p>Returns:</p> Type Description <p>The file descriptor proto matching the name.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_database.py</code> <pre><code>def FindFileByName(self, name):\n  \"\"\"Finds the file descriptor proto by file name.\n\n  Typically the file name is a relative path ending to a .proto file. The\n  proto with the given name will have to have been added to this database\n  using the Add method or else an error will be raised.\n\n  Args:\n    name: The file name to find.\n\n  Returns:\n    The file descriptor proto matching the name.\n\n  Raises:\n    KeyError if no file by the given name was added.\n  \"\"\"\n\n  return self._file_desc_protos_by_file[name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_database.html#client.ayon_nuke.vendor.google.protobuf.descriptor_database.DescriptorDatabase.FindFileContainingSymbol","title":"<code>FindFileContainingSymbol(symbol)</code>","text":"<p>Finds the file descriptor proto containing the specified symbol.</p> <p>The symbol should be a fully qualified name including the file descriptor's package and any containing messages. Some examples:</p> <p>'some.package.name.Message' 'some.package.name.Message.NestedEnum' 'some.package.name.Message.some_field'</p> <p>The file descriptor proto containing the specified symbol must be added to this database using the Add method or else an error will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <p>The fully qualified symbol name.</p> required <p>Returns:</p> Type Description <p>The file descriptor proto containing the symbol.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_database.py</code> <pre><code>def FindFileContainingSymbol(self, symbol):\n  \"\"\"Finds the file descriptor proto containing the specified symbol.\n\n  The symbol should be a fully qualified name including the file descriptor's\n  package and any containing messages. Some examples:\n\n  'some.package.name.Message'\n  'some.package.name.Message.NestedEnum'\n  'some.package.name.Message.some_field'\n\n  The file descriptor proto containing the specified symbol must be added to\n  this database using the Add method or else an error will be raised.\n\n  Args:\n    symbol: The fully qualified symbol name.\n\n  Returns:\n    The file descriptor proto containing the symbol.\n\n  Raises:\n    KeyError if no file contains the specified symbol.\n  \"\"\"\n  try:\n    return self._file_desc_protos_by_symbol[symbol]\n  except KeyError:\n    # Fields, enum values, and nested extensions are not in\n    # _file_desc_protos_by_symbol. Try to find the top level\n    # descriptor. Non-existent nested symbol under a valid top level\n    # descriptor can also be found. The behavior is the same with\n    # protobuf C++.\n    top_level, _, _ = symbol.rpartition('.')\n    try:\n      return self._file_desc_protos_by_symbol[top_level]\n    except KeyError:\n      # Raise the original symbol as a KeyError for better diagnostics.\n      raise KeyError(symbol)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_database.html#client.ayon_nuke.vendor.google.protobuf.descriptor_database.DescriptorDatabaseConflictingDefinitionError","title":"<code>DescriptorDatabaseConflictingDefinitionError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Raised when a proto is added with the same name &amp; different descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_database.py</code> <pre><code>class DescriptorDatabaseConflictingDefinitionError(Error):\n  \"\"\"Raised when a proto is added with the same name &amp; different descriptor.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pb2.html","title":"descriptor_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html","title":"descriptor_pool","text":"<p>Provides DescriptorPool to use as a container for proto2 descriptors.</p> <p>The DescriptorPool is used in conjection with a DescriptorDatabase to maintain a collection of protocol buffer descriptors for use when dynamically creating message types at runtime.</p> <p>For most applications protocol buffers should be used via modules generated by the protocol buffer compiler tool. This should only be used when the type of protocol buffers used in an application or library cannot be predetermined.</p> <p>Below is a straightforward example on how to use this class::</p> <p>pool = DescriptorPool()   file_descriptor_protos = [ ... ]   for file_descriptor_proto in file_descriptor_protos:     pool.Add(file_descriptor_proto)   my_message_descriptor = pool.FindMessageTypeByName('some.package.MessageType')</p> <p>The message descriptor can be used in conjunction with the message_factory module in order to create a protocol buffer class that can be encoded and decoded.</p> <p>If you want to get a Python class for the specified proto, use the helper functions inside google.protobuf.message_factory directly instead of this class.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool","title":"<code>DescriptorPool</code>","text":"<p>               Bases: <code>object</code></p> <p>A collection of protobufs dynamically constructed by descriptor protos.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>class DescriptorPool(object):\n  \"\"\"A collection of protobufs dynamically constructed by descriptor protos.\"\"\"\n\n  if _USE_C_DESCRIPTORS:\n\n    def __new__(cls, descriptor_db=None):\n      # pylint: disable=protected-access\n      return descriptor._message.DescriptorPool(descriptor_db)\n\n  def __init__(self, descriptor_db=None):\n    \"\"\"Initializes a Pool of proto buffs.\n\n    The descriptor_db argument to the constructor is provided to allow\n    specialized file descriptor proto lookup code to be triggered on demand. An\n    example would be an implementation which will read and compile a file\n    specified in a call to FindFileByName() and not require the call to Add()\n    at all. Results from this database will be cached internally here as well.\n\n    Args:\n      descriptor_db: A secondary source of file descriptors.\n    \"\"\"\n\n    self._internal_db = descriptor_database.DescriptorDatabase()\n    self._descriptor_db = descriptor_db\n    self._descriptors = {}\n    self._enum_descriptors = {}\n    self._service_descriptors = {}\n    self._file_descriptors = {}\n    self._toplevel_extensions = {}\n    # TODO(jieluo): Remove _file_desc_by_toplevel_extension after\n    # maybe year 2020 for compatibility issue (with 3.4.1 only).\n    self._file_desc_by_toplevel_extension = {}\n    self._top_enum_values = {}\n    # We store extensions in two two-level mappings: The first key is the\n    # descriptor of the message being extended, the second key is the extension\n    # full name or its tag number.\n    self._extensions_by_name = collections.defaultdict(dict)\n    self._extensions_by_number = collections.defaultdict(dict)\n\n  def _CheckConflictRegister(self, desc, desc_name, file_name):\n    \"\"\"Check if the descriptor name conflicts with another of the same name.\n\n    Args:\n      desc: Descriptor of a message, enum, service, extension or enum value.\n      desc_name (str): the full name of desc.\n      file_name (str): The file name of descriptor.\n    \"\"\"\n    for register, descriptor_type in [\n        (self._descriptors, descriptor.Descriptor),\n        (self._enum_descriptors, descriptor.EnumDescriptor),\n        (self._service_descriptors, descriptor.ServiceDescriptor),\n        (self._toplevel_extensions, descriptor.FieldDescriptor),\n        (self._top_enum_values, descriptor.EnumValueDescriptor)]:\n      if desc_name in register:\n        old_desc = register[desc_name]\n        if isinstance(old_desc, descriptor.EnumValueDescriptor):\n          old_file = old_desc.type.file.name\n        else:\n          old_file = old_desc.file.name\n\n        if not isinstance(desc, descriptor_type) or (\n            old_file != file_name):\n          error_msg = ('Conflict register for file \"' + file_name +\n                       '\": ' + desc_name +\n                       ' is already defined in file \"' +\n                       old_file + '\". Please fix the conflict by adding '\n                       'package name on the proto file, or use different '\n                       'name for the duplication.')\n          if isinstance(desc, descriptor.EnumValueDescriptor):\n            error_msg += ('\\nNote: enum values appear as '\n                          'siblings of the enum type instead of '\n                          'children of it.')\n\n          raise TypeError(error_msg)\n\n        return\n\n  def Add(self, file_desc_proto):\n    \"\"\"Adds the FileDescriptorProto and its types to this pool.\n\n    Args:\n      file_desc_proto (FileDescriptorProto): The file descriptor to add.\n    \"\"\"\n\n    self._internal_db.Add(file_desc_proto)\n\n  def AddSerializedFile(self, serialized_file_desc_proto):\n    \"\"\"Adds the FileDescriptorProto and its types to this pool.\n\n    Args:\n      serialized_file_desc_proto (bytes): A bytes string, serialization of the\n        :class:`FileDescriptorProto` to add.\n\n    Returns:\n      FileDescriptor: Descriptor for the added file.\n    \"\"\"\n\n    # pylint: disable=g-import-not-at-top\n    from google.protobuf import descriptor_pb2\n    file_desc_proto = descriptor_pb2.FileDescriptorProto.FromString(\n        serialized_file_desc_proto)\n    file_desc = self._ConvertFileProtoToFileDescriptor(file_desc_proto)\n    file_desc.serialized_pb = serialized_file_desc_proto\n    return file_desc\n\n  # Add Descriptor to descriptor pool is dreprecated. Please use Add()\n  # or AddSerializedFile() to add a FileDescriptorProto instead.\n  @_Deprecated\n  def AddDescriptor(self, desc):\n    self._AddDescriptor(desc)\n\n  # Never call this method. It is for internal usage only.\n  def _AddDescriptor(self, desc):\n    \"\"\"Adds a Descriptor to the pool, non-recursively.\n\n    If the Descriptor contains nested messages or enums, the caller must\n    explicitly register them. This method also registers the FileDescriptor\n    associated with the message.\n\n    Args:\n      desc: A Descriptor.\n    \"\"\"\n    if not isinstance(desc, descriptor.Descriptor):\n      raise TypeError('Expected instance of descriptor.Descriptor.')\n\n    self._CheckConflictRegister(desc, desc.full_name, desc.file.name)\n\n    self._descriptors[desc.full_name] = desc\n    self._AddFileDescriptor(desc.file)\n\n  # Add EnumDescriptor to descriptor pool is dreprecated. Please use Add()\n  # or AddSerializedFile() to add a FileDescriptorProto instead.\n  @_Deprecated\n  def AddEnumDescriptor(self, enum_desc):\n    self._AddEnumDescriptor(enum_desc)\n\n  # Never call this method. It is for internal usage only.\n  def _AddEnumDescriptor(self, enum_desc):\n    \"\"\"Adds an EnumDescriptor to the pool.\n\n    This method also registers the FileDescriptor associated with the enum.\n\n    Args:\n      enum_desc: An EnumDescriptor.\n    \"\"\"\n\n    if not isinstance(enum_desc, descriptor.EnumDescriptor):\n      raise TypeError('Expected instance of descriptor.EnumDescriptor.')\n\n    file_name = enum_desc.file.name\n    self._CheckConflictRegister(enum_desc, enum_desc.full_name, file_name)\n    self._enum_descriptors[enum_desc.full_name] = enum_desc\n\n    # Top enum values need to be indexed.\n    # Count the number of dots to see whether the enum is toplevel or nested\n    # in a message. We cannot use enum_desc.containing_type at this stage.\n    if enum_desc.file.package:\n      top_level = (enum_desc.full_name.count('.')\n                   - enum_desc.file.package.count('.') == 1)\n    else:\n      top_level = enum_desc.full_name.count('.') == 0\n    if top_level:\n      file_name = enum_desc.file.name\n      package = enum_desc.file.package\n      for enum_value in enum_desc.values:\n        full_name = _NormalizeFullyQualifiedName(\n            '.'.join((package, enum_value.name)))\n        self._CheckConflictRegister(enum_value, full_name, file_name)\n        self._top_enum_values[full_name] = enum_value\n    self._AddFileDescriptor(enum_desc.file)\n\n  # Add ServiceDescriptor to descriptor pool is dreprecated. Please use Add()\n  # or AddSerializedFile() to add a FileDescriptorProto instead.\n  @_Deprecated\n  def AddServiceDescriptor(self, service_desc):\n    self._AddServiceDescriptor(service_desc)\n\n  # Never call this method. It is for internal usage only.\n  def _AddServiceDescriptor(self, service_desc):\n    \"\"\"Adds a ServiceDescriptor to the pool.\n\n    Args:\n      service_desc: A ServiceDescriptor.\n    \"\"\"\n\n    if not isinstance(service_desc, descriptor.ServiceDescriptor):\n      raise TypeError('Expected instance of descriptor.ServiceDescriptor.')\n\n    self._CheckConflictRegister(service_desc, service_desc.full_name,\n                                service_desc.file.name)\n    self._service_descriptors[service_desc.full_name] = service_desc\n\n  # Add ExtensionDescriptor to descriptor pool is dreprecated. Please use Add()\n  # or AddSerializedFile() to add a FileDescriptorProto instead.\n  @_Deprecated\n  def AddExtensionDescriptor(self, extension):\n    self._AddExtensionDescriptor(extension)\n\n  # Never call this method. It is for internal usage only.\n  def _AddExtensionDescriptor(self, extension):\n    \"\"\"Adds a FieldDescriptor describing an extension to the pool.\n\n    Args:\n      extension: A FieldDescriptor.\n\n    Raises:\n      AssertionError: when another extension with the same number extends the\n        same message.\n      TypeError: when the specified extension is not a\n        descriptor.FieldDescriptor.\n    \"\"\"\n    if not (isinstance(extension, descriptor.FieldDescriptor) and\n            extension.is_extension):\n      raise TypeError('Expected an extension descriptor.')\n\n    if extension.extension_scope is None:\n      self._toplevel_extensions[extension.full_name] = extension\n\n    try:\n      existing_desc = self._extensions_by_number[\n          extension.containing_type][extension.number]\n    except KeyError:\n      pass\n    else:\n      if extension is not existing_desc:\n        raise AssertionError(\n            'Extensions \"%s\" and \"%s\" both try to extend message type \"%s\" '\n            'with field number %d.' %\n            (extension.full_name, existing_desc.full_name,\n             extension.containing_type.full_name, extension.number))\n\n    self._extensions_by_number[extension.containing_type][\n        extension.number] = extension\n    self._extensions_by_name[extension.containing_type][\n        extension.full_name] = extension\n\n    # Also register MessageSet extensions with the type name.\n    if _IsMessageSetExtension(extension):\n      self._extensions_by_name[extension.containing_type][\n          extension.message_type.full_name] = extension\n\n  @_Deprecated\n  def AddFileDescriptor(self, file_desc):\n    self._InternalAddFileDescriptor(file_desc)\n\n  # Never call this method. It is for internal usage only.\n  def _InternalAddFileDescriptor(self, file_desc):\n    \"\"\"Adds a FileDescriptor to the pool, non-recursively.\n\n    If the FileDescriptor contains messages or enums, the caller must explicitly\n    register them.\n\n    Args:\n      file_desc: A FileDescriptor.\n    \"\"\"\n\n    self._AddFileDescriptor(file_desc)\n    # TODO(jieluo): This is a temporary solution for FieldDescriptor.file.\n    # FieldDescriptor.file is added in code gen. Remove this solution after\n    # maybe 2020 for compatibility reason (with 3.4.1 only).\n    for extension in file_desc.extensions_by_name.values():\n      self._file_desc_by_toplevel_extension[\n          extension.full_name] = file_desc\n\n  def _AddFileDescriptor(self, file_desc):\n    \"\"\"Adds a FileDescriptor to the pool, non-recursively.\n\n    If the FileDescriptor contains messages or enums, the caller must explicitly\n    register them.\n\n    Args:\n      file_desc: A FileDescriptor.\n    \"\"\"\n\n    if not isinstance(file_desc, descriptor.FileDescriptor):\n      raise TypeError('Expected instance of descriptor.FileDescriptor.')\n    self._file_descriptors[file_desc.name] = file_desc\n\n  def FindFileByName(self, file_name):\n    \"\"\"Gets a FileDescriptor by file name.\n\n    Args:\n      file_name (str): The path to the file to get a descriptor for.\n\n    Returns:\n      FileDescriptor: The descriptor for the named file.\n\n    Raises:\n      KeyError: if the file cannot be found in the pool.\n    \"\"\"\n\n    try:\n      return self._file_descriptors[file_name]\n    except KeyError:\n      pass\n\n    try:\n      file_proto = self._internal_db.FindFileByName(file_name)\n    except KeyError as error:\n      if self._descriptor_db:\n        file_proto = self._descriptor_db.FindFileByName(file_name)\n      else:\n        raise error\n    if not file_proto:\n      raise KeyError('Cannot find a file named %s' % file_name)\n    return self._ConvertFileProtoToFileDescriptor(file_proto)\n\n  def FindFileContainingSymbol(self, symbol):\n    \"\"\"Gets the FileDescriptor for the file containing the specified symbol.\n\n    Args:\n      symbol (str): The name of the symbol to search for.\n\n    Returns:\n      FileDescriptor: Descriptor for the file that contains the specified\n      symbol.\n\n    Raises:\n      KeyError: if the file cannot be found in the pool.\n    \"\"\"\n\n    symbol = _NormalizeFullyQualifiedName(symbol)\n    try:\n      return self._InternalFindFileContainingSymbol(symbol)\n    except KeyError:\n      pass\n\n    try:\n      # Try fallback database. Build and find again if possible.\n      self._FindFileContainingSymbolInDb(symbol)\n      return self._InternalFindFileContainingSymbol(symbol)\n    except KeyError:\n      raise KeyError('Cannot find a file containing %s' % symbol)\n\n  def _InternalFindFileContainingSymbol(self, symbol):\n    \"\"\"Gets the already built FileDescriptor containing the specified symbol.\n\n    Args:\n      symbol (str): The name of the symbol to search for.\n\n    Returns:\n      FileDescriptor: Descriptor for the file that contains the specified\n      symbol.\n\n    Raises:\n      KeyError: if the file cannot be found in the pool.\n    \"\"\"\n    try:\n      return self._descriptors[symbol].file\n    except KeyError:\n      pass\n\n    try:\n      return self._enum_descriptors[symbol].file\n    except KeyError:\n      pass\n\n    try:\n      return self._service_descriptors[symbol].file\n    except KeyError:\n      pass\n\n    try:\n      return self._top_enum_values[symbol].type.file\n    except KeyError:\n      pass\n\n    try:\n      return self._file_desc_by_toplevel_extension[symbol]\n    except KeyError:\n      pass\n\n    # Try fields, enum values and nested extensions inside a message.\n    top_name, _, sub_name = symbol.rpartition('.')\n    try:\n      message = self.FindMessageTypeByName(top_name)\n      assert (sub_name in message.extensions_by_name or\n              sub_name in message.fields_by_name or\n              sub_name in message.enum_values_by_name)\n      return message.file\n    except (KeyError, AssertionError):\n      raise KeyError('Cannot find a file containing %s' % symbol)\n\n  def FindMessageTypeByName(self, full_name):\n    \"\"\"Loads the named descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the descriptor to load.\n\n    Returns:\n      Descriptor: The descriptor for the named type.\n\n    Raises:\n      KeyError: if the message cannot be found in the pool.\n    \"\"\"\n\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    if full_name not in self._descriptors:\n      self._FindFileContainingSymbolInDb(full_name)\n    return self._descriptors[full_name]\n\n  def FindEnumTypeByName(self, full_name):\n    \"\"\"Loads the named enum descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the enum descriptor to load.\n\n    Returns:\n      EnumDescriptor: The enum descriptor for the named type.\n\n    Raises:\n      KeyError: if the enum cannot be found in the pool.\n    \"\"\"\n\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    if full_name not in self._enum_descriptors:\n      self._FindFileContainingSymbolInDb(full_name)\n    return self._enum_descriptors[full_name]\n\n  def FindFieldByName(self, full_name):\n    \"\"\"Loads the named field descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the field descriptor to load.\n\n    Returns:\n      FieldDescriptor: The field descriptor for the named field.\n\n    Raises:\n      KeyError: if the field cannot be found in the pool.\n    \"\"\"\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    message_name, _, field_name = full_name.rpartition('.')\n    message_descriptor = self.FindMessageTypeByName(message_name)\n    return message_descriptor.fields_by_name[field_name]\n\n  def FindOneofByName(self, full_name):\n    \"\"\"Loads the named oneof descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the oneof descriptor to load.\n\n    Returns:\n      OneofDescriptor: The oneof descriptor for the named oneof.\n\n    Raises:\n      KeyError: if the oneof cannot be found in the pool.\n    \"\"\"\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    message_name, _, oneof_name = full_name.rpartition('.')\n    message_descriptor = self.FindMessageTypeByName(message_name)\n    return message_descriptor.oneofs_by_name[oneof_name]\n\n  def FindExtensionByName(self, full_name):\n    \"\"\"Loads the named extension descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the extension descriptor to load.\n\n    Returns:\n      FieldDescriptor: The field descriptor for the named extension.\n\n    Raises:\n      KeyError: if the extension cannot be found in the pool.\n    \"\"\"\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    try:\n      # The proto compiler does not give any link between the FileDescriptor\n      # and top-level extensions unless the FileDescriptorProto is added to\n      # the DescriptorDatabase, but this can impact memory usage.\n      # So we registered these extensions by name explicitly.\n      return self._toplevel_extensions[full_name]\n    except KeyError:\n      pass\n    message_name, _, extension_name = full_name.rpartition('.')\n    try:\n      # Most extensions are nested inside a message.\n      scope = self.FindMessageTypeByName(message_name)\n    except KeyError:\n      # Some extensions are defined at file scope.\n      scope = self._FindFileContainingSymbolInDb(full_name)\n    return scope.extensions_by_name[extension_name]\n\n  def FindExtensionByNumber(self, message_descriptor, number):\n    \"\"\"Gets the extension of the specified message with the specified number.\n\n    Extensions have to be registered to this pool by calling :func:`Add` or\n    :func:`AddExtensionDescriptor`.\n\n    Args:\n      message_descriptor (Descriptor): descriptor of the extended message.\n      number (int): Number of the extension field.\n\n    Returns:\n      FieldDescriptor: The descriptor for the extension.\n\n    Raises:\n      KeyError: when no extension with the given number is known for the\n        specified message.\n    \"\"\"\n    try:\n      return self._extensions_by_number[message_descriptor][number]\n    except KeyError:\n      self._TryLoadExtensionFromDB(message_descriptor, number)\n      return self._extensions_by_number[message_descriptor][number]\n\n  def FindAllExtensions(self, message_descriptor):\n    \"\"\"Gets all the known extensions of a given message.\n\n    Extensions have to be registered to this pool by build related\n    :func:`Add` or :func:`AddExtensionDescriptor`.\n\n    Args:\n      message_descriptor (Descriptor): Descriptor of the extended message.\n\n    Returns:\n      list[FieldDescriptor]: Field descriptors describing the extensions.\n    \"\"\"\n    # Fallback to descriptor db if FindAllExtensionNumbers is provided.\n    if self._descriptor_db and hasattr(\n        self._descriptor_db, 'FindAllExtensionNumbers'):\n      full_name = message_descriptor.full_name\n      all_numbers = self._descriptor_db.FindAllExtensionNumbers(full_name)\n      for number in all_numbers:\n        if number in self._extensions_by_number[message_descriptor]:\n          continue\n        self._TryLoadExtensionFromDB(message_descriptor, number)\n\n    return list(self._extensions_by_number[message_descriptor].values())\n\n  def _TryLoadExtensionFromDB(self, message_descriptor, number):\n    \"\"\"Try to Load extensions from descriptor db.\n\n    Args:\n      message_descriptor: descriptor of the extended message.\n      number: the extension number that needs to be loaded.\n    \"\"\"\n    if not self._descriptor_db:\n      return\n    # Only supported when FindFileContainingExtension is provided.\n    if not hasattr(\n        self._descriptor_db, 'FindFileContainingExtension'):\n      return\n\n    full_name = message_descriptor.full_name\n    file_proto = self._descriptor_db.FindFileContainingExtension(\n        full_name, number)\n\n    if file_proto is None:\n      return\n\n    try:\n      self._ConvertFileProtoToFileDescriptor(file_proto)\n    except:\n      warn_msg = ('Unable to load proto file %s for extension number %d.' %\n                  (file_proto.name, number))\n      warnings.warn(warn_msg, RuntimeWarning)\n\n  def FindServiceByName(self, full_name):\n    \"\"\"Loads the named service descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the service descriptor to load.\n\n    Returns:\n      ServiceDescriptor: The service descriptor for the named service.\n\n    Raises:\n      KeyError: if the service cannot be found in the pool.\n    \"\"\"\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    if full_name not in self._service_descriptors:\n      self._FindFileContainingSymbolInDb(full_name)\n    return self._service_descriptors[full_name]\n\n  def FindMethodByName(self, full_name):\n    \"\"\"Loads the named service method descriptor from the pool.\n\n    Args:\n      full_name (str): The full name of the method descriptor to load.\n\n    Returns:\n      MethodDescriptor: The method descriptor for the service method.\n\n    Raises:\n      KeyError: if the method cannot be found in the pool.\n    \"\"\"\n    full_name = _NormalizeFullyQualifiedName(full_name)\n    service_name, _, method_name = full_name.rpartition('.')\n    service_descriptor = self.FindServiceByName(service_name)\n    return service_descriptor.methods_by_name[method_name]\n\n  def _FindFileContainingSymbolInDb(self, symbol):\n    \"\"\"Finds the file in descriptor DB containing the specified symbol.\n\n    Args:\n      symbol (str): The name of the symbol to search for.\n\n    Returns:\n      FileDescriptor: The file that contains the specified symbol.\n\n    Raises:\n      KeyError: if the file cannot be found in the descriptor database.\n    \"\"\"\n    try:\n      file_proto = self._internal_db.FindFileContainingSymbol(symbol)\n    except KeyError as error:\n      if self._descriptor_db:\n        file_proto = self._descriptor_db.FindFileContainingSymbol(symbol)\n      else:\n        raise error\n    if not file_proto:\n      raise KeyError('Cannot find a file containing %s' % symbol)\n    return self._ConvertFileProtoToFileDescriptor(file_proto)\n\n  def _ConvertFileProtoToFileDescriptor(self, file_proto):\n    \"\"\"Creates a FileDescriptor from a proto or returns a cached copy.\n\n    This method also has the side effect of loading all the symbols found in\n    the file into the appropriate dictionaries in the pool.\n\n    Args:\n      file_proto: The proto to convert.\n\n    Returns:\n      A FileDescriptor matching the passed in proto.\n    \"\"\"\n    if file_proto.name not in self._file_descriptors:\n      built_deps = list(self._GetDeps(file_proto.dependency))\n      direct_deps = [self.FindFileByName(n) for n in file_proto.dependency]\n      public_deps = [direct_deps[i] for i in file_proto.public_dependency]\n\n      file_descriptor = descriptor.FileDescriptor(\n          pool=self,\n          name=file_proto.name,\n          package=file_proto.package,\n          syntax=file_proto.syntax,\n          options=_OptionsOrNone(file_proto),\n          serialized_pb=file_proto.SerializeToString(),\n          dependencies=direct_deps,\n          public_dependencies=public_deps,\n          # pylint: disable=protected-access\n          create_key=descriptor._internal_create_key)\n      scope = {}\n\n      # This loop extracts all the message and enum types from all the\n      # dependencies of the file_proto. This is necessary to create the\n      # scope of available message types when defining the passed in\n      # file proto.\n      for dependency in built_deps:\n        scope.update(self._ExtractSymbols(\n            dependency.message_types_by_name.values()))\n        scope.update((_PrefixWithDot(enum.full_name), enum)\n                     for enum in dependency.enum_types_by_name.values())\n\n      for message_type in file_proto.message_type:\n        message_desc = self._ConvertMessageDescriptor(\n            message_type, file_proto.package, file_descriptor, scope,\n            file_proto.syntax)\n        file_descriptor.message_types_by_name[message_desc.name] = (\n            message_desc)\n\n      for enum_type in file_proto.enum_type:\n        file_descriptor.enum_types_by_name[enum_type.name] = (\n            self._ConvertEnumDescriptor(enum_type, file_proto.package,\n                                        file_descriptor, None, scope, True))\n\n      for index, extension_proto in enumerate(file_proto.extension):\n        extension_desc = self._MakeFieldDescriptor(\n            extension_proto, file_proto.package, index, file_descriptor,\n            is_extension=True)\n        extension_desc.containing_type = self._GetTypeFromScope(\n            file_descriptor.package, extension_proto.extendee, scope)\n        self._SetFieldType(extension_proto, extension_desc,\n                           file_descriptor.package, scope)\n        file_descriptor.extensions_by_name[extension_desc.name] = (\n            extension_desc)\n        self._file_desc_by_toplevel_extension[extension_desc.full_name] = (\n            file_descriptor)\n\n      for desc_proto in file_proto.message_type:\n        self._SetAllFieldTypes(file_proto.package, desc_proto, scope)\n\n      if file_proto.package:\n        desc_proto_prefix = _PrefixWithDot(file_proto.package)\n      else:\n        desc_proto_prefix = ''\n\n      for desc_proto in file_proto.message_type:\n        desc = self._GetTypeFromScope(\n            desc_proto_prefix, desc_proto.name, scope)\n        file_descriptor.message_types_by_name[desc_proto.name] = desc\n\n      for index, service_proto in enumerate(file_proto.service):\n        file_descriptor.services_by_name[service_proto.name] = (\n            self._MakeServiceDescriptor(service_proto, index, scope,\n                                        file_proto.package, file_descriptor))\n\n      self._file_descriptors[file_proto.name] = file_descriptor\n\n    # Add extensions to the pool\n    file_desc = self._file_descriptors[file_proto.name]\n    for extension in file_desc.extensions_by_name.values():\n      self._AddExtensionDescriptor(extension)\n    for message_type in file_desc.message_types_by_name.values():\n      for extension in message_type.extensions:\n        self._AddExtensionDescriptor(extension)\n\n    return file_desc\n\n  def _ConvertMessageDescriptor(self, desc_proto, package=None, file_desc=None,\n                                scope=None, syntax=None):\n    \"\"\"Adds the proto to the pool in the specified package.\n\n    Args:\n      desc_proto: The descriptor_pb2.DescriptorProto protobuf message.\n      package: The package the proto should be located in.\n      file_desc: The file containing this message.\n      scope: Dict mapping short and full symbols to message and enum types.\n      syntax: string indicating syntax of the file (\"proto2\" or \"proto3\")\n\n    Returns:\n      The added descriptor.\n    \"\"\"\n\n    if package:\n      desc_name = '.'.join((package, desc_proto.name))\n    else:\n      desc_name = desc_proto.name\n\n    if file_desc is None:\n      file_name = None\n    else:\n      file_name = file_desc.name\n\n    if scope is None:\n      scope = {}\n\n    nested = [\n        self._ConvertMessageDescriptor(\n            nested, desc_name, file_desc, scope, syntax)\n        for nested in desc_proto.nested_type]\n    enums = [\n        self._ConvertEnumDescriptor(enum, desc_name, file_desc, None,\n                                    scope, False)\n        for enum in desc_proto.enum_type]\n    fields = [self._MakeFieldDescriptor(field, desc_name, index, file_desc)\n              for index, field in enumerate(desc_proto.field)]\n    extensions = [\n        self._MakeFieldDescriptor(extension, desc_name, index, file_desc,\n                                  is_extension=True)\n        for index, extension in enumerate(desc_proto.extension)]\n    oneofs = [\n        # pylint: disable=g-complex-comprehension\n        descriptor.OneofDescriptor(\n            desc.name,\n            '.'.join((desc_name, desc.name)),\n            index,\n            None,\n            [],\n            _OptionsOrNone(desc),\n            # pylint: disable=protected-access\n            create_key=descriptor._internal_create_key)\n        for index, desc in enumerate(desc_proto.oneof_decl)\n    ]\n    extension_ranges = [(r.start, r.end) for r in desc_proto.extension_range]\n    if extension_ranges:\n      is_extendable = True\n    else:\n      is_extendable = False\n    desc = descriptor.Descriptor(\n        name=desc_proto.name,\n        full_name=desc_name,\n        filename=file_name,\n        containing_type=None,\n        fields=fields,\n        oneofs=oneofs,\n        nested_types=nested,\n        enum_types=enums,\n        extensions=extensions,\n        options=_OptionsOrNone(desc_proto),\n        is_extendable=is_extendable,\n        extension_ranges=extension_ranges,\n        file=file_desc,\n        serialized_start=None,\n        serialized_end=None,\n        syntax=syntax,\n        # pylint: disable=protected-access\n        create_key=descriptor._internal_create_key)\n    for nested in desc.nested_types:\n      nested.containing_type = desc\n    for enum in desc.enum_types:\n      enum.containing_type = desc\n    for field_index, field_desc in enumerate(desc_proto.field):\n      if field_desc.HasField('oneof_index'):\n        oneof_index = field_desc.oneof_index\n        oneofs[oneof_index].fields.append(fields[field_index])\n        fields[field_index].containing_oneof = oneofs[oneof_index]\n\n    scope[_PrefixWithDot(desc_name)] = desc\n    self._CheckConflictRegister(desc, desc.full_name, desc.file.name)\n    self._descriptors[desc_name] = desc\n    return desc\n\n  def _ConvertEnumDescriptor(self, enum_proto, package=None, file_desc=None,\n                             containing_type=None, scope=None, top_level=False):\n    \"\"\"Make a protobuf EnumDescriptor given an EnumDescriptorProto protobuf.\n\n    Args:\n      enum_proto: The descriptor_pb2.EnumDescriptorProto protobuf message.\n      package: Optional package name for the new message EnumDescriptor.\n      file_desc: The file containing the enum descriptor.\n      containing_type: The type containing this enum.\n      scope: Scope containing available types.\n      top_level: If True, the enum is a top level symbol. If False, the enum\n          is defined inside a message.\n\n    Returns:\n      The added descriptor\n    \"\"\"\n\n    if package:\n      enum_name = '.'.join((package, enum_proto.name))\n    else:\n      enum_name = enum_proto.name\n\n    if file_desc is None:\n      file_name = None\n    else:\n      file_name = file_desc.name\n\n    values = [self._MakeEnumValueDescriptor(value, index)\n              for index, value in enumerate(enum_proto.value)]\n    desc = descriptor.EnumDescriptor(name=enum_proto.name,\n                                     full_name=enum_name,\n                                     filename=file_name,\n                                     file=file_desc,\n                                     values=values,\n                                     containing_type=containing_type,\n                                     options=_OptionsOrNone(enum_proto),\n                                     # pylint: disable=protected-access\n                                     create_key=descriptor._internal_create_key)\n    scope['.%s' % enum_name] = desc\n    self._CheckConflictRegister(desc, desc.full_name, desc.file.name)\n    self._enum_descriptors[enum_name] = desc\n\n    # Add top level enum values.\n    if top_level:\n      for value in values:\n        full_name = _NormalizeFullyQualifiedName(\n            '.'.join((package, value.name)))\n        self._CheckConflictRegister(value, full_name, file_name)\n        self._top_enum_values[full_name] = value\n\n    return desc\n\n  def _MakeFieldDescriptor(self, field_proto, message_name, index,\n                           file_desc, is_extension=False):\n    \"\"\"Creates a field descriptor from a FieldDescriptorProto.\n\n    For message and enum type fields, this method will do a look up\n    in the pool for the appropriate descriptor for that type. If it\n    is unavailable, it will fall back to the _source function to\n    create it. If this type is still unavailable, construction will\n    fail.\n\n    Args:\n      field_proto: The proto describing the field.\n      message_name: The name of the containing message.\n      index: Index of the field\n      file_desc: The file containing the field descriptor.\n      is_extension: Indication that this field is for an extension.\n\n    Returns:\n      An initialized FieldDescriptor object\n    \"\"\"\n\n    if message_name:\n      full_name = '.'.join((message_name, field_proto.name))\n    else:\n      full_name = field_proto.name\n\n    if field_proto.json_name:\n      json_name = field_proto.json_name\n    else:\n      json_name = None\n\n    return descriptor.FieldDescriptor(\n        name=field_proto.name,\n        full_name=full_name,\n        index=index,\n        number=field_proto.number,\n        type=field_proto.type,\n        cpp_type=None,\n        message_type=None,\n        enum_type=None,\n        containing_type=None,\n        label=field_proto.label,\n        has_default_value=False,\n        default_value=None,\n        is_extension=is_extension,\n        extension_scope=None,\n        options=_OptionsOrNone(field_proto),\n        json_name=json_name,\n        file=file_desc,\n        # pylint: disable=protected-access\n        create_key=descriptor._internal_create_key)\n\n  def _SetAllFieldTypes(self, package, desc_proto, scope):\n    \"\"\"Sets all the descriptor's fields's types.\n\n    This method also sets the containing types on any extensions.\n\n    Args:\n      package: The current package of desc_proto.\n      desc_proto: The message descriptor to update.\n      scope: Enclosing scope of available types.\n    \"\"\"\n\n    package = _PrefixWithDot(package)\n\n    main_desc = self._GetTypeFromScope(package, desc_proto.name, scope)\n\n    if package == '.':\n      nested_package = _PrefixWithDot(desc_proto.name)\n    else:\n      nested_package = '.'.join([package, desc_proto.name])\n\n    for field_proto, field_desc in zip(desc_proto.field, main_desc.fields):\n      self._SetFieldType(field_proto, field_desc, nested_package, scope)\n\n    for extension_proto, extension_desc in (\n        zip(desc_proto.extension, main_desc.extensions)):\n      extension_desc.containing_type = self._GetTypeFromScope(\n          nested_package, extension_proto.extendee, scope)\n      self._SetFieldType(extension_proto, extension_desc, nested_package, scope)\n\n    for nested_type in desc_proto.nested_type:\n      self._SetAllFieldTypes(nested_package, nested_type, scope)\n\n  def _SetFieldType(self, field_proto, field_desc, package, scope):\n    \"\"\"Sets the field's type, cpp_type, message_type and enum_type.\n\n    Args:\n      field_proto: Data about the field in proto format.\n      field_desc: The descriptor to modify.\n      package: The package the field's container is in.\n      scope: Enclosing scope of available types.\n    \"\"\"\n    if field_proto.type_name:\n      desc = self._GetTypeFromScope(package, field_proto.type_name, scope)\n    else:\n      desc = None\n\n    if not field_proto.HasField('type'):\n      if isinstance(desc, descriptor.Descriptor):\n        field_proto.type = descriptor.FieldDescriptor.TYPE_MESSAGE\n      else:\n        field_proto.type = descriptor.FieldDescriptor.TYPE_ENUM\n\n    field_desc.cpp_type = descriptor.FieldDescriptor.ProtoTypeToCppProtoType(\n        field_proto.type)\n\n    if (field_proto.type == descriptor.FieldDescriptor.TYPE_MESSAGE\n        or field_proto.type == descriptor.FieldDescriptor.TYPE_GROUP):\n      field_desc.message_type = desc\n\n    if field_proto.type == descriptor.FieldDescriptor.TYPE_ENUM:\n      field_desc.enum_type = desc\n\n    if field_proto.label == descriptor.FieldDescriptor.LABEL_REPEATED:\n      field_desc.has_default_value = False\n      field_desc.default_value = []\n    elif field_proto.HasField('default_value'):\n      field_desc.has_default_value = True\n      if (field_proto.type == descriptor.FieldDescriptor.TYPE_DOUBLE or\n          field_proto.type == descriptor.FieldDescriptor.TYPE_FLOAT):\n        field_desc.default_value = float(field_proto.default_value)\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_STRING:\n        field_desc.default_value = field_proto.default_value\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_BOOL:\n        field_desc.default_value = field_proto.default_value.lower() == 'true'\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_ENUM:\n        field_desc.default_value = field_desc.enum_type.values_by_name[\n            field_proto.default_value].number\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_BYTES:\n        field_desc.default_value = text_encoding.CUnescape(\n            field_proto.default_value)\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_MESSAGE:\n        field_desc.default_value = None\n      else:\n        # All other types are of the \"int\" type.\n        field_desc.default_value = int(field_proto.default_value)\n    else:\n      field_desc.has_default_value = False\n      if (field_proto.type == descriptor.FieldDescriptor.TYPE_DOUBLE or\n          field_proto.type == descriptor.FieldDescriptor.TYPE_FLOAT):\n        field_desc.default_value = 0.0\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_STRING:\n        field_desc.default_value = u''\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_BOOL:\n        field_desc.default_value = False\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_ENUM:\n        field_desc.default_value = field_desc.enum_type.values[0].number\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_BYTES:\n        field_desc.default_value = b''\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_MESSAGE:\n        field_desc.default_value = None\n      elif field_proto.type == descriptor.FieldDescriptor.TYPE_GROUP:\n        field_desc.default_value = None\n      else:\n        # All other types are of the \"int\" type.\n        field_desc.default_value = 0\n\n    field_desc.type = field_proto.type\n\n  def _MakeEnumValueDescriptor(self, value_proto, index):\n    \"\"\"Creates a enum value descriptor object from a enum value proto.\n\n    Args:\n      value_proto: The proto describing the enum value.\n      index: The index of the enum value.\n\n    Returns:\n      An initialized EnumValueDescriptor object.\n    \"\"\"\n\n    return descriptor.EnumValueDescriptor(\n        name=value_proto.name,\n        index=index,\n        number=value_proto.number,\n        options=_OptionsOrNone(value_proto),\n        type=None,\n        # pylint: disable=protected-access\n        create_key=descriptor._internal_create_key)\n\n  def _MakeServiceDescriptor(self, service_proto, service_index, scope,\n                             package, file_desc):\n    \"\"\"Make a protobuf ServiceDescriptor given a ServiceDescriptorProto.\n\n    Args:\n      service_proto: The descriptor_pb2.ServiceDescriptorProto protobuf message.\n      service_index: The index of the service in the File.\n      scope: Dict mapping short and full symbols to message and enum types.\n      package: Optional package name for the new message EnumDescriptor.\n      file_desc: The file containing the service descriptor.\n\n    Returns:\n      The added descriptor.\n    \"\"\"\n\n    if package:\n      service_name = '.'.join((package, service_proto.name))\n    else:\n      service_name = service_proto.name\n\n    methods = [self._MakeMethodDescriptor(method_proto, service_name, package,\n                                          scope, index)\n               for index, method_proto in enumerate(service_proto.method)]\n    desc = descriptor.ServiceDescriptor(\n        name=service_proto.name,\n        full_name=service_name,\n        index=service_index,\n        methods=methods,\n        options=_OptionsOrNone(service_proto),\n        file=file_desc,\n        # pylint: disable=protected-access\n        create_key=descriptor._internal_create_key)\n    self._CheckConflictRegister(desc, desc.full_name, desc.file.name)\n    self._service_descriptors[service_name] = desc\n    return desc\n\n  def _MakeMethodDescriptor(self, method_proto, service_name, package, scope,\n                            index):\n    \"\"\"Creates a method descriptor from a MethodDescriptorProto.\n\n    Args:\n      method_proto: The proto describing the method.\n      service_name: The name of the containing service.\n      package: Optional package name to look up for types.\n      scope: Scope containing available types.\n      index: Index of the method in the service.\n\n    Returns:\n      An initialized MethodDescriptor object.\n    \"\"\"\n    full_name = '.'.join((service_name, method_proto.name))\n    input_type = self._GetTypeFromScope(\n        package, method_proto.input_type, scope)\n    output_type = self._GetTypeFromScope(\n        package, method_proto.output_type, scope)\n    return descriptor.MethodDescriptor(\n        name=method_proto.name,\n        full_name=full_name,\n        index=index,\n        containing_service=None,\n        input_type=input_type,\n        output_type=output_type,\n        client_streaming=method_proto.client_streaming,\n        server_streaming=method_proto.server_streaming,\n        options=_OptionsOrNone(method_proto),\n        # pylint: disable=protected-access\n        create_key=descriptor._internal_create_key)\n\n  def _ExtractSymbols(self, descriptors):\n    \"\"\"Pulls out all the symbols from descriptor protos.\n\n    Args:\n      descriptors: The messages to extract descriptors from.\n    Yields:\n      A two element tuple of the type name and descriptor object.\n    \"\"\"\n\n    for desc in descriptors:\n      yield (_PrefixWithDot(desc.full_name), desc)\n      for symbol in self._ExtractSymbols(desc.nested_types):\n        yield symbol\n      for enum in desc.enum_types:\n        yield (_PrefixWithDot(enum.full_name), enum)\n\n  def _GetDeps(self, dependencies, visited=None):\n    \"\"\"Recursively finds dependencies for file protos.\n\n    Args:\n      dependencies: The names of the files being depended on.\n      visited: The names of files already found.\n\n    Yields:\n      Each direct and indirect dependency.\n    \"\"\"\n\n    visited = visited or set()\n    for dependency in dependencies:\n      if dependency not in visited:\n        visited.add(dependency)\n        dep_desc = self.FindFileByName(dependency)\n        yield dep_desc\n        public_files = [d.name for d in dep_desc.public_dependencies]\n        yield from self._GetDeps(public_files, visited)\n\n  def _GetTypeFromScope(self, package, type_name, scope):\n    \"\"\"Finds a given type name in the current scope.\n\n    Args:\n      package: The package the proto should be located in.\n      type_name: The name of the type to be found in the scope.\n      scope: Dict mapping short and full symbols to message and enum types.\n\n    Returns:\n      The descriptor for the requested type.\n    \"\"\"\n    if type_name not in scope:\n      components = _PrefixWithDot(package).split('.')\n      while components:\n        possible_match = '.'.join(components + [type_name])\n        if possible_match in scope:\n          type_name = possible_match\n          break\n        else:\n          components.pop(-1)\n    return scope[type_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.Add","title":"<code>Add(file_desc_proto)</code>","text":"<p>Adds the FileDescriptorProto and its types to this pool.</p> <p>Parameters:</p> Name Type Description Default <code>file_desc_proto</code> <code>FileDescriptorProto</code> <p>The file descriptor to add.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def Add(self, file_desc_proto):\n  \"\"\"Adds the FileDescriptorProto and its types to this pool.\n\n  Args:\n    file_desc_proto (FileDescriptorProto): The file descriptor to add.\n  \"\"\"\n\n  self._internal_db.Add(file_desc_proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.AddSerializedFile","title":"<code>AddSerializedFile(serialized_file_desc_proto)</code>","text":"<p>Adds the FileDescriptorProto and its types to this pool.</p> <p>Parameters:</p> Name Type Description Default <code>serialized_file_desc_proto</code> <code>bytes</code> <p>A bytes string, serialization of the :class:<code>FileDescriptorProto</code> to add.</p> required <p>Returns:</p> Name Type Description <code>FileDescriptor</code> <p>Descriptor for the added file.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def AddSerializedFile(self, serialized_file_desc_proto):\n  \"\"\"Adds the FileDescriptorProto and its types to this pool.\n\n  Args:\n    serialized_file_desc_proto (bytes): A bytes string, serialization of the\n      :class:`FileDescriptorProto` to add.\n\n  Returns:\n    FileDescriptor: Descriptor for the added file.\n  \"\"\"\n\n  # pylint: disable=g-import-not-at-top\n  from google.protobuf import descriptor_pb2\n  file_desc_proto = descriptor_pb2.FileDescriptorProto.FromString(\n      serialized_file_desc_proto)\n  file_desc = self._ConvertFileProtoToFileDescriptor(file_desc_proto)\n  file_desc.serialized_pb = serialized_file_desc_proto\n  return file_desc\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindAllExtensions","title":"<code>FindAllExtensions(message_descriptor)</code>","text":"<p>Gets all the known extensions of a given message.</p> <p>Extensions have to be registered to this pool by build related :func:<code>Add</code> or :func:<code>AddExtensionDescriptor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message_descriptor</code> <code>Descriptor</code> <p>Descriptor of the extended message.</p> required <p>Returns:</p> Type Description <p>list[FieldDescriptor]: Field descriptors describing the extensions.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindAllExtensions(self, message_descriptor):\n  \"\"\"Gets all the known extensions of a given message.\n\n  Extensions have to be registered to this pool by build related\n  :func:`Add` or :func:`AddExtensionDescriptor`.\n\n  Args:\n    message_descriptor (Descriptor): Descriptor of the extended message.\n\n  Returns:\n    list[FieldDescriptor]: Field descriptors describing the extensions.\n  \"\"\"\n  # Fallback to descriptor db if FindAllExtensionNumbers is provided.\n  if self._descriptor_db and hasattr(\n      self._descriptor_db, 'FindAllExtensionNumbers'):\n    full_name = message_descriptor.full_name\n    all_numbers = self._descriptor_db.FindAllExtensionNumbers(full_name)\n    for number in all_numbers:\n      if number in self._extensions_by_number[message_descriptor]:\n        continue\n      self._TryLoadExtensionFromDB(message_descriptor, number)\n\n  return list(self._extensions_by_number[message_descriptor].values())\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindEnumTypeByName","title":"<code>FindEnumTypeByName(full_name)</code>","text":"<p>Loads the named enum descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the enum descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>EnumDescriptor</code> <p>The enum descriptor for the named type.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the enum cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindEnumTypeByName(self, full_name):\n  \"\"\"Loads the named enum descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the enum descriptor to load.\n\n  Returns:\n    EnumDescriptor: The enum descriptor for the named type.\n\n  Raises:\n    KeyError: if the enum cannot be found in the pool.\n  \"\"\"\n\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  if full_name not in self._enum_descriptors:\n    self._FindFileContainingSymbolInDb(full_name)\n  return self._enum_descriptors[full_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindExtensionByName","title":"<code>FindExtensionByName(full_name)</code>","text":"<p>Loads the named extension descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the extension descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>FieldDescriptor</code> <p>The field descriptor for the named extension.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the extension cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindExtensionByName(self, full_name):\n  \"\"\"Loads the named extension descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the extension descriptor to load.\n\n  Returns:\n    FieldDescriptor: The field descriptor for the named extension.\n\n  Raises:\n    KeyError: if the extension cannot be found in the pool.\n  \"\"\"\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  try:\n    # The proto compiler does not give any link between the FileDescriptor\n    # and top-level extensions unless the FileDescriptorProto is added to\n    # the DescriptorDatabase, but this can impact memory usage.\n    # So we registered these extensions by name explicitly.\n    return self._toplevel_extensions[full_name]\n  except KeyError:\n    pass\n  message_name, _, extension_name = full_name.rpartition('.')\n  try:\n    # Most extensions are nested inside a message.\n    scope = self.FindMessageTypeByName(message_name)\n  except KeyError:\n    # Some extensions are defined at file scope.\n    scope = self._FindFileContainingSymbolInDb(full_name)\n  return scope.extensions_by_name[extension_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindExtensionByNumber","title":"<code>FindExtensionByNumber(message_descriptor, number)</code>","text":"<p>Gets the extension of the specified message with the specified number.</p> <p>Extensions have to be registered to this pool by calling :func:<code>Add</code> or :func:<code>AddExtensionDescriptor</code>.</p> <p>Parameters:</p> Name Type Description Default <code>message_descriptor</code> <code>Descriptor</code> <p>descriptor of the extended message.</p> required <code>number</code> <code>int</code> <p>Number of the extension field.</p> required <p>Returns:</p> Name Type Description <code>FieldDescriptor</code> <p>The descriptor for the extension.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>when no extension with the given number is known for the specified message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindExtensionByNumber(self, message_descriptor, number):\n  \"\"\"Gets the extension of the specified message with the specified number.\n\n  Extensions have to be registered to this pool by calling :func:`Add` or\n  :func:`AddExtensionDescriptor`.\n\n  Args:\n    message_descriptor (Descriptor): descriptor of the extended message.\n    number (int): Number of the extension field.\n\n  Returns:\n    FieldDescriptor: The descriptor for the extension.\n\n  Raises:\n    KeyError: when no extension with the given number is known for the\n      specified message.\n  \"\"\"\n  try:\n    return self._extensions_by_number[message_descriptor][number]\n  except KeyError:\n    self._TryLoadExtensionFromDB(message_descriptor, number)\n    return self._extensions_by_number[message_descriptor][number]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindFieldByName","title":"<code>FindFieldByName(full_name)</code>","text":"<p>Loads the named field descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the field descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>FieldDescriptor</code> <p>The field descriptor for the named field.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the field cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindFieldByName(self, full_name):\n  \"\"\"Loads the named field descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the field descriptor to load.\n\n  Returns:\n    FieldDescriptor: The field descriptor for the named field.\n\n  Raises:\n    KeyError: if the field cannot be found in the pool.\n  \"\"\"\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  message_name, _, field_name = full_name.rpartition('.')\n  message_descriptor = self.FindMessageTypeByName(message_name)\n  return message_descriptor.fields_by_name[field_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindFileByName","title":"<code>FindFileByName(file_name)</code>","text":"<p>Gets a FileDescriptor by file name.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str</code> <p>The path to the file to get a descriptor for.</p> required <p>Returns:</p> Name Type Description <code>FileDescriptor</code> <p>The descriptor for the named file.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the file cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindFileByName(self, file_name):\n  \"\"\"Gets a FileDescriptor by file name.\n\n  Args:\n    file_name (str): The path to the file to get a descriptor for.\n\n  Returns:\n    FileDescriptor: The descriptor for the named file.\n\n  Raises:\n    KeyError: if the file cannot be found in the pool.\n  \"\"\"\n\n  try:\n    return self._file_descriptors[file_name]\n  except KeyError:\n    pass\n\n  try:\n    file_proto = self._internal_db.FindFileByName(file_name)\n  except KeyError as error:\n    if self._descriptor_db:\n      file_proto = self._descriptor_db.FindFileByName(file_name)\n    else:\n      raise error\n  if not file_proto:\n    raise KeyError('Cannot find a file named %s' % file_name)\n  return self._ConvertFileProtoToFileDescriptor(file_proto)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindFileContainingSymbol","title":"<code>FindFileContainingSymbol(symbol)</code>","text":"<p>Gets the FileDescriptor for the file containing the specified symbol.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>The name of the symbol to search for.</p> required <p>Returns:</p> Name Type Description <code>FileDescriptor</code> <p>Descriptor for the file that contains the specified</p> <p>symbol.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the file cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindFileContainingSymbol(self, symbol):\n  \"\"\"Gets the FileDescriptor for the file containing the specified symbol.\n\n  Args:\n    symbol (str): The name of the symbol to search for.\n\n  Returns:\n    FileDescriptor: Descriptor for the file that contains the specified\n    symbol.\n\n  Raises:\n    KeyError: if the file cannot be found in the pool.\n  \"\"\"\n\n  symbol = _NormalizeFullyQualifiedName(symbol)\n  try:\n    return self._InternalFindFileContainingSymbol(symbol)\n  except KeyError:\n    pass\n\n  try:\n    # Try fallback database. Build and find again if possible.\n    self._FindFileContainingSymbolInDb(symbol)\n    return self._InternalFindFileContainingSymbol(symbol)\n  except KeyError:\n    raise KeyError('Cannot find a file containing %s' % symbol)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindMessageTypeByName","title":"<code>FindMessageTypeByName(full_name)</code>","text":"<p>Loads the named descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>Descriptor</code> <p>The descriptor for the named type.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the message cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindMessageTypeByName(self, full_name):\n  \"\"\"Loads the named descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the descriptor to load.\n\n  Returns:\n    Descriptor: The descriptor for the named type.\n\n  Raises:\n    KeyError: if the message cannot be found in the pool.\n  \"\"\"\n\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  if full_name not in self._descriptors:\n    self._FindFileContainingSymbolInDb(full_name)\n  return self._descriptors[full_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindMethodByName","title":"<code>FindMethodByName(full_name)</code>","text":"<p>Loads the named service method descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the method descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>MethodDescriptor</code> <p>The method descriptor for the service method.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the method cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindMethodByName(self, full_name):\n  \"\"\"Loads the named service method descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the method descriptor to load.\n\n  Returns:\n    MethodDescriptor: The method descriptor for the service method.\n\n  Raises:\n    KeyError: if the method cannot be found in the pool.\n  \"\"\"\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  service_name, _, method_name = full_name.rpartition('.')\n  service_descriptor = self.FindServiceByName(service_name)\n  return service_descriptor.methods_by_name[method_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindOneofByName","title":"<code>FindOneofByName(full_name)</code>","text":"<p>Loads the named oneof descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the oneof descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>OneofDescriptor</code> <p>The oneof descriptor for the named oneof.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the oneof cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindOneofByName(self, full_name):\n  \"\"\"Loads the named oneof descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the oneof descriptor to load.\n\n  Returns:\n    OneofDescriptor: The oneof descriptor for the named oneof.\n\n  Raises:\n    KeyError: if the oneof cannot be found in the pool.\n  \"\"\"\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  message_name, _, oneof_name = full_name.rpartition('.')\n  message_descriptor = self.FindMessageTypeByName(message_name)\n  return message_descriptor.oneofs_by_name[oneof_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.FindServiceByName","title":"<code>FindServiceByName(full_name)</code>","text":"<p>Loads the named service descriptor from the pool.</p> <p>Parameters:</p> Name Type Description Default <code>full_name</code> <code>str</code> <p>The full name of the service descriptor to load.</p> required <p>Returns:</p> Name Type Description <code>ServiceDescriptor</code> <p>The service descriptor for the named service.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the service cannot be found in the pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def FindServiceByName(self, full_name):\n  \"\"\"Loads the named service descriptor from the pool.\n\n  Args:\n    full_name (str): The full name of the service descriptor to load.\n\n  Returns:\n    ServiceDescriptor: The service descriptor for the named service.\n\n  Raises:\n    KeyError: if the service cannot be found in the pool.\n  \"\"\"\n  full_name = _NormalizeFullyQualifiedName(full_name)\n  if full_name not in self._service_descriptors:\n    self._FindFileContainingSymbolInDb(full_name)\n  return self._service_descriptors[full_name]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/descriptor_pool.html#client.ayon_nuke.vendor.google.protobuf.descriptor_pool.DescriptorPool.__init__","title":"<code>__init__(descriptor_db=None)</code>","text":"<p>Initializes a Pool of proto buffs.</p> <p>The descriptor_db argument to the constructor is provided to allow specialized file descriptor proto lookup code to be triggered on demand. An example would be an implementation which will read and compile a file specified in a call to FindFileByName() and not require the call to Add() at all. Results from this database will be cached internally here as well.</p> <p>Parameters:</p> Name Type Description Default <code>descriptor_db</code> <p>A secondary source of file descriptors.</p> <code>None</code> Source code in <code>client/ayon_nuke/vendor/google/protobuf/descriptor_pool.py</code> <pre><code>def __init__(self, descriptor_db=None):\n  \"\"\"Initializes a Pool of proto buffs.\n\n  The descriptor_db argument to the constructor is provided to allow\n  specialized file descriptor proto lookup code to be triggered on demand. An\n  example would be an implementation which will read and compile a file\n  specified in a call to FindFileByName() and not require the call to Add()\n  at all. Results from this database will be cached internally here as well.\n\n  Args:\n    descriptor_db: A secondary source of file descriptors.\n  \"\"\"\n\n  self._internal_db = descriptor_database.DescriptorDatabase()\n  self._descriptor_db = descriptor_db\n  self._descriptors = {}\n  self._enum_descriptors = {}\n  self._service_descriptors = {}\n  self._file_descriptors = {}\n  self._toplevel_extensions = {}\n  # TODO(jieluo): Remove _file_desc_by_toplevel_extension after\n  # maybe year 2020 for compatibility issue (with 3.4.1 only).\n  self._file_desc_by_toplevel_extension = {}\n  self._top_enum_values = {}\n  # We store extensions in two two-level mappings: The first key is the\n  # descriptor of the message being extended, the second key is the extension\n  # full name or its tag number.\n  self._extensions_by_name = collections.defaultdict(dict)\n  self._extensions_by_number = collections.defaultdict(dict)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/duration_pb2.html","title":"duration_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/empty_pb2.html","title":"empty_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/field_mask_pb2.html","title":"field_mask_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html","title":"json_format","text":"<p>Contains routines for printing protocol messages in JSON format.</p> <p>Simple usage example:</p> <p># Create a proto object and serialize it to a json format string.   message = my_proto_pb2.MyMessage(foo='bar')   json_string = json_format.MessageToJson(message)</p> <p># Parse a json format string to proto object.   message = json_format.Parse(json_string, my_proto_pb2.MyMessage())</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.Error","title":"<code>Error</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Top-level module error for json_format.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>class Error(Exception):\n  \"\"\"Top-level module error for json_format.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.ParseError","title":"<code>ParseError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Thrown in case of parsing error.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>class ParseError(Error):\n  \"\"\"Thrown in case of parsing error.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.SerializeToJsonError","title":"<code>SerializeToJsonError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Thrown if serialization to JSON fails.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>class SerializeToJsonError(Error):\n  \"\"\"Thrown if serialization to JSON fails.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.MessageToDict","title":"<code>MessageToDict(message, including_default_value_fields=False, preserving_proto_field_name=False, use_integers_for_enums=False, descriptor_pool=None, float_precision=None)</code>","text":"<p>Converts protobuf message to a dictionary.</p> <p>When the dictionary is encoded to JSON, it conforms to proto3 JSON spec.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The protocol buffers message instance to serialize.</p> required <code>including_default_value_fields</code> <p>If True, singular primitive fields,   repeated fields, and map fields will always be serialized.  If   False, only serialize non-empty fields.  Singular message fields   and oneof fields are not affected by this option.</p> <code>False</code> <code>preserving_proto_field_name</code> <p>If True, use the original proto field   names as defined in the .proto file. If False, convert the field   names to lowerCamelCase.</p> <code>False</code> <code>use_integers_for_enums</code> <p>If true, print integers instead of enum names.</p> <code>False</code> <code>descriptor_pool</code> <p>A Descriptor Pool for resolving types. If None use the   default.</p> <code>None</code> <code>float_precision</code> <p>If set, use this to specify float field valid digits.</p> <code>None</code> <p>Returns:</p> Type Description <p>A dict representation of the protocol buffer message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>def MessageToDict(\n    message,\n    including_default_value_fields=False,\n    preserving_proto_field_name=False,\n    use_integers_for_enums=False,\n    descriptor_pool=None,\n    float_precision=None):\n  \"\"\"Converts protobuf message to a dictionary.\n\n  When the dictionary is encoded to JSON, it conforms to proto3 JSON spec.\n\n  Args:\n    message: The protocol buffers message instance to serialize.\n    including_default_value_fields: If True, singular primitive fields,\n        repeated fields, and map fields will always be serialized.  If\n        False, only serialize non-empty fields.  Singular message fields\n        and oneof fields are not affected by this option.\n    preserving_proto_field_name: If True, use the original proto field\n        names as defined in the .proto file. If False, convert the field\n        names to lowerCamelCase.\n    use_integers_for_enums: If true, print integers instead of enum names.\n    descriptor_pool: A Descriptor Pool for resolving types. If None use the\n        default.\n    float_precision: If set, use this to specify float field valid digits.\n\n  Returns:\n    A dict representation of the protocol buffer message.\n  \"\"\"\n  printer = _Printer(\n      including_default_value_fields,\n      preserving_proto_field_name,\n      use_integers_for_enums,\n      descriptor_pool,\n      float_precision=float_precision)\n  # pylint: disable=protected-access\n  return printer._MessageToJsonObject(message)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.MessageToJson","title":"<code>MessageToJson(message, including_default_value_fields=False, preserving_proto_field_name=False, indent=2, sort_keys=False, use_integers_for_enums=False, descriptor_pool=None, float_precision=None, ensure_ascii=True)</code>","text":"<p>Converts protobuf message to JSON format.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The protocol buffers message instance to serialize.</p> required <code>including_default_value_fields</code> <p>If True, singular primitive fields,   repeated fields, and map fields will always be serialized.  If   False, only serialize non-empty fields.  Singular message fields   and oneof fields are not affected by this option.</p> <code>False</code> <code>preserving_proto_field_name</code> <p>If True, use the original proto field   names as defined in the .proto file. If False, convert the field   names to lowerCamelCase.</p> <code>False</code> <code>indent</code> <p>The JSON object will be pretty-printed with this indent level.   An indent level of 0 or negative will only insert newlines.</p> <code>2</code> <code>sort_keys</code> <p>If True, then the output will be sorted by field names.</p> <code>False</code> <code>use_integers_for_enums</code> <p>If true, print integers instead of enum names.</p> <code>False</code> <code>descriptor_pool</code> <p>A Descriptor Pool for resolving types. If None use the   default.</p> <code>None</code> <code>float_precision</code> <p>If set, use this to specify float field valid digits.</p> <code>None</code> <code>ensure_ascii</code> <p>If True, strings with non-ASCII characters are escaped.   If False, Unicode strings are returned unchanged.</p> <code>True</code> <p>Returns:</p> Type Description <p>A string containing the JSON formatted protocol buffer message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>def MessageToJson(\n    message,\n    including_default_value_fields=False,\n    preserving_proto_field_name=False,\n    indent=2,\n    sort_keys=False,\n    use_integers_for_enums=False,\n    descriptor_pool=None,\n    float_precision=None,\n    ensure_ascii=True):\n  \"\"\"Converts protobuf message to JSON format.\n\n  Args:\n    message: The protocol buffers message instance to serialize.\n    including_default_value_fields: If True, singular primitive fields,\n        repeated fields, and map fields will always be serialized.  If\n        False, only serialize non-empty fields.  Singular message fields\n        and oneof fields are not affected by this option.\n    preserving_proto_field_name: If True, use the original proto field\n        names as defined in the .proto file. If False, convert the field\n        names to lowerCamelCase.\n    indent: The JSON object will be pretty-printed with this indent level.\n        An indent level of 0 or negative will only insert newlines.\n    sort_keys: If True, then the output will be sorted by field names.\n    use_integers_for_enums: If true, print integers instead of enum names.\n    descriptor_pool: A Descriptor Pool for resolving types. If None use the\n        default.\n    float_precision: If set, use this to specify float field valid digits.\n    ensure_ascii: If True, strings with non-ASCII characters are escaped.\n        If False, Unicode strings are returned unchanged.\n\n  Returns:\n    A string containing the JSON formatted protocol buffer message.\n  \"\"\"\n  printer = _Printer(\n      including_default_value_fields,\n      preserving_proto_field_name,\n      use_integers_for_enums,\n      descriptor_pool,\n      float_precision=float_precision)\n  return printer.ToJsonString(message, indent, sort_keys, ensure_ascii)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.Parse","title":"<code>Parse(text, message, ignore_unknown_fields=False, descriptor_pool=None, max_recursion_depth=100)</code>","text":"<p>Parses a JSON representation of a protocol message into a message.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>Message JSON representation.</p> required <code>message</code> <p>A protocol buffer message to merge into.</p> required <code>ignore_unknown_fields</code> <p>If True, do not raise errors for unknown fields.</p> <code>False</code> <code>descriptor_pool</code> <p>A Descriptor Pool for resolving types. If None use the default.</p> <code>None</code> <code>max_recursion_depth</code> <p>max recursion depth of JSON message to be deserialized. JSON messages over this depth will fail to be deserialized. Default value is 100.</p> <code>100</code> <p>Returns:</p> Type Description <p>The same message passed as argument.</p> <p>Raises::   ParseError: On JSON parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>def Parse(text,\n          message,\n          ignore_unknown_fields=False,\n          descriptor_pool=None,\n          max_recursion_depth=100):\n  \"\"\"Parses a JSON representation of a protocol message into a message.\n\n  Args:\n    text: Message JSON representation.\n    message: A protocol buffer message to merge into.\n    ignore_unknown_fields: If True, do not raise errors for unknown fields.\n    descriptor_pool: A Descriptor Pool for resolving types. If None use the\n      default.\n    max_recursion_depth: max recursion depth of JSON message to be\n      deserialized. JSON messages over this depth will fail to be\n      deserialized. Default value is 100.\n\n  Returns:\n    The same message passed as argument.\n\n  Raises::\n    ParseError: On JSON parsing problems.\n  \"\"\"\n  if not isinstance(text, str):\n    text = text.decode('utf-8')\n  try:\n    js = json.loads(text, object_pairs_hook=_DuplicateChecker)\n  except ValueError as e:\n    raise ParseError('Failed to load JSON: {0}.'.format(str(e)))\n  return ParseDict(js, message, ignore_unknown_fields, descriptor_pool,\n                   max_recursion_depth)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/json_format.html#client.ayon_nuke.vendor.google.protobuf.json_format.ParseDict","title":"<code>ParseDict(js_dict, message, ignore_unknown_fields=False, descriptor_pool=None, max_recursion_depth=100)</code>","text":"<p>Parses a JSON dictionary representation into a message.</p> <p>Parameters:</p> Name Type Description Default <code>js_dict</code> <p>Dict representation of a JSON message.</p> required <code>message</code> <p>A protocol buffer message to merge into.</p> required <code>ignore_unknown_fields</code> <p>If True, do not raise errors for unknown fields.</p> <code>False</code> <code>descriptor_pool</code> <p>A Descriptor Pool for resolving types. If None use the default.</p> <code>None</code> <code>max_recursion_depth</code> <p>max recursion depth of JSON message to be deserialized. JSON messages over this depth will fail to be deserialized. Default value is 100.</p> <code>100</code> <p>Returns:</p> Type Description <p>The same message passed as argument.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/json_format.py</code> <pre><code>def ParseDict(js_dict,\n              message,\n              ignore_unknown_fields=False,\n              descriptor_pool=None,\n              max_recursion_depth=100):\n  \"\"\"Parses a JSON dictionary representation into a message.\n\n  Args:\n    js_dict: Dict representation of a JSON message.\n    message: A protocol buffer message to merge into.\n    ignore_unknown_fields: If True, do not raise errors for unknown fields.\n    descriptor_pool: A Descriptor Pool for resolving types. If None use the\n      default.\n    max_recursion_depth: max recursion depth of JSON message to be\n      deserialized. JSON messages over this depth will fail to be\n      deserialized. Default value is 100.\n\n  Returns:\n    The same message passed as argument.\n  \"\"\"\n  parser = _Parser(ignore_unknown_fields, descriptor_pool, max_recursion_depth)\n  parser.ConvertMessage(js_dict, message, '')\n  return message\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html","title":"message","text":"<p>Contains an abstract base class for protocol messages.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.DecodeError","title":"<code>DecodeError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Exception raised when deserializing messages.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>class DecodeError(Error):\n  \"\"\"Exception raised when deserializing messages.\"\"\"\n  pass\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.EncodeError","title":"<code>EncodeError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Exception raised when serializing messages.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>class EncodeError(Error):\n  \"\"\"Exception raised when serializing messages.\"\"\"\n  pass\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Error","title":"<code>Error</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base error type for this module.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>class Error(Exception):\n  \"\"\"Base error type for this module.\"\"\"\n  pass\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message","title":"<code>Message</code>","text":"<p>               Bases: <code>object</code></p> <p>Abstract base class for protocol messages.</p> <p>Protocol message classes are almost always generated by the protocol compiler.  These generated types subclass Message and implement the methods shown below.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>class Message(object):\n\n  \"\"\"Abstract base class for protocol messages.\n\n  Protocol message classes are almost always generated by the protocol\n  compiler.  These generated types subclass Message and implement the methods\n  shown below.\n  \"\"\"\n\n  # TODO(robinson): Link to an HTML document here.\n\n  # TODO(robinson): Document that instances of this class will also\n  # have an Extensions attribute with __getitem__ and __setitem__.\n  # Again, not sure how to best convey this.\n\n  # TODO(robinson): Document that the class must also have a static\n  #   RegisterExtension(extension_field) method.\n  #   Not sure how to best express at this point.\n\n  # TODO(robinson): Document these fields and methods.\n\n  __slots__ = []\n\n  #: The :class:`google.protobuf.descriptor.Descriptor` for this message type.\n  DESCRIPTOR = None\n\n  def __deepcopy__(self, memo=None):\n    clone = type(self)()\n    clone.MergeFrom(self)\n    return clone\n\n  def __eq__(self, other_msg):\n    \"\"\"Recursively compares two messages by value and structure.\"\"\"\n    raise NotImplementedError\n\n  def __ne__(self, other_msg):\n    # Can't just say self != other_msg, since that would infinitely recurse. :)\n    return not self == other_msg\n\n  def __hash__(self):\n    raise TypeError('unhashable object')\n\n  def __str__(self):\n    \"\"\"Outputs a human-readable representation of the message.\"\"\"\n    raise NotImplementedError\n\n  def __unicode__(self):\n    \"\"\"Outputs a human-readable representation of the message.\"\"\"\n    raise NotImplementedError\n\n  def MergeFrom(self, other_msg):\n    \"\"\"Merges the contents of the specified message into current message.\n\n    This method merges the contents of the specified message into the current\n    message. Singular fields that are set in the specified message overwrite\n    the corresponding fields in the current message. Repeated fields are\n    appended. Singular sub-messages and groups are recursively merged.\n\n    Args:\n      other_msg (Message): A message to merge into the current message.\n    \"\"\"\n    raise NotImplementedError\n\n  def CopyFrom(self, other_msg):\n    \"\"\"Copies the content of the specified message into the current message.\n\n    The method clears the current message and then merges the specified\n    message using MergeFrom.\n\n    Args:\n      other_msg (Message): A message to copy into the current one.\n    \"\"\"\n    if self is other_msg:\n      return\n    self.Clear()\n    self.MergeFrom(other_msg)\n\n  def Clear(self):\n    \"\"\"Clears all data that was set in the message.\"\"\"\n    raise NotImplementedError\n\n  def SetInParent(self):\n    \"\"\"Mark this as present in the parent.\n\n    This normally happens automatically when you assign a field of a\n    sub-message, but sometimes you want to make the sub-message\n    present while keeping it empty.  If you find yourself using this,\n    you may want to reconsider your design.\n    \"\"\"\n    raise NotImplementedError\n\n  def IsInitialized(self):\n    \"\"\"Checks if the message is initialized.\n\n    Returns:\n      bool: The method returns True if the message is initialized (i.e. all of\n      its required fields are set).\n    \"\"\"\n    raise NotImplementedError\n\n  # TODO(robinson): MergeFromString() should probably return None and be\n  # implemented in terms of a helper that returns the # of bytes read.  Our\n  # deserialization routines would use the helper when recursively\n  # deserializing, but the end user would almost always just want the no-return\n  # MergeFromString().\n\n  def MergeFromString(self, serialized):\n    \"\"\"Merges serialized protocol buffer data into this message.\n\n    When we find a field in `serialized` that is already present\n    in this message:\n\n    -   If it's a \"repeated\" field, we append to the end of our list.\n    -   Else, if it's a scalar, we overwrite our field.\n    -   Else, (it's a nonrepeated composite), we recursively merge\n        into the existing composite.\n\n    Args:\n      serialized (bytes): Any object that allows us to call\n        ``memoryview(serialized)`` to access a string of bytes using the\n        buffer interface.\n\n    Returns:\n      int: The number of bytes read from `serialized`.\n      For non-group messages, this will always be `len(serialized)`,\n      but for messages which are actually groups, this will\n      generally be less than `len(serialized)`, since we must\n      stop when we reach an ``END_GROUP`` tag.  Note that if\n      we *do* stop because of an ``END_GROUP`` tag, the number\n      of bytes returned does not include the bytes\n      for the ``END_GROUP`` tag information.\n\n    Raises:\n      DecodeError: if the input cannot be parsed.\n    \"\"\"\n    # TODO(robinson): Document handling of unknown fields.\n    # TODO(robinson): When we switch to a helper, this will return None.\n    raise NotImplementedError\n\n  def ParseFromString(self, serialized):\n    \"\"\"Parse serialized protocol buffer data into this message.\n\n    Like :func:`MergeFromString()`, except we clear the object first.\n\n    Raises:\n      message.DecodeError if the input cannot be parsed.\n    \"\"\"\n    self.Clear()\n    return self.MergeFromString(serialized)\n\n  def SerializeToString(self, **kwargs):\n    \"\"\"Serializes the protocol message to a binary string.\n\n    Keyword Args:\n      deterministic (bool): If true, requests deterministic serialization\n        of the protobuf, with predictable ordering of map keys.\n\n    Returns:\n      A binary string representation of the message if all of the required\n      fields in the message are set (i.e. the message is initialized).\n\n    Raises:\n      EncodeError: if the message isn't initialized (see :func:`IsInitialized`).\n    \"\"\"\n    raise NotImplementedError\n\n  def SerializePartialToString(self, **kwargs):\n    \"\"\"Serializes the protocol message to a binary string.\n\n    This method is similar to SerializeToString but doesn't check if the\n    message is initialized.\n\n    Keyword Args:\n      deterministic (bool): If true, requests deterministic serialization\n        of the protobuf, with predictable ordering of map keys.\n\n    Returns:\n      bytes: A serialized representation of the partial message.\n    \"\"\"\n    raise NotImplementedError\n\n  # TODO(robinson): Decide whether we like these better\n  # than auto-generated has_foo() and clear_foo() methods\n  # on the instances themselves.  This way is less consistent\n  # with C++, but it makes reflection-type access easier and\n  # reduces the number of magically autogenerated things.\n  #\n  # TODO(robinson): Be sure to document (and test) exactly\n  # which field names are accepted here.  Are we case-sensitive?\n  # What do we do with fields that share names with Python keywords\n  # like 'lambda' and 'yield'?\n  #\n  # nnorwitz says:\n  # \"\"\"\n  # Typically (in python), an underscore is appended to names that are\n  # keywords. So they would become lambda_ or yield_.\n  # \"\"\"\n  def ListFields(self):\n    \"\"\"Returns a list of (FieldDescriptor, value) tuples for present fields.\n\n    A message field is non-empty if HasField() would return true. A singular\n    primitive field is non-empty if HasField() would return true in proto2 or it\n    is non zero in proto3. A repeated field is non-empty if it contains at least\n    one element. The fields are ordered by field number.\n\n    Returns:\n      list[tuple(FieldDescriptor, value)]: field descriptors and values\n      for all fields in the message which are not empty. The values vary by\n      field type.\n    \"\"\"\n    raise NotImplementedError\n\n  def HasField(self, field_name):\n    \"\"\"Checks if a certain field is set for the message.\n\n    For a oneof group, checks if any field inside is set. Note that if the\n    field_name is not defined in the message descriptor, :exc:`ValueError` will\n    be raised.\n\n    Args:\n      field_name (str): The name of the field to check for presence.\n\n    Returns:\n      bool: Whether a value has been set for the named field.\n\n    Raises:\n      ValueError: if the `field_name` is not a member of this message.\n    \"\"\"\n    raise NotImplementedError\n\n  def ClearField(self, field_name):\n    \"\"\"Clears the contents of a given field.\n\n    Inside a oneof group, clears the field set. If the name neither refers to a\n    defined field or oneof group, :exc:`ValueError` is raised.\n\n    Args:\n      field_name (str): The name of the field to check for presence.\n\n    Raises:\n      ValueError: if the `field_name` is not a member of this message.\n    \"\"\"\n    raise NotImplementedError\n\n  def WhichOneof(self, oneof_group):\n    \"\"\"Returns the name of the field that is set inside a oneof group.\n\n    If no field is set, returns None.\n\n    Args:\n      oneof_group (str): the name of the oneof group to check.\n\n    Returns:\n      str or None: The name of the group that is set, or None.\n\n    Raises:\n      ValueError: no group with the given name exists\n    \"\"\"\n    raise NotImplementedError\n\n  def HasExtension(self, extension_handle):\n    \"\"\"Checks if a certain extension is present for this message.\n\n    Extensions are retrieved using the :attr:`Extensions` mapping (if present).\n\n    Args:\n      extension_handle: The handle for the extension to check.\n\n    Returns:\n      bool: Whether the extension is present for this message.\n\n    Raises:\n      KeyError: if the extension is repeated. Similar to repeated fields,\n        there is no separate notion of presence: a \"not present\" repeated\n        extension is an empty list.\n    \"\"\"\n    raise NotImplementedError\n\n  def ClearExtension(self, extension_handle):\n    \"\"\"Clears the contents of a given extension.\n\n    Args:\n      extension_handle: The handle for the extension to clear.\n    \"\"\"\n    raise NotImplementedError\n\n  def UnknownFields(self):\n    \"\"\"Returns the UnknownFieldSet.\n\n    Returns:\n      UnknownFieldSet: The unknown fields stored in this message.\n    \"\"\"\n    raise NotImplementedError\n\n  def DiscardUnknownFields(self):\n    \"\"\"Clears all fields in the :class:`UnknownFieldSet`.\n\n    This operation is recursive for nested message.\n    \"\"\"\n    raise NotImplementedError\n\n  def ByteSize(self):\n    \"\"\"Returns the serialized size of this message.\n\n    Recursively calls ByteSize() on all contained messages.\n\n    Returns:\n      int: The number of bytes required to serialize this message.\n    \"\"\"\n    raise NotImplementedError\n\n  @classmethod\n  def FromString(cls, s):\n    raise NotImplementedError\n\n  @staticmethod\n  def RegisterExtension(extension_handle):\n    raise NotImplementedError\n\n  def _SetListener(self, message_listener):\n    \"\"\"Internal method used by the protocol message implementation.\n    Clients should not call this directly.\n\n    Sets a listener that this message will call on certain state transitions.\n\n    The purpose of this method is to register back-edges from children to\n    parents at runtime, for the purpose of setting \"has\" bits and\n    byte-size-dirty bits in the parent and ancestor objects whenever a child or\n    descendant object is modified.\n\n    If the client wants to disconnect this Message from the object tree, she\n    explicitly sets callback to None.\n\n    If message_listener is None, unregisters any existing listener.  Otherwise,\n    message_listener must implement the MessageListener interface in\n    internal/message_listener.py, and we discard any listener registered\n    via a previous _SetListener() call.\n    \"\"\"\n    raise NotImplementedError\n\n  def __getstate__(self):\n    \"\"\"Support the pickle protocol.\"\"\"\n    return dict(serialized=self.SerializePartialToString())\n\n  def __setstate__(self, state):\n    \"\"\"Support the pickle protocol.\"\"\"\n    self.__init__()\n    serialized = state['serialized']\n    # On Python 3, using encoding='latin1' is required for unpickling\n    # protos pickled by Python 2.\n    if not isinstance(serialized, bytes):\n      serialized = serialized.encode('latin1')\n    self.ParseFromString(serialized)\n\n  def __reduce__(self):\n    message_descriptor = self.DESCRIPTOR\n    if message_descriptor.containing_type is None:\n      return type(self), (), self.__getstate__()\n    # the message type must be nested.\n    # Python does not pickle nested classes; use the symbol_database on the\n    # receiving end.\n    container = message_descriptor\n    return (_InternalConstructMessage, (container.full_name,),\n            self.__getstate__())\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.ByteSize","title":"<code>ByteSize()</code>","text":"<p>Returns the serialized size of this message.</p> <p>Recursively calls ByteSize() on all contained messages.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of bytes required to serialize this message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def ByteSize(self):\n  \"\"\"Returns the serialized size of this message.\n\n  Recursively calls ByteSize() on all contained messages.\n\n  Returns:\n    int: The number of bytes required to serialize this message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.Clear","title":"<code>Clear()</code>","text":"<p>Clears all data that was set in the message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def Clear(self):\n  \"\"\"Clears all data that was set in the message.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.ClearExtension","title":"<code>ClearExtension(extension_handle)</code>","text":"<p>Clears the contents of a given extension.</p> <p>Parameters:</p> Name Type Description Default <code>extension_handle</code> <p>The handle for the extension to clear.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def ClearExtension(self, extension_handle):\n  \"\"\"Clears the contents of a given extension.\n\n  Args:\n    extension_handle: The handle for the extension to clear.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.ClearField","title":"<code>ClearField(field_name)</code>","text":"<p>Clears the contents of a given field.</p> <p>Inside a oneof group, clears the field set. If the name neither refers to a defined field or oneof group, :exc:<code>ValueError</code> is raised.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The name of the field to check for presence.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>field_name</code> is not a member of this message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def ClearField(self, field_name):\n  \"\"\"Clears the contents of a given field.\n\n  Inside a oneof group, clears the field set. If the name neither refers to a\n  defined field or oneof group, :exc:`ValueError` is raised.\n\n  Args:\n    field_name (str): The name of the field to check for presence.\n\n  Raises:\n    ValueError: if the `field_name` is not a member of this message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.CopyFrom","title":"<code>CopyFrom(other_msg)</code>","text":"<p>Copies the content of the specified message into the current message.</p> <p>The method clears the current message and then merges the specified message using MergeFrom.</p> <p>Parameters:</p> Name Type Description Default <code>other_msg</code> <code>Message</code> <p>A message to copy into the current one.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def CopyFrom(self, other_msg):\n  \"\"\"Copies the content of the specified message into the current message.\n\n  The method clears the current message and then merges the specified\n  message using MergeFrom.\n\n  Args:\n    other_msg (Message): A message to copy into the current one.\n  \"\"\"\n  if self is other_msg:\n    return\n  self.Clear()\n  self.MergeFrom(other_msg)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.DiscardUnknownFields","title":"<code>DiscardUnknownFields()</code>","text":"<p>Clears all fields in the :class:<code>UnknownFieldSet</code>.</p> <p>This operation is recursive for nested message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def DiscardUnknownFields(self):\n  \"\"\"Clears all fields in the :class:`UnknownFieldSet`.\n\n  This operation is recursive for nested message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.HasExtension","title":"<code>HasExtension(extension_handle)</code>","text":"<p>Checks if a certain extension is present for this message.</p> <p>Extensions are retrieved using the :attr:<code>Extensions</code> mapping (if present).</p> <p>Parameters:</p> Name Type Description Default <code>extension_handle</code> <p>The handle for the extension to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether the extension is present for this message.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the extension is repeated. Similar to repeated fields, there is no separate notion of presence: a \"not present\" repeated extension is an empty list.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def HasExtension(self, extension_handle):\n  \"\"\"Checks if a certain extension is present for this message.\n\n  Extensions are retrieved using the :attr:`Extensions` mapping (if present).\n\n  Args:\n    extension_handle: The handle for the extension to check.\n\n  Returns:\n    bool: Whether the extension is present for this message.\n\n  Raises:\n    KeyError: if the extension is repeated. Similar to repeated fields,\n      there is no separate notion of presence: a \"not present\" repeated\n      extension is an empty list.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.HasField","title":"<code>HasField(field_name)</code>","text":"<p>Checks if a certain field is set for the message.</p> <p>For a oneof group, checks if any field inside is set. Note that if the field_name is not defined in the message descriptor, :exc:<code>ValueError</code> will be raised.</p> <p>Parameters:</p> Name Type Description Default <code>field_name</code> <code>str</code> <p>The name of the field to check for presence.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Whether a value has been set for the named field.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the <code>field_name</code> is not a member of this message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def HasField(self, field_name):\n  \"\"\"Checks if a certain field is set for the message.\n\n  For a oneof group, checks if any field inside is set. Note that if the\n  field_name is not defined in the message descriptor, :exc:`ValueError` will\n  be raised.\n\n  Args:\n    field_name (str): The name of the field to check for presence.\n\n  Returns:\n    bool: Whether a value has been set for the named field.\n\n  Raises:\n    ValueError: if the `field_name` is not a member of this message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.IsInitialized","title":"<code>IsInitialized()</code>","text":"<p>Checks if the message is initialized.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>The method returns True if the message is initialized (i.e. all of</p> <p>its required fields are set).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def IsInitialized(self):\n  \"\"\"Checks if the message is initialized.\n\n  Returns:\n    bool: The method returns True if the message is initialized (i.e. all of\n    its required fields are set).\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.ListFields","title":"<code>ListFields()</code>","text":"<p>Returns a list of (FieldDescriptor, value) tuples for present fields.</p> <p>A message field is non-empty if HasField() would return true. A singular primitive field is non-empty if HasField() would return true in proto2 or it is non zero in proto3. A repeated field is non-empty if it contains at least one element. The fields are ordered by field number.</p> <p>Returns:</p> Type Description <p>list[tuple(FieldDescriptor, value)]: field descriptors and values</p> <p>for all fields in the message which are not empty. The values vary by</p> <p>field type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def ListFields(self):\n  \"\"\"Returns a list of (FieldDescriptor, value) tuples for present fields.\n\n  A message field is non-empty if HasField() would return true. A singular\n  primitive field is non-empty if HasField() would return true in proto2 or it\n  is non zero in proto3. A repeated field is non-empty if it contains at least\n  one element. The fields are ordered by field number.\n\n  Returns:\n    list[tuple(FieldDescriptor, value)]: field descriptors and values\n    for all fields in the message which are not empty. The values vary by\n    field type.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.MergeFrom","title":"<code>MergeFrom(other_msg)</code>","text":"<p>Merges the contents of the specified message into current message.</p> <p>This method merges the contents of the specified message into the current message. Singular fields that are set in the specified message overwrite the corresponding fields in the current message. Repeated fields are appended. Singular sub-messages and groups are recursively merged.</p> <p>Parameters:</p> Name Type Description Default <code>other_msg</code> <code>Message</code> <p>A message to merge into the current message.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def MergeFrom(self, other_msg):\n  \"\"\"Merges the contents of the specified message into current message.\n\n  This method merges the contents of the specified message into the current\n  message. Singular fields that are set in the specified message overwrite\n  the corresponding fields in the current message. Repeated fields are\n  appended. Singular sub-messages and groups are recursively merged.\n\n  Args:\n    other_msg (Message): A message to merge into the current message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.MergeFromString","title":"<code>MergeFromString(serialized)</code>","text":"<p>Merges serialized protocol buffer data into this message.</p> <p>When we find a field in <code>serialized</code> that is already present in this message:</p> <ul> <li>If it's a \"repeated\" field, we append to the end of our list.</li> <li>Else, if it's a scalar, we overwrite our field.</li> <li>Else, (it's a nonrepeated composite), we recursively merge     into the existing composite.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>serialized</code> <code>bytes</code> <p>Any object that allows us to call <code>memoryview(serialized)</code> to access a string of bytes using the buffer interface.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The number of bytes read from <code>serialized</code>.</p> <p>For non-group messages, this will always be <code>len(serialized)</code>,</p> <p>but for messages which are actually groups, this will</p> <p>generally be less than <code>len(serialized)</code>, since we must</p> <p>stop when we reach an <code>END_GROUP</code> tag.  Note that if</p> <p>we do stop because of an <code>END_GROUP</code> tag, the number</p> <p>of bytes returned does not include the bytes</p> <p>for the <code>END_GROUP</code> tag information.</p> <p>Raises:</p> Type Description <code>DecodeError</code> <p>if the input cannot be parsed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def MergeFromString(self, serialized):\n  \"\"\"Merges serialized protocol buffer data into this message.\n\n  When we find a field in `serialized` that is already present\n  in this message:\n\n  -   If it's a \"repeated\" field, we append to the end of our list.\n  -   Else, if it's a scalar, we overwrite our field.\n  -   Else, (it's a nonrepeated composite), we recursively merge\n      into the existing composite.\n\n  Args:\n    serialized (bytes): Any object that allows us to call\n      ``memoryview(serialized)`` to access a string of bytes using the\n      buffer interface.\n\n  Returns:\n    int: The number of bytes read from `serialized`.\n    For non-group messages, this will always be `len(serialized)`,\n    but for messages which are actually groups, this will\n    generally be less than `len(serialized)`, since we must\n    stop when we reach an ``END_GROUP`` tag.  Note that if\n    we *do* stop because of an ``END_GROUP`` tag, the number\n    of bytes returned does not include the bytes\n    for the ``END_GROUP`` tag information.\n\n  Raises:\n    DecodeError: if the input cannot be parsed.\n  \"\"\"\n  # TODO(robinson): Document handling of unknown fields.\n  # TODO(robinson): When we switch to a helper, this will return None.\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.ParseFromString","title":"<code>ParseFromString(serialized)</code>","text":"<p>Parse serialized protocol buffer data into this message.</p> <p>Like :func:<code>MergeFromString()</code>, except we clear the object first.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def ParseFromString(self, serialized):\n  \"\"\"Parse serialized protocol buffer data into this message.\n\n  Like :func:`MergeFromString()`, except we clear the object first.\n\n  Raises:\n    message.DecodeError if the input cannot be parsed.\n  \"\"\"\n  self.Clear()\n  return self.MergeFromString(serialized)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.SerializePartialToString","title":"<code>SerializePartialToString(**kwargs)</code>","text":"<p>Serializes the protocol message to a binary string.</p> <p>This method is similar to SerializeToString but doesn't check if the message is initialized.</p> <p>Other Parameters:</p> Name Type Description <code>deterministic</code> <code>bool</code> <p>If true, requests deterministic serialization of the protobuf, with predictable ordering of map keys.</p> <p>Returns:</p> Name Type Description <code>bytes</code> <p>A serialized representation of the partial message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def SerializePartialToString(self, **kwargs):\n  \"\"\"Serializes the protocol message to a binary string.\n\n  This method is similar to SerializeToString but doesn't check if the\n  message is initialized.\n\n  Keyword Args:\n    deterministic (bool): If true, requests deterministic serialization\n      of the protobuf, with predictable ordering of map keys.\n\n  Returns:\n    bytes: A serialized representation of the partial message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.SerializeToString","title":"<code>SerializeToString(**kwargs)</code>","text":"<p>Serializes the protocol message to a binary string.</p> <p>Other Parameters:</p> Name Type Description <code>deterministic</code> <code>bool</code> <p>If true, requests deterministic serialization of the protobuf, with predictable ordering of map keys.</p> <p>Returns:</p> Type Description <p>A binary string representation of the message if all of the required</p> <p>fields in the message are set (i.e. the message is initialized).</p> <p>Raises:</p> Type Description <code>EncodeError</code> <p>if the message isn't initialized (see :func:<code>IsInitialized</code>).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def SerializeToString(self, **kwargs):\n  \"\"\"Serializes the protocol message to a binary string.\n\n  Keyword Args:\n    deterministic (bool): If true, requests deterministic serialization\n      of the protobuf, with predictable ordering of map keys.\n\n  Returns:\n    A binary string representation of the message if all of the required\n    fields in the message are set (i.e. the message is initialized).\n\n  Raises:\n    EncodeError: if the message isn't initialized (see :func:`IsInitialized`).\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.SetInParent","title":"<code>SetInParent()</code>","text":"<p>Mark this as present in the parent.</p> <p>This normally happens automatically when you assign a field of a sub-message, but sometimes you want to make the sub-message present while keeping it empty.  If you find yourself using this, you may want to reconsider your design.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def SetInParent(self):\n  \"\"\"Mark this as present in the parent.\n\n  This normally happens automatically when you assign a field of a\n  sub-message, but sometimes you want to make the sub-message\n  present while keeping it empty.  If you find yourself using this,\n  you may want to reconsider your design.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.UnknownFields","title":"<code>UnknownFields()</code>","text":"<p>Returns the UnknownFieldSet.</p> <p>Returns:</p> Name Type Description <code>UnknownFieldSet</code> <p>The unknown fields stored in this message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def UnknownFields(self):\n  \"\"\"Returns the UnknownFieldSet.\n\n  Returns:\n    UnknownFieldSet: The unknown fields stored in this message.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.WhichOneof","title":"<code>WhichOneof(oneof_group)</code>","text":"<p>Returns the name of the field that is set inside a oneof group.</p> <p>If no field is set, returns None.</p> <p>Parameters:</p> Name Type Description Default <code>oneof_group</code> <code>str</code> <p>the name of the oneof group to check.</p> required <p>Returns:</p> Type Description <p>str or None: The name of the group that is set, or None.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>no group with the given name exists</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def WhichOneof(self, oneof_group):\n  \"\"\"Returns the name of the field that is set inside a oneof group.\n\n  If no field is set, returns None.\n\n  Args:\n    oneof_group (str): the name of the oneof group to check.\n\n  Returns:\n    str or None: The name of the group that is set, or None.\n\n  Raises:\n    ValueError: no group with the given name exists\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.__eq__","title":"<code>__eq__(other_msg)</code>","text":"<p>Recursively compares two messages by value and structure.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def __eq__(self, other_msg):\n  \"\"\"Recursively compares two messages by value and structure.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.__getstate__","title":"<code>__getstate__()</code>","text":"<p>Support the pickle protocol.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def __getstate__(self):\n  \"\"\"Support the pickle protocol.\"\"\"\n  return dict(serialized=self.SerializePartialToString())\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.__setstate__","title":"<code>__setstate__(state)</code>","text":"<p>Support the pickle protocol.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def __setstate__(self, state):\n  \"\"\"Support the pickle protocol.\"\"\"\n  self.__init__()\n  serialized = state['serialized']\n  # On Python 3, using encoding='latin1' is required for unpickling\n  # protos pickled by Python 2.\n  if not isinstance(serialized, bytes):\n    serialized = serialized.encode('latin1')\n  self.ParseFromString(serialized)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.__str__","title":"<code>__str__()</code>","text":"<p>Outputs a human-readable representation of the message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def __str__(self):\n  \"\"\"Outputs a human-readable representation of the message.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message.html#client.ayon_nuke.vendor.google.protobuf.message.Message.__unicode__","title":"<code>__unicode__()</code>","text":"<p>Outputs a human-readable representation of the message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message.py</code> <pre><code>def __unicode__(self):\n  \"\"\"Outputs a human-readable representation of the message.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html","title":"message_factory","text":"<p>Provides a factory class for generating dynamic messages.</p> <p>The easiest way to use this class is if you have access to the FileDescriptor protos containing the messages you want to create you can just do the following:</p> <p>message_classes = message_factory.GetMessages(iterable_of_file_descriptors) my_proto_instance = message_classes'some.proto.package.MessageName'</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html#client.ayon_nuke.vendor.google.protobuf.message_factory.MessageFactory","title":"<code>MessageFactory</code>","text":"<p>               Bases: <code>object</code></p> <p>Factory for creating Proto2 messages from descriptors in a pool.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message_factory.py</code> <pre><code>class MessageFactory(object):\n  \"\"\"Factory for creating Proto2 messages from descriptors in a pool.\"\"\"\n\n  def __init__(self, pool=None):\n    \"\"\"Initializes a new factory.\"\"\"\n    self.pool = pool or descriptor_pool.DescriptorPool()\n\n    # local cache of all classes built from protobuf descriptors\n    self._classes = {}\n\n  def GetPrototype(self, descriptor):\n    \"\"\"Obtains a proto2 message class based on the passed in descriptor.\n\n    Passing a descriptor with a fully qualified name matching a previous\n    invocation will cause the same class to be returned.\n\n    Args:\n      descriptor: The descriptor to build from.\n\n    Returns:\n      A class describing the passed in descriptor.\n    \"\"\"\n    if descriptor not in self._classes:\n      result_class = self.CreatePrototype(descriptor)\n      # The assignment to _classes is redundant for the base implementation, but\n      # might avoid confusion in cases where CreatePrototype gets overridden and\n      # does not call the base implementation.\n      self._classes[descriptor] = result_class\n      return result_class\n    return self._classes[descriptor]\n\n  def CreatePrototype(self, descriptor):\n    \"\"\"Builds a proto2 message class based on the passed in descriptor.\n\n    Don't call this function directly, it always creates a new class. Call\n    GetPrototype() instead. This method is meant to be overridden in subblasses\n    to perform additional operations on the newly constructed class.\n\n    Args:\n      descriptor: The descriptor to build from.\n\n    Returns:\n      A class describing the passed in descriptor.\n    \"\"\"\n    descriptor_name = descriptor.name\n    result_class = _GENERATED_PROTOCOL_MESSAGE_TYPE(\n        descriptor_name,\n        (message.Message,),\n        {\n            'DESCRIPTOR': descriptor,\n            # If module not set, it wrongly points to message_factory module.\n            '__module__': None,\n        })\n    result_class._FACTORY = self  # pylint: disable=protected-access\n    # Assign in _classes before doing recursive calls to avoid infinite\n    # recursion.\n    self._classes[descriptor] = result_class\n    for field in descriptor.fields:\n      if field.message_type:\n        self.GetPrototype(field.message_type)\n    for extension in result_class.DESCRIPTOR.extensions:\n      if extension.containing_type not in self._classes:\n        self.GetPrototype(extension.containing_type)\n      extended_class = self._classes[extension.containing_type]\n      extended_class.RegisterExtension(extension)\n    return result_class\n\n  def GetMessages(self, files):\n    \"\"\"Gets all the messages from a specified file.\n\n    This will find and resolve dependencies, failing if the descriptor\n    pool cannot satisfy them.\n\n    Args:\n      files: The file names to extract messages from.\n\n    Returns:\n      A dictionary mapping proto names to the message classes. This will include\n      any dependent messages as well as any messages defined in the same file as\n      a specified message.\n    \"\"\"\n    result = {}\n    for file_name in files:\n      file_desc = self.pool.FindFileByName(file_name)\n      for desc in file_desc.message_types_by_name.values():\n        result[desc.full_name] = self.GetPrototype(desc)\n\n      # While the extension FieldDescriptors are created by the descriptor pool,\n      # the python classes created in the factory need them to be registered\n      # explicitly, which is done below.\n      #\n      # The call to RegisterExtension will specifically check if the\n      # extension was already registered on the object and either\n      # ignore the registration if the original was the same, or raise\n      # an error if they were different.\n\n      for extension in file_desc.extensions_by_name.values():\n        if extension.containing_type not in self._classes:\n          self.GetPrototype(extension.containing_type)\n        extended_class = self._classes[extension.containing_type]\n        extended_class.RegisterExtension(extension)\n    return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html#client.ayon_nuke.vendor.google.protobuf.message_factory.MessageFactory.CreatePrototype","title":"<code>CreatePrototype(descriptor)</code>","text":"<p>Builds a proto2 message class based on the passed in descriptor.</p> <p>Don't call this function directly, it always creates a new class. Call GetPrototype() instead. This method is meant to be overridden in subblasses to perform additional operations on the newly constructed class.</p> <p>Parameters:</p> Name Type Description Default <code>descriptor</code> <p>The descriptor to build from.</p> required <p>Returns:</p> Type Description <p>A class describing the passed in descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message_factory.py</code> <pre><code>def CreatePrototype(self, descriptor):\n  \"\"\"Builds a proto2 message class based on the passed in descriptor.\n\n  Don't call this function directly, it always creates a new class. Call\n  GetPrototype() instead. This method is meant to be overridden in subblasses\n  to perform additional operations on the newly constructed class.\n\n  Args:\n    descriptor: The descriptor to build from.\n\n  Returns:\n    A class describing the passed in descriptor.\n  \"\"\"\n  descriptor_name = descriptor.name\n  result_class = _GENERATED_PROTOCOL_MESSAGE_TYPE(\n      descriptor_name,\n      (message.Message,),\n      {\n          'DESCRIPTOR': descriptor,\n          # If module not set, it wrongly points to message_factory module.\n          '__module__': None,\n      })\n  result_class._FACTORY = self  # pylint: disable=protected-access\n  # Assign in _classes before doing recursive calls to avoid infinite\n  # recursion.\n  self._classes[descriptor] = result_class\n  for field in descriptor.fields:\n    if field.message_type:\n      self.GetPrototype(field.message_type)\n  for extension in result_class.DESCRIPTOR.extensions:\n    if extension.containing_type not in self._classes:\n      self.GetPrototype(extension.containing_type)\n    extended_class = self._classes[extension.containing_type]\n    extended_class.RegisterExtension(extension)\n  return result_class\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html#client.ayon_nuke.vendor.google.protobuf.message_factory.MessageFactory.GetMessages","title":"<code>GetMessages(files)</code>","text":"<p>Gets all the messages from a specified file.</p> <p>This will find and resolve dependencies, failing if the descriptor pool cannot satisfy them.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <p>The file names to extract messages from.</p> required <p>Returns:</p> Type Description <p>A dictionary mapping proto names to the message classes. This will include</p> <p>any dependent messages as well as any messages defined in the same file as</p> <p>a specified message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message_factory.py</code> <pre><code>def GetMessages(self, files):\n  \"\"\"Gets all the messages from a specified file.\n\n  This will find and resolve dependencies, failing if the descriptor\n  pool cannot satisfy them.\n\n  Args:\n    files: The file names to extract messages from.\n\n  Returns:\n    A dictionary mapping proto names to the message classes. This will include\n    any dependent messages as well as any messages defined in the same file as\n    a specified message.\n  \"\"\"\n  result = {}\n  for file_name in files:\n    file_desc = self.pool.FindFileByName(file_name)\n    for desc in file_desc.message_types_by_name.values():\n      result[desc.full_name] = self.GetPrototype(desc)\n\n    # While the extension FieldDescriptors are created by the descriptor pool,\n    # the python classes created in the factory need them to be registered\n    # explicitly, which is done below.\n    #\n    # The call to RegisterExtension will specifically check if the\n    # extension was already registered on the object and either\n    # ignore the registration if the original was the same, or raise\n    # an error if they were different.\n\n    for extension in file_desc.extensions_by_name.values():\n      if extension.containing_type not in self._classes:\n        self.GetPrototype(extension.containing_type)\n      extended_class = self._classes[extension.containing_type]\n      extended_class.RegisterExtension(extension)\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html#client.ayon_nuke.vendor.google.protobuf.message_factory.MessageFactory.GetPrototype","title":"<code>GetPrototype(descriptor)</code>","text":"<p>Obtains a proto2 message class based on the passed in descriptor.</p> <p>Passing a descriptor with a fully qualified name matching a previous invocation will cause the same class to be returned.</p> <p>Parameters:</p> Name Type Description Default <code>descriptor</code> <p>The descriptor to build from.</p> required <p>Returns:</p> Type Description <p>A class describing the passed in descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message_factory.py</code> <pre><code>def GetPrototype(self, descriptor):\n  \"\"\"Obtains a proto2 message class based on the passed in descriptor.\n\n  Passing a descriptor with a fully qualified name matching a previous\n  invocation will cause the same class to be returned.\n\n  Args:\n    descriptor: The descriptor to build from.\n\n  Returns:\n    A class describing the passed in descriptor.\n  \"\"\"\n  if descriptor not in self._classes:\n    result_class = self.CreatePrototype(descriptor)\n    # The assignment to _classes is redundant for the base implementation, but\n    # might avoid confusion in cases where CreatePrototype gets overridden and\n    # does not call the base implementation.\n    self._classes[descriptor] = result_class\n    return result_class\n  return self._classes[descriptor]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html#client.ayon_nuke.vendor.google.protobuf.message_factory.MessageFactory.__init__","title":"<code>__init__(pool=None)</code>","text":"<p>Initializes a new factory.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message_factory.py</code> <pre><code>def __init__(self, pool=None):\n  \"\"\"Initializes a new factory.\"\"\"\n  self.pool = pool or descriptor_pool.DescriptorPool()\n\n  # local cache of all classes built from protobuf descriptors\n  self._classes = {}\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/message_factory.html#client.ayon_nuke.vendor.google.protobuf.message_factory.GetMessages","title":"<code>GetMessages(file_protos)</code>","text":"<p>Builds a dictionary of all the messages available in a set of files.</p> <p>Parameters:</p> Name Type Description Default <code>file_protos</code> <p>Iterable of FileDescriptorProto to build messages out of.</p> required <p>Returns:</p> Type Description <p>A dictionary mapping proto names to the message classes. This will include</p> <p>any dependent messages as well as any messages defined in the same file as</p> <p>a specified message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/message_factory.py</code> <pre><code>def GetMessages(file_protos):\n  \"\"\"Builds a dictionary of all the messages available in a set of files.\n\n  Args:\n    file_protos: Iterable of FileDescriptorProto to build messages out of.\n\n  Returns:\n    A dictionary mapping proto names to the message classes. This will include\n    any dependent messages as well as any messages defined in the same file as\n    a specified message.\n  \"\"\"\n  # The cpp implementation of the protocol buffer library requires to add the\n  # message in topological order of the dependency graph.\n  file_by_name = {file_proto.name: file_proto for file_proto in file_protos}\n  def _AddFile(file_proto):\n    for dependency in file_proto.dependency:\n      if dependency in file_by_name:\n        # Remove from elements to be visited, in order to cut cycles.\n        _AddFile(file_by_name.pop(dependency))\n    _FACTORY.pool.Add(file_proto)\n  while file_by_name:\n    _AddFile(file_by_name.popitem()[1])\n  return _FACTORY.GetMessages([file_proto.name for file_proto in file_protos])\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/proto_builder.html","title":"proto_builder","text":"<p>Dynamic Protobuf class creator.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/proto_builder.html#client.ayon_nuke.vendor.google.protobuf.proto_builder.MakeSimpleProtoClass","title":"<code>MakeSimpleProtoClass(fields, full_name=None, pool=None)</code>","text":"<p>Create a Protobuf class whose fields are basic types.</p> <p>Note: this doesn't validate field names!</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <p>dict of {name: field_type} mappings for each field in the proto. If   this is an OrderedDict the order will be maintained, otherwise the   fields will be sorted by name.</p> required <code>full_name</code> <p>optional str, the fully-qualified name of the proto type.</p> <code>None</code> <code>pool</code> <p>optional DescriptorPool instance.</p> <code>None</code> <p>Returns:   a class, the new protobuf class with a FileDescriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/proto_builder.py</code> <pre><code>def MakeSimpleProtoClass(fields, full_name=None, pool=None):\n  \"\"\"Create a Protobuf class whose fields are basic types.\n\n  Note: this doesn't validate field names!\n\n  Args:\n    fields: dict of {name: field_type} mappings for each field in the proto. If\n        this is an OrderedDict the order will be maintained, otherwise the\n        fields will be sorted by name.\n    full_name: optional str, the fully-qualified name of the proto type.\n    pool: optional DescriptorPool instance.\n  Returns:\n    a class, the new protobuf class with a FileDescriptor.\n  \"\"\"\n  factory = message_factory.MessageFactory(pool=pool)\n\n  if full_name is not None:\n    try:\n      proto_cls = _GetMessageFromFactory(factory, full_name)\n      return proto_cls\n    except KeyError:\n      # The factory's DescriptorPool doesn't know about this class yet.\n      pass\n\n  # Get a list of (name, field_type) tuples from the fields dict. If fields was\n  # an OrderedDict we keep the order, but otherwise we sort the field to ensure\n  # consistent ordering.\n  field_items = fields.items()\n  if not isinstance(fields, OrderedDict):\n    field_items = sorted(field_items)\n\n  # Use a consistent file name that is unlikely to conflict with any imported\n  # proto files.\n  fields_hash = hashlib.sha1()\n  for f_name, f_type in field_items:\n    fields_hash.update(f_name.encode('utf-8'))\n    fields_hash.update(str(f_type).encode('utf-8'))\n  proto_file_name = fields_hash.hexdigest() + '.proto'\n\n  # If the proto is anonymous, use the same hash to name it.\n  if full_name is None:\n    full_name = ('net.proto2.python.public.proto_builder.AnonymousProto_' +\n                 fields_hash.hexdigest())\n    try:\n      proto_cls = _GetMessageFromFactory(factory, full_name)\n      return proto_cls\n    except KeyError:\n      # The factory's DescriptorPool doesn't know about this class yet.\n      pass\n\n  # This is the first time we see this proto: add a new descriptor to the pool.\n  factory.pool.Add(\n      _MakeFileDescriptorProto(proto_file_name, full_name, field_items))\n  return _GetMessageFromFactory(factory, full_name)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/reflection.html","title":"reflection","text":"<p>Contains a metaclass and helper functions used to create protocol message classes from Descriptor objects at runtime.</p> <p>Recall that a metaclass is the \"type\" of a class. (A class is to a metaclass what an instance is to a class.)</p> <p>In this case, we use the GeneratedProtocolMessageType metaclass to inject all the useful functionality into the classes output by the protocol compiler at compile-time.</p> <p>The upshot of all this is that the real implementation details for ALL pure-Python protocol buffers are here in this file.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/reflection.html#client.ayon_nuke.vendor.google.protobuf.reflection.MakeClass","title":"<code>MakeClass(descriptor)</code>","text":"<p>Construct a class object for a protobuf described by descriptor.</p> <p>DEPRECATED: use MessageFactory.GetPrototype() instead.</p> <p>Parameters:</p> Name Type Description Default <code>descriptor</code> <p>A descriptor.Descriptor object describing the protobuf.</p> required <p>Returns:   The Message class object described by the descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/reflection.py</code> <pre><code>def MakeClass(descriptor):\n  \"\"\"Construct a class object for a protobuf described by descriptor.\n\n  DEPRECATED: use MessageFactory.GetPrototype() instead.\n\n  Args:\n    descriptor: A descriptor.Descriptor object describing the protobuf.\n  Returns:\n    The Message class object described by the descriptor.\n  \"\"\"\n  # Original implementation leads to duplicate message classes, which won't play\n  # well with extensions. Message factory info is also missing.\n  # Redirect to message_factory.\n  return symbol_database.Default().GetPrototype(descriptor)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/reflection.html#client.ayon_nuke.vendor.google.protobuf.reflection.ParseMessage","title":"<code>ParseMessage(descriptor, byte_str)</code>","text":"<p>Generate a new Message instance from this Descriptor and a byte string.</p> <p>DEPRECATED: ParseMessage is deprecated because it is using MakeClass(). Please use MessageFactory.GetPrototype() instead.</p> <p>Parameters:</p> Name Type Description Default <code>descriptor</code> <p>Protobuf Descriptor object</p> required <code>byte_str</code> <p>Serialized protocol buffer byte string</p> required <p>Returns:</p> Type Description <p>Newly created protobuf Message object.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/reflection.py</code> <pre><code>def ParseMessage(descriptor, byte_str):\n  \"\"\"Generate a new Message instance from this Descriptor and a byte string.\n\n  DEPRECATED: ParseMessage is deprecated because it is using MakeClass().\n  Please use MessageFactory.GetPrototype() instead.\n\n  Args:\n    descriptor: Protobuf Descriptor object\n    byte_str: Serialized protocol buffer byte string\n\n  Returns:\n    Newly created protobuf Message object.\n  \"\"\"\n  result_class = MakeClass(descriptor)\n  new_msg = result_class()\n  new_msg.ParseFromString(byte_str)\n  return new_msg\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html","title":"service","text":"<p>DEPRECATED:  Declares the RPC service interfaces.</p> <p>This module declares the abstract interfaces underlying proto2 RPC services.  These are intended to be independent of any particular RPC implementation, so that proto2 services can be used on top of a variety of implementations.  Starting with version 2.3.0, RPC implementations should not try to build on these, but should instead provide code generator plugins which generate code specific to the particular RPC implementation.  This way the generated code can be more appropriate for the implementation in use and can avoid unnecessary layers of indirection.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcChannel","title":"<code>RpcChannel</code>","text":"<p>               Bases: <code>object</code></p> <p>Abstract interface for an RPC channel.</p> <p>An RpcChannel represents a communication line to a service which can be used to call that service's methods.  The service may be running on another machine. Normally, you should not use an RpcChannel directly, but instead construct a stub {@link Service} wrapping it.  Example:</p> Example <p>RpcChannel channel = rpcImpl.Channel(\"remotehost.example.com:1234\") RpcController controller = rpcImpl.Controller() MyService service = MyService_Stub(channel) service.MyMethod(controller, request, callback)</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>class RpcChannel(object):\n\n  \"\"\"Abstract interface for an RPC channel.\n\n  An RpcChannel represents a communication line to a service which can be used\n  to call that service's methods.  The service may be running on another\n  machine. Normally, you should not use an RpcChannel directly, but instead\n  construct a stub {@link Service} wrapping it.  Example:\n\n  Example:\n    RpcChannel channel = rpcImpl.Channel(\"remotehost.example.com:1234\")\n    RpcController controller = rpcImpl.Controller()\n    MyService service = MyService_Stub(channel)\n    service.MyMethod(controller, request, callback)\n  \"\"\"\n\n  def CallMethod(self, method_descriptor, rpc_controller,\n                 request, response_class, done):\n    \"\"\"Calls the method identified by the descriptor.\n\n    Call the given method of the remote service.  The signature of this\n    procedure looks the same as Service.CallMethod(), but the requirements\n    are less strict in one important way:  the request object doesn't have to\n    be of any specific class as long as its descriptor is method.input_type.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcChannel.CallMethod","title":"<code>CallMethod(method_descriptor, rpc_controller, request, response_class, done)</code>","text":"<p>Calls the method identified by the descriptor.</p> <p>Call the given method of the remote service.  The signature of this procedure looks the same as Service.CallMethod(), but the requirements are less strict in one important way:  the request object doesn't have to be of any specific class as long as its descriptor is method.input_type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def CallMethod(self, method_descriptor, rpc_controller,\n               request, response_class, done):\n  \"\"\"Calls the method identified by the descriptor.\n\n  Call the given method of the remote service.  The signature of this\n  procedure looks the same as Service.CallMethod(), but the requirements\n  are less strict in one important way:  the request object doesn't have to\n  be of any specific class as long as its descriptor is method.input_type.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController","title":"<code>RpcController</code>","text":"<p>               Bases: <code>object</code></p> <p>An RpcController mediates a single method call.</p> <p>The primary purpose of the controller is to provide a way to manipulate settings specific to the RPC implementation and to find out about RPC-level errors. The methods provided by the RpcController interface are intended to be a \"least common denominator\" set of features which we expect all implementations to support.  Specific implementations may provide more advanced features (e.g. deadline propagation).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>class RpcController(object):\n\n  \"\"\"An RpcController mediates a single method call.\n\n  The primary purpose of the controller is to provide a way to manipulate\n  settings specific to the RPC implementation and to find out about RPC-level\n  errors. The methods provided by the RpcController interface are intended\n  to be a \"least common denominator\" set of features which we expect all\n  implementations to support.  Specific implementations may provide more\n  advanced features (e.g. deadline propagation).\n  \"\"\"\n\n  # Client-side methods below\n\n  def Reset(self):\n    \"\"\"Resets the RpcController to its initial state.\n\n    After the RpcController has been reset, it may be reused in\n    a new call. Must not be called while an RPC is in progress.\n    \"\"\"\n    raise NotImplementedError\n\n  def Failed(self):\n    \"\"\"Returns true if the call failed.\n\n    After a call has finished, returns true if the call failed.  The possible\n    reasons for failure depend on the RPC implementation.  Failed() must not\n    be called before a call has finished.  If Failed() returns true, the\n    contents of the response message are undefined.\n    \"\"\"\n    raise NotImplementedError\n\n  def ErrorText(self):\n    \"\"\"If Failed is true, returns a human-readable description of the error.\"\"\"\n    raise NotImplementedError\n\n  def StartCancel(self):\n    \"\"\"Initiate cancellation.\n\n    Advises the RPC system that the caller desires that the RPC call be\n    canceled.  The RPC system may cancel it immediately, may wait awhile and\n    then cancel it, or may not even cancel the call at all.  If the call is\n    canceled, the \"done\" callback will still be called and the RpcController\n    will indicate that the call failed at that time.\n    \"\"\"\n    raise NotImplementedError\n\n  # Server-side methods below\n\n  def SetFailed(self, reason):\n    \"\"\"Sets a failure reason.\n\n    Causes Failed() to return true on the client side.  \"reason\" will be\n    incorporated into the message returned by ErrorText().  If you find\n    you need to return machine-readable information about failures, you\n    should incorporate it into your response protocol buffer and should\n    NOT call SetFailed().\n    \"\"\"\n    raise NotImplementedError\n\n  def IsCanceled(self):\n    \"\"\"Checks if the client cancelled the RPC.\n\n    If true, indicates that the client canceled the RPC, so the server may\n    as well give up on replying to it.  The server should still call the\n    final \"done\" callback.\n    \"\"\"\n    raise NotImplementedError\n\n  def NotifyOnCancel(self, callback):\n    \"\"\"Sets a callback to invoke on cancel.\n\n    Asks that the given callback be called when the RPC is canceled.  The\n    callback will always be called exactly once.  If the RPC completes without\n    being canceled, the callback will be called after completion.  If the RPC\n    has already been canceled when NotifyOnCancel() is called, the callback\n    will be called immediately.\n\n    NotifyOnCancel() must be called no more than once per request.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.ErrorText","title":"<code>ErrorText()</code>","text":"<p>If Failed is true, returns a human-readable description of the error.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def ErrorText(self):\n  \"\"\"If Failed is true, returns a human-readable description of the error.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.Failed","title":"<code>Failed()</code>","text":"<p>Returns true if the call failed.</p> <p>After a call has finished, returns true if the call failed.  The possible reasons for failure depend on the RPC implementation.  Failed() must not be called before a call has finished.  If Failed() returns true, the contents of the response message are undefined.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def Failed(self):\n  \"\"\"Returns true if the call failed.\n\n  After a call has finished, returns true if the call failed.  The possible\n  reasons for failure depend on the RPC implementation.  Failed() must not\n  be called before a call has finished.  If Failed() returns true, the\n  contents of the response message are undefined.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.IsCanceled","title":"<code>IsCanceled()</code>","text":"<p>Checks if the client cancelled the RPC.</p> <p>If true, indicates that the client canceled the RPC, so the server may as well give up on replying to it.  The server should still call the final \"done\" callback.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def IsCanceled(self):\n  \"\"\"Checks if the client cancelled the RPC.\n\n  If true, indicates that the client canceled the RPC, so the server may\n  as well give up on replying to it.  The server should still call the\n  final \"done\" callback.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.NotifyOnCancel","title":"<code>NotifyOnCancel(callback)</code>","text":"<p>Sets a callback to invoke on cancel.</p> <p>Asks that the given callback be called when the RPC is canceled.  The callback will always be called exactly once.  If the RPC completes without being canceled, the callback will be called after completion.  If the RPC has already been canceled when NotifyOnCancel() is called, the callback will be called immediately.</p> <p>NotifyOnCancel() must be called no more than once per request.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def NotifyOnCancel(self, callback):\n  \"\"\"Sets a callback to invoke on cancel.\n\n  Asks that the given callback be called when the RPC is canceled.  The\n  callback will always be called exactly once.  If the RPC completes without\n  being canceled, the callback will be called after completion.  If the RPC\n  has already been canceled when NotifyOnCancel() is called, the callback\n  will be called immediately.\n\n  NotifyOnCancel() must be called no more than once per request.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.Reset","title":"<code>Reset()</code>","text":"<p>Resets the RpcController to its initial state.</p> <p>After the RpcController has been reset, it may be reused in a new call. Must not be called while an RPC is in progress.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def Reset(self):\n  \"\"\"Resets the RpcController to its initial state.\n\n  After the RpcController has been reset, it may be reused in\n  a new call. Must not be called while an RPC is in progress.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.SetFailed","title":"<code>SetFailed(reason)</code>","text":"<p>Sets a failure reason.</p> <p>Causes Failed() to return true on the client side.  \"reason\" will be incorporated into the message returned by ErrorText().  If you find you need to return machine-readable information about failures, you should incorporate it into your response protocol buffer and should NOT call SetFailed().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def SetFailed(self, reason):\n  \"\"\"Sets a failure reason.\n\n  Causes Failed() to return true on the client side.  \"reason\" will be\n  incorporated into the message returned by ErrorText().  If you find\n  you need to return machine-readable information about failures, you\n  should incorporate it into your response protocol buffer and should\n  NOT call SetFailed().\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcController.StartCancel","title":"<code>StartCancel()</code>","text":"<p>Initiate cancellation.</p> <p>Advises the RPC system that the caller desires that the RPC call be canceled.  The RPC system may cancel it immediately, may wait awhile and then cancel it, or may not even cancel the call at all.  If the call is canceled, the \"done\" callback will still be called and the RpcController will indicate that the call failed at that time.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def StartCancel(self):\n  \"\"\"Initiate cancellation.\n\n  Advises the RPC system that the caller desires that the RPC call be\n  canceled.  The RPC system may cancel it immediately, may wait awhile and\n  then cancel it, or may not even cancel the call at all.  If the call is\n  canceled, the \"done\" callback will still be called and the RpcController\n  will indicate that the call failed at that time.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.RpcException","title":"<code>RpcException</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Exception raised on failed blocking RPC method call.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>class RpcException(Exception):\n  \"\"\"Exception raised on failed blocking RPC method call.\"\"\"\n  pass\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.Service","title":"<code>Service</code>","text":"<p>               Bases: <code>object</code></p> <p>Abstract base interface for protocol-buffer-based RPC services.</p> <p>Services themselves are abstract classes (implemented either by servers or as stubs), but they subclass this base interface. The methods of this interface can be used to call the methods of the service without knowing its exact type at compile time (analogous to the Message interface).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>class Service(object):\n\n  \"\"\"Abstract base interface for protocol-buffer-based RPC services.\n\n  Services themselves are abstract classes (implemented either by servers or as\n  stubs), but they subclass this base interface. The methods of this\n  interface can be used to call the methods of the service without knowing\n  its exact type at compile time (analogous to the Message interface).\n  \"\"\"\n\n  def GetDescriptor():\n    \"\"\"Retrieves this service's descriptor.\"\"\"\n    raise NotImplementedError\n\n  def CallMethod(self, method_descriptor, rpc_controller,\n                 request, done):\n    \"\"\"Calls a method of the service specified by method_descriptor.\n\n    If \"done\" is None then the call is blocking and the response\n    message will be returned directly.  Otherwise the call is asynchronous\n    and \"done\" will later be called with the response value.\n\n    In the blocking case, RpcException will be raised on error.\n\n    Preconditions:\n\n    * method_descriptor.service == GetDescriptor\n    * request is of the exact same classes as returned by\n      GetRequestClass(method).\n    * After the call has started, the request must not be modified.\n    * \"rpc_controller\" is of the correct type for the RPC implementation being\n      used by this Service.  For stubs, the \"correct type\" depends on the\n      RpcChannel which the stub is using.\n\n    Postconditions:\n\n    * \"done\" will be called when the method is complete.  This may be\n      before CallMethod() returns or it may be at some point in the future.\n    * If the RPC failed, the response value passed to \"done\" will be None.\n      Further details about the failure can be found by querying the\n      RpcController.\n    \"\"\"\n    raise NotImplementedError\n\n  def GetRequestClass(self, method_descriptor):\n    \"\"\"Returns the class of the request message for the specified method.\n\n    CallMethod() requires that the request is of a particular subclass of\n    Message. GetRequestClass() gets the default instance of this required\n    type.\n\n    Example:\n      method = service.GetDescriptor().FindMethodByName(\"Foo\")\n      request = stub.GetRequestClass(method)()\n      request.ParseFromString(input)\n      service.CallMethod(method, request, callback)\n    \"\"\"\n    raise NotImplementedError\n\n  def GetResponseClass(self, method_descriptor):\n    \"\"\"Returns the class of the response message for the specified method.\n\n    This method isn't really needed, as the RpcChannel's CallMethod constructs\n    the response protocol message. It's provided anyway in case it is useful\n    for the caller to know the response type in advance.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.Service.CallMethod","title":"<code>CallMethod(method_descriptor, rpc_controller, request, done)</code>","text":"<p>Calls a method of the service specified by method_descriptor.</p> <p>If \"done\" is None then the call is blocking and the response message will be returned directly.  Otherwise the call is asynchronous and \"done\" will later be called with the response value.</p> <p>In the blocking case, RpcException will be raised on error.</p> <p>Preconditions:</p> <ul> <li>method_descriptor.service == GetDescriptor</li> <li>request is of the exact same classes as returned by   GetRequestClass(method).</li> <li>After the call has started, the request must not be modified.</li> <li>\"rpc_controller\" is of the correct type for the RPC implementation being   used by this Service.  For stubs, the \"correct type\" depends on the   RpcChannel which the stub is using.</li> </ul> <p>Postconditions:</p> <ul> <li>\"done\" will be called when the method is complete.  This may be   before CallMethod() returns or it may be at some point in the future.</li> <li>If the RPC failed, the response value passed to \"done\" will be None.   Further details about the failure can be found by querying the   RpcController.</li> </ul> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def CallMethod(self, method_descriptor, rpc_controller,\n               request, done):\n  \"\"\"Calls a method of the service specified by method_descriptor.\n\n  If \"done\" is None then the call is blocking and the response\n  message will be returned directly.  Otherwise the call is asynchronous\n  and \"done\" will later be called with the response value.\n\n  In the blocking case, RpcException will be raised on error.\n\n  Preconditions:\n\n  * method_descriptor.service == GetDescriptor\n  * request is of the exact same classes as returned by\n    GetRequestClass(method).\n  * After the call has started, the request must not be modified.\n  * \"rpc_controller\" is of the correct type for the RPC implementation being\n    used by this Service.  For stubs, the \"correct type\" depends on the\n    RpcChannel which the stub is using.\n\n  Postconditions:\n\n  * \"done\" will be called when the method is complete.  This may be\n    before CallMethod() returns or it may be at some point in the future.\n  * If the RPC failed, the response value passed to \"done\" will be None.\n    Further details about the failure can be found by querying the\n    RpcController.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.Service.GetDescriptor","title":"<code>GetDescriptor()</code>","text":"<p>Retrieves this service's descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def GetDescriptor():\n  \"\"\"Retrieves this service's descriptor.\"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.Service.GetRequestClass","title":"<code>GetRequestClass(method_descriptor)</code>","text":"<p>Returns the class of the request message for the specified method.</p> <p>CallMethod() requires that the request is of a particular subclass of Message. GetRequestClass() gets the default instance of this required type.</p> Example <p>method = service.GetDescriptor().FindMethodByName(\"Foo\") request = stub.GetRequestClass(method)() request.ParseFromString(input) service.CallMethod(method, request, callback)</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def GetRequestClass(self, method_descriptor):\n  \"\"\"Returns the class of the request message for the specified method.\n\n  CallMethod() requires that the request is of a particular subclass of\n  Message. GetRequestClass() gets the default instance of this required\n  type.\n\n  Example:\n    method = service.GetDescriptor().FindMethodByName(\"Foo\")\n    request = stub.GetRequestClass(method)()\n    request.ParseFromString(input)\n    service.CallMethod(method, request, callback)\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service.html#client.ayon_nuke.vendor.google.protobuf.service.Service.GetResponseClass","title":"<code>GetResponseClass(method_descriptor)</code>","text":"<p>Returns the class of the response message for the specified method.</p> <p>This method isn't really needed, as the RpcChannel's CallMethod constructs the response protocol message. It's provided anyway in case it is useful for the caller to know the response type in advance.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service.py</code> <pre><code>def GetResponseClass(self, method_descriptor):\n  \"\"\"Returns the class of the response message for the specified method.\n\n  This method isn't really needed, as the RpcChannel's CallMethod constructs\n  the response protocol message. It's provided anyway in case it is useful\n  for the caller to know the response type in advance.\n  \"\"\"\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service_reflection.html","title":"service_reflection","text":"<p>Contains metaclasses used to create protocol service and service stub classes from ServiceDescriptor objects at runtime.</p> <p>The GeneratedServiceType and GeneratedServiceStubType metaclasses are used to inject all useful functionality into the classes output by the protocol compiler at compile-time.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service_reflection.html#client.ayon_nuke.vendor.google.protobuf.service_reflection.GeneratedServiceStubType","title":"<code>GeneratedServiceStubType</code>","text":"<p>               Bases: <code>GeneratedServiceType</code></p> <p>Metaclass for service stubs created at runtime from ServiceDescriptors.</p> <p>This class has similar responsibilities as GeneratedServiceType, except that it creates the service stub classes.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service_reflection.py</code> <pre><code>class GeneratedServiceStubType(GeneratedServiceType):\n\n  \"\"\"Metaclass for service stubs created at runtime from ServiceDescriptors.\n\n  This class has similar responsibilities as GeneratedServiceType, except that\n  it creates the service stub classes.\n  \"\"\"\n\n  _DESCRIPTOR_KEY = 'DESCRIPTOR'\n\n  def __init__(cls, name, bases, dictionary):\n    \"\"\"Creates a message service stub class.\n\n    Args:\n      name: Name of the class (ignored, here).\n      bases: Base classes of the class being constructed.\n      dictionary: The class dictionary of the class being constructed.\n        dictionary[_DESCRIPTOR_KEY] must contain a ServiceDescriptor object\n        describing this protocol service type.\n    \"\"\"\n    super(GeneratedServiceStubType, cls).__init__(name, bases, dictionary)\n    # Don't do anything if this class doesn't have a descriptor. This happens\n    # when a service stub is subclassed.\n    if GeneratedServiceStubType._DESCRIPTOR_KEY not in dictionary:\n      return\n\n    descriptor = dictionary[GeneratedServiceStubType._DESCRIPTOR_KEY]\n    service_stub_builder = _ServiceStubBuilder(descriptor)\n    service_stub_builder.BuildServiceStub(cls)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service_reflection.html#client.ayon_nuke.vendor.google.protobuf.service_reflection.GeneratedServiceStubType.__init__","title":"<code>__init__(name, bases, dictionary)</code>","text":"<p>Creates a message service stub class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Name of the class (ignored, here).</p> required <code>bases</code> <p>Base classes of the class being constructed.</p> required <code>dictionary</code> <p>The class dictionary of the class being constructed. dictionary[_DESCRIPTOR_KEY] must contain a ServiceDescriptor object describing this protocol service type.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/service_reflection.py</code> <pre><code>def __init__(cls, name, bases, dictionary):\n  \"\"\"Creates a message service stub class.\n\n  Args:\n    name: Name of the class (ignored, here).\n    bases: Base classes of the class being constructed.\n    dictionary: The class dictionary of the class being constructed.\n      dictionary[_DESCRIPTOR_KEY] must contain a ServiceDescriptor object\n      describing this protocol service type.\n  \"\"\"\n  super(GeneratedServiceStubType, cls).__init__(name, bases, dictionary)\n  # Don't do anything if this class doesn't have a descriptor. This happens\n  # when a service stub is subclassed.\n  if GeneratedServiceStubType._DESCRIPTOR_KEY not in dictionary:\n    return\n\n  descriptor = dictionary[GeneratedServiceStubType._DESCRIPTOR_KEY]\n  service_stub_builder = _ServiceStubBuilder(descriptor)\n  service_stub_builder.BuildServiceStub(cls)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service_reflection.html#client.ayon_nuke.vendor.google.protobuf.service_reflection.GeneratedServiceType","title":"<code>GeneratedServiceType</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass for service classes created at runtime from ServiceDescriptors.</p> <p>Implementations for all methods described in the Service class are added here by this class. We also create properties to allow getting/setting all fields in the protocol message.</p> <p>The protocol compiler currently uses this metaclass to create protocol service classes at runtime. Clients can also manually create their own classes at runtime, as in this example::</p> <p>mydescriptor = ServiceDescriptor(.....)   class MyProtoService(service.Service):     metaclass = GeneratedServiceType     DESCRIPTOR = mydescriptor   myservice_instance = MyProtoService()   # ...</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/service_reflection.py</code> <pre><code>class GeneratedServiceType(type):\n\n  \"\"\"Metaclass for service classes created at runtime from ServiceDescriptors.\n\n  Implementations for all methods described in the Service class are added here\n  by this class. We also create properties to allow getting/setting all fields\n  in the protocol message.\n\n  The protocol compiler currently uses this metaclass to create protocol service\n  classes at runtime. Clients can also manually create their own classes at\n  runtime, as in this example::\n\n    mydescriptor = ServiceDescriptor(.....)\n    class MyProtoService(service.Service):\n      __metaclass__ = GeneratedServiceType\n      DESCRIPTOR = mydescriptor\n    myservice_instance = MyProtoService()\n    # ...\n  \"\"\"\n\n  _DESCRIPTOR_KEY = 'DESCRIPTOR'\n\n  def __init__(cls, name, bases, dictionary):\n    \"\"\"Creates a message service class.\n\n    Args:\n      name: Name of the class (ignored, but required by the metaclass\n        protocol).\n      bases: Base classes of the class being constructed.\n      dictionary: The class dictionary of the class being constructed.\n        dictionary[_DESCRIPTOR_KEY] must contain a ServiceDescriptor object\n        describing this protocol service type.\n    \"\"\"\n    # Don't do anything if this class doesn't have a descriptor. This happens\n    # when a service class is subclassed.\n    if GeneratedServiceType._DESCRIPTOR_KEY not in dictionary:\n      return\n\n    descriptor = dictionary[GeneratedServiceType._DESCRIPTOR_KEY]\n    service_builder = _ServiceBuilder(descriptor)\n    service_builder.BuildService(cls)\n    cls.DESCRIPTOR = descriptor\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/service_reflection.html#client.ayon_nuke.vendor.google.protobuf.service_reflection.GeneratedServiceType.__init__","title":"<code>__init__(name, bases, dictionary)</code>","text":"<p>Creates a message service class.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Name of the class (ignored, but required by the metaclass protocol).</p> required <code>bases</code> <p>Base classes of the class being constructed.</p> required <code>dictionary</code> <p>The class dictionary of the class being constructed. dictionary[_DESCRIPTOR_KEY] must contain a ServiceDescriptor object describing this protocol service type.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/service_reflection.py</code> <pre><code>def __init__(cls, name, bases, dictionary):\n  \"\"\"Creates a message service class.\n\n  Args:\n    name: Name of the class (ignored, but required by the metaclass\n      protocol).\n    bases: Base classes of the class being constructed.\n    dictionary: The class dictionary of the class being constructed.\n      dictionary[_DESCRIPTOR_KEY] must contain a ServiceDescriptor object\n      describing this protocol service type.\n  \"\"\"\n  # Don't do anything if this class doesn't have a descriptor. This happens\n  # when a service class is subclassed.\n  if GeneratedServiceType._DESCRIPTOR_KEY not in dictionary:\n    return\n\n  descriptor = dictionary[GeneratedServiceType._DESCRIPTOR_KEY]\n  service_builder = _ServiceBuilder(descriptor)\n  service_builder.BuildService(cls)\n  cls.DESCRIPTOR = descriptor\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/source_context_pb2.html","title":"source_context_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/struct_pb2.html","title":"struct_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html","title":"symbol_database","text":"<p>A database of Python protocol buffer generated symbols.</p> <p>SymbolDatabase is the MessageFactory for messages generated at compile time, and makes it easy to create new instances of a registered type, given only the type's protocol buffer symbol name.</p> <p>Example usage::</p> <p>db = symbol_database.SymbolDatabase()</p> <p># Register symbols of interest, from one or multiple files.   db.RegisterFileDescriptor(my_proto_pb2.DESCRIPTOR)   db.RegisterMessage(my_proto_pb2.MyMessage)   db.RegisterEnumDescriptor(my_proto_pb2.MyEnum.DESCRIPTOR)</p> <p># The database can be used as a MessageFactory, to generate types based on   # their name:   types = db.GetMessages(['my_proto.proto'])   my_message_instance = types'MyMessage'</p> <p># The database's underlying descriptor pool can be queried, so it's not   # necessary to know a type's filename to be able to generate it:   filename = db.pool.FindFileContainingSymbol('MyMessage')   my_message_instance = db.GetMessages([filename])'MyMessage'</p> <p># This functionality is also provided directly via a convenience method:   my_message_instance = db.GetSymbol('MyMessage')()</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase","title":"<code>SymbolDatabase</code>","text":"<p>               Bases: <code>MessageFactory</code></p> <p>A database of Python generated symbols.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>class SymbolDatabase(message_factory.MessageFactory):\n  \"\"\"A database of Python generated symbols.\"\"\"\n\n  def RegisterMessage(self, message):\n    \"\"\"Registers the given message type in the local database.\n\n    Calls to GetSymbol() and GetMessages() will return messages registered here.\n\n    Args:\n      message: A :class:`google.protobuf.message.Message` subclass (or\n        instance); its descriptor will be registered.\n\n    Returns:\n      The provided message.\n    \"\"\"\n\n    desc = message.DESCRIPTOR\n    self._classes[desc] = message\n    self.RegisterMessageDescriptor(desc)\n    return message\n\n  def RegisterMessageDescriptor(self, message_descriptor):\n    \"\"\"Registers the given message descriptor in the local database.\n\n    Args:\n      message_descriptor (Descriptor): the message descriptor to add.\n    \"\"\"\n    if api_implementation.Type() == 'python':\n      # pylint: disable=protected-access\n      self.pool._AddDescriptor(message_descriptor)\n\n  def RegisterEnumDescriptor(self, enum_descriptor):\n    \"\"\"Registers the given enum descriptor in the local database.\n\n    Args:\n      enum_descriptor (EnumDescriptor): The enum descriptor to register.\n\n    Returns:\n      EnumDescriptor: The provided descriptor.\n    \"\"\"\n    if api_implementation.Type() == 'python':\n      # pylint: disable=protected-access\n      self.pool._AddEnumDescriptor(enum_descriptor)\n    return enum_descriptor\n\n  def RegisterServiceDescriptor(self, service_descriptor):\n    \"\"\"Registers the given service descriptor in the local database.\n\n    Args:\n      service_descriptor (ServiceDescriptor): the service descriptor to\n        register.\n    \"\"\"\n    if api_implementation.Type() == 'python':\n      # pylint: disable=protected-access\n      self.pool._AddServiceDescriptor(service_descriptor)\n\n  def RegisterFileDescriptor(self, file_descriptor):\n    \"\"\"Registers the given file descriptor in the local database.\n\n    Args:\n      file_descriptor (FileDescriptor): The file descriptor to register.\n    \"\"\"\n    if api_implementation.Type() == 'python':\n      # pylint: disable=protected-access\n      self.pool._InternalAddFileDescriptor(file_descriptor)\n\n  def GetSymbol(self, symbol):\n    \"\"\"Tries to find a symbol in the local database.\n\n    Currently, this method only returns message.Message instances, however, if\n    may be extended in future to support other symbol types.\n\n    Args:\n      symbol (str): a protocol buffer symbol.\n\n    Returns:\n      A Python class corresponding to the symbol.\n\n    Raises:\n      KeyError: if the symbol could not be found.\n    \"\"\"\n\n    return self._classes[self.pool.FindMessageTypeByName(symbol)]\n\n  def GetMessages(self, files):\n    # TODO(amauryfa): Fix the differences with MessageFactory.\n    \"\"\"Gets all registered messages from a specified file.\n\n    Only messages already created and registered will be returned; (this is the\n    case for imported _pb2 modules)\n    But unlike MessageFactory, this version also returns already defined nested\n    messages, but does not register any message extensions.\n\n    Args:\n      files (list[str]): The file names to extract messages from.\n\n    Returns:\n      A dictionary mapping proto names to the message classes.\n\n    Raises:\n      KeyError: if a file could not be found.\n    \"\"\"\n\n    def _GetAllMessages(desc):\n      \"\"\"Walk a message Descriptor and recursively yields all message names.\"\"\"\n      yield desc\n      for msg_desc in desc.nested_types:\n        for nested_desc in _GetAllMessages(msg_desc):\n          yield nested_desc\n\n    result = {}\n    for file_name in files:\n      file_desc = self.pool.FindFileByName(file_name)\n      for msg_desc in file_desc.message_types_by_name.values():\n        for desc in _GetAllMessages(msg_desc):\n          try:\n            result[desc.full_name] = self._classes[desc]\n          except KeyError:\n            # This descriptor has no registered class, skip it.\n            pass\n    return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.GetMessages","title":"<code>GetMessages(files)</code>","text":"<p>Gets all registered messages from a specified file.</p> <p>Only messages already created and registered will be returned; (this is the case for imported _pb2 modules) But unlike MessageFactory, this version also returns already defined nested messages, but does not register any message extensions.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>list[str]</code> <p>The file names to extract messages from.</p> required <p>Returns:</p> Type Description <p>A dictionary mapping proto names to the message classes.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if a file could not be found.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def GetMessages(self, files):\n  # TODO(amauryfa): Fix the differences with MessageFactory.\n  \"\"\"Gets all registered messages from a specified file.\n\n  Only messages already created and registered will be returned; (this is the\n  case for imported _pb2 modules)\n  But unlike MessageFactory, this version also returns already defined nested\n  messages, but does not register any message extensions.\n\n  Args:\n    files (list[str]): The file names to extract messages from.\n\n  Returns:\n    A dictionary mapping proto names to the message classes.\n\n  Raises:\n    KeyError: if a file could not be found.\n  \"\"\"\n\n  def _GetAllMessages(desc):\n    \"\"\"Walk a message Descriptor and recursively yields all message names.\"\"\"\n    yield desc\n    for msg_desc in desc.nested_types:\n      for nested_desc in _GetAllMessages(msg_desc):\n        yield nested_desc\n\n  result = {}\n  for file_name in files:\n    file_desc = self.pool.FindFileByName(file_name)\n    for msg_desc in file_desc.message_types_by_name.values():\n      for desc in _GetAllMessages(msg_desc):\n        try:\n          result[desc.full_name] = self._classes[desc]\n        except KeyError:\n          # This descriptor has no registered class, skip it.\n          pass\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.GetSymbol","title":"<code>GetSymbol(symbol)</code>","text":"<p>Tries to find a symbol in the local database.</p> <p>Currently, this method only returns message.Message instances, however, if may be extended in future to support other symbol types.</p> <p>Parameters:</p> Name Type Description Default <code>symbol</code> <code>str</code> <p>a protocol buffer symbol.</p> required <p>Returns:</p> Type Description <p>A Python class corresponding to the symbol.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>if the symbol could not be found.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def GetSymbol(self, symbol):\n  \"\"\"Tries to find a symbol in the local database.\n\n  Currently, this method only returns message.Message instances, however, if\n  may be extended in future to support other symbol types.\n\n  Args:\n    symbol (str): a protocol buffer symbol.\n\n  Returns:\n    A Python class corresponding to the symbol.\n\n  Raises:\n    KeyError: if the symbol could not be found.\n  \"\"\"\n\n  return self._classes[self.pool.FindMessageTypeByName(symbol)]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.RegisterEnumDescriptor","title":"<code>RegisterEnumDescriptor(enum_descriptor)</code>","text":"<p>Registers the given enum descriptor in the local database.</p> <p>Parameters:</p> Name Type Description Default <code>enum_descriptor</code> <code>EnumDescriptor</code> <p>The enum descriptor to register.</p> required <p>Returns:</p> Name Type Description <code>EnumDescriptor</code> <p>The provided descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def RegisterEnumDescriptor(self, enum_descriptor):\n  \"\"\"Registers the given enum descriptor in the local database.\n\n  Args:\n    enum_descriptor (EnumDescriptor): The enum descriptor to register.\n\n  Returns:\n    EnumDescriptor: The provided descriptor.\n  \"\"\"\n  if api_implementation.Type() == 'python':\n    # pylint: disable=protected-access\n    self.pool._AddEnumDescriptor(enum_descriptor)\n  return enum_descriptor\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.RegisterFileDescriptor","title":"<code>RegisterFileDescriptor(file_descriptor)</code>","text":"<p>Registers the given file descriptor in the local database.</p> <p>Parameters:</p> Name Type Description Default <code>file_descriptor</code> <code>FileDescriptor</code> <p>The file descriptor to register.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def RegisterFileDescriptor(self, file_descriptor):\n  \"\"\"Registers the given file descriptor in the local database.\n\n  Args:\n    file_descriptor (FileDescriptor): The file descriptor to register.\n  \"\"\"\n  if api_implementation.Type() == 'python':\n    # pylint: disable=protected-access\n    self.pool._InternalAddFileDescriptor(file_descriptor)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.RegisterMessage","title":"<code>RegisterMessage(message)</code>","text":"<p>Registers the given message type in the local database.</p> <p>Calls to GetSymbol() and GetMessages() will return messages registered here.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>A :class:<code>google.protobuf.message.Message</code> subclass (or instance); its descriptor will be registered.</p> required <p>Returns:</p> Type Description <p>The provided message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def RegisterMessage(self, message):\n  \"\"\"Registers the given message type in the local database.\n\n  Calls to GetSymbol() and GetMessages() will return messages registered here.\n\n  Args:\n    message: A :class:`google.protobuf.message.Message` subclass (or\n      instance); its descriptor will be registered.\n\n  Returns:\n    The provided message.\n  \"\"\"\n\n  desc = message.DESCRIPTOR\n  self._classes[desc] = message\n  self.RegisterMessageDescriptor(desc)\n  return message\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.RegisterMessageDescriptor","title":"<code>RegisterMessageDescriptor(message_descriptor)</code>","text":"<p>Registers the given message descriptor in the local database.</p> <p>Parameters:</p> Name Type Description Default <code>message_descriptor</code> <code>Descriptor</code> <p>the message descriptor to add.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def RegisterMessageDescriptor(self, message_descriptor):\n  \"\"\"Registers the given message descriptor in the local database.\n\n  Args:\n    message_descriptor (Descriptor): the message descriptor to add.\n  \"\"\"\n  if api_implementation.Type() == 'python':\n    # pylint: disable=protected-access\n    self.pool._AddDescriptor(message_descriptor)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.SymbolDatabase.RegisterServiceDescriptor","title":"<code>RegisterServiceDescriptor(service_descriptor)</code>","text":"<p>Registers the given service descriptor in the local database.</p> <p>Parameters:</p> Name Type Description Default <code>service_descriptor</code> <code>ServiceDescriptor</code> <p>the service descriptor to register.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def RegisterServiceDescriptor(self, service_descriptor):\n  \"\"\"Registers the given service descriptor in the local database.\n\n  Args:\n    service_descriptor (ServiceDescriptor): the service descriptor to\n      register.\n  \"\"\"\n  if api_implementation.Type() == 'python':\n    # pylint: disable=protected-access\n    self.pool._AddServiceDescriptor(service_descriptor)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/symbol_database.html#client.ayon_nuke.vendor.google.protobuf.symbol_database.Default","title":"<code>Default()</code>","text":"<p>Returns the default SymbolDatabase.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/symbol_database.py</code> <pre><code>def Default():\n  \"\"\"Returns the default SymbolDatabase.\"\"\"\n  return _DEFAULT\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_encoding.html","title":"text_encoding","text":"<p>Encoding related utilities.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_encoding.html#client.ayon_nuke.vendor.google.protobuf.text_encoding.CEscape","title":"<code>CEscape(text, as_utf8)</code>","text":"<p>Escape a bytes string for use in an text protocol buffer.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>A byte string to be escaped.</p> required <code>as_utf8</code> <p>Specifies if result may contain non-ASCII characters.   In Python 3 this allows unescaped non-ASCII Unicode characters.   In Python 2 the return value will be valid UTF-8 rather than only ASCII.</p> required <p>Returns:   Escaped string (str).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_encoding.py</code> <pre><code>def CEscape(text, as_utf8):\n  # type: (...) -&gt; str\n  \"\"\"Escape a bytes string for use in an text protocol buffer.\n\n  Args:\n    text: A byte string to be escaped.\n    as_utf8: Specifies if result may contain non-ASCII characters.\n        In Python 3 this allows unescaped non-ASCII Unicode characters.\n        In Python 2 the return value will be valid UTF-8 rather than only ASCII.\n  Returns:\n    Escaped string (str).\n  \"\"\"\n  # Python's text.encode() 'string_escape' or 'unicode_escape' codecs do not\n  # satisfy our needs; they encodes unprintable characters using two-digit hex\n  # escapes whereas our C++ unescaping function allows hex escapes to be any\n  # length.  So, \"\\0011\".encode('string_escape') ends up being \"\\\\x011\", which\n  # will be decoded in C++ as a single-character string with char code 0x11.\n  text_is_unicode = isinstance(text, str)\n  if as_utf8 and text_is_unicode:\n    # We're already unicode, no processing beyond control char escapes.\n    return text.translate(_cescape_chr_to_symbol_map)\n  ord_ = ord if text_is_unicode else lambda x: x  # bytes iterate as ints.\n  if as_utf8:\n    return ''.join(_cescape_unicode_to_str[ord_(c)] for c in text)\n  return ''.join(_cescape_byte_to_str[ord_(c)] for c in text)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_encoding.html#client.ayon_nuke.vendor.google.protobuf.text_encoding.CUnescape","title":"<code>CUnescape(text)</code>","text":"<p>Unescape a text string with C-style escape sequences to UTF-8 bytes.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>The data to parse in a str.</p> required <p>Returns:   A byte string.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_encoding.py</code> <pre><code>def CUnescape(text):\n  # type: (str) -&gt; bytes\n  \"\"\"Unescape a text string with C-style escape sequences to UTF-8 bytes.\n\n  Args:\n    text: The data to parse in a str.\n  Returns:\n    A byte string.\n  \"\"\"\n\n  def ReplaceHex(m):\n    # Only replace the match if the number of leading back slashes is odd. i.e.\n    # the slash itself is not escaped.\n    if len(m.group(1)) &amp; 1:\n      return m.group(1) + 'x0' + m.group(2)\n    return m.group(0)\n\n  # This is required because the 'string_escape' encoding doesn't\n  # allow single-digit hex escapes (like '\\xf').\n  result = _CUNESCAPE_HEX.sub(ReplaceHex, text)\n\n  return (result.encode('utf-8')  # Make it bytes to allow decode.\n          .decode('unicode_escape')\n          # Make it bytes again to return the proper type.\n          .encode('raw_unicode_escape'))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html","title":"text_format","text":"<p>Contains routines for printing protocol messages in text format.</p> <p>Simple usage example::</p> <p># Create a proto object and serialize it to a text proto string.   message = my_proto_pb2.MyMessage(foo='bar')   text_proto = text_format.MessageToString(message)</p> <p># Parse a text proto string.   message = text_format.Parse(text_proto, my_proto_pb2.MyMessage())</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Error","title":"<code>Error</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Top-level module error for text_format.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>class Error(Exception):\n  \"\"\"Top-level module error for text_format.\"\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.ParseError","title":"<code>ParseError</code>","text":"<p>               Bases: <code>Error</code></p> <p>Thrown in case of text parsing or tokenizing error.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>class ParseError(Error):\n  \"\"\"Thrown in case of text parsing or tokenizing error.\"\"\"\n\n  def __init__(self, message=None, line=None, column=None):\n    if message is not None and line is not None:\n      loc = str(line)\n      if column is not None:\n        loc += ':{0}'.format(column)\n      message = '{0} : {1}'.format(loc, message)\n    if message is not None:\n      super(ParseError, self).__init__(message)\n    else:\n      super(ParseError, self).__init__()\n    self._line = line\n    self._column = column\n\n  def GetLine(self):\n    return self._line\n\n  def GetColumn(self):\n    return self._column\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer","title":"<code>Tokenizer</code>","text":"<p>               Bases: <code>object</code></p> <p>Protocol buffer text representation tokenizer.</p> <p>This class handles the lower level string parsing by splitting it into meaningful tokens.</p> <p>It was directly ported from the Java protocol buffer API.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>class Tokenizer(object):\n  \"\"\"Protocol buffer text representation tokenizer.\n\n  This class handles the lower level string parsing by splitting it into\n  meaningful tokens.\n\n  It was directly ported from the Java protocol buffer API.\n  \"\"\"\n\n  _WHITESPACE = re.compile(r'\\s+')\n  _COMMENT = re.compile(r'(\\s*#.*$)', re.MULTILINE)\n  _WHITESPACE_OR_COMMENT = re.compile(r'(\\s|(#.*$))+', re.MULTILINE)\n  _TOKEN = re.compile('|'.join([\n      r'[a-zA-Z_][0-9a-zA-Z_+-]*',  # an identifier\n      r'([0-9+-]|(\\.[0-9]))[0-9a-zA-Z_.+-]*',  # a number\n  ] + [  # quoted str for each quote mark\n      # Avoid backtracking! https://stackoverflow.com/a/844267\n      r'{qt}[^{qt}\\n\\\\]*((\\\\.)+[^{qt}\\n\\\\]*)*({qt}|\\\\?$)'.format(qt=mark)\n      for mark in _QUOTES\n  ]))\n\n  _IDENTIFIER = re.compile(r'[^\\d\\W]\\w*')\n  _IDENTIFIER_OR_NUMBER = re.compile(r'\\w+')\n\n  def __init__(self, lines, skip_comments=True):\n    self._position = 0\n    self._line = -1\n    self._column = 0\n    self._token_start = None\n    self.token = ''\n    self._lines = iter(lines)\n    self._current_line = ''\n    self._previous_line = 0\n    self._previous_column = 0\n    self._more_lines = True\n    self._skip_comments = skip_comments\n    self._whitespace_pattern = (skip_comments and self._WHITESPACE_OR_COMMENT\n                                or self._WHITESPACE)\n    self._SkipWhitespace()\n    self.NextToken()\n\n  def LookingAt(self, token):\n    return self.token == token\n\n  def AtEnd(self):\n    \"\"\"Checks the end of the text was reached.\n\n    Returns:\n      True iff the end was reached.\n    \"\"\"\n    return not self.token\n\n  def _PopLine(self):\n    while len(self._current_line) &lt;= self._column:\n      try:\n        self._current_line = next(self._lines)\n      except StopIteration:\n        self._current_line = ''\n        self._more_lines = False\n        return\n      else:\n        self._line += 1\n        self._column = 0\n\n  def _SkipWhitespace(self):\n    while True:\n      self._PopLine()\n      match = self._whitespace_pattern.match(self._current_line, self._column)\n      if not match:\n        break\n      length = len(match.group(0))\n      self._column += length\n\n  def TryConsume(self, token):\n    \"\"\"Tries to consume a given piece of text.\n\n    Args:\n      token: Text to consume.\n\n    Returns:\n      True iff the text was consumed.\n    \"\"\"\n    if self.token == token:\n      self.NextToken()\n      return True\n    return False\n\n  def Consume(self, token):\n    \"\"\"Consumes a piece of text.\n\n    Args:\n      token: Text to consume.\n\n    Raises:\n      ParseError: If the text couldn't be consumed.\n    \"\"\"\n    if not self.TryConsume(token):\n      raise self.ParseError('Expected \"%s\".' % token)\n\n  def ConsumeComment(self):\n    result = self.token\n    if not self._COMMENT.match(result):\n      raise self.ParseError('Expected comment.')\n    self.NextToken()\n    return result\n\n  def ConsumeCommentOrTrailingComment(self):\n    \"\"\"Consumes a comment, returns a 2-tuple (trailing bool, comment str).\"\"\"\n\n    # Tokenizer initializes _previous_line and _previous_column to 0. As the\n    # tokenizer starts, it looks like there is a previous token on the line.\n    just_started = self._line == 0 and self._column == 0\n\n    before_parsing = self._previous_line\n    comment = self.ConsumeComment()\n\n    # A trailing comment is a comment on the same line than the previous token.\n    trailing = (self._previous_line == before_parsing\n                and not just_started)\n\n    return trailing, comment\n\n  def TryConsumeIdentifier(self):\n    try:\n      self.ConsumeIdentifier()\n      return True\n    except ParseError:\n      return False\n\n  def ConsumeIdentifier(self):\n    \"\"\"Consumes protocol message field identifier.\n\n    Returns:\n      Identifier string.\n\n    Raises:\n      ParseError: If an identifier couldn't be consumed.\n    \"\"\"\n    result = self.token\n    if not self._IDENTIFIER.match(result):\n      raise self.ParseError('Expected identifier.')\n    self.NextToken()\n    return result\n\n  def TryConsumeIdentifierOrNumber(self):\n    try:\n      self.ConsumeIdentifierOrNumber()\n      return True\n    except ParseError:\n      return False\n\n  def ConsumeIdentifierOrNumber(self):\n    \"\"\"Consumes protocol message field identifier.\n\n    Returns:\n      Identifier string.\n\n    Raises:\n      ParseError: If an identifier couldn't be consumed.\n    \"\"\"\n    result = self.token\n    if not self._IDENTIFIER_OR_NUMBER.match(result):\n      raise self.ParseError('Expected identifier or number, got %s.' % result)\n    self.NextToken()\n    return result\n\n  def TryConsumeInteger(self):\n    try:\n      self.ConsumeInteger()\n      return True\n    except ParseError:\n      return False\n\n  def ConsumeInteger(self):\n    \"\"\"Consumes an integer number.\n\n    Returns:\n      The integer parsed.\n\n    Raises:\n      ParseError: If an integer couldn't be consumed.\n    \"\"\"\n    try:\n      result = _ParseAbstractInteger(self.token)\n    except ValueError as e:\n      raise self.ParseError(str(e))\n    self.NextToken()\n    return result\n\n  def TryConsumeFloat(self):\n    try:\n      self.ConsumeFloat()\n      return True\n    except ParseError:\n      return False\n\n  def ConsumeFloat(self):\n    \"\"\"Consumes an floating point number.\n\n    Returns:\n      The number parsed.\n\n    Raises:\n      ParseError: If a floating point number couldn't be consumed.\n    \"\"\"\n    try:\n      result = ParseFloat(self.token)\n    except ValueError as e:\n      raise self.ParseError(str(e))\n    self.NextToken()\n    return result\n\n  def ConsumeBool(self):\n    \"\"\"Consumes a boolean value.\n\n    Returns:\n      The bool parsed.\n\n    Raises:\n      ParseError: If a boolean value couldn't be consumed.\n    \"\"\"\n    try:\n      result = ParseBool(self.token)\n    except ValueError as e:\n      raise self.ParseError(str(e))\n    self.NextToken()\n    return result\n\n  def TryConsumeByteString(self):\n    try:\n      self.ConsumeByteString()\n      return True\n    except ParseError:\n      return False\n\n  def ConsumeString(self):\n    \"\"\"Consumes a string value.\n\n    Returns:\n      The string parsed.\n\n    Raises:\n      ParseError: If a string value couldn't be consumed.\n    \"\"\"\n    the_bytes = self.ConsumeByteString()\n    try:\n      return str(the_bytes, 'utf-8')\n    except UnicodeDecodeError as e:\n      raise self._StringParseError(e)\n\n  def ConsumeByteString(self):\n    \"\"\"Consumes a byte array value.\n\n    Returns:\n      The array parsed (as a string).\n\n    Raises:\n      ParseError: If a byte array value couldn't be consumed.\n    \"\"\"\n    the_list = [self._ConsumeSingleByteString()]\n    while self.token and self.token[0] in _QUOTES:\n      the_list.append(self._ConsumeSingleByteString())\n    return b''.join(the_list)\n\n  def _ConsumeSingleByteString(self):\n    \"\"\"Consume one token of a string literal.\n\n    String literals (whether bytes or text) can come in multiple adjacent\n    tokens which are automatically concatenated, like in C or Python.  This\n    method only consumes one token.\n\n    Returns:\n      The token parsed.\n    Raises:\n      ParseError: When the wrong format data is found.\n    \"\"\"\n    text = self.token\n    if len(text) &lt; 1 or text[0] not in _QUOTES:\n      raise self.ParseError('Expected string but found: %r' % (text,))\n\n    if len(text) &lt; 2 or text[-1] != text[0]:\n      raise self.ParseError('String missing ending quote: %r' % (text,))\n\n    try:\n      result = text_encoding.CUnescape(text[1:-1])\n    except ValueError as e:\n      raise self.ParseError(str(e))\n    self.NextToken()\n    return result\n\n  def ConsumeEnum(self, field):\n    try:\n      result = ParseEnum(field, self.token)\n    except ValueError as e:\n      raise self.ParseError(str(e))\n    self.NextToken()\n    return result\n\n  def ParseErrorPreviousToken(self, message):\n    \"\"\"Creates and *returns* a ParseError for the previously read token.\n\n    Args:\n      message: A message to set for the exception.\n\n    Returns:\n      A ParseError instance.\n    \"\"\"\n    return ParseError(message, self._previous_line + 1,\n                      self._previous_column + 1)\n\n  def ParseError(self, message):\n    \"\"\"Creates and *returns* a ParseError for the current token.\"\"\"\n    return ParseError('\\'' + self._current_line + '\\': ' + message,\n                      self._line + 1, self._column + 1)\n\n  def _StringParseError(self, e):\n    return self.ParseError('Couldn\\'t parse string: ' + str(e))\n\n  def NextToken(self):\n    \"\"\"Reads the next meaningful token.\"\"\"\n    self._previous_line = self._line\n    self._previous_column = self._column\n\n    self._column += len(self.token)\n    self._SkipWhitespace()\n\n    if not self._more_lines:\n      self.token = ''\n      return\n\n    match = self._TOKEN.match(self._current_line, self._column)\n    if not match and not self._skip_comments:\n      match = self._COMMENT.match(self._current_line, self._column)\n    if match:\n      token = match.group(0)\n      self.token = token\n    else:\n      self.token = self._current_line[self._column]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.AtEnd","title":"<code>AtEnd()</code>","text":"<p>Checks the end of the text was reached.</p> <p>Returns:</p> Type Description <p>True iff the end was reached.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def AtEnd(self):\n  \"\"\"Checks the end of the text was reached.\n\n  Returns:\n    True iff the end was reached.\n  \"\"\"\n  return not self.token\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.Consume","title":"<code>Consume(token)</code>","text":"<p>Consumes a piece of text.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <p>Text to consume.</p> required <p>Raises:</p> Type Description <code>ParseError</code> <p>If the text couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def Consume(self, token):\n  \"\"\"Consumes a piece of text.\n\n  Args:\n    token: Text to consume.\n\n  Raises:\n    ParseError: If the text couldn't be consumed.\n  \"\"\"\n  if not self.TryConsume(token):\n    raise self.ParseError('Expected \"%s\".' % token)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeBool","title":"<code>ConsumeBool()</code>","text":"<p>Consumes a boolean value.</p> <p>Returns:</p> Type Description <p>The bool parsed.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If a boolean value couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeBool(self):\n  \"\"\"Consumes a boolean value.\n\n  Returns:\n    The bool parsed.\n\n  Raises:\n    ParseError: If a boolean value couldn't be consumed.\n  \"\"\"\n  try:\n    result = ParseBool(self.token)\n  except ValueError as e:\n    raise self.ParseError(str(e))\n  self.NextToken()\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeByteString","title":"<code>ConsumeByteString()</code>","text":"<p>Consumes a byte array value.</p> <p>Returns:</p> Type Description <p>The array parsed (as a string).</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If a byte array value couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeByteString(self):\n  \"\"\"Consumes a byte array value.\n\n  Returns:\n    The array parsed (as a string).\n\n  Raises:\n    ParseError: If a byte array value couldn't be consumed.\n  \"\"\"\n  the_list = [self._ConsumeSingleByteString()]\n  while self.token and self.token[0] in _QUOTES:\n    the_list.append(self._ConsumeSingleByteString())\n  return b''.join(the_list)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeCommentOrTrailingComment","title":"<code>ConsumeCommentOrTrailingComment()</code>","text":"<p>Consumes a comment, returns a 2-tuple (trailing bool, comment str).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeCommentOrTrailingComment(self):\n  \"\"\"Consumes a comment, returns a 2-tuple (trailing bool, comment str).\"\"\"\n\n  # Tokenizer initializes _previous_line and _previous_column to 0. As the\n  # tokenizer starts, it looks like there is a previous token on the line.\n  just_started = self._line == 0 and self._column == 0\n\n  before_parsing = self._previous_line\n  comment = self.ConsumeComment()\n\n  # A trailing comment is a comment on the same line than the previous token.\n  trailing = (self._previous_line == before_parsing\n              and not just_started)\n\n  return trailing, comment\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeFloat","title":"<code>ConsumeFloat()</code>","text":"<p>Consumes an floating point number.</p> <p>Returns:</p> Type Description <p>The number parsed.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If a floating point number couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeFloat(self):\n  \"\"\"Consumes an floating point number.\n\n  Returns:\n    The number parsed.\n\n  Raises:\n    ParseError: If a floating point number couldn't be consumed.\n  \"\"\"\n  try:\n    result = ParseFloat(self.token)\n  except ValueError as e:\n    raise self.ParseError(str(e))\n  self.NextToken()\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeIdentifier","title":"<code>ConsumeIdentifier()</code>","text":"<p>Consumes protocol message field identifier.</p> <p>Returns:</p> Type Description <p>Identifier string.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If an identifier couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeIdentifier(self):\n  \"\"\"Consumes protocol message field identifier.\n\n  Returns:\n    Identifier string.\n\n  Raises:\n    ParseError: If an identifier couldn't be consumed.\n  \"\"\"\n  result = self.token\n  if not self._IDENTIFIER.match(result):\n    raise self.ParseError('Expected identifier.')\n  self.NextToken()\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeIdentifierOrNumber","title":"<code>ConsumeIdentifierOrNumber()</code>","text":"<p>Consumes protocol message field identifier.</p> <p>Returns:</p> Type Description <p>Identifier string.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If an identifier couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeIdentifierOrNumber(self):\n  \"\"\"Consumes protocol message field identifier.\n\n  Returns:\n    Identifier string.\n\n  Raises:\n    ParseError: If an identifier couldn't be consumed.\n  \"\"\"\n  result = self.token\n  if not self._IDENTIFIER_OR_NUMBER.match(result):\n    raise self.ParseError('Expected identifier or number, got %s.' % result)\n  self.NextToken()\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeInteger","title":"<code>ConsumeInteger()</code>","text":"<p>Consumes an integer number.</p> <p>Returns:</p> Type Description <p>The integer parsed.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If an integer couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeInteger(self):\n  \"\"\"Consumes an integer number.\n\n  Returns:\n    The integer parsed.\n\n  Raises:\n    ParseError: If an integer couldn't be consumed.\n  \"\"\"\n  try:\n    result = _ParseAbstractInteger(self.token)\n  except ValueError as e:\n    raise self.ParseError(str(e))\n  self.NextToken()\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ConsumeString","title":"<code>ConsumeString()</code>","text":"<p>Consumes a string value.</p> <p>Returns:</p> Type Description <p>The string parsed.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>If a string value couldn't be consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ConsumeString(self):\n  \"\"\"Consumes a string value.\n\n  Returns:\n    The string parsed.\n\n  Raises:\n    ParseError: If a string value couldn't be consumed.\n  \"\"\"\n  the_bytes = self.ConsumeByteString()\n  try:\n    return str(the_bytes, 'utf-8')\n  except UnicodeDecodeError as e:\n    raise self._StringParseError(e)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.NextToken","title":"<code>NextToken()</code>","text":"<p>Reads the next meaningful token.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def NextToken(self):\n  \"\"\"Reads the next meaningful token.\"\"\"\n  self._previous_line = self._line\n  self._previous_column = self._column\n\n  self._column += len(self.token)\n  self._SkipWhitespace()\n\n  if not self._more_lines:\n    self.token = ''\n    return\n\n  match = self._TOKEN.match(self._current_line, self._column)\n  if not match and not self._skip_comments:\n    match = self._COMMENT.match(self._current_line, self._column)\n  if match:\n    token = match.group(0)\n    self.token = token\n  else:\n    self.token = self._current_line[self._column]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ParseError","title":"<code>ParseError(message)</code>","text":"<p>Creates and returns a ParseError for the current token.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseError(self, message):\n  \"\"\"Creates and *returns* a ParseError for the current token.\"\"\"\n  return ParseError('\\'' + self._current_line + '\\': ' + message,\n                    self._line + 1, self._column + 1)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.ParseErrorPreviousToken","title":"<code>ParseErrorPreviousToken(message)</code>","text":"<p>Creates and returns a ParseError for the previously read token.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>A message to set for the exception.</p> required <p>Returns:</p> Type Description <p>A ParseError instance.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseErrorPreviousToken(self, message):\n  \"\"\"Creates and *returns* a ParseError for the previously read token.\n\n  Args:\n    message: A message to set for the exception.\n\n  Returns:\n    A ParseError instance.\n  \"\"\"\n  return ParseError(message, self._previous_line + 1,\n                    self._previous_column + 1)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Tokenizer.TryConsume","title":"<code>TryConsume(token)</code>","text":"<p>Tries to consume a given piece of text.</p> <p>Parameters:</p> Name Type Description Default <code>token</code> <p>Text to consume.</p> required <p>Returns:</p> Type Description <p>True iff the text was consumed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def TryConsume(self, token):\n  \"\"\"Tries to consume a given piece of text.\n\n  Args:\n    token: Text to consume.\n\n  Returns:\n    True iff the text was consumed.\n  \"\"\"\n  if self.token == token:\n    self.NextToken()\n    return True\n  return False\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Merge","title":"<code>Merge(text, message, allow_unknown_extension=False, allow_field_number=False, descriptor_pool=None, allow_unknown_field=False)</code>","text":"<p>Parses a text representation of a protocol message into a message.</p> <p>Like Parse(), but allows repeated values for a non-repeated field, and uses the last one. This means any non-repeated, top-level fields specified in text replace those in the message.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Message text representation.</p> required <code>message</code> <code>Message</code> <p>A protocol buffer message to merge into.</p> required <code>allow_unknown_extension</code> <p>if True, skip over missing extensions and keep parsing</p> <code>False</code> <code>allow_field_number</code> <p>if True, both field number and field name are allowed.</p> <code>False</code> <code>descriptor_pool</code> <code>DescriptorPool</code> <p>Descriptor pool used to resolve Any types.</p> <code>None</code> <code>allow_unknown_field</code> <p>if True, skip over unknown field and keep parsing. Avoid to use this option if possible. It may hide some errors (e.g. spelling error on field name)</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Message</code> <p>The same message passed as argument.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>On text parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def Merge(text,\n          message,\n          allow_unknown_extension=False,\n          allow_field_number=False,\n          descriptor_pool=None,\n          allow_unknown_field=False):\n  \"\"\"Parses a text representation of a protocol message into a message.\n\n  Like Parse(), but allows repeated values for a non-repeated field, and uses\n  the last one. This means any non-repeated, top-level fields specified in text\n  replace those in the message.\n\n  Args:\n    text (str): Message text representation.\n    message (Message): A protocol buffer message to merge into.\n    allow_unknown_extension: if True, skip over missing extensions and keep\n      parsing\n    allow_field_number: if True, both field number and field name are allowed.\n    descriptor_pool (DescriptorPool): Descriptor pool used to resolve Any types.\n    allow_unknown_field: if True, skip over unknown field and keep\n      parsing. Avoid to use this option if possible. It may hide some\n      errors (e.g. spelling error on field name)\n\n  Returns:\n    Message: The same message passed as argument.\n\n  Raises:\n    ParseError: On text parsing problems.\n  \"\"\"\n  return MergeLines(\n      text.split(b'\\n' if isinstance(text, bytes) else u'\\n'),\n      message,\n      allow_unknown_extension,\n      allow_field_number,\n      descriptor_pool=descriptor_pool,\n      allow_unknown_field=allow_unknown_field)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.MergeLines","title":"<code>MergeLines(lines, message, allow_unknown_extension=False, allow_field_number=False, descriptor_pool=None, allow_unknown_field=False)</code>","text":"<p>Parses a text representation of a protocol message into a message.</p> <p>See Merge() for more details.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <p>An iterable of lines of a message's text representation.</p> required <code>message</code> <p>A protocol buffer message to merge into.</p> required <code>allow_unknown_extension</code> <p>if True, skip over missing extensions and keep parsing</p> <code>False</code> <code>allow_field_number</code> <p>if True, both field number and field name are allowed.</p> <code>False</code> <code>descriptor_pool</code> <p>A DescriptorPool used to resolve Any types.</p> <code>None</code> <code>allow_unknown_field</code> <p>if True, skip over unknown field and keep parsing. Avoid to use this option if possible. It may hide some errors (e.g. spelling error on field name)</p> <code>False</code> <p>Returns:</p> Type Description <p>The same message passed as argument.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>On text parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def MergeLines(lines,\n               message,\n               allow_unknown_extension=False,\n               allow_field_number=False,\n               descriptor_pool=None,\n               allow_unknown_field=False):\n  \"\"\"Parses a text representation of a protocol message into a message.\n\n  See Merge() for more details.\n\n  Args:\n    lines: An iterable of lines of a message's text representation.\n    message: A protocol buffer message to merge into.\n    allow_unknown_extension: if True, skip over missing extensions and keep\n      parsing\n    allow_field_number: if True, both field number and field name are allowed.\n    descriptor_pool: A DescriptorPool used to resolve Any types.\n    allow_unknown_field: if True, skip over unknown field and keep\n      parsing. Avoid to use this option if possible. It may hide some\n      errors (e.g. spelling error on field name)\n\n  Returns:\n    The same message passed as argument.\n\n  Raises:\n    ParseError: On text parsing problems.\n  \"\"\"\n  parser = _Parser(allow_unknown_extension,\n                   allow_field_number,\n                   descriptor_pool=descriptor_pool,\n                   allow_unknown_field=allow_unknown_field)\n  return parser.MergeLines(lines, message)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.MessageToBytes","title":"<code>MessageToBytes(message, **kwargs)</code>","text":"<p>Convert protobuf message to encoded text format.  See MessageToString.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def MessageToBytes(message, **kwargs):\n  # type: (...) -&gt; bytes\n  \"\"\"Convert protobuf message to encoded text format.  See MessageToString.\"\"\"\n  text = MessageToString(message, **kwargs)\n  if isinstance(text, bytes):\n    return text\n  codec = 'utf-8' if kwargs.get('as_utf8') else 'ascii'\n  return text.encode(codec)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.MessageToString","title":"<code>MessageToString(message, as_utf8=False, as_one_line=False, use_short_repeated_primitives=False, pointy_brackets=False, use_index_order=False, float_format=None, double_format=None, use_field_number=False, descriptor_pool=None, indent=0, message_formatter=None, print_unknown_fields=False, force_colon=False)</code>","text":"<p>Convert protobuf message to text format.</p> <p>Double values can be formatted compactly with 15 digits of precision (which is the most that IEEE 754 \"double\" can guarantee) using double_format='.15g'. To ensure that converting to text and back to a proto will result in an identical value, double_format='.17g' should be used.</p> <p>Parameters:</p> Name Type Description Default <code>message</code> <p>The protocol buffers message.</p> required <code>as_utf8</code> <p>Return unescaped Unicode for non-ASCII characters.   In Python 3 actual Unicode characters may appear as is in strings.   In Python 2 the return value will be valid UTF-8 rather than only ASCII.</p> <code>False</code> <code>as_one_line</code> <p>Don't introduce newlines between fields.</p> <code>False</code> <code>use_short_repeated_primitives</code> <p>Use short repeated format for primitives.</p> <code>False</code> <code>pointy_brackets</code> <p>If True, use angle brackets instead of curly braces for nesting.</p> <code>False</code> <code>use_index_order</code> <p>If True, fields of a proto message will be printed using the order defined in source code instead of the field number, extensions will be printed at the end of the message and their relative order is determined by the extension number. By default, use the field number order.</p> <code>False</code> <code>float_format</code> <code>str</code> <p>If set, use this to specify float field formatting (per the \"Format Specification Mini-Language\"); otherwise, shortest float that has same value in wire will be printed. Also affect double field if double_format is not set but float_format is set.</p> <code>None</code> <code>double_format</code> <code>str</code> <p>If set, use this to specify double field formatting (per the \"Format Specification Mini-Language\"); if it is not set but float_format is set, use float_format. Otherwise, use <code>str()</code></p> <code>None</code> <code>use_field_number</code> <p>If True, print field numbers instead of names.</p> <code>False</code> <code>descriptor_pool</code> <code>DescriptorPool</code> <p>Descriptor pool used to resolve Any types.</p> <code>None</code> <code>indent</code> <code>int</code> <p>The initial indent level, in terms of spaces, for pretty print.</p> <code>0</code> <code>message_formatter</code> <code>function(message, indent, as_one_line) -&gt; unicode|None</code> <p>Custom formatter for selected sub-messages (usually based on message type). Use to pretty print parts of the protobuf for easier diffing.</p> <code>None</code> <code>print_unknown_fields</code> <p>If True, unknown fields will be printed.</p> <code>False</code> <code>force_colon</code> <p>If set, a colon will be added after the field name even if the field is a proto message.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>A string of the text formatted protocol buffer message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def MessageToString(\n    message,\n    as_utf8=False,\n    as_one_line=False,\n    use_short_repeated_primitives=False,\n    pointy_brackets=False,\n    use_index_order=False,\n    float_format=None,\n    double_format=None,\n    use_field_number=False,\n    descriptor_pool=None,\n    indent=0,\n    message_formatter=None,\n    print_unknown_fields=False,\n    force_colon=False):\n  # type: (...) -&gt; str\n  \"\"\"Convert protobuf message to text format.\n\n  Double values can be formatted compactly with 15 digits of\n  precision (which is the most that IEEE 754 \"double\" can guarantee)\n  using double_format='.15g'. To ensure that converting to text and back to a\n  proto will result in an identical value, double_format='.17g' should be used.\n\n  Args:\n    message: The protocol buffers message.\n    as_utf8: Return unescaped Unicode for non-ASCII characters.\n        In Python 3 actual Unicode characters may appear as is in strings.\n        In Python 2 the return value will be valid UTF-8 rather than only ASCII.\n    as_one_line: Don't introduce newlines between fields.\n    use_short_repeated_primitives: Use short repeated format for primitives.\n    pointy_brackets: If True, use angle brackets instead of curly braces for\n      nesting.\n    use_index_order: If True, fields of a proto message will be printed using\n      the order defined in source code instead of the field number, extensions\n      will be printed at the end of the message and their relative order is\n      determined by the extension number. By default, use the field number\n      order.\n    float_format (str): If set, use this to specify float field formatting\n      (per the \"Format Specification Mini-Language\"); otherwise, shortest float\n      that has same value in wire will be printed. Also affect double field\n      if double_format is not set but float_format is set.\n    double_format (str): If set, use this to specify double field formatting\n      (per the \"Format Specification Mini-Language\"); if it is not set but\n      float_format is set, use float_format. Otherwise, use ``str()``\n    use_field_number: If True, print field numbers instead of names.\n    descriptor_pool (DescriptorPool): Descriptor pool used to resolve Any types.\n    indent (int): The initial indent level, in terms of spaces, for pretty\n      print.\n    message_formatter (function(message, indent, as_one_line) -&gt; unicode|None):\n      Custom formatter for selected sub-messages (usually based on message\n      type). Use to pretty print parts of the protobuf for easier diffing.\n    print_unknown_fields: If True, unknown fields will be printed.\n    force_colon: If set, a colon will be added after the field name even if the\n      field is a proto message.\n\n  Returns:\n    str: A string of the text formatted protocol buffer message.\n  \"\"\"\n  out = TextWriter(as_utf8)\n  printer = _Printer(\n      out,\n      indent,\n      as_utf8,\n      as_one_line,\n      use_short_repeated_primitives,\n      pointy_brackets,\n      use_index_order,\n      float_format,\n      double_format,\n      use_field_number,\n      descriptor_pool,\n      message_formatter,\n      print_unknown_fields=print_unknown_fields,\n      force_colon=force_colon)\n  printer.PrintMessage(message)\n  result = out.getvalue()\n  out.close()\n  if as_one_line:\n    return result.rstrip()\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.Parse","title":"<code>Parse(text, message, allow_unknown_extension=False, allow_field_number=False, descriptor_pool=None, allow_unknown_field=False)</code>","text":"<p>Parses a text representation of a protocol message into a message.</p> <p>NOTE: for historical reasons this function does not clear the input message. This is different from what the binary msg.ParseFrom(...) does. If text contains a field already set in message, the value is appended if the field is repeated. Otherwise, an error is raised.</p> <p>Example::</p> <p>a = MyProto()   a.repeated_field.append('test')   b = MyProto()</p> <p># Repeated fields are combined   text_format.Parse(repr(a), b)   text_format.Parse(repr(a), b) # repeated_field contains [\"test\", \"test\"]</p> <p># Non-repeated fields cannot be overwritten   a.singular_field = 1   b.singular_field = 2   text_format.Parse(repr(a), b) # ParseError</p> <p># Binary version:   b.ParseFromString(a.SerializeToString()) # repeated_field is now \"test\"</p> <p>Caller is responsible for clearing the message as needed.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Message text representation.</p> required <code>message</code> <code>Message</code> <p>A protocol buffer message to merge into.</p> required <code>allow_unknown_extension</code> <p>if True, skip over missing extensions and keep parsing</p> <code>False</code> <code>allow_field_number</code> <p>if True, both field number and field name are allowed.</p> <code>False</code> <code>descriptor_pool</code> <code>DescriptorPool</code> <p>Descriptor pool used to resolve Any types.</p> <code>None</code> <code>allow_unknown_field</code> <p>if True, skip over unknown field and keep parsing. Avoid to use this option if possible. It may hide some errors (e.g. spelling error on field name)</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Message</code> <p>The same message passed as argument.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>On text parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def Parse(text,\n          message,\n          allow_unknown_extension=False,\n          allow_field_number=False,\n          descriptor_pool=None,\n          allow_unknown_field=False):\n  \"\"\"Parses a text representation of a protocol message into a message.\n\n  NOTE: for historical reasons this function does not clear the input\n  message. This is different from what the binary msg.ParseFrom(...) does.\n  If text contains a field already set in message, the value is appended if the\n  field is repeated. Otherwise, an error is raised.\n\n  Example::\n\n    a = MyProto()\n    a.repeated_field.append('test')\n    b = MyProto()\n\n    # Repeated fields are combined\n    text_format.Parse(repr(a), b)\n    text_format.Parse(repr(a), b) # repeated_field contains [\"test\", \"test\"]\n\n    # Non-repeated fields cannot be overwritten\n    a.singular_field = 1\n    b.singular_field = 2\n    text_format.Parse(repr(a), b) # ParseError\n\n    # Binary version:\n    b.ParseFromString(a.SerializeToString()) # repeated_field is now \"test\"\n\n  Caller is responsible for clearing the message as needed.\n\n  Args:\n    text (str): Message text representation.\n    message (Message): A protocol buffer message to merge into.\n    allow_unknown_extension: if True, skip over missing extensions and keep\n      parsing\n    allow_field_number: if True, both field number and field name are allowed.\n    descriptor_pool (DescriptorPool): Descriptor pool used to resolve Any types.\n    allow_unknown_field: if True, skip over unknown field and keep\n      parsing. Avoid to use this option if possible. It may hide some\n      errors (e.g. spelling error on field name)\n\n  Returns:\n    Message: The same message passed as argument.\n\n  Raises:\n    ParseError: On text parsing problems.\n  \"\"\"\n  return ParseLines(text.split(b'\\n' if isinstance(text, bytes) else u'\\n'),\n                    message,\n                    allow_unknown_extension,\n                    allow_field_number,\n                    descriptor_pool=descriptor_pool,\n                    allow_unknown_field=allow_unknown_field)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.ParseBool","title":"<code>ParseBool(text)</code>","text":"<p>Parse a boolean value.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>Text to parse.</p> required <p>Returns:</p> Type Description <p>Boolean values parsed</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If text is not a valid boolean.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseBool(text):\n  \"\"\"Parse a boolean value.\n\n  Args:\n    text: Text to parse.\n\n  Returns:\n    Boolean values parsed\n\n  Raises:\n    ValueError: If text is not a valid boolean.\n  \"\"\"\n  if text in ('true', 't', '1', 'True'):\n    return True\n  elif text in ('false', 'f', '0', 'False'):\n    return False\n  else:\n    raise ValueError('Expected \"true\" or \"false\".')\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.ParseEnum","title":"<code>ParseEnum(field, value)</code>","text":"<p>Parse an enum value.</p> <p>The value can be specified by a number (the enum value), or by a string literal (the enum name).</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <p>Enum field descriptor.</p> required <code>value</code> <p>String value.</p> required <p>Returns:</p> Type Description <p>Enum value number.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the enum value could not be parsed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseEnum(field, value):\n  \"\"\"Parse an enum value.\n\n  The value can be specified by a number (the enum value), or by\n  a string literal (the enum name).\n\n  Args:\n    field: Enum field descriptor.\n    value: String value.\n\n  Returns:\n    Enum value number.\n\n  Raises:\n    ValueError: If the enum value could not be parsed.\n  \"\"\"\n  enum_descriptor = field.enum_type\n  try:\n    number = int(value, 0)\n  except ValueError:\n    # Identifier.\n    enum_value = enum_descriptor.values_by_name.get(value, None)\n    if enum_value is None:\n      raise ValueError('Enum type \"%s\" has no value named %s.' %\n                       (enum_descriptor.full_name, value))\n  else:\n    # Numeric value.\n    if hasattr(field.file, 'syntax'):\n      # Attribute is checked for compatibility.\n      if field.file.syntax == 'proto3':\n        # Proto3 accept numeric unknown enums.\n        return number\n    enum_value = enum_descriptor.values_by_number.get(number, None)\n    if enum_value is None:\n      raise ValueError('Enum type \"%s\" has no value with number %d.' %\n                       (enum_descriptor.full_name, number))\n  return enum_value.number\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.ParseFloat","title":"<code>ParseFloat(text)</code>","text":"<p>Parse a floating point number.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>Text to parse.</p> required <p>Returns:</p> Type Description <p>The number parsed.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a floating point number couldn't be parsed.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseFloat(text):\n  \"\"\"Parse a floating point number.\n\n  Args:\n    text: Text to parse.\n\n  Returns:\n    The number parsed.\n\n  Raises:\n    ValueError: If a floating point number couldn't be parsed.\n  \"\"\"\n  try:\n    # Assume Python compatible syntax.\n    return float(text)\n  except ValueError:\n    # Check alternative spellings.\n    if _FLOAT_INFINITY.match(text):\n      if text[0] == '-':\n        return float('-inf')\n      else:\n        return float('inf')\n    elif _FLOAT_NAN.match(text):\n      return float('nan')\n    else:\n      # assume '1.0f' format\n      try:\n        return float(text.rstrip('f'))\n      except ValueError:\n        raise ValueError('Couldn\\'t parse float: %s' % text)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.ParseInteger","title":"<code>ParseInteger(text, is_signed=False, is_long=False)</code>","text":"<p>Parses an integer.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <p>The text to parse.</p> required <code>is_signed</code> <p>True if a signed integer must be parsed.</p> <code>False</code> <code>is_long</code> <p>True if a long integer must be parsed.</p> <code>False</code> <p>Returns:</p> Type Description <p>The integer value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Thrown Iff the text is not a valid integer.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseInteger(text, is_signed=False, is_long=False):\n  \"\"\"Parses an integer.\n\n  Args:\n    text: The text to parse.\n    is_signed: True if a signed integer must be parsed.\n    is_long: True if a long integer must be parsed.\n\n  Returns:\n    The integer value.\n\n  Raises:\n    ValueError: Thrown Iff the text is not a valid integer.\n  \"\"\"\n  # Do the actual parsing. Exception handling is propagated to caller.\n  result = _ParseAbstractInteger(text)\n\n  # Check if the integer is sane. Exceptions handled by callers.\n  checker = _INTEGER_CHECKERS[2 * int(is_long) + int(is_signed)]\n  checker.CheckValue(result)\n  return result\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.ParseLines","title":"<code>ParseLines(lines, message, allow_unknown_extension=False, allow_field_number=False, descriptor_pool=None, allow_unknown_field=False)</code>","text":"<p>Parses a text representation of a protocol message into a message.</p> <p>See Parse() for caveats.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <p>An iterable of lines of a message's text representation.</p> required <code>message</code> <p>A protocol buffer message to merge into.</p> required <code>allow_unknown_extension</code> <p>if True, skip over missing extensions and keep parsing</p> <code>False</code> <code>allow_field_number</code> <p>if True, both field number and field name are allowed.</p> <code>False</code> <code>descriptor_pool</code> <p>A DescriptorPool used to resolve Any types.</p> <code>None</code> <code>allow_unknown_field</code> <p>if True, skip over unknown field and keep parsing. Avoid to use this option if possible. It may hide some errors (e.g. spelling error on field name)</p> <code>False</code> <p>Returns:</p> Type Description <p>The same message passed as argument.</p> <p>Raises:</p> Type Description <code>ParseError</code> <p>On text parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def ParseLines(lines,\n               message,\n               allow_unknown_extension=False,\n               allow_field_number=False,\n               descriptor_pool=None,\n               allow_unknown_field=False):\n  \"\"\"Parses a text representation of a protocol message into a message.\n\n  See Parse() for caveats.\n\n  Args:\n    lines: An iterable of lines of a message's text representation.\n    message: A protocol buffer message to merge into.\n    allow_unknown_extension: if True, skip over missing extensions and keep\n      parsing\n    allow_field_number: if True, both field number and field name are allowed.\n    descriptor_pool: A DescriptorPool used to resolve Any types.\n    allow_unknown_field: if True, skip over unknown field and keep\n      parsing. Avoid to use this option if possible. It may hide some\n      errors (e.g. spelling error on field name)\n\n  Returns:\n    The same message passed as argument.\n\n  Raises:\n    ParseError: On text parsing problems.\n  \"\"\"\n  parser = _Parser(allow_unknown_extension,\n                   allow_field_number,\n                   descriptor_pool=descriptor_pool,\n                   allow_unknown_field=allow_unknown_field)\n  return parser.ParseLines(lines, message)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.PrintField","title":"<code>PrintField(field, value, out, indent=0, as_utf8=False, as_one_line=False, use_short_repeated_primitives=False, pointy_brackets=False, use_index_order=False, float_format=None, double_format=None, message_formatter=None, print_unknown_fields=False, force_colon=False)</code>","text":"<p>Print a single field name/value pair.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def PrintField(field,\n               value,\n               out,\n               indent=0,\n               as_utf8=False,\n               as_one_line=False,\n               use_short_repeated_primitives=False,\n               pointy_brackets=False,\n               use_index_order=False,\n               float_format=None,\n               double_format=None,\n               message_formatter=None,\n               print_unknown_fields=False,\n               force_colon=False):\n  \"\"\"Print a single field name/value pair.\"\"\"\n  printer = _Printer(out, indent, as_utf8, as_one_line,\n                     use_short_repeated_primitives, pointy_brackets,\n                     use_index_order, float_format, double_format,\n                     message_formatter=message_formatter,\n                     print_unknown_fields=print_unknown_fields,\n                     force_colon=force_colon)\n  printer.PrintField(field, value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/text_format.html#client.ayon_nuke.vendor.google.protobuf.text_format.PrintFieldValue","title":"<code>PrintFieldValue(field, value, out, indent=0, as_utf8=False, as_one_line=False, use_short_repeated_primitives=False, pointy_brackets=False, use_index_order=False, float_format=None, double_format=None, message_formatter=None, print_unknown_fields=False, force_colon=False)</code>","text":"<p>Print a single field value (not including name).</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/text_format.py</code> <pre><code>def PrintFieldValue(field,\n                    value,\n                    out,\n                    indent=0,\n                    as_utf8=False,\n                    as_one_line=False,\n                    use_short_repeated_primitives=False,\n                    pointy_brackets=False,\n                    use_index_order=False,\n                    float_format=None,\n                    double_format=None,\n                    message_formatter=None,\n                    print_unknown_fields=False,\n                    force_colon=False):\n  \"\"\"Print a single field value (not including name).\"\"\"\n  printer = _Printer(out, indent, as_utf8, as_one_line,\n                     use_short_repeated_primitives, pointy_brackets,\n                     use_index_order, float_format, double_format,\n                     message_formatter=message_formatter,\n                     print_unknown_fields=print_unknown_fields,\n                     force_colon=force_colon)\n  printer.PrintFieldValue(field, value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/timestamp_pb2.html","title":"timestamp_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/type_pb2.html","title":"type_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/wrappers_pb2.html","title":"wrappers_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/compiler/index.html","title":"compiler","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/compiler/plugin_pb2.html","title":"plugin_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/index.html","title":"internal","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html","title":"_parameterized","text":"<p>Adds support for parameterized tests to Python's unittest TestCase class.</p> <p>A parameterized test is a method in a test case that is invoked with different argument tuples.</p> <p>A simple example:</p> <p>class AdditionExample(parameterized.TestCase):     @parameterized.parameters(        (1, 2, 3),        (4, 5, 9),        (1, 1, 3))     def testAddition(self, op1, op2, result):       self.assertEqual(result, op1 + op2)</p> <p>Each invocation is a separate test case and properly isolated just like a normal test method, with its own setUp/tearDown cycle. In the example above, there are three separate testcases, one of which will fail due to an assertion error (1 + 1 != 3).</p> <p>Parameters for individual test cases can be tuples (with positional parameters) or dictionaries (with named parameters):</p> <p>class AdditionExample(parameterized.TestCase):     @parameterized.parameters(        {'op1': 1, 'op2': 2, 'result': 3},        {'op1': 4, 'op2': 5, 'result': 9},     )     def testAddition(self, op1, op2, result):       self.assertEqual(result, op1 + op2)</p> <p>If a parameterized test fails, the error message will show the original test name (which is modified internally) and the arguments for the specific invocation, which are part of the string returned by the shortDescription() method on test cases.</p> <p>The id method of the test, used internally by the unittest framework, is also modified to show the arguments. To make sure that test names stay the same across several invocations, object representations like</p> <p>class Foo(object):   ...  pass repr(Foo())   '&lt;main.Foo object at 0x23d8610&gt;'</p> <p>are turned into '&lt;main.Foo&gt;'. For even more descriptive names, especially in test logs, you can use the named_parameters decorator. In this case, only tuples are supported, and the first parameters has to be a string (or an object that returns an apt name when converted via str()):</p> <p>class NamedExample(parameterized.TestCase):     @parameterized.named_parameters(        ('Normal', 'aa', 'aaa', True),        ('EmptyPrefix', '', 'abc', True),        ('BothEmpty', '', '', True))     def testStartsWith(self, prefix, string, result):       self.assertEqual(result, strings.startswith(prefix))</p> <p>Named tests also have the benefit that they can be run individually from the command line:</p> <p>$ testmodule.py NamedExample.testStartsWithNormal   .</p> <p>Ran 1 test in 0.000s</p> <p>OK</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized--parameterized-classes","title":"Parameterized Classes","text":"<p>If invocation arguments are shared across test methods in a single TestCase class, instead of decorating all test methods individually, the class itself can be decorated:</p> <p>@parameterized.parameters(     (1, 2, 3)     (4, 5, 9))   class ArithmeticTest(parameterized.TestCase):     def testAdd(self, arg1, arg2, result):       self.assertEqual(arg1 + arg2, result)</p> <pre><code>def testSubtract(self, arg2, arg2, result):\n  self.assertEqual(result - arg1, arg2)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized--inputs-from-iterables","title":"Inputs from Iterables","text":"<p>If parameters should be shared across several test cases, or are dynamically created from other sources, a single non-tuple iterable can be passed into the decorator. This iterable will be used to obtain the test cases:</p> <p>class AdditionExample(parameterized.TestCase):     @parameterized.parameters(       c.op1, c.op2, c.result for c in testcases     )     def testAddition(self, op1, op2, result):       self.assertEqual(result, op1 + op2)</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized--single-argument-test-methods","title":"Single-Argument Test Methods","text":"<p>If a test method takes only one argument, the single argument does not need to be wrapped into a tuple:</p> <p>class NegativeNumberExample(parameterized.TestCase):     @parameterized.parameters(        -1, -3, -4, -5     )     def testIsNegative(self, arg):       self.assertTrue(IsNegative(arg))</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized.TestCase","title":"<code>TestCase</code>","text":"<p>               Bases: <code>TestCase</code></p> <p>Base class for test cases using the parameters decorator.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.py</code> <pre><code>class TestCase(unittest.TestCase, metaclass=TestGeneratorMetaclass):\n  \"\"\"Base class for test cases using the parameters decorator.\"\"\"\n\n  def _OriginalName(self):\n    return self._testMethodName.split(_SEPARATOR)[0]\n\n  def __str__(self):\n    return '%s (%s)' % (self._OriginalName(), _StrClass(self.__class__))\n\n  def id(self):  # pylint: disable=invalid-name\n    \"\"\"Returns the descriptive ID of the test.\n\n    This is used internally by the unittesting framework to get a name\n    for the test to be used in reports.\n\n    Returns:\n      The test id.\n    \"\"\"\n    return '%s.%s%s' % (_StrClass(self.__class__),\n                        self._OriginalName(),\n                        self._id_suffix.get(self._testMethodName, ''))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized.TestCase.id","title":"<code>id()</code>","text":"<p>Returns the descriptive ID of the test.</p> <p>This is used internally by the unittesting framework to get a name for the test to be used in reports.</p> <p>Returns:</p> Type Description <p>The test id.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.py</code> <pre><code>def id(self):  # pylint: disable=invalid-name\n  \"\"\"Returns the descriptive ID of the test.\n\n  This is used internally by the unittesting framework to get a name\n  for the test to be used in reports.\n\n  Returns:\n    The test id.\n  \"\"\"\n  return '%s.%s%s' % (_StrClass(self.__class__),\n                      self._OriginalName(),\n                      self._id_suffix.get(self._testMethodName, ''))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized.TestGeneratorMetaclass","title":"<code>TestGeneratorMetaclass</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass for test cases with test generators.</p> <p>A test generator is an iterable in a testcase that produces callables. These callables must be single-argument methods. These methods are injected into the class namespace and the original iterable is removed. If the name of the iterable conforms to the test pattern, the injected methods will be picked up as tests by the unittest framework.</p> <p>In general, it is supposed to be used in conjunction with the parameters decorator.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.py</code> <pre><code>class TestGeneratorMetaclass(type):\n  \"\"\"Metaclass for test cases with test generators.\n\n  A test generator is an iterable in a testcase that produces callables. These\n  callables must be single-argument methods. These methods are injected into\n  the class namespace and the original iterable is removed. If the name of the\n  iterable conforms to the test pattern, the injected methods will be picked\n  up as tests by the unittest framework.\n\n  In general, it is supposed to be used in conjunction with the\n  parameters decorator.\n  \"\"\"\n\n  def __new__(mcs, class_name, bases, dct):\n    dct['_id_suffix'] = id_suffix = {}\n    for name, obj in dct.copy().items():\n      if (name.startswith(unittest.TestLoader.testMethodPrefix) and\n          _NonStringIterable(obj)):\n        iterator = iter(obj)\n        dct.pop(name)\n        _UpdateClassDictForParamTestCase(dct, id_suffix, name, iterator)\n\n    return type.__new__(mcs, class_name, bases, dct)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized.CoopTestCase","title":"<code>CoopTestCase(other_base_class)</code>","text":"<p>Returns a new base class with a cooperative metaclass base.</p> <p>This enables the TestCase to be used in combination with other base classes that have custom metaclasses, such as mox.MoxTestBase.</p> <p>Only works with metaclasses that do not override type.new.</p> <p>Example:</p> <p>import google3   import mox</p> <p>from google3.testing.pybase import parameterized</p> <p>class ExampleTest(parameterized.CoopTestCase(mox.MoxTestBase)):     ...</p> <p>Parameters:</p> Name Type Description Default <code>other_base_class</code> <p>(class) A test case base class.</p> required <p>Returns:</p> Type Description <p>A new class object.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.py</code> <pre><code>def CoopTestCase(other_base_class):\n  \"\"\"Returns a new base class with a cooperative metaclass base.\n\n  This enables the TestCase to be used in combination\n  with other base classes that have custom metaclasses, such as\n  mox.MoxTestBase.\n\n  Only works with metaclasses that do not override type.__new__.\n\n  Example:\n\n    import google3\n    import mox\n\n    from google3.testing.pybase import parameterized\n\n    class ExampleTest(parameterized.CoopTestCase(mox.MoxTestBase)):\n      ...\n\n  Args:\n    other_base_class: (class) A test case base class.\n\n  Returns:\n    A new class object.\n  \"\"\"\n  metaclass = type(\n      'CoopMetaclass',\n      (other_base_class.__metaclass__,\n       TestGeneratorMetaclass), {})\n  return metaclass(\n      'CoopTestCase',\n      (other_base_class, TestCase), {})\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized.named_parameters","title":"<code>named_parameters(*testcases)</code>","text":"<p>A decorator for creating parameterized tests.</p> <p>See the module docstring for a usage example. The first element of each parameter tuple should be a string and will be appended to the name of the test method.</p> <p>Parameters:</p> Name Type Description Default <code>*testcases</code> <p>Parameters for the decorated method, either a single           iterable, or a list of tuples.</p> <code>()</code> <p>Returns:</p> Type Description <p>A test generator to be handled by TestGeneratorMetaclass.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.py</code> <pre><code>def named_parameters(*testcases):  # pylint: disable=invalid-name\n  \"\"\"A decorator for creating parameterized tests.\n\n  See the module docstring for a usage example. The first element of\n  each parameter tuple should be a string and will be appended to the\n  name of the test method.\n\n  Args:\n    *testcases: Parameters for the decorated method, either a single\n                iterable, or a list of tuples.\n\n  Returns:\n     A test generator to be handled by TestGeneratorMetaclass.\n  \"\"\"\n  return _ParameterDecorator(_FIRST_ARG, testcases)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.html#client.ayon_nuke.vendor.google.protobuf.internal._parameterized.parameters","title":"<code>parameters(*testcases)</code>","text":"<p>A decorator for creating parameterized tests.</p> <p>See the module docstring for a usage example. Args:   *testcases: Parameters for the decorated method, either a single               iterable, or a list of tuples/dicts/objects (for tests               with only one argument).</p> <p>Returns:</p> Type Description <p>A test generator to be handled by TestGeneratorMetaclass.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/_parameterized.py</code> <pre><code>def parameters(*testcases):  # pylint: disable=invalid-name\n  \"\"\"A decorator for creating parameterized tests.\n\n  See the module docstring for a usage example.\n  Args:\n    *testcases: Parameters for the decorated method, either a single\n                iterable, or a list of tuples/dicts/objects (for tests\n                with only one argument).\n\n  Returns:\n     A test generator to be handled by TestGeneratorMetaclass.\n  \"\"\"\n  return _ParameterDecorator(_ARGUMENT_REPR, testcases)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/api_implementation.html","title":"api_implementation","text":"<p>Determine which implementation of the protobuf API is used in this process.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/builder.html","title":"builder","text":"<p>Builds descriptors, message classes and services for generated _pb2.py.</p> <p>This file is only called in python generated _pb2.py files. It builds descriptors, message classes and services that users can directly use in generated code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/builder.html#client.ayon_nuke.vendor.google.protobuf.internal.builder.BuildMessageAndEnumDescriptors","title":"<code>BuildMessageAndEnumDescriptors(file_des, module)</code>","text":"<p>Builds message and enum descriptors.</p> <p>Parameters:</p> Name Type Description Default <code>file_des</code> <p>FileDescriptor of the .proto file</p> required <code>module</code> <p>Generated _pb2 module</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/builder.py</code> <pre><code>def BuildMessageAndEnumDescriptors(file_des, module):\n  \"\"\"Builds message and enum descriptors.\n\n  Args:\n    file_des: FileDescriptor of the .proto file\n    module: Generated _pb2 module\n  \"\"\"\n\n  def BuildNestedDescriptors(msg_des, prefix):\n    for (name, nested_msg) in msg_des.nested_types_by_name.items():\n      module_name = prefix + name.upper()\n      module[module_name] = nested_msg\n      BuildNestedDescriptors(nested_msg, module_name + '_')\n    for enum_des in msg_des.enum_types:\n      module[prefix + enum_des.name.upper()] = enum_des\n\n  for (name, msg_des) in file_des.message_types_by_name.items():\n    module_name = '_' + name.upper()\n    module[module_name] = msg_des\n    BuildNestedDescriptors(msg_des, module_name + '_')\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/builder.html#client.ayon_nuke.vendor.google.protobuf.internal.builder.BuildServices","title":"<code>BuildServices(file_des, module_name, module)</code>","text":"<p>Builds services classes and services stub class.</p> <p>Parameters:</p> Name Type Description Default <code>file_des</code> <p>FileDescriptor of the .proto file</p> required <code>module_name</code> <p>str, the name of generated _pb2 module</p> required <code>module</code> <p>Generated _pb2 module</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/builder.py</code> <pre><code>def BuildServices(file_des, module_name, module):\n  \"\"\"Builds services classes and services stub class.\n\n  Args:\n    file_des: FileDescriptor of the .proto file\n    module_name: str, the name of generated _pb2 module\n    module: Generated _pb2 module\n  \"\"\"\n  # pylint: disable=g-import-not-at-top\n  from google.protobuf import service as _service\n  from google.protobuf import service_reflection\n  # pylint: enable=g-import-not-at-top\n  for (name, service) in file_des.services_by_name.items():\n    module[name] = service_reflection.GeneratedServiceType(\n        name, (_service.Service,),\n        dict(DESCRIPTOR=service, __module__=module_name))\n    stub_name = name + '_Stub'\n    module[stub_name] = service_reflection.GeneratedServiceStubType(\n        stub_name, (module[name],),\n        dict(DESCRIPTOR=service, __module__=module_name))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/builder.html#client.ayon_nuke.vendor.google.protobuf.internal.builder.BuildTopDescriptorsAndMessages","title":"<code>BuildTopDescriptorsAndMessages(file_des, module_name, module)</code>","text":"<p>Builds top level descriptors and message classes.</p> <p>Parameters:</p> Name Type Description Default <code>file_des</code> <p>FileDescriptor of the .proto file</p> required <code>module_name</code> <p>str, the name of generated _pb2 module</p> required <code>module</code> <p>Generated _pb2 module</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/builder.py</code> <pre><code>def BuildTopDescriptorsAndMessages(file_des, module_name, module):\n  \"\"\"Builds top level descriptors and message classes.\n\n  Args:\n    file_des: FileDescriptor of the .proto file\n    module_name: str, the name of generated _pb2 module\n    module: Generated _pb2 module\n  \"\"\"\n\n  def BuildMessage(msg_des):\n    create_dict = {}\n    for (name, nested_msg) in msg_des.nested_types_by_name.items():\n      create_dict[name] = BuildMessage(nested_msg)\n    create_dict['DESCRIPTOR'] = msg_des\n    create_dict['__module__'] = module_name\n    message_class = _reflection.GeneratedProtocolMessageType(\n        msg_des.name, (_message.Message,), create_dict)\n    _sym_db.RegisterMessage(message_class)\n    return message_class\n\n  # top level enums\n  for (name, enum_des) in file_des.enum_types_by_name.items():\n    module['_' + name.upper()] = enum_des\n    module[name] = enum_type_wrapper.EnumTypeWrapper(enum_des)\n    for enum_value in enum_des.values:\n      module[enum_value.name] = enum_value.number\n\n  # top level extensions\n  for (name, extension_des) in file_des.extensions_by_name.items():\n    module[name.upper() + '_FIELD_NUMBER'] = extension_des.number\n    module[name] = extension_des\n\n  # services\n  for (name, service) in file_des.services_by_name.items():\n    module['_' + name.upper()] = service\n\n  # Build messages.\n  for (name, msg_des) in file_des.message_types_by_name.items():\n    module[name] = BuildMessage(msg_des)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html","title":"containers","text":"<p>Contains container classes to represent different protocol buffer types.</p> <p>This file defines container classes which represent categories of protocol buffer field types which need extra maintenance. Currently these categories are:</p> <ul> <li>Repeated scalar fields - These are all repeated fields which aren't     composite (e.g. they are of simple types like int32, string, etc).</li> <li>Repeated composite fields - Repeated fields which are composite. This     includes groups and nested messages.</li> </ul>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.BaseContainer","title":"<code>BaseContainer</code>","text":"<p>               Bases: <code>Sequence[_T]</code></p> <p>Base container class.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>class BaseContainer(Sequence[_T]):\n  \"\"\"Base container class.\"\"\"\n\n  # Minimizes memory usage and disallows assignment to other attributes.\n  __slots__ = ['_message_listener', '_values']\n\n  def __init__(self, message_listener: Any) -&gt; None:\n    \"\"\"\n    Args:\n      message_listener: A MessageListener implementation.\n        The RepeatedScalarFieldContainer will call this object's\n        Modified() method when it is modified.\n    \"\"\"\n    self._message_listener = message_listener\n    self._values = []\n\n  @overload\n  def __getitem__(self, key: int) -&gt; _T:\n    ...\n\n  @overload\n  def __getitem__(self, key: slice) -&gt; List[_T]:\n    ...\n\n  def __getitem__(self, key):\n    \"\"\"Retrieves item by the specified key.\"\"\"\n    return self._values[key]\n\n  def __len__(self) -&gt; int:\n    \"\"\"Returns the number of elements in the container.\"\"\"\n    return len(self._values)\n\n  def __ne__(self, other: Any) -&gt; bool:\n    \"\"\"Checks if another instance isn't equal to this one.\"\"\"\n    # The concrete classes should define __eq__.\n    return not self == other\n\n  __hash__ = None\n\n  def __repr__(self) -&gt; str:\n    return repr(self._values)\n\n  def sort(self, *args, **kwargs) -&gt; None:\n    # Continue to support the old sort_function keyword argument.\n    # This is expected to be a rare occurrence, so use LBYL to avoid\n    # the overhead of actually catching KeyError.\n    if 'sort_function' in kwargs:\n      kwargs['cmp'] = kwargs.pop('sort_function')\n    self._values.sort(*args, **kwargs)\n\n  def reverse(self) -&gt; None:\n    self._values.reverse()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.BaseContainer.__getitem__","title":"<code>__getitem__(key)</code>","text":"<pre><code>__getitem__(key: int) -&gt; _T\n</code></pre><pre><code>__getitem__(key: slice) -&gt; List[_T]\n</code></pre> <p>Retrieves item by the specified key.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __getitem__(self, key):\n  \"\"\"Retrieves item by the specified key.\"\"\"\n  return self._values[key]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.BaseContainer.__init__","title":"<code>__init__(message_listener)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>message_listener</code> <code>Any</code> <p>A MessageListener implementation. The RepeatedScalarFieldContainer will call this object's Modified() method when it is modified.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __init__(self, message_listener: Any) -&gt; None:\n  \"\"\"\n  Args:\n    message_listener: A MessageListener implementation.\n      The RepeatedScalarFieldContainer will call this object's\n      Modified() method when it is modified.\n  \"\"\"\n  self._message_listener = message_listener\n  self._values = []\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.BaseContainer.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of elements in the container.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __len__(self) -&gt; int:\n  \"\"\"Returns the number of elements in the container.\"\"\"\n  return len(self._values)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.BaseContainer.__ne__","title":"<code>__ne__(other)</code>","text":"<p>Checks if another instance isn't equal to this one.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __ne__(self, other: Any) -&gt; bool:\n  \"\"\"Checks if another instance isn't equal to this one.\"\"\"\n  # The concrete classes should define __eq__.\n  return not self == other\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.MessageMap","title":"<code>MessageMap</code>","text":"<p>               Bases: <code>MutableMapping[_K, _V]</code></p> <p>Simple, type-checked, dict-like container for with submessage values.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>class MessageMap(MutableMapping[_K, _V]):\n  \"\"\"Simple, type-checked, dict-like container for with submessage values.\"\"\"\n\n  # Disallows assignment to other attributes.\n  __slots__ = ['_key_checker', '_values', '_message_listener',\n               '_message_descriptor', '_entry_descriptor']\n\n  def __init__(\n      self,\n      message_listener: Any,\n      message_descriptor: Any,\n      key_checker: Any,\n      entry_descriptor: Any,\n  ) -&gt; None:\n    \"\"\"\n    Args:\n      message_listener: A MessageListener implementation.\n        The ScalarMap will call this object's Modified() method when it\n        is modified.\n      key_checker: A type_checkers.ValueChecker instance to run on keys\n        inserted into this container.\n      value_checker: A type_checkers.ValueChecker instance to run on values\n        inserted into this container.\n      entry_descriptor: The MessageDescriptor of a map entry: key and value.\n    \"\"\"\n    self._message_listener = message_listener\n    self._message_descriptor = message_descriptor\n    self._key_checker = key_checker\n    self._entry_descriptor = entry_descriptor\n    self._values = {}\n\n  def __getitem__(self, key: _K) -&gt; _V:\n    key = self._key_checker.CheckValue(key)\n    try:\n      return self._values[key]\n    except KeyError:\n      new_element = self._message_descriptor._concrete_class()\n      new_element._SetListener(self._message_listener)\n      self._values[key] = new_element\n      self._message_listener.Modified()\n      return new_element\n\n  def get_or_create(self, key: _K) -&gt; _V:\n    \"\"\"get_or_create() is an alias for getitem (ie. map[key]).\n\n    Args:\n      key: The key to get or create in the map.\n\n    This is useful in cases where you want to be explicit that the call is\n    mutating the map.  This can avoid lint errors for statements like this\n    that otherwise would appear to be pointless statements:\n\n      msg.my_map[key]\n    \"\"\"\n    return self[key]\n\n  @overload\n  def get(self, key: _K) -&gt; Optional[_V]:\n    ...\n\n  @overload\n  def get(self, key: _K, default: _T) -&gt; Union[_V, _T]:\n    ...\n\n  # We need to override this explicitly, because our defaultdict-like behavior\n  # will make the default implementation (from our base class) always insert\n  # the key.\n  def get(self, key, default=None):\n    if key in self:\n      return self[key]\n    else:\n      return default\n\n  def __contains__(self, item: _K) -&gt; bool:\n    item = self._key_checker.CheckValue(item)\n    return item in self._values\n\n  def __setitem__(self, key: _K, value: _V) -&gt; NoReturn:\n    raise ValueError('May not set values directly, call my_map[key].foo = 5')\n\n  def __delitem__(self, key: _K) -&gt; None:\n    key = self._key_checker.CheckValue(key)\n    del self._values[key]\n    self._message_listener.Modified()\n\n  def __len__(self) -&gt; int:\n    return len(self._values)\n\n  def __iter__(self) -&gt; Iterator[_K]:\n    return iter(self._values)\n\n  def __repr__(self) -&gt; str:\n    return repr(self._values)\n\n  def MergeFrom(self, other: 'MessageMap[_K, _V]') -&gt; None:\n    # pylint: disable=protected-access\n    for key in other._values:\n      # According to documentation: \"When parsing from the wire or when merging,\n      # if there are duplicate map keys the last key seen is used\".\n      if key in self:\n        del self[key]\n      self[key].CopyFrom(other[key])\n    # self._message_listener.Modified() not required here, because\n    # mutations to submessages already propagate.\n\n  def InvalidateIterators(self) -&gt; None:\n    # It appears that the only way to reliably invalidate iterators to\n    # self._values is to ensure that its size changes.\n    original = self._values\n    self._values = original.copy()\n    original[None] = None\n\n  # This is defined in the abstract base, but we can do it much more cheaply.\n  def clear(self) -&gt; None:\n    self._values.clear()\n    self._message_listener.Modified()\n\n  def GetEntryClass(self) -&gt; Any:\n    return self._entry_descriptor._concrete_class\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.MessageMap.__init__","title":"<code>__init__(message_listener, message_descriptor, key_checker, entry_descriptor)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>message_listener</code> <code>Any</code> <p>A MessageListener implementation. The ScalarMap will call this object's Modified() method when it is modified.</p> required <code>key_checker</code> <code>Any</code> <p>A type_checkers.ValueChecker instance to run on keys inserted into this container.</p> required <code>value_checker</code> <p>A type_checkers.ValueChecker instance to run on values inserted into this container.</p> required <code>entry_descriptor</code> <code>Any</code> <p>The MessageDescriptor of a map entry: key and value.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __init__(\n    self,\n    message_listener: Any,\n    message_descriptor: Any,\n    key_checker: Any,\n    entry_descriptor: Any,\n) -&gt; None:\n  \"\"\"\n  Args:\n    message_listener: A MessageListener implementation.\n      The ScalarMap will call this object's Modified() method when it\n      is modified.\n    key_checker: A type_checkers.ValueChecker instance to run on keys\n      inserted into this container.\n    value_checker: A type_checkers.ValueChecker instance to run on values\n      inserted into this container.\n    entry_descriptor: The MessageDescriptor of a map entry: key and value.\n  \"\"\"\n  self._message_listener = message_listener\n  self._message_descriptor = message_descriptor\n  self._key_checker = key_checker\n  self._entry_descriptor = entry_descriptor\n  self._values = {}\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.MessageMap.get_or_create","title":"<code>get_or_create(key)</code>","text":"<p>get_or_create() is an alias for getitem (ie. map[key]).</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>_K</code> <p>The key to get or create in the map.</p> required <p>This is useful in cases where you want to be explicit that the call is mutating the map.  This can avoid lint errors for statements like this that otherwise would appear to be pointless statements:</p> <p>msg.my_map[key]</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def get_or_create(self, key: _K) -&gt; _V:\n  \"\"\"get_or_create() is an alias for getitem (ie. map[key]).\n\n  Args:\n    key: The key to get or create in the map.\n\n  This is useful in cases where you want to be explicit that the call is\n  mutating the map.  This can avoid lint errors for statements like this\n  that otherwise would appear to be pointless statements:\n\n    msg.my_map[key]\n  \"\"\"\n  return self[key]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer","title":"<code>RepeatedCompositeFieldContainer</code>","text":"<p>               Bases: <code>BaseContainer[_T]</code>, <code>MutableSequence[_T]</code></p> <p>Simple, list-like container for holding repeated composite fields.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>class RepeatedCompositeFieldContainer(BaseContainer[_T], MutableSequence[_T]):\n  \"\"\"Simple, list-like container for holding repeated composite fields.\"\"\"\n\n  # Disallows assignment to other attributes.\n  __slots__ = ['_message_descriptor']\n\n  def __init__(self, message_listener: Any, message_descriptor: Any) -&gt; None:\n    \"\"\"\n    Note that we pass in a descriptor instead of the generated directly,\n    since at the time we construct a _RepeatedCompositeFieldContainer we\n    haven't yet necessarily initialized the type that will be contained in the\n    container.\n\n    Args:\n      message_listener: A MessageListener implementation.\n        The RepeatedCompositeFieldContainer will call this object's\n        Modified() method when it is modified.\n      message_descriptor: A Descriptor instance describing the protocol type\n        that should be present in this container.  We'll use the\n        _concrete_class field of this descriptor when the client calls add().\n    \"\"\"\n    super().__init__(message_listener)\n    self._message_descriptor = message_descriptor\n\n  def add(self, **kwargs: Any) -&gt; _T:\n    \"\"\"Adds a new element at the end of the list and returns it. Keyword\n    arguments may be used to initialize the element.\n    \"\"\"\n    new_element = self._message_descriptor._concrete_class(**kwargs)\n    new_element._SetListener(self._message_listener)\n    self._values.append(new_element)\n    if not self._message_listener.dirty:\n      self._message_listener.Modified()\n    return new_element\n\n  def append(self, value: _T) -&gt; None:\n    \"\"\"Appends one element by copying the message.\"\"\"\n    new_element = self._message_descriptor._concrete_class()\n    new_element._SetListener(self._message_listener)\n    new_element.CopyFrom(value)\n    self._values.append(new_element)\n    if not self._message_listener.dirty:\n      self._message_listener.Modified()\n\n  def insert(self, key: int, value: _T) -&gt; None:\n    \"\"\"Inserts the item at the specified position by copying.\"\"\"\n    new_element = self._message_descriptor._concrete_class()\n    new_element._SetListener(self._message_listener)\n    new_element.CopyFrom(value)\n    self._values.insert(key, new_element)\n    if not self._message_listener.dirty:\n      self._message_listener.Modified()\n\n  def extend(self, elem_seq: Iterable[_T]) -&gt; None:\n    \"\"\"Extends by appending the given sequence of elements of the same type\n\n    as this one, copying each individual message.\n    \"\"\"\n    message_class = self._message_descriptor._concrete_class\n    listener = self._message_listener\n    values = self._values\n    for message in elem_seq:\n      new_element = message_class()\n      new_element._SetListener(listener)\n      new_element.MergeFrom(message)\n      values.append(new_element)\n    listener.Modified()\n\n  def MergeFrom(\n      self,\n      other: Union['RepeatedCompositeFieldContainer[_T]', Iterable[_T]],\n  ) -&gt; None:\n    \"\"\"Appends the contents of another repeated field of the same type to this\n    one, copying each individual message.\n    \"\"\"\n    self.extend(other)\n\n  def remove(self, elem: _T) -&gt; None:\n    \"\"\"Removes an item from the list. Similar to list.remove().\"\"\"\n    self._values.remove(elem)\n    self._message_listener.Modified()\n\n  def pop(self, key: Optional[int] = -1) -&gt; _T:\n    \"\"\"Removes and returns an item at a given index. Similar to list.pop().\"\"\"\n    value = self._values[key]\n    self.__delitem__(key)\n    return value\n\n  @overload\n  def __setitem__(self, key: int, value: _T) -&gt; None:\n    ...\n\n  @overload\n  def __setitem__(self, key: slice, value: Iterable[_T]) -&gt; None:\n    ...\n\n  def __setitem__(self, key, value):\n    # This method is implemented to make RepeatedCompositeFieldContainer\n    # structurally compatible with typing.MutableSequence. It is\n    # otherwise unsupported and will always raise an error.\n    raise TypeError(\n        f'{self.__class__.__name__} object does not support item assignment')\n\n  def __delitem__(self, key: Union[int, slice]) -&gt; None:\n    \"\"\"Deletes the item at the specified position.\"\"\"\n    del self._values[key]\n    self._message_listener.Modified()\n\n  def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compares the current instance with another one.\"\"\"\n    if self is other:\n      return True\n    if not isinstance(other, self.__class__):\n      raise TypeError('Can only compare repeated composite fields against '\n                      'other repeated composite fields.')\n    return self._values == other._values\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.MergeFrom","title":"<code>MergeFrom(other)</code>","text":"<p>Appends the contents of another repeated field of the same type to this one, copying each individual message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def MergeFrom(\n    self,\n    other: Union['RepeatedCompositeFieldContainer[_T]', Iterable[_T]],\n) -&gt; None:\n  \"\"\"Appends the contents of another repeated field of the same type to this\n  one, copying each individual message.\n  \"\"\"\n  self.extend(other)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Deletes the item at the specified position.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __delitem__(self, key: Union[int, slice]) -&gt; None:\n  \"\"\"Deletes the item at the specified position.\"\"\"\n  del self._values[key]\n  self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compares the current instance with another one.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n  \"\"\"Compares the current instance with another one.\"\"\"\n  if self is other:\n    return True\n  if not isinstance(other, self.__class__):\n    raise TypeError('Can only compare repeated composite fields against '\n                    'other repeated composite fields.')\n  return self._values == other._values\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.__init__","title":"<code>__init__(message_listener, message_descriptor)</code>","text":"<p>Note that we pass in a descriptor instead of the generated directly, since at the time we construct a _RepeatedCompositeFieldContainer we haven't yet necessarily initialized the type that will be contained in the container.</p> <p>Parameters:</p> Name Type Description Default <code>message_listener</code> <code>Any</code> <p>A MessageListener implementation. The RepeatedCompositeFieldContainer will call this object's Modified() method when it is modified.</p> required <code>message_descriptor</code> <code>Any</code> <p>A Descriptor instance describing the protocol type that should be present in this container.  We'll use the _concrete_class field of this descriptor when the client calls add().</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __init__(self, message_listener: Any, message_descriptor: Any) -&gt; None:\n  \"\"\"\n  Note that we pass in a descriptor instead of the generated directly,\n  since at the time we construct a _RepeatedCompositeFieldContainer we\n  haven't yet necessarily initialized the type that will be contained in the\n  container.\n\n  Args:\n    message_listener: A MessageListener implementation.\n      The RepeatedCompositeFieldContainer will call this object's\n      Modified() method when it is modified.\n    message_descriptor: A Descriptor instance describing the protocol type\n      that should be present in this container.  We'll use the\n      _concrete_class field of this descriptor when the client calls add().\n  \"\"\"\n  super().__init__(message_listener)\n  self._message_descriptor = message_descriptor\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.add","title":"<code>add(**kwargs)</code>","text":"<p>Adds a new element at the end of the list and returns it. Keyword arguments may be used to initialize the element.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def add(self, **kwargs: Any) -&gt; _T:\n  \"\"\"Adds a new element at the end of the list and returns it. Keyword\n  arguments may be used to initialize the element.\n  \"\"\"\n  new_element = self._message_descriptor._concrete_class(**kwargs)\n  new_element._SetListener(self._message_listener)\n  self._values.append(new_element)\n  if not self._message_listener.dirty:\n    self._message_listener.Modified()\n  return new_element\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.append","title":"<code>append(value)</code>","text":"<p>Appends one element by copying the message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def append(self, value: _T) -&gt; None:\n  \"\"\"Appends one element by copying the message.\"\"\"\n  new_element = self._message_descriptor._concrete_class()\n  new_element._SetListener(self._message_listener)\n  new_element.CopyFrom(value)\n  self._values.append(new_element)\n  if not self._message_listener.dirty:\n    self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.extend","title":"<code>extend(elem_seq)</code>","text":"<p>Extends by appending the given sequence of elements of the same type</p> <p>as this one, copying each individual message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def extend(self, elem_seq: Iterable[_T]) -&gt; None:\n  \"\"\"Extends by appending the given sequence of elements of the same type\n\n  as this one, copying each individual message.\n  \"\"\"\n  message_class = self._message_descriptor._concrete_class\n  listener = self._message_listener\n  values = self._values\n  for message in elem_seq:\n    new_element = message_class()\n    new_element._SetListener(listener)\n    new_element.MergeFrom(message)\n    values.append(new_element)\n  listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.insert","title":"<code>insert(key, value)</code>","text":"<p>Inserts the item at the specified position by copying.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def insert(self, key: int, value: _T) -&gt; None:\n  \"\"\"Inserts the item at the specified position by copying.\"\"\"\n  new_element = self._message_descriptor._concrete_class()\n  new_element._SetListener(self._message_listener)\n  new_element.CopyFrom(value)\n  self._values.insert(key, new_element)\n  if not self._message_listener.dirty:\n    self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.pop","title":"<code>pop(key=-1)</code>","text":"<p>Removes and returns an item at a given index. Similar to list.pop().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def pop(self, key: Optional[int] = -1) -&gt; _T:\n  \"\"\"Removes and returns an item at a given index. Similar to list.pop().\"\"\"\n  value = self._values[key]\n  self.__delitem__(key)\n  return value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedCompositeFieldContainer.remove","title":"<code>remove(elem)</code>","text":"<p>Removes an item from the list. Similar to list.remove().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def remove(self, elem: _T) -&gt; None:\n  \"\"\"Removes an item from the list. Similar to list.remove().\"\"\"\n  self._values.remove(elem)\n  self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer","title":"<code>RepeatedScalarFieldContainer</code>","text":"<p>               Bases: <code>BaseContainer[_T]</code>, <code>MutableSequence[_T]</code></p> <p>Simple, type-checked, list-like container for holding repeated scalars.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>class RepeatedScalarFieldContainer(BaseContainer[_T], MutableSequence[_T]):\n  \"\"\"Simple, type-checked, list-like container for holding repeated scalars.\"\"\"\n\n  # Disallows assignment to other attributes.\n  __slots__ = ['_type_checker']\n\n  def __init__(\n      self,\n      message_listener: Any,\n      type_checker: Any,\n  ) -&gt; None:\n    \"\"\"Args:\n\n      message_listener: A MessageListener implementation. The\n      RepeatedScalarFieldContainer will call this object's Modified() method\n      when it is modified.\n      type_checker: A type_checkers.ValueChecker instance to run on elements\n      inserted into this container.\n    \"\"\"\n    super().__init__(message_listener)\n    self._type_checker = type_checker\n\n  def append(self, value: _T) -&gt; None:\n    \"\"\"Appends an item to the list. Similar to list.append().\"\"\"\n    self._values.append(self._type_checker.CheckValue(value))\n    if not self._message_listener.dirty:\n      self._message_listener.Modified()\n\n  def insert(self, key: int, value: _T) -&gt; None:\n    \"\"\"Inserts the item at the specified position. Similar to list.insert().\"\"\"\n    self._values.insert(key, self._type_checker.CheckValue(value))\n    if not self._message_listener.dirty:\n      self._message_listener.Modified()\n\n  def extend(self, elem_seq: Iterable[_T]) -&gt; None:\n    \"\"\"Extends by appending the given iterable. Similar to list.extend().\"\"\"\n    if elem_seq is None:\n      return\n    try:\n      elem_seq_iter = iter(elem_seq)\n    except TypeError:\n      if not elem_seq:\n        # silently ignore falsy inputs :-/.\n        # TODO(ptucker): Deprecate this behavior. b/18413862\n        return\n      raise\n\n    new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n    if new_values:\n      self._values.extend(new_values)\n    self._message_listener.Modified()\n\n  def MergeFrom(\n      self,\n      other: Union['RepeatedScalarFieldContainer[_T]', Iterable[_T]],\n  ) -&gt; None:\n    \"\"\"Appends the contents of another repeated field of the same type to this\n    one. We do not check the types of the individual fields.\n    \"\"\"\n    self._values.extend(other)\n    self._message_listener.Modified()\n\n  def remove(self, elem: _T):\n    \"\"\"Removes an item from the list. Similar to list.remove().\"\"\"\n    self._values.remove(elem)\n    self._message_listener.Modified()\n\n  def pop(self, key: Optional[int] = -1) -&gt; _T:\n    \"\"\"Removes and returns an item at a given index. Similar to list.pop().\"\"\"\n    value = self._values[key]\n    self.__delitem__(key)\n    return value\n\n  @overload\n  def __setitem__(self, key: int, value: _T) -&gt; None:\n    ...\n\n  @overload\n  def __setitem__(self, key: slice, value: Iterable[_T]) -&gt; None:\n    ...\n\n  def __setitem__(self, key, value) -&gt; None:\n    \"\"\"Sets the item on the specified position.\"\"\"\n    if isinstance(key, slice):\n      if key.step is not None:\n        raise ValueError('Extended slices not supported')\n      self._values[key] = map(self._type_checker.CheckValue, value)\n      self._message_listener.Modified()\n    else:\n      self._values[key] = self._type_checker.CheckValue(value)\n      self._message_listener.Modified()\n\n  def __delitem__(self, key: Union[int, slice]) -&gt; None:\n    \"\"\"Deletes the item at the specified position.\"\"\"\n    del self._values[key]\n    self._message_listener.Modified()\n\n  def __eq__(self, other: Any) -&gt; bool:\n    \"\"\"Compares the current instance with another one.\"\"\"\n    if self is other:\n      return True\n    # Special case for the same type which should be common and fast.\n    if isinstance(other, self.__class__):\n      return other._values == self._values\n    # We are presumably comparing against some other sequence type.\n    return other == self._values\n\n  def __deepcopy__(\n      self,\n      unused_memo: Any = None,\n  ) -&gt; 'RepeatedScalarFieldContainer[_T]':\n    clone = RepeatedScalarFieldContainer(\n        copy.deepcopy(self._message_listener), self._type_checker)\n    clone.MergeFrom(self)\n    return clone\n\n  def __reduce__(self, **kwargs) -&gt; NoReturn:\n    raise pickle.PickleError(\n        \"Can't pickle repeated scalar fields, convert to list first\")\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.MergeFrom","title":"<code>MergeFrom(other)</code>","text":"<p>Appends the contents of another repeated field of the same type to this one. We do not check the types of the individual fields.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def MergeFrom(\n    self,\n    other: Union['RepeatedScalarFieldContainer[_T]', Iterable[_T]],\n) -&gt; None:\n  \"\"\"Appends the contents of another repeated field of the same type to this\n  one. We do not check the types of the individual fields.\n  \"\"\"\n  self._values.extend(other)\n  self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.__delitem__","title":"<code>__delitem__(key)</code>","text":"<p>Deletes the item at the specified position.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __delitem__(self, key: Union[int, slice]) -&gt; None:\n  \"\"\"Deletes the item at the specified position.\"\"\"\n  del self._values[key]\n  self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.__eq__","title":"<code>__eq__(other)</code>","text":"<p>Compares the current instance with another one.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __eq__(self, other: Any) -&gt; bool:\n  \"\"\"Compares the current instance with another one.\"\"\"\n  if self is other:\n    return True\n  # Special case for the same type which should be common and fast.\n  if isinstance(other, self.__class__):\n    return other._values == self._values\n  # We are presumably comparing against some other sequence type.\n  return other == self._values\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.__init__","title":"<code>__init__(message_listener, type_checker)</code>","text":"<p>Args:</p> <p>message_listener: A MessageListener implementation. The RepeatedScalarFieldContainer will call this object's Modified() method when it is modified. type_checker: A type_checkers.ValueChecker instance to run on elements inserted into this container.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __init__(\n    self,\n    message_listener: Any,\n    type_checker: Any,\n) -&gt; None:\n  \"\"\"Args:\n\n    message_listener: A MessageListener implementation. The\n    RepeatedScalarFieldContainer will call this object's Modified() method\n    when it is modified.\n    type_checker: A type_checkers.ValueChecker instance to run on elements\n    inserted into this container.\n  \"\"\"\n  super().__init__(message_listener)\n  self._type_checker = type_checker\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.__setitem__","title":"<code>__setitem__(key, value)</code>","text":"<pre><code>__setitem__(key: int, value: _T) -&gt; None\n</code></pre><pre><code>__setitem__(key: slice, value: Iterable[_T]) -&gt; None\n</code></pre> <p>Sets the item on the specified position.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __setitem__(self, key, value) -&gt; None:\n  \"\"\"Sets the item on the specified position.\"\"\"\n  if isinstance(key, slice):\n    if key.step is not None:\n      raise ValueError('Extended slices not supported')\n    self._values[key] = map(self._type_checker.CheckValue, value)\n    self._message_listener.Modified()\n  else:\n    self._values[key] = self._type_checker.CheckValue(value)\n    self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.append","title":"<code>append(value)</code>","text":"<p>Appends an item to the list. Similar to list.append().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def append(self, value: _T) -&gt; None:\n  \"\"\"Appends an item to the list. Similar to list.append().\"\"\"\n  self._values.append(self._type_checker.CheckValue(value))\n  if not self._message_listener.dirty:\n    self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.extend","title":"<code>extend(elem_seq)</code>","text":"<p>Extends by appending the given iterable. Similar to list.extend().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def extend(self, elem_seq: Iterable[_T]) -&gt; None:\n  \"\"\"Extends by appending the given iterable. Similar to list.extend().\"\"\"\n  if elem_seq is None:\n    return\n  try:\n    elem_seq_iter = iter(elem_seq)\n  except TypeError:\n    if not elem_seq:\n      # silently ignore falsy inputs :-/.\n      # TODO(ptucker): Deprecate this behavior. b/18413862\n      return\n    raise\n\n  new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\n  if new_values:\n    self._values.extend(new_values)\n  self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.insert","title":"<code>insert(key, value)</code>","text":"<p>Inserts the item at the specified position. Similar to list.insert().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def insert(self, key: int, value: _T) -&gt; None:\n  \"\"\"Inserts the item at the specified position. Similar to list.insert().\"\"\"\n  self._values.insert(key, self._type_checker.CheckValue(value))\n  if not self._message_listener.dirty:\n    self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.pop","title":"<code>pop(key=-1)</code>","text":"<p>Removes and returns an item at a given index. Similar to list.pop().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def pop(self, key: Optional[int] = -1) -&gt; _T:\n  \"\"\"Removes and returns an item at a given index. Similar to list.pop().\"\"\"\n  value = self._values[key]\n  self.__delitem__(key)\n  return value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.RepeatedScalarFieldContainer.remove","title":"<code>remove(elem)</code>","text":"<p>Removes an item from the list. Similar to list.remove().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def remove(self, elem: _T):\n  \"\"\"Removes an item from the list. Similar to list.remove().\"\"\"\n  self._values.remove(elem)\n  self._message_listener.Modified()\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.ScalarMap","title":"<code>ScalarMap</code>","text":"<p>               Bases: <code>MutableMapping[_K, _V]</code></p> <p>Simple, type-checked, dict-like container for holding repeated scalars.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>class ScalarMap(MutableMapping[_K, _V]):\n  \"\"\"Simple, type-checked, dict-like container for holding repeated scalars.\"\"\"\n\n  # Disallows assignment to other attributes.\n  __slots__ = ['_key_checker', '_value_checker', '_values', '_message_listener',\n               '_entry_descriptor']\n\n  def __init__(\n      self,\n      message_listener: Any,\n      key_checker: Any,\n      value_checker: Any,\n      entry_descriptor: Any,\n  ) -&gt; None:\n    \"\"\"\n    Args:\n      message_listener: A MessageListener implementation.\n        The ScalarMap will call this object's Modified() method when it\n        is modified.\n      key_checker: A type_checkers.ValueChecker instance to run on keys\n        inserted into this container.\n      value_checker: A type_checkers.ValueChecker instance to run on values\n        inserted into this container.\n      entry_descriptor: The MessageDescriptor of a map entry: key and value.\n    \"\"\"\n    self._message_listener = message_listener\n    self._key_checker = key_checker\n    self._value_checker = value_checker\n    self._entry_descriptor = entry_descriptor\n    self._values = {}\n\n  def __getitem__(self, key: _K) -&gt; _V:\n    try:\n      return self._values[key]\n    except KeyError:\n      key = self._key_checker.CheckValue(key)\n      val = self._value_checker.DefaultValue()\n      self._values[key] = val\n      return val\n\n  def __contains__(self, item: _K) -&gt; bool:\n    # We check the key's type to match the strong-typing flavor of the API.\n    # Also this makes it easier to match the behavior of the C++ implementation.\n    self._key_checker.CheckValue(item)\n    return item in self._values\n\n  @overload\n  def get(self, key: _K) -&gt; Optional[_V]:\n    ...\n\n  @overload\n  def get(self, key: _K, default: _T) -&gt; Union[_V, _T]:\n    ...\n\n  # We need to override this explicitly, because our defaultdict-like behavior\n  # will make the default implementation (from our base class) always insert\n  # the key.\n  def get(self, key, default=None):\n    if key in self:\n      return self[key]\n    else:\n      return default\n\n  def __setitem__(self, key: _K, value: _V) -&gt; _T:\n    checked_key = self._key_checker.CheckValue(key)\n    checked_value = self._value_checker.CheckValue(value)\n    self._values[checked_key] = checked_value\n    self._message_listener.Modified()\n\n  def __delitem__(self, key: _K) -&gt; None:\n    del self._values[key]\n    self._message_listener.Modified()\n\n  def __len__(self) -&gt; int:\n    return len(self._values)\n\n  def __iter__(self) -&gt; Iterator[_K]:\n    return iter(self._values)\n\n  def __repr__(self) -&gt; str:\n    return repr(self._values)\n\n  def MergeFrom(self, other: 'ScalarMap[_K, _V]') -&gt; None:\n    self._values.update(other._values)\n    self._message_listener.Modified()\n\n  def InvalidateIterators(self) -&gt; None:\n    # It appears that the only way to reliably invalidate iterators to\n    # self._values is to ensure that its size changes.\n    original = self._values\n    self._values = original.copy()\n    original[None] = None\n\n  # This is defined in the abstract base, but we can do it much more cheaply.\n  def clear(self) -&gt; None:\n    self._values.clear()\n    self._message_listener.Modified()\n\n  def GetEntryClass(self) -&gt; Any:\n    return self._entry_descriptor._concrete_class\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.ScalarMap.__init__","title":"<code>__init__(message_listener, key_checker, value_checker, entry_descriptor)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>message_listener</code> <code>Any</code> <p>A MessageListener implementation. The ScalarMap will call this object's Modified() method when it is modified.</p> required <code>key_checker</code> <code>Any</code> <p>A type_checkers.ValueChecker instance to run on keys inserted into this container.</p> required <code>value_checker</code> <code>Any</code> <p>A type_checkers.ValueChecker instance to run on values inserted into this container.</p> required <code>entry_descriptor</code> <code>Any</code> <p>The MessageDescriptor of a map entry: key and value.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>def __init__(\n    self,\n    message_listener: Any,\n    key_checker: Any,\n    value_checker: Any,\n    entry_descriptor: Any,\n) -&gt; None:\n  \"\"\"\n  Args:\n    message_listener: A MessageListener implementation.\n      The ScalarMap will call this object's Modified() method when it\n      is modified.\n    key_checker: A type_checkers.ValueChecker instance to run on keys\n      inserted into this container.\n    value_checker: A type_checkers.ValueChecker instance to run on values\n      inserted into this container.\n    entry_descriptor: The MessageDescriptor of a map entry: key and value.\n  \"\"\"\n  self._message_listener = message_listener\n  self._key_checker = key_checker\n  self._value_checker = value_checker\n  self._entry_descriptor = entry_descriptor\n  self._values = {}\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/containers.html#client.ayon_nuke.vendor.google.protobuf.internal.containers.UnknownFieldSet","title":"<code>UnknownFieldSet</code>","text":"<p>UnknownField container</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/containers.py</code> <pre><code>class UnknownFieldSet:\n  \"\"\"UnknownField container\"\"\"\n\n  # Disallows assignment to other attributes.\n  __slots__ = ['_values']\n\n  def __init__(self):\n    self._values = []\n\n  def __getitem__(self, index):\n    if self._values is None:\n      raise ValueError('UnknownFields does not exist. '\n                       'The parent message might be cleared.')\n    size = len(self._values)\n    if index &lt; 0:\n      index += size\n    if index &lt; 0 or index &gt;= size:\n      raise IndexError('index %d out of range'.index)\n\n    return UnknownFieldRef(self, index)\n\n  def _internal_get(self, index):\n    return self._values[index]\n\n  def __len__(self):\n    if self._values is None:\n      raise ValueError('UnknownFields does not exist. '\n                       'The parent message might be cleared.')\n    return len(self._values)\n\n  def _add(self, field_number, wire_type, data):\n    unknown_field = _UnknownField(field_number, wire_type, data)\n    self._values.append(unknown_field)\n    return unknown_field\n\n  def __iter__(self):\n    for i in range(len(self)):\n      yield UnknownFieldRef(self, i)\n\n  def _extend(self, other):\n    if other is None:\n      return\n    # pylint: disable=protected-access\n    self._values.extend(other._values)\n\n  def __eq__(self, other):\n    if self is other:\n      return True\n    # Sort unknown fields because their order shouldn't\n    # affect equality test.\n    values = list(self._values)\n    if other is None:\n      return not values\n    values.sort()\n    # pylint: disable=protected-access\n    other_values = sorted(other._values)\n    return values == other_values\n\n  def _clear(self):\n    for value in self._values:\n      # pylint: disable=protected-access\n      if isinstance(value._data, UnknownFieldSet):\n        value._data._clear()  # pylint: disable=protected-access\n    self._values = None\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html","title":"decoder","text":"<p>Code for decoding protocol buffer primitives.</p> <p>This code is very similar to encoder.py -- read the docs for that module first.</p> <p>A \"decoder\" is a function with the signature:   Decode(buffer, pos, end, message, field_dict) The arguments are:   buffer:     The string containing the encoded message.   pos:        The current position in the string.   end:        The position in the string where the current message ends.  May be               less than len(buffer) if we're reading a sub-message.   message:    The message object into which we're parsing.   field_dict: message._fields (avoids a hashtable lookup). The decoder reads the field and stores it into field_dict, returning the new buffer position.  A decoder for a repeated field may proactively decode all of the elements of that field, if they appear consecutively.</p> Note that decoders may throw any of the following <p>IndexError:  Indicates a truncated message. struct.error:  Unpacking of a fixed-width field failed. message.DecodeError:  Other errors.</p> <p>Decoders are expected to raise an exception if they are called with pos &gt; end. This allows callers to be lax about bounds checking:  it's fineto read past \"end\" as long as you are sure that someone else will notice and throw an exception later on.</p> <p>Something up the call stack is expected to catch IndexError and struct.error and convert them to message.DecodeError.</p> Decoders are constructed using decoder constructors with the signature <p>MakeDecoder(field_number, is_repeated, is_packed, key, new_default)</p> <p>The arguments are:   field_number:  The field number of the field we want to decode.   is_repeated:   Is the field a repeated field? (bool)   is_packed:     Is the field a packed field? (bool)   key:           The key to use when looking up the field within field_dict.                  (This is actually the FieldDescriptor but nothing in this                  file should depend on that.)   new_default:   A function which takes a message object as a parameter and                  returns a new instance of the default value for this field.                  (This is called for repeated fields and sub-messages, when an                  instance does not already exist.)</p> <p>As with encoders, we define a decoder constructor for every type of field. Then, for every field of every message class we construct an actual decoder. That decoder goes into a dict indexed by tag, so when we decode a message we repeatedly read a tag, look up the corresponding decoder, and invoke it.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.BytesDecoder","title":"<code>BytesDecoder(field_number, is_repeated, is_packed, key, new_default, clear_if_default=False)</code>","text":"<p>Returns a decoder for a bytes field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def BytesDecoder(field_number, is_repeated, is_packed, key, new_default,\n                 clear_if_default=False):\n  \"\"\"Returns a decoder for a bytes field.\"\"\"\n\n  local_DecodeVarint = _DecodeVarint\n\n  assert not is_packed\n  if is_repeated:\n    tag_bytes = encoder.TagBytes(field_number,\n                                 wire_format.WIRETYPE_LENGTH_DELIMITED)\n    tag_len = len(tag_bytes)\n    def DecodeRepeatedField(buffer, pos, end, message, field_dict):\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      while 1:\n        (size, pos) = local_DecodeVarint(buffer, pos)\n        new_pos = pos + size\n        if new_pos &gt; end:\n          raise _DecodeError('Truncated string.')\n        value.append(buffer[pos:new_pos].tobytes())\n        # Predict that the next tag is another copy of the same repeated field.\n        pos = new_pos + tag_len\n        if buffer[new_pos:pos] != tag_bytes or new_pos == end:\n          # Prediction failed.  Return.\n          return new_pos\n    return DecodeRepeatedField\n  else:\n    def DecodeField(buffer, pos, end, message, field_dict):\n      (size, pos) = local_DecodeVarint(buffer, pos)\n      new_pos = pos + size\n      if new_pos &gt; end:\n        raise _DecodeError('Truncated string.')\n      if clear_if_default and not size:\n        field_dict.pop(key, None)\n      else:\n        field_dict[key] = buffer[pos:new_pos].tobytes()\n      return new_pos\n    return DecodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.EnumDecoder","title":"<code>EnumDecoder(field_number, is_repeated, is_packed, key, new_default, clear_if_default=False)</code>","text":"<p>Returns a decoder for enum field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def EnumDecoder(field_number, is_repeated, is_packed, key, new_default,\n                clear_if_default=False):\n  \"\"\"Returns a decoder for enum field.\"\"\"\n  enum_type = key.enum_type\n  if is_packed:\n    local_DecodeVarint = _DecodeVarint\n    def DecodePackedField(buffer, pos, end, message, field_dict):\n      \"\"\"Decode serialized packed enum to its value and a new position.\n\n      Args:\n        buffer: memoryview of the serialized bytes.\n        pos: int, position in the memory view to start at.\n        end: int, end position of serialized data\n        message: Message object to store unknown fields in\n        field_dict: Map[Descriptor, Any] to store decoded values in.\n\n      Returns:\n        int, new position in serialized data.\n      \"\"\"\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      (endpoint, pos) = local_DecodeVarint(buffer, pos)\n      endpoint += pos\n      if endpoint &gt; end:\n        raise _DecodeError('Truncated message.')\n      while pos &lt; endpoint:\n        value_start_pos = pos\n        (element, pos) = _DecodeSignedVarint32(buffer, pos)\n        # pylint: disable=protected-access\n        if element in enum_type.values_by_number:\n          value.append(element)\n        else:\n          if not message._unknown_fields:\n            message._unknown_fields = []\n          tag_bytes = encoder.TagBytes(field_number,\n                                       wire_format.WIRETYPE_VARINT)\n\n          message._unknown_fields.append(\n              (tag_bytes, buffer[value_start_pos:pos].tobytes()))\n          if message._unknown_field_set is None:\n            message._unknown_field_set = containers.UnknownFieldSet()\n          message._unknown_field_set._add(\n              field_number, wire_format.WIRETYPE_VARINT, element)\n          # pylint: enable=protected-access\n      if pos &gt; endpoint:\n        if element in enum_type.values_by_number:\n          del value[-1]   # Discard corrupt value.\n        else:\n          del message._unknown_fields[-1]\n          # pylint: disable=protected-access\n          del message._unknown_field_set._values[-1]\n          # pylint: enable=protected-access\n        raise _DecodeError('Packed element was truncated.')\n      return pos\n    return DecodePackedField\n  elif is_repeated:\n    tag_bytes = encoder.TagBytes(field_number, wire_format.WIRETYPE_VARINT)\n    tag_len = len(tag_bytes)\n    def DecodeRepeatedField(buffer, pos, end, message, field_dict):\n      \"\"\"Decode serialized repeated enum to its value and a new position.\n\n      Args:\n        buffer: memoryview of the serialized bytes.\n        pos: int, position in the memory view to start at.\n        end: int, end position of serialized data\n        message: Message object to store unknown fields in\n        field_dict: Map[Descriptor, Any] to store decoded values in.\n\n      Returns:\n        int, new position in serialized data.\n      \"\"\"\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      while 1:\n        (element, new_pos) = _DecodeSignedVarint32(buffer, pos)\n        # pylint: disable=protected-access\n        if element in enum_type.values_by_number:\n          value.append(element)\n        else:\n          if not message._unknown_fields:\n            message._unknown_fields = []\n          message._unknown_fields.append(\n              (tag_bytes, buffer[pos:new_pos].tobytes()))\n          if message._unknown_field_set is None:\n            message._unknown_field_set = containers.UnknownFieldSet()\n          message._unknown_field_set._add(\n              field_number, wire_format.WIRETYPE_VARINT, element)\n        # pylint: enable=protected-access\n        # Predict that the next tag is another copy of the same repeated\n        # field.\n        pos = new_pos + tag_len\n        if buffer[new_pos:pos] != tag_bytes or new_pos &gt;= end:\n          # Prediction failed.  Return.\n          if new_pos &gt; end:\n            raise _DecodeError('Truncated message.')\n          return new_pos\n    return DecodeRepeatedField\n  else:\n    def DecodeField(buffer, pos, end, message, field_dict):\n      \"\"\"Decode serialized repeated enum to its value and a new position.\n\n      Args:\n        buffer: memoryview of the serialized bytes.\n        pos: int, position in the memory view to start at.\n        end: int, end position of serialized data\n        message: Message object to store unknown fields in\n        field_dict: Map[Descriptor, Any] to store decoded values in.\n\n      Returns:\n        int, new position in serialized data.\n      \"\"\"\n      value_start_pos = pos\n      (enum_value, pos) = _DecodeSignedVarint32(buffer, pos)\n      if pos &gt; end:\n        raise _DecodeError('Truncated message.')\n      if clear_if_default and not enum_value:\n        field_dict.pop(key, None)\n        return pos\n      # pylint: disable=protected-access\n      if enum_value in enum_type.values_by_number:\n        field_dict[key] = enum_value\n      else:\n        if not message._unknown_fields:\n          message._unknown_fields = []\n        tag_bytes = encoder.TagBytes(field_number,\n                                     wire_format.WIRETYPE_VARINT)\n        message._unknown_fields.append(\n            (tag_bytes, buffer[value_start_pos:pos].tobytes()))\n        if message._unknown_field_set is None:\n          message._unknown_field_set = containers.UnknownFieldSet()\n        message._unknown_field_set._add(\n            field_number, wire_format.WIRETYPE_VARINT, enum_value)\n        # pylint: enable=protected-access\n      return pos\n    return DecodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.GroupDecoder","title":"<code>GroupDecoder(field_number, is_repeated, is_packed, key, new_default)</code>","text":"<p>Returns a decoder for a group field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def GroupDecoder(field_number, is_repeated, is_packed, key, new_default):\n  \"\"\"Returns a decoder for a group field.\"\"\"\n\n  end_tag_bytes = encoder.TagBytes(field_number,\n                                   wire_format.WIRETYPE_END_GROUP)\n  end_tag_len = len(end_tag_bytes)\n\n  assert not is_packed\n  if is_repeated:\n    tag_bytes = encoder.TagBytes(field_number,\n                                 wire_format.WIRETYPE_START_GROUP)\n    tag_len = len(tag_bytes)\n    def DecodeRepeatedField(buffer, pos, end, message, field_dict):\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      while 1:\n        value = field_dict.get(key)\n        if value is None:\n          value = field_dict.setdefault(key, new_default(message))\n        # Read sub-message.\n        pos = value.add()._InternalParse(buffer, pos, end)\n        # Read end tag.\n        new_pos = pos+end_tag_len\n        if buffer[pos:new_pos] != end_tag_bytes or new_pos &gt; end:\n          raise _DecodeError('Missing group end tag.')\n        # Predict that the next tag is another copy of the same repeated field.\n        pos = new_pos + tag_len\n        if buffer[new_pos:pos] != tag_bytes or new_pos == end:\n          # Prediction failed.  Return.\n          return new_pos\n    return DecodeRepeatedField\n  else:\n    def DecodeField(buffer, pos, end, message, field_dict):\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      # Read sub-message.\n      pos = value._InternalParse(buffer, pos, end)\n      # Read end tag.\n      new_pos = pos+end_tag_len\n      if buffer[pos:new_pos] != end_tag_bytes or new_pos &gt; end:\n        raise _DecodeError('Missing group end tag.')\n      return new_pos\n    return DecodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.MapDecoder","title":"<code>MapDecoder(field_descriptor, new_default, is_message_map)</code>","text":"<p>Returns a decoder for a map field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def MapDecoder(field_descriptor, new_default, is_message_map):\n  \"\"\"Returns a decoder for a map field.\"\"\"\n\n  key = field_descriptor\n  tag_bytes = encoder.TagBytes(field_descriptor.number,\n                               wire_format.WIRETYPE_LENGTH_DELIMITED)\n  tag_len = len(tag_bytes)\n  local_DecodeVarint = _DecodeVarint\n  # Can't read _concrete_class yet; might not be initialized.\n  message_type = field_descriptor.message_type\n\n  def DecodeMap(buffer, pos, end, message, field_dict):\n    submsg = message_type._concrete_class()\n    value = field_dict.get(key)\n    if value is None:\n      value = field_dict.setdefault(key, new_default(message))\n    while 1:\n      # Read length.\n      (size, pos) = local_DecodeVarint(buffer, pos)\n      new_pos = pos + size\n      if new_pos &gt; end:\n        raise _DecodeError('Truncated message.')\n      # Read sub-message.\n      submsg.Clear()\n      if submsg._InternalParse(buffer, pos, new_pos) != new_pos:\n        # The only reason _InternalParse would return early is if it\n        # encountered an end-group tag.\n        raise _DecodeError('Unexpected end-group tag.')\n\n      if is_message_map:\n        value[submsg.key].CopyFrom(submsg.value)\n      else:\n        value[submsg.key] = submsg.value\n\n      # Predict that the next tag is another copy of the same repeated field.\n      pos = new_pos + tag_len\n      if buffer[new_pos:pos] != tag_bytes or new_pos == end:\n        # Prediction failed.  Return.\n        return new_pos\n\n  return DecodeMap\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.MessageDecoder","title":"<code>MessageDecoder(field_number, is_repeated, is_packed, key, new_default)</code>","text":"<p>Returns a decoder for a message field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def MessageDecoder(field_number, is_repeated, is_packed, key, new_default):\n  \"\"\"Returns a decoder for a message field.\"\"\"\n\n  local_DecodeVarint = _DecodeVarint\n\n  assert not is_packed\n  if is_repeated:\n    tag_bytes = encoder.TagBytes(field_number,\n                                 wire_format.WIRETYPE_LENGTH_DELIMITED)\n    tag_len = len(tag_bytes)\n    def DecodeRepeatedField(buffer, pos, end, message, field_dict):\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      while 1:\n        # Read length.\n        (size, pos) = local_DecodeVarint(buffer, pos)\n        new_pos = pos + size\n        if new_pos &gt; end:\n          raise _DecodeError('Truncated message.')\n        # Read sub-message.\n        if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:\n          # The only reason _InternalParse would return early is if it\n          # encountered an end-group tag.\n          raise _DecodeError('Unexpected end-group tag.')\n        # Predict that the next tag is another copy of the same repeated field.\n        pos = new_pos + tag_len\n        if buffer[new_pos:pos] != tag_bytes or new_pos == end:\n          # Prediction failed.  Return.\n          return new_pos\n    return DecodeRepeatedField\n  else:\n    def DecodeField(buffer, pos, end, message, field_dict):\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      # Read length.\n      (size, pos) = local_DecodeVarint(buffer, pos)\n      new_pos = pos + size\n      if new_pos &gt; end:\n        raise _DecodeError('Truncated message.')\n      # Read sub-message.\n      if value._InternalParse(buffer, pos, new_pos) != new_pos:\n        # The only reason _InternalParse would return early is if it encountered\n        # an end-group tag.\n        raise _DecodeError('Unexpected end-group tag.')\n      return new_pos\n    return DecodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.MessageSetItemDecoder","title":"<code>MessageSetItemDecoder(descriptor)</code>","text":"<p>Returns a decoder for a MessageSet item.</p> <p>The parameter is the message Descriptor.</p> The message set message looks like this <p>message MessageSet {   repeated group Item = 1 {     required int32 type_id = 2;     required string message = 3;   } }</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def MessageSetItemDecoder(descriptor):\n  \"\"\"Returns a decoder for a MessageSet item.\n\n  The parameter is the message Descriptor.\n\n  The message set message looks like this:\n    message MessageSet {\n      repeated group Item = 1 {\n        required int32 type_id = 2;\n        required string message = 3;\n      }\n    }\n  \"\"\"\n\n  type_id_tag_bytes = encoder.TagBytes(2, wire_format.WIRETYPE_VARINT)\n  message_tag_bytes = encoder.TagBytes(3, wire_format.WIRETYPE_LENGTH_DELIMITED)\n  item_end_tag_bytes = encoder.TagBytes(1, wire_format.WIRETYPE_END_GROUP)\n\n  local_ReadTag = ReadTag\n  local_DecodeVarint = _DecodeVarint\n  local_SkipField = SkipField\n\n  def DecodeItem(buffer, pos, end, message, field_dict):\n    \"\"\"Decode serialized message set to its value and new position.\n\n    Args:\n      buffer: memoryview of the serialized bytes.\n      pos: int, position in the memory view to start at.\n      end: int, end position of serialized data\n      message: Message object to store unknown fields in\n      field_dict: Map[Descriptor, Any] to store decoded values in.\n\n    Returns:\n      int, new position in serialized data.\n    \"\"\"\n    message_set_item_start = pos\n    type_id = -1\n    message_start = -1\n    message_end = -1\n\n    # Technically, type_id and message can appear in any order, so we need\n    # a little loop here.\n    while 1:\n      (tag_bytes, pos) = local_ReadTag(buffer, pos)\n      if tag_bytes == type_id_tag_bytes:\n        (type_id, pos) = local_DecodeVarint(buffer, pos)\n      elif tag_bytes == message_tag_bytes:\n        (size, message_start) = local_DecodeVarint(buffer, pos)\n        pos = message_end = message_start + size\n      elif tag_bytes == item_end_tag_bytes:\n        break\n      else:\n        pos = SkipField(buffer, pos, end, tag_bytes)\n        if pos == -1:\n          raise _DecodeError('Missing group end tag.')\n\n    if pos &gt; end:\n      raise _DecodeError('Truncated message.')\n\n    if type_id == -1:\n      raise _DecodeError('MessageSet item missing type_id.')\n    if message_start == -1:\n      raise _DecodeError('MessageSet item missing message.')\n\n    extension = message.Extensions._FindExtensionByNumber(type_id)\n    # pylint: disable=protected-access\n    if extension is not None:\n      value = field_dict.get(extension)\n      if value is None:\n        message_type = extension.message_type\n        if not hasattr(message_type, '_concrete_class'):\n          # pylint: disable=protected-access\n          message._FACTORY.GetPrototype(message_type)\n        value = field_dict.setdefault(\n            extension, message_type._concrete_class())\n      if value._InternalParse(buffer, message_start,message_end) != message_end:\n        # The only reason _InternalParse would return early is if it encountered\n        # an end-group tag.\n        raise _DecodeError('Unexpected end-group tag.')\n    else:\n      if not message._unknown_fields:\n        message._unknown_fields = []\n      message._unknown_fields.append(\n          (MESSAGE_SET_ITEM_TAG, buffer[message_set_item_start:pos].tobytes()))\n      if message._unknown_field_set is None:\n        message._unknown_field_set = containers.UnknownFieldSet()\n      message._unknown_field_set._add(\n          type_id,\n          wire_format.WIRETYPE_LENGTH_DELIMITED,\n          buffer[message_start:message_end].tobytes())\n      # pylint: enable=protected-access\n\n    return pos\n\n  return DecodeItem\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.ReadTag","title":"<code>ReadTag(buffer, pos)</code>","text":"<p>Read a tag from the memoryview, and return a (tag_bytes, new_pos) tuple.</p> <p>We return the raw bytes of the tag rather than decoding them.  The raw bytes can then be used to look up the proper decoder.  This effectively allows us to trade some work that would be done in pure-python (decoding a varint) for work that is done in C (searching for a byte string in a hash table). In a low-level language it would be much cheaper to decode the varint and use that, but not in Python.</p> <p>Parameters:</p> Name Type Description Default <code>buffer</code> <p>memoryview object of the encoded bytes</p> required <code>pos</code> <p>int of the current position to start from</p> required <p>Returns:</p> Type Description <p>Tuple[bytes, int] of the tag data and new position.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def ReadTag(buffer, pos):\n  \"\"\"Read a tag from the memoryview, and return a (tag_bytes, new_pos) tuple.\n\n  We return the raw bytes of the tag rather than decoding them.  The raw\n  bytes can then be used to look up the proper decoder.  This effectively allows\n  us to trade some work that would be done in pure-python (decoding a varint)\n  for work that is done in C (searching for a byte string in a hash table).\n  In a low-level language it would be much cheaper to decode the varint and\n  use that, but not in Python.\n\n  Args:\n    buffer: memoryview object of the encoded bytes\n    pos: int of the current position to start from\n\n  Returns:\n    Tuple[bytes, int] of the tag data and new position.\n  \"\"\"\n  start = pos\n  while buffer[pos] &amp; 0x80:\n    pos += 1\n  pos += 1\n\n  tag_bytes = buffer[start:pos].tobytes()\n  return tag_bytes, pos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/decoder.html#client.ayon_nuke.vendor.google.protobuf.internal.decoder.StringDecoder","title":"<code>StringDecoder(field_number, is_repeated, is_packed, key, new_default, clear_if_default=False)</code>","text":"<p>Returns a decoder for a string field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/decoder.py</code> <pre><code>def StringDecoder(field_number, is_repeated, is_packed, key, new_default,\n                  clear_if_default=False):\n  \"\"\"Returns a decoder for a string field.\"\"\"\n\n  local_DecodeVarint = _DecodeVarint\n\n  def _ConvertToUnicode(memview):\n    \"\"\"Convert byte to unicode.\"\"\"\n    byte_str = memview.tobytes()\n    try:\n      value = str(byte_str, 'utf-8')\n    except UnicodeDecodeError as e:\n      # add more information to the error message and re-raise it.\n      e.reason = '%s in field: %s' % (e, key.full_name)\n      raise\n\n    return value\n\n  assert not is_packed\n  if is_repeated:\n    tag_bytes = encoder.TagBytes(field_number,\n                                 wire_format.WIRETYPE_LENGTH_DELIMITED)\n    tag_len = len(tag_bytes)\n    def DecodeRepeatedField(buffer, pos, end, message, field_dict):\n      value = field_dict.get(key)\n      if value is None:\n        value = field_dict.setdefault(key, new_default(message))\n      while 1:\n        (size, pos) = local_DecodeVarint(buffer, pos)\n        new_pos = pos + size\n        if new_pos &gt; end:\n          raise _DecodeError('Truncated string.')\n        value.append(_ConvertToUnicode(buffer[pos:new_pos]))\n        # Predict that the next tag is another copy of the same repeated field.\n        pos = new_pos + tag_len\n        if buffer[new_pos:pos] != tag_bytes or new_pos == end:\n          # Prediction failed.  Return.\n          return new_pos\n    return DecodeRepeatedField\n  else:\n    def DecodeField(buffer, pos, end, message, field_dict):\n      (size, pos) = local_DecodeVarint(buffer, pos)\n      new_pos = pos + size\n      if new_pos &gt; end:\n        raise _DecodeError('Truncated string.')\n      if clear_if_default and not size:\n        field_dict.pop(key, None)\n      else:\n        field_dict[key] = _ConvertToUnicode(buffer[pos:new_pos])\n      return new_pos\n    return DecodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html","title":"encoder","text":"<p>Code for encoding protocol message primitives.</p> <p>Contains the logic for encoding every logical protocol field type into one of the 5 physical wire types.</p> <p>This code is designed to push the Python interpreter's performance to the limits.</p> <p>The basic idea is that at startup time, for every field (i.e. every FieldDescriptor) we construct two functions:  a \"sizer\" and an \"encoder\".  The sizer takes a value of this field's type and computes its byte size.  The encoder takes a writer function and a value.  It encodes the value into byte strings and invokes the writer function to write those strings.  Typically the writer function is the write() method of a BytesIO.</p> <p>We try to do as much work as possible when constructing the writer and the sizer rather than when calling them.  In particular: * We copy any needed global functions to local variables, so that we do not need   to do costly global table lookups at runtime. * Similarly, we try to do any attribute lookups at startup time if possible. * Every field's tag is encoded to bytes at startup, since it can't change at   runtime. * Whatever component of the field size we can compute at startup, we do. * We avoid sharing code if doing so would make the code slower and not sharing   does not burden us too much.  For example, encoders for repeated fields do   not just call the encoders for singular fields in a loop because this would   add an extra function call overhead for every loop iteration; instead, we   manually inline the single-value encoder into the loop. * If a Python function lacks a return statement, Python actually generates   instructions to pop the result of the last statement off the stack, push   None onto the stack, and then return that.  If we really don't care what   value is returned, then we can save two instructions by returning the   result of the last statement.  It looks funny but it helps. * We assume that type and bounds checking has happened at a higher level.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.BoolEncoder","title":"<code>BoolEncoder(field_number, is_repeated, is_packed)</code>","text":"<p>Returns an encoder for a boolean field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def BoolEncoder(field_number, is_repeated, is_packed):\n  \"\"\"Returns an encoder for a boolean field.\"\"\"\n\n  false_byte = b'\\x00'\n  true_byte = b'\\x01'\n  if is_packed:\n    tag_bytes = TagBytes(field_number, wire_format.WIRETYPE_LENGTH_DELIMITED)\n    local_EncodeVarint = _EncodeVarint\n    def EncodePackedField(write, value, deterministic):\n      write(tag_bytes)\n      local_EncodeVarint(write, len(value), deterministic)\n      for element in value:\n        if element:\n          write(true_byte)\n        else:\n          write(false_byte)\n    return EncodePackedField\n  elif is_repeated:\n    tag_bytes = TagBytes(field_number, wire_format.WIRETYPE_VARINT)\n    def EncodeRepeatedField(write, value, unused_deterministic=None):\n      for element in value:\n        write(tag_bytes)\n        if element:\n          write(true_byte)\n        else:\n          write(false_byte)\n    return EncodeRepeatedField\n  else:\n    tag_bytes = TagBytes(field_number, wire_format.WIRETYPE_VARINT)\n    def EncodeField(write, value, unused_deterministic=None):\n      write(tag_bytes)\n      if value:\n        return write(true_byte)\n      return write(false_byte)\n    return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.BytesEncoder","title":"<code>BytesEncoder(field_number, is_repeated, is_packed)</code>","text":"<p>Returns an encoder for a bytes field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def BytesEncoder(field_number, is_repeated, is_packed):\n  \"\"\"Returns an encoder for a bytes field.\"\"\"\n\n  tag = TagBytes(field_number, wire_format.WIRETYPE_LENGTH_DELIMITED)\n  local_EncodeVarint = _EncodeVarint\n  local_len = len\n  assert not is_packed\n  if is_repeated:\n    def EncodeRepeatedField(write, value, deterministic):\n      for element in value:\n        write(tag)\n        local_EncodeVarint(write, local_len(element), deterministic)\n        write(element)\n    return EncodeRepeatedField\n  else:\n    def EncodeField(write, value, deterministic):\n      write(tag)\n      local_EncodeVarint(write, local_len(value), deterministic)\n      return write(value)\n    return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.BytesSizer","title":"<code>BytesSizer(field_number, is_repeated, is_packed)</code>","text":"<p>Returns a sizer for a bytes field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def BytesSizer(field_number, is_repeated, is_packed):\n  \"\"\"Returns a sizer for a bytes field.\"\"\"\n\n  tag_size = _TagSize(field_number)\n  local_VarintSize = _VarintSize\n  local_len = len\n  assert not is_packed\n  if is_repeated:\n    def RepeatedFieldSize(value):\n      result = tag_size * len(value)\n      for element in value:\n        l = local_len(element)\n        result += local_VarintSize(l) + l\n      return result\n    return RepeatedFieldSize\n  else:\n    def FieldSize(value):\n      l = local_len(value)\n      return tag_size + local_VarintSize(l) + l\n    return FieldSize\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.GroupEncoder","title":"<code>GroupEncoder(field_number, is_repeated, is_packed)</code>","text":"<p>Returns an encoder for a group field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def GroupEncoder(field_number, is_repeated, is_packed):\n  \"\"\"Returns an encoder for a group field.\"\"\"\n\n  start_tag = TagBytes(field_number, wire_format.WIRETYPE_START_GROUP)\n  end_tag = TagBytes(field_number, wire_format.WIRETYPE_END_GROUP)\n  assert not is_packed\n  if is_repeated:\n    def EncodeRepeatedField(write, value, deterministic):\n      for element in value:\n        write(start_tag)\n        element._InternalSerialize(write, deterministic)\n        write(end_tag)\n    return EncodeRepeatedField\n  else:\n    def EncodeField(write, value, deterministic):\n      write(start_tag)\n      value._InternalSerialize(write, deterministic)\n      return write(end_tag)\n    return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.GroupSizer","title":"<code>GroupSizer(field_number, is_repeated, is_packed)</code>","text":"<p>Returns a sizer for a group field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def GroupSizer(field_number, is_repeated, is_packed):\n  \"\"\"Returns a sizer for a group field.\"\"\"\n\n  tag_size = _TagSize(field_number) * 2\n  assert not is_packed\n  if is_repeated:\n    def RepeatedFieldSize(value):\n      result = tag_size * len(value)\n      for element in value:\n        result += element.ByteSize()\n      return result\n    return RepeatedFieldSize\n  else:\n    def FieldSize(value):\n      return tag_size + value.ByteSize()\n    return FieldSize\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.MapEncoder","title":"<code>MapEncoder(field_descriptor)</code>","text":"<p>Encoder for extensions of MessageSet.</p> Maps always have a wire format like this <p>message MapEntry {   key_type key = 1;   value_type value = 2; } repeated MapEntry map = N;</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def MapEncoder(field_descriptor):\n  \"\"\"Encoder for extensions of MessageSet.\n\n  Maps always have a wire format like this:\n    message MapEntry {\n      key_type key = 1;\n      value_type value = 2;\n    }\n    repeated MapEntry map = N;\n  \"\"\"\n  # Can't look at field_descriptor.message_type._concrete_class because it may\n  # not have been initialized yet.\n  message_type = field_descriptor.message_type\n  encode_message = MessageEncoder(field_descriptor.number, False, False)\n\n  def EncodeField(write, value, deterministic):\n    value_keys = sorted(value.keys()) if deterministic else value\n    for key in value_keys:\n      entry_msg = message_type._concrete_class(key=key, value=value[key])\n      encode_message(write, entry_msg, deterministic)\n\n  return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.MapSizer","title":"<code>MapSizer(field_descriptor, is_message_map)</code>","text":"<p>Returns a sizer for a map field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def MapSizer(field_descriptor, is_message_map):\n  \"\"\"Returns a sizer for a map field.\"\"\"\n\n  # Can't look at field_descriptor.message_type._concrete_class because it may\n  # not have been initialized yet.\n  message_type = field_descriptor.message_type\n  message_sizer = MessageSizer(field_descriptor.number, False, False)\n\n  def FieldSize(map_value):\n    total = 0\n    for key in map_value:\n      value = map_value[key]\n      # It's wasteful to create the messages and throw them away one second\n      # later since we'll do the same for the actual encode.  But there's not an\n      # obvious way to avoid this within the current design without tons of code\n      # duplication. For message map, value.ByteSize() should be called to\n      # update the status.\n      entry_msg = message_type._concrete_class(key=key, value=value)\n      total += message_sizer(entry_msg)\n      if is_message_map:\n        value.ByteSize()\n    return total\n\n  return FieldSize\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.MessageEncoder","title":"<code>MessageEncoder(field_number, is_repeated, is_packed)</code>","text":"<p>Returns an encoder for a message field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def MessageEncoder(field_number, is_repeated, is_packed):\n  \"\"\"Returns an encoder for a message field.\"\"\"\n\n  tag = TagBytes(field_number, wire_format.WIRETYPE_LENGTH_DELIMITED)\n  local_EncodeVarint = _EncodeVarint\n  assert not is_packed\n  if is_repeated:\n    def EncodeRepeatedField(write, value, deterministic):\n      for element in value:\n        write(tag)\n        local_EncodeVarint(write, element.ByteSize(), deterministic)\n        element._InternalSerialize(write, deterministic)\n    return EncodeRepeatedField\n  else:\n    def EncodeField(write, value, deterministic):\n      write(tag)\n      local_EncodeVarint(write, value.ByteSize(), deterministic)\n      return value._InternalSerialize(write, deterministic)\n    return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.MessageSetItemEncoder","title":"<code>MessageSetItemEncoder(field_number)</code>","text":"<p>Encoder for extensions of MessageSet.</p> The message set message looks like this <p>message MessageSet {   repeated group Item = 1 {     required int32 type_id = 2;     required string message = 3;   } }</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def MessageSetItemEncoder(field_number):\n  \"\"\"Encoder for extensions of MessageSet.\n\n  The message set message looks like this:\n    message MessageSet {\n      repeated group Item = 1 {\n        required int32 type_id = 2;\n        required string message = 3;\n      }\n    }\n  \"\"\"\n  start_bytes = b\"\".join([\n      TagBytes(1, wire_format.WIRETYPE_START_GROUP),\n      TagBytes(2, wire_format.WIRETYPE_VARINT),\n      _VarintBytes(field_number),\n      TagBytes(3, wire_format.WIRETYPE_LENGTH_DELIMITED)])\n  end_bytes = TagBytes(1, wire_format.WIRETYPE_END_GROUP)\n  local_EncodeVarint = _EncodeVarint\n\n  def EncodeField(write, value, deterministic):\n    write(start_bytes)\n    local_EncodeVarint(write, value.ByteSize(), deterministic)\n    value._InternalSerialize(write, deterministic)\n    return write(end_bytes)\n\n  return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.MessageSetItemSizer","title":"<code>MessageSetItemSizer(field_number)</code>","text":"<p>Returns a sizer for extensions of MessageSet.</p> The message set message looks like this <p>message MessageSet {   repeated group Item = 1 {     required int32 type_id = 2;     required string message = 3;   } }</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def MessageSetItemSizer(field_number):\n  \"\"\"Returns a sizer for extensions of MessageSet.\n\n  The message set message looks like this:\n    message MessageSet {\n      repeated group Item = 1 {\n        required int32 type_id = 2;\n        required string message = 3;\n      }\n    }\n  \"\"\"\n  static_size = (_TagSize(1) * 2 + _TagSize(2) + _VarintSize(field_number) +\n                 _TagSize(3))\n  local_VarintSize = _VarintSize\n\n  def FieldSize(value):\n    l = value.ByteSize()\n    return static_size + local_VarintSize(l) + l\n\n  return FieldSize\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.MessageSizer","title":"<code>MessageSizer(field_number, is_repeated, is_packed)</code>","text":"<p>Returns a sizer for a message field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def MessageSizer(field_number, is_repeated, is_packed):\n  \"\"\"Returns a sizer for a message field.\"\"\"\n\n  tag_size = _TagSize(field_number)\n  local_VarintSize = _VarintSize\n  assert not is_packed\n  if is_repeated:\n    def RepeatedFieldSize(value):\n      result = tag_size * len(value)\n      for element in value:\n        l = element.ByteSize()\n        result += local_VarintSize(l) + l\n      return result\n    return RepeatedFieldSize\n  else:\n    def FieldSize(value):\n      l = value.ByteSize()\n      return tag_size + local_VarintSize(l) + l\n    return FieldSize\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.StringEncoder","title":"<code>StringEncoder(field_number, is_repeated, is_packed)</code>","text":"<p>Returns an encoder for a string field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def StringEncoder(field_number, is_repeated, is_packed):\n  \"\"\"Returns an encoder for a string field.\"\"\"\n\n  tag = TagBytes(field_number, wire_format.WIRETYPE_LENGTH_DELIMITED)\n  local_EncodeVarint = _EncodeVarint\n  local_len = len\n  assert not is_packed\n  if is_repeated:\n    def EncodeRepeatedField(write, value, deterministic):\n      for element in value:\n        encoded = element.encode('utf-8')\n        write(tag)\n        local_EncodeVarint(write, local_len(encoded), deterministic)\n        write(encoded)\n    return EncodeRepeatedField\n  else:\n    def EncodeField(write, value, deterministic):\n      encoded = value.encode('utf-8')\n      write(tag)\n      local_EncodeVarint(write, local_len(encoded), deterministic)\n      return write(encoded)\n    return EncodeField\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.StringSizer","title":"<code>StringSizer(field_number, is_repeated, is_packed)</code>","text":"<p>Returns a sizer for a string field.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def StringSizer(field_number, is_repeated, is_packed):\n  \"\"\"Returns a sizer for a string field.\"\"\"\n\n  tag_size = _TagSize(field_number)\n  local_VarintSize = _VarintSize\n  local_len = len\n  assert not is_packed\n  if is_repeated:\n    def RepeatedFieldSize(value):\n      result = tag_size * len(value)\n      for element in value:\n        l = local_len(element.encode('utf-8'))\n        result += local_VarintSize(l) + l\n      return result\n    return RepeatedFieldSize\n  else:\n    def FieldSize(value):\n      l = local_len(value.encode('utf-8'))\n      return tag_size + local_VarintSize(l) + l\n    return FieldSize\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/encoder.html#client.ayon_nuke.vendor.google.protobuf.internal.encoder.TagBytes","title":"<code>TagBytes(field_number, wire_type)</code>","text":"<p>Encode the given tag and return the bytes.  Only called at startup.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/encoder.py</code> <pre><code>def TagBytes(field_number, wire_type):\n  \"\"\"Encode the given tag and return the bytes.  Only called at startup.\"\"\"\n\n  return bytes(_VarintBytes(wire_format.PackTag(field_number, wire_type)))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html","title":"enum_type_wrapper","text":"<p>A simple wrapper around enum types to expose utility functions.</p> <p>Instances are created as properties with the same name as the enum they wrap on proto classes.  For usage, see:   reflection_test.py</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper","title":"<code>EnumTypeWrapper</code>","text":"<p>               Bases: <code>object</code></p> <p>A utility for finding the names of enum values.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>class EnumTypeWrapper(object):\n  \"\"\"A utility for finding the names of enum values.\"\"\"\n\n  DESCRIPTOR = None\n\n  # This is a type alias, which mypy typing stubs can type as\n  # a genericized parameter constrained to an int, allowing subclasses\n  # to be typed with more constraint in .pyi stubs\n  # Eg.\n  # def MyGeneratedEnum(Message):\n  #   ValueType = NewType('ValueType', int)\n  #   def Name(self, number: MyGeneratedEnum.ValueType) -&gt; str\n  ValueType = int\n\n  def __init__(self, enum_type):\n    \"\"\"Inits EnumTypeWrapper with an EnumDescriptor.\"\"\"\n    self._enum_type = enum_type\n    self.DESCRIPTOR = enum_type  # pylint: disable=invalid-name\n\n  def Name(self, number):  # pylint: disable=invalid-name\n    \"\"\"Returns a string containing the name of an enum value.\"\"\"\n    try:\n      return self._enum_type.values_by_number[number].name\n    except KeyError:\n      pass  # fall out to break exception chaining\n\n    if not isinstance(number, int):\n      raise TypeError(\n          'Enum value for {} must be an int, but got {} {!r}.'.format(\n              self._enum_type.name, type(number), number))\n    else:\n      # repr here to handle the odd case when you pass in a boolean.\n      raise ValueError('Enum {} has no name defined for value {!r}'.format(\n          self._enum_type.name, number))\n\n  def Value(self, name):  # pylint: disable=invalid-name\n    \"\"\"Returns the value corresponding to the given enum name.\"\"\"\n    try:\n      return self._enum_type.values_by_name[name].number\n    except KeyError:\n      pass  # fall out to break exception chaining\n    raise ValueError('Enum {} has no value defined for name {!r}'.format(\n        self._enum_type.name, name))\n\n  def keys(self):\n    \"\"\"Return a list of the string names in the enum.\n\n    Returns:\n      A list of strs, in the order they were defined in the .proto file.\n    \"\"\"\n\n    return [value_descriptor.name\n            for value_descriptor in self._enum_type.values]\n\n  def values(self):\n    \"\"\"Return a list of the integer values in the enum.\n\n    Returns:\n      A list of ints, in the order they were defined in the .proto file.\n    \"\"\"\n\n    return [value_descriptor.number\n            for value_descriptor in self._enum_type.values]\n\n  def items(self):\n    \"\"\"Return a list of the (name, value) pairs of the enum.\n\n    Returns:\n      A list of (str, int) pairs, in the order they were defined\n      in the .proto file.\n    \"\"\"\n    return [(value_descriptor.name, value_descriptor.number)\n            for value_descriptor in self._enum_type.values]\n\n  def __getattr__(self, name):\n    \"\"\"Returns the value corresponding to the given enum name.\"\"\"\n    try:\n      return super(\n          EnumTypeWrapper,\n          self).__getattribute__('_enum_type').values_by_name[name].number\n    except KeyError:\n      pass  # fall out to break exception chaining\n    raise AttributeError('Enum {} has no value defined for name {!r}'.format(\n        self._enum_type.name, name))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.Name","title":"<code>Name(number)</code>","text":"<p>Returns a string containing the name of an enum value.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def Name(self, number):  # pylint: disable=invalid-name\n  \"\"\"Returns a string containing the name of an enum value.\"\"\"\n  try:\n    return self._enum_type.values_by_number[number].name\n  except KeyError:\n    pass  # fall out to break exception chaining\n\n  if not isinstance(number, int):\n    raise TypeError(\n        'Enum value for {} must be an int, but got {} {!r}.'.format(\n            self._enum_type.name, type(number), number))\n  else:\n    # repr here to handle the odd case when you pass in a boolean.\n    raise ValueError('Enum {} has no name defined for value {!r}'.format(\n        self._enum_type.name, number))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.Value","title":"<code>Value(name)</code>","text":"<p>Returns the value corresponding to the given enum name.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def Value(self, name):  # pylint: disable=invalid-name\n  \"\"\"Returns the value corresponding to the given enum name.\"\"\"\n  try:\n    return self._enum_type.values_by_name[name].number\n  except KeyError:\n    pass  # fall out to break exception chaining\n  raise ValueError('Enum {} has no value defined for name {!r}'.format(\n      self._enum_type.name, name))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.__getattr__","title":"<code>__getattr__(name)</code>","text":"<p>Returns the value corresponding to the given enum name.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def __getattr__(self, name):\n  \"\"\"Returns the value corresponding to the given enum name.\"\"\"\n  try:\n    return super(\n        EnumTypeWrapper,\n        self).__getattribute__('_enum_type').values_by_name[name].number\n  except KeyError:\n    pass  # fall out to break exception chaining\n  raise AttributeError('Enum {} has no value defined for name {!r}'.format(\n      self._enum_type.name, name))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.__init__","title":"<code>__init__(enum_type)</code>","text":"<p>Inits EnumTypeWrapper with an EnumDescriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def __init__(self, enum_type):\n  \"\"\"Inits EnumTypeWrapper with an EnumDescriptor.\"\"\"\n  self._enum_type = enum_type\n  self.DESCRIPTOR = enum_type  # pylint: disable=invalid-name\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.items","title":"<code>items()</code>","text":"<p>Return a list of the (name, value) pairs of the enum.</p> <p>Returns:</p> Type Description <p>A list of (str, int) pairs, in the order they were defined</p> <p>in the .proto file.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def items(self):\n  \"\"\"Return a list of the (name, value) pairs of the enum.\n\n  Returns:\n    A list of (str, int) pairs, in the order they were defined\n    in the .proto file.\n  \"\"\"\n  return [(value_descriptor.name, value_descriptor.number)\n          for value_descriptor in self._enum_type.values]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.keys","title":"<code>keys()</code>","text":"<p>Return a list of the string names in the enum.</p> <p>Returns:</p> Type Description <p>A list of strs, in the order they were defined in the .proto file.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def keys(self):\n  \"\"\"Return a list of the string names in the enum.\n\n  Returns:\n    A list of strs, in the order they were defined in the .proto file.\n  \"\"\"\n\n  return [value_descriptor.name\n          for value_descriptor in self._enum_type.values]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.html#client.ayon_nuke.vendor.google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper.values","title":"<code>values()</code>","text":"<p>Return a list of the integer values in the enum.</p> <p>Returns:</p> Type Description <p>A list of ints, in the order they were defined in the .proto file.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/enum_type_wrapper.py</code> <pre><code>def values(self):\n  \"\"\"Return a list of the integer values in the enum.\n\n  Returns:\n    A list of ints, in the order they were defined in the .proto file.\n  \"\"\"\n\n  return [value_descriptor.number\n          for value_descriptor in self._enum_type.values]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/extension_dict.html","title":"extension_dict","text":"<p>Contains _ExtensionDict class to represent extensions.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/message_listener.html","title":"message_listener","text":"<p>Defines a listener interface for observing certain state transitions on Message objects.</p> <p>Also defines a null implementation of this interface.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/message_listener.html#client.ayon_nuke.vendor.google.protobuf.internal.message_listener.MessageListener","title":"<code>MessageListener</code>","text":"<p>               Bases: <code>object</code></p> <p>Listens for modifications made to a message.  Meant to be registered via Message._SetListener().</p> <p>Attributes:</p> Name Type Description <code>dirty</code> <p>If True, then calling Modified() would be a no-op.  This can be       used to avoid these calls entirely in the common case.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/message_listener.py</code> <pre><code>class MessageListener(object):\n\n  \"\"\"Listens for modifications made to a message.  Meant to be registered via\n  Message._SetListener().\n\n  Attributes:\n    dirty:  If True, then calling Modified() would be a no-op.  This can be\n            used to avoid these calls entirely in the common case.\n  \"\"\"\n\n  def Modified(self):\n    \"\"\"Called every time the message is modified in such a way that the parent\n    message may need to be updated.  This currently means either:\n    (a) The message was modified for the first time, so the parent message\n        should henceforth mark the message as present.\n    (b) The message's cached byte size became dirty -- i.e. the message was\n        modified for the first time after a previous call to ByteSize().\n        Therefore the parent should also mark its byte size as dirty.\n    Note that (a) implies (b), since new objects start out with a client cached\n    size (zero).  However, we document (a) explicitly because it is important.\n\n    Modified() will *only* be called in response to one of these two events --\n    not every time the sub-message is modified.\n\n    Note that if the listener's |dirty| attribute is true, then calling\n    Modified at the moment would be a no-op, so it can be skipped.  Performance-\n    sensitive callers should check this attribute directly before calling since\n    it will be true most of the time.\n    \"\"\"\n\n    raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/message_listener.html#client.ayon_nuke.vendor.google.protobuf.internal.message_listener.MessageListener.Modified","title":"<code>Modified()</code>","text":"<p>Called every time the message is modified in such a way that the parent message may need to be updated.  This currently means either: (a) The message was modified for the first time, so the parent message     should henceforth mark the message as present. (b) The message's cached byte size became dirty -- i.e. the message was     modified for the first time after a previous call to ByteSize().     Therefore the parent should also mark its byte size as dirty. Note that (a) implies (b), since new objects start out with a client cached size (zero).  However, we document (a) explicitly because it is important.</p> <p>Modified() will only be called in response to one of these two events -- not every time the sub-message is modified.</p> <p>Note that if the listener's |dirty| attribute is true, then calling Modified at the moment would be a no-op, so it can be skipped.  Performance- sensitive callers should check this attribute directly before calling since it will be true most of the time.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/message_listener.py</code> <pre><code>def Modified(self):\n  \"\"\"Called every time the message is modified in such a way that the parent\n  message may need to be updated.  This currently means either:\n  (a) The message was modified for the first time, so the parent message\n      should henceforth mark the message as present.\n  (b) The message's cached byte size became dirty -- i.e. the message was\n      modified for the first time after a previous call to ByteSize().\n      Therefore the parent should also mark its byte size as dirty.\n  Note that (a) implies (b), since new objects start out with a client cached\n  size (zero).  However, we document (a) explicitly because it is important.\n\n  Modified() will *only* be called in response to one of these two events --\n  not every time the sub-message is modified.\n\n  Note that if the listener's |dirty| attribute is true, then calling\n  Modified at the moment would be a no-op, so it can be skipped.  Performance-\n  sensitive callers should check this attribute directly before calling since\n  it will be true most of the time.\n  \"\"\"\n\n  raise NotImplementedError\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/message_listener.html#client.ayon_nuke.vendor.google.protobuf.internal.message_listener.NullMessageListener","title":"<code>NullMessageListener</code>","text":"<p>               Bases: <code>object</code></p> <p>No-op MessageListener implementation.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/message_listener.py</code> <pre><code>class NullMessageListener(object):\n\n  \"\"\"No-op MessageListener implementation.\"\"\"\n\n  def Modified(self):\n    pass\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/message_set_extensions_pb2.html","title":"message_set_extensions_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/missing_enum_values_pb2.html","title":"missing_enum_values_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/more_extensions_dynamic_pb2.html","title":"more_extensions_dynamic_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/more_extensions_pb2.html","title":"more_extensions_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/more_messages_pb2.html","title":"more_messages_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/no_package_pb2.html","title":"no_package_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/python_message.html","title":"python_message","text":"<p>Contains a metaclass and helper functions used to create protocol message classes from Descriptor objects at runtime.</p> <p>Recall that a metaclass is the \"type\" of a class. (A class is to a metaclass what an instance is to a class.)</p> <p>In this case, we use the GeneratedProtocolMessageType metaclass to inject all the useful functionality into the classes output by the protocol compiler at compile-time.</p> <p>The upshot of all this is that the real implementation details for ALL pure-Python protocol buffers are here in this file.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/python_message.html#client.ayon_nuke.vendor.google.protobuf.internal.python_message.GeneratedProtocolMessageType","title":"<code>GeneratedProtocolMessageType</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass for protocol message classes created at runtime from Descriptors.</p> <p>We add implementations for all methods described in the Message class.  We also create properties to allow getting/setting all fields in the protocol message.  Finally, we create slots to prevent users from accidentally \"setting\" nonexistent fields in the protocol message, which then wouldn't get serialized / deserialized properly.</p> <p>The protocol compiler currently uses this metaclass to create protocol message classes at runtime.  Clients can also manually create their own classes at runtime, as in this example:</p> <p>mydescriptor = Descriptor(.....) factory = symbol_database.Default() factory.pool.AddDescriptor(mydescriptor) MyProtoClass = factory.GetPrototype(mydescriptor) myproto_instance = MyProtoClass() myproto.foo_field = 23 ...</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/python_message.py</code> <pre><code>class GeneratedProtocolMessageType(type):\n\n  \"\"\"Metaclass for protocol message classes created at runtime from Descriptors.\n\n  We add implementations for all methods described in the Message class.  We\n  also create properties to allow getting/setting all fields in the protocol\n  message.  Finally, we create slots to prevent users from accidentally\n  \"setting\" nonexistent fields in the protocol message, which then wouldn't get\n  serialized / deserialized properly.\n\n  The protocol compiler currently uses this metaclass to create protocol\n  message classes at runtime.  Clients can also manually create their own\n  classes at runtime, as in this example:\n\n  mydescriptor = Descriptor(.....)\n  factory = symbol_database.Default()\n  factory.pool.AddDescriptor(mydescriptor)\n  MyProtoClass = factory.GetPrototype(mydescriptor)\n  myproto_instance = MyProtoClass()\n  myproto.foo_field = 23\n  ...\n  \"\"\"\n\n  # Must be consistent with the protocol-compiler code in\n  # proto2/compiler/internal/generator.*.\n  _DESCRIPTOR_KEY = 'DESCRIPTOR'\n\n  def __new__(cls, name, bases, dictionary):\n    \"\"\"Custom allocation for runtime-generated class types.\n\n    We override __new__ because this is apparently the only place\n    where we can meaningfully set __slots__ on the class we're creating(?).\n    (The interplay between metaclasses and slots is not very well-documented).\n\n    Args:\n      name: Name of the class (ignored, but required by the\n        metaclass protocol).\n      bases: Base classes of the class we're constructing.\n        (Should be message.Message).  We ignore this field, but\n        it's required by the metaclass protocol\n      dictionary: The class dictionary of the class we're\n        constructing.  dictionary[_DESCRIPTOR_KEY] must contain\n        a Descriptor object describing this protocol message\n        type.\n\n    Returns:\n      Newly-allocated class.\n\n    Raises:\n      RuntimeError: Generated code only work with python cpp extension.\n    \"\"\"\n    descriptor = dictionary[GeneratedProtocolMessageType._DESCRIPTOR_KEY]\n\n    if isinstance(descriptor, str):\n      raise RuntimeError('The generated code only work with python cpp '\n                         'extension, but it is using pure python runtime.')\n\n    # If a concrete class already exists for this descriptor, don't try to\n    # create another.  Doing so will break any messages that already exist with\n    # the existing class.\n    #\n    # The C++ implementation appears to have its own internal `PyMessageFactory`\n    # to achieve similar results.\n    #\n    # This most commonly happens in `text_format.py` when using descriptors from\n    # a custom pool; it calls symbol_database.Global().getPrototype() on a\n    # descriptor which already has an existing concrete class.\n    new_class = getattr(descriptor, '_concrete_class', None)\n    if new_class:\n      return new_class\n\n    if descriptor.full_name in well_known_types.WKTBASES:\n      bases += (well_known_types.WKTBASES[descriptor.full_name],)\n    _AddClassAttributesForNestedExtensions(descriptor, dictionary)\n    _AddSlots(descriptor, dictionary)\n\n    superclass = super(GeneratedProtocolMessageType, cls)\n    new_class = superclass.__new__(cls, name, bases, dictionary)\n    return new_class\n\n  def __init__(cls, name, bases, dictionary):\n    \"\"\"Here we perform the majority of our work on the class.\n    We add enum getters, an __init__ method, implementations\n    of all Message methods, and properties for all fields\n    in the protocol type.\n\n    Args:\n      name: Name of the class (ignored, but required by the\n        metaclass protocol).\n      bases: Base classes of the class we're constructing.\n        (Should be message.Message).  We ignore this field, but\n        it's required by the metaclass protocol\n      dictionary: The class dictionary of the class we're\n        constructing.  dictionary[_DESCRIPTOR_KEY] must contain\n        a Descriptor object describing this protocol message\n        type.\n    \"\"\"\n    descriptor = dictionary[GeneratedProtocolMessageType._DESCRIPTOR_KEY]\n\n    # If this is an _existing_ class looked up via `_concrete_class` in the\n    # __new__ method above, then we don't need to re-initialize anything.\n    existing_class = getattr(descriptor, '_concrete_class', None)\n    if existing_class:\n      assert existing_class is cls, (\n          'Duplicate `GeneratedProtocolMessageType` created for descriptor %r'\n          % (descriptor.full_name))\n      return\n\n    cls._decoders_by_tag = {}\n    if (descriptor.has_options and\n        descriptor.GetOptions().message_set_wire_format):\n      cls._decoders_by_tag[decoder.MESSAGE_SET_ITEM_TAG] = (\n          decoder.MessageSetItemDecoder(descriptor), None)\n\n    # Attach stuff to each FieldDescriptor for quick lookup later on.\n    for field in descriptor.fields:\n      _AttachFieldHelpers(cls, field)\n\n    descriptor._concrete_class = cls  # pylint: disable=protected-access\n    _AddEnumValues(descriptor, cls)\n    _AddInitMethod(descriptor, cls)\n    _AddPropertiesForFields(descriptor, cls)\n    _AddPropertiesForExtensions(descriptor, cls)\n    _AddStaticMethods(cls)\n    _AddMessageMethods(descriptor, cls)\n    _AddPrivateHelperMethods(descriptor, cls)\n\n    superclass = super(GeneratedProtocolMessageType, cls)\n    superclass.__init__(name, bases, dictionary)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/python_message.html#client.ayon_nuke.vendor.google.protobuf.internal.python_message.GeneratedProtocolMessageType.__init__","title":"<code>__init__(name, bases, dictionary)</code>","text":"<p>Here we perform the majority of our work on the class. We add enum getters, an init method, implementations of all Message methods, and properties for all fields in the protocol type.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Name of the class (ignored, but required by the metaclass protocol).</p> required <code>bases</code> <p>Base classes of the class we're constructing. (Should be message.Message).  We ignore this field, but it's required by the metaclass protocol</p> required <code>dictionary</code> <p>The class dictionary of the class we're constructing.  dictionary[_DESCRIPTOR_KEY] must contain a Descriptor object describing this protocol message type.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/python_message.py</code> <pre><code>def __init__(cls, name, bases, dictionary):\n  \"\"\"Here we perform the majority of our work on the class.\n  We add enum getters, an __init__ method, implementations\n  of all Message methods, and properties for all fields\n  in the protocol type.\n\n  Args:\n    name: Name of the class (ignored, but required by the\n      metaclass protocol).\n    bases: Base classes of the class we're constructing.\n      (Should be message.Message).  We ignore this field, but\n      it's required by the metaclass protocol\n    dictionary: The class dictionary of the class we're\n      constructing.  dictionary[_DESCRIPTOR_KEY] must contain\n      a Descriptor object describing this protocol message\n      type.\n  \"\"\"\n  descriptor = dictionary[GeneratedProtocolMessageType._DESCRIPTOR_KEY]\n\n  # If this is an _existing_ class looked up via `_concrete_class` in the\n  # __new__ method above, then we don't need to re-initialize anything.\n  existing_class = getattr(descriptor, '_concrete_class', None)\n  if existing_class:\n    assert existing_class is cls, (\n        'Duplicate `GeneratedProtocolMessageType` created for descriptor %r'\n        % (descriptor.full_name))\n    return\n\n  cls._decoders_by_tag = {}\n  if (descriptor.has_options and\n      descriptor.GetOptions().message_set_wire_format):\n    cls._decoders_by_tag[decoder.MESSAGE_SET_ITEM_TAG] = (\n        decoder.MessageSetItemDecoder(descriptor), None)\n\n  # Attach stuff to each FieldDescriptor for quick lookup later on.\n  for field in descriptor.fields:\n    _AttachFieldHelpers(cls, field)\n\n  descriptor._concrete_class = cls  # pylint: disable=protected-access\n  _AddEnumValues(descriptor, cls)\n  _AddInitMethod(descriptor, cls)\n  _AddPropertiesForFields(descriptor, cls)\n  _AddPropertiesForExtensions(descriptor, cls)\n  _AddStaticMethods(cls)\n  _AddMessageMethods(descriptor, cls)\n  _AddPrivateHelperMethods(descriptor, cls)\n\n  superclass = super(GeneratedProtocolMessageType, cls)\n  superclass.__init__(name, bases, dictionary)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/python_message.html#client.ayon_nuke.vendor.google.protobuf.internal.python_message.GeneratedProtocolMessageType.__new__","title":"<code>__new__(name, bases, dictionary)</code>","text":"<p>Custom allocation for runtime-generated class types.</p> <p>We override new because this is apparently the only place where we can meaningfully set slots on the class we're creating(?). (The interplay between metaclasses and slots is not very well-documented).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>Name of the class (ignored, but required by the metaclass protocol).</p> required <code>bases</code> <p>Base classes of the class we're constructing. (Should be message.Message).  We ignore this field, but it's required by the metaclass protocol</p> required <code>dictionary</code> <p>The class dictionary of the class we're constructing.  dictionary[_DESCRIPTOR_KEY] must contain a Descriptor object describing this protocol message type.</p> required <p>Returns:</p> Type Description <p>Newly-allocated class.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>Generated code only work with python cpp extension.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/python_message.py</code> <pre><code>def __new__(cls, name, bases, dictionary):\n  \"\"\"Custom allocation for runtime-generated class types.\n\n  We override __new__ because this is apparently the only place\n  where we can meaningfully set __slots__ on the class we're creating(?).\n  (The interplay between metaclasses and slots is not very well-documented).\n\n  Args:\n    name: Name of the class (ignored, but required by the\n      metaclass protocol).\n    bases: Base classes of the class we're constructing.\n      (Should be message.Message).  We ignore this field, but\n      it's required by the metaclass protocol\n    dictionary: The class dictionary of the class we're\n      constructing.  dictionary[_DESCRIPTOR_KEY] must contain\n      a Descriptor object describing this protocol message\n      type.\n\n  Returns:\n    Newly-allocated class.\n\n  Raises:\n    RuntimeError: Generated code only work with python cpp extension.\n  \"\"\"\n  descriptor = dictionary[GeneratedProtocolMessageType._DESCRIPTOR_KEY]\n\n  if isinstance(descriptor, str):\n    raise RuntimeError('The generated code only work with python cpp '\n                       'extension, but it is using pure python runtime.')\n\n  # If a concrete class already exists for this descriptor, don't try to\n  # create another.  Doing so will break any messages that already exist with\n  # the existing class.\n  #\n  # The C++ implementation appears to have its own internal `PyMessageFactory`\n  # to achieve similar results.\n  #\n  # This most commonly happens in `text_format.py` when using descriptors from\n  # a custom pool; it calls symbol_database.Global().getPrototype() on a\n  # descriptor which already has an existing concrete class.\n  new_class = getattr(descriptor, '_concrete_class', None)\n  if new_class:\n    return new_class\n\n  if descriptor.full_name in well_known_types.WKTBASES:\n    bases += (well_known_types.WKTBASES[descriptor.full_name],)\n  _AddClassAttributesForNestedExtensions(descriptor, dictionary)\n  _AddSlots(descriptor, dictionary)\n\n  superclass = super(GeneratedProtocolMessageType, cls)\n  new_class = superclass.__new__(cls, name, bases, dictionary)\n  return new_class\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html","title":"type_checkers","text":"<p>Provides type checking routines.</p> <p>This module defines type checking utilities in the forms of dictionaries:</p> <p>VALUE_CHECKERS: A dictionary of field types and a value validation object. TYPE_TO_BYTE_SIZE_FN: A dictionary with field types and a size computing   function. TYPE_TO_SERIALIZE_METHOD: A dictionary with field types and serialization   function. FIELD_TYPE_TO_WIRE_TYPE: A dictionary with field typed and their   corresponding wire types. TYPE_TO_DESERIALIZE_METHOD: A dictionary with field types and deserialization   function.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.BoolValueChecker","title":"<code>BoolValueChecker</code>","text":"<p>               Bases: <code>object</code></p> <p>Type checker used for bool fields.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class BoolValueChecker(object):\n  \"\"\"Type checker used for bool fields.\"\"\"\n\n  def CheckValue(self, proposed_value):\n    if not hasattr(proposed_value, '__index__') or (\n        type(proposed_value).__module__ == 'numpy' and\n        type(proposed_value).__name__ == 'ndarray'):\n      message = ('%.1024r has type %s, but expected one of: %s' %\n                 (proposed_value, type(proposed_value), (bool, int)))\n      raise TypeError(message)\n    return bool(proposed_value)\n\n  def DefaultValue(self):\n    return False\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.DoubleValueChecker","title":"<code>DoubleValueChecker</code>","text":"<p>               Bases: <code>object</code></p> <p>Checker used for double fields.</p> <p>Performs type-check and range check.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class DoubleValueChecker(object):\n  \"\"\"Checker used for double fields.\n\n  Performs type-check and range check.\n  \"\"\"\n\n  def CheckValue(self, proposed_value):\n    \"\"\"Check and convert proposed_value to float.\"\"\"\n    if (not hasattr(proposed_value, '__float__') and\n        not hasattr(proposed_value, '__index__')) or (\n            type(proposed_value).__module__ == 'numpy' and\n            type(proposed_value).__name__ == 'ndarray'):\n      message = ('%.1024r has type %s, but expected one of: int, float' %\n                 (proposed_value, type(proposed_value)))\n      raise TypeError(message)\n    return float(proposed_value)\n\n  def DefaultValue(self):\n    return 0.0\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.DoubleValueChecker.CheckValue","title":"<code>CheckValue(proposed_value)</code>","text":"<p>Check and convert proposed_value to float.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>def CheckValue(self, proposed_value):\n  \"\"\"Check and convert proposed_value to float.\"\"\"\n  if (not hasattr(proposed_value, '__float__') and\n      not hasattr(proposed_value, '__index__')) or (\n          type(proposed_value).__module__ == 'numpy' and\n          type(proposed_value).__name__ == 'ndarray'):\n    message = ('%.1024r has type %s, but expected one of: int, float' %\n               (proposed_value, type(proposed_value)))\n    raise TypeError(message)\n  return float(proposed_value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.EnumValueChecker","title":"<code>EnumValueChecker</code>","text":"<p>               Bases: <code>object</code></p> <p>Checker used for enum fields.  Performs type-check and range check.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class EnumValueChecker(object):\n\n  \"\"\"Checker used for enum fields.  Performs type-check and range check.\"\"\"\n\n  def __init__(self, enum_type):\n    self._enum_type = enum_type\n\n  def CheckValue(self, proposed_value):\n    if not isinstance(proposed_value, numbers.Integral):\n      message = ('%.1024r has type %s, but expected one of: %s' %\n                 (proposed_value, type(proposed_value), (int,)))\n      raise TypeError(message)\n    if int(proposed_value) not in self._enum_type.values_by_number:\n      raise ValueError('Unknown enum value: %d' % proposed_value)\n    return proposed_value\n\n  def DefaultValue(self):\n    return self._enum_type.values[0].number\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.FloatValueChecker","title":"<code>FloatValueChecker</code>","text":"<p>               Bases: <code>DoubleValueChecker</code></p> <p>Checker used for float fields.</p> <p>Performs type-check and range check.</p> <p>Values exceeding a 32-bit float will be converted to inf/-inf.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class FloatValueChecker(DoubleValueChecker):\n  \"\"\"Checker used for float fields.\n\n  Performs type-check and range check.\n\n  Values exceeding a 32-bit float will be converted to inf/-inf.\n  \"\"\"\n\n  def CheckValue(self, proposed_value):\n    \"\"\"Check and convert proposed_value to float.\"\"\"\n    converted_value = super().CheckValue(proposed_value)\n    # This inf rounding matches the C++ proto SafeDoubleToFloat logic.\n    if converted_value &gt; _FLOAT_MAX:\n      return _INF\n    if converted_value &lt; _FLOAT_MIN:\n      return _NEG_INF\n\n    return TruncateToFourByteFloat(converted_value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.FloatValueChecker.CheckValue","title":"<code>CheckValue(proposed_value)</code>","text":"<p>Check and convert proposed_value to float.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>def CheckValue(self, proposed_value):\n  \"\"\"Check and convert proposed_value to float.\"\"\"\n  converted_value = super().CheckValue(proposed_value)\n  # This inf rounding matches the C++ proto SafeDoubleToFloat logic.\n  if converted_value &gt; _FLOAT_MAX:\n    return _INF\n  if converted_value &lt; _FLOAT_MIN:\n    return _NEG_INF\n\n  return TruncateToFourByteFloat(converted_value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.IntValueChecker","title":"<code>IntValueChecker</code>","text":"<p>               Bases: <code>object</code></p> <p>Checker used for integer fields.  Performs type-check and range check.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class IntValueChecker(object):\n\n  \"\"\"Checker used for integer fields.  Performs type-check and range check.\"\"\"\n\n  def CheckValue(self, proposed_value):\n    if not hasattr(proposed_value, '__index__') or (\n        type(proposed_value).__module__ == 'numpy' and\n        type(proposed_value).__name__ == 'ndarray'):\n      message = ('%.1024r has type %s, but expected one of: %s' %\n                 (proposed_value, type(proposed_value), (int,)))\n      raise TypeError(message)\n\n    if not self._MIN &lt;= int(proposed_value) &lt;= self._MAX:\n      raise ValueError('Value out of range: %d' % proposed_value)\n    # We force all values to int to make alternate implementations where the\n    # distinction is more significant (e.g. the C++ implementation) simpler.\n    proposed_value = int(proposed_value)\n    return proposed_value\n\n  def DefaultValue(self):\n    return 0\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.TypeChecker","title":"<code>TypeChecker</code>","text":"<p>               Bases: <code>object</code></p> <p>Type checker used to catch type errors as early as possible when the client is setting scalar fields in protocol messages.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class TypeChecker(object):\n\n  \"\"\"Type checker used to catch type errors as early as possible\n  when the client is setting scalar fields in protocol messages.\n  \"\"\"\n\n  def __init__(self, *acceptable_types):\n    self._acceptable_types = acceptable_types\n\n  def CheckValue(self, proposed_value):\n    \"\"\"Type check the provided value and return it.\n\n    The returned value might have been normalized to another type.\n    \"\"\"\n    if not isinstance(proposed_value, self._acceptable_types):\n      message = ('%.1024r has type %s, but expected one of: %s' %\n                 (proposed_value, type(proposed_value), self._acceptable_types))\n      raise TypeError(message)\n    return proposed_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.TypeChecker.CheckValue","title":"<code>CheckValue(proposed_value)</code>","text":"<p>Type check the provided value and return it.</p> <p>The returned value might have been normalized to another type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>def CheckValue(self, proposed_value):\n  \"\"\"Type check the provided value and return it.\n\n  The returned value might have been normalized to another type.\n  \"\"\"\n  if not isinstance(proposed_value, self._acceptable_types):\n    message = ('%.1024r has type %s, but expected one of: %s' %\n               (proposed_value, type(proposed_value), self._acceptable_types))\n    raise TypeError(message)\n  return proposed_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.UnicodeValueChecker","title":"<code>UnicodeValueChecker</code>","text":"<p>               Bases: <code>object</code></p> <p>Checker used for string fields.</p> <p>Always returns a unicode value, even if the input is of type str.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>class UnicodeValueChecker(object):\n\n  \"\"\"Checker used for string fields.\n\n  Always returns a unicode value, even if the input is of type str.\n  \"\"\"\n\n  def CheckValue(self, proposed_value):\n    if not isinstance(proposed_value, (bytes, str)):\n      message = ('%.1024r has type %s, but expected one of: %s' %\n                 (proposed_value, type(proposed_value), (bytes, str)))\n      raise TypeError(message)\n\n    # If the value is of type 'bytes' make sure that it is valid UTF-8 data.\n    if isinstance(proposed_value, bytes):\n      try:\n        proposed_value = proposed_value.decode('utf-8')\n      except UnicodeDecodeError:\n        raise ValueError('%.1024r has type bytes, but isn\\'t valid UTF-8 '\n                         'encoding. Non-UTF-8 strings must be converted to '\n                         'unicode objects before being added.' %\n                         (proposed_value))\n    else:\n      try:\n        proposed_value.encode('utf8')\n      except UnicodeEncodeError:\n        raise ValueError('%.1024r isn\\'t a valid unicode string and '\n                         'can\\'t be encoded in UTF-8.'%\n                         (proposed_value))\n\n    return proposed_value\n\n  def DefaultValue(self):\n    return u\"\"\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.GetTypeChecker","title":"<code>GetTypeChecker(field)</code>","text":"<p>Returns a type checker for a message field of the specified types.</p> <p>Parameters:</p> Name Type Description Default <code>field</code> <p>FieldDescriptor object for this field.</p> required <p>Returns:</p> Type Description <p>An instance of TypeChecker which can be used to verify the types</p> <p>of values assigned to a field of the specified type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>def GetTypeChecker(field):\n  \"\"\"Returns a type checker for a message field of the specified types.\n\n  Args:\n    field: FieldDescriptor object for this field.\n\n  Returns:\n    An instance of TypeChecker which can be used to verify the types\n    of values assigned to a field of the specified type.\n  \"\"\"\n  if (field.cpp_type == _FieldDescriptor.CPPTYPE_STRING and\n      field.type == _FieldDescriptor.TYPE_STRING):\n    return UnicodeValueChecker()\n  if field.cpp_type == _FieldDescriptor.CPPTYPE_ENUM:\n    if SupportsOpenEnums(field):\n      # When open enums are supported, any int32 can be assigned.\n      return _VALUE_CHECKERS[_FieldDescriptor.CPPTYPE_INT32]\n    else:\n      return EnumValueChecker(field.enum_type)\n  return _VALUE_CHECKERS[field.cpp_type]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.html#client.ayon_nuke.vendor.google.protobuf.internal.type_checkers.ToShortestFloat","title":"<code>ToShortestFloat(original)</code>","text":"<p>Returns the shortest float that has same value in wire.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/type_checkers.py</code> <pre><code>def ToShortestFloat(original):\n  \"\"\"Returns the shortest float that has same value in wire.\"\"\"\n  # All 4 byte floats have between 6 and 9 significant digits, so we\n  # start with 6 as the lower bound.\n  # It has to be iterative because use '.9g' directly can not get rid\n  # of the noises for most values. For example if set a float_field=0.9\n  # use '.9g' will print 0.899999976.\n  precision = 6\n  rounded = float('{0:.{1}g}'.format(original, precision))\n  while TruncateToFourByteFloat(rounded) != original:\n    precision += 1\n    rounded = float('{0:.{1}g}'.format(original, precision))\n  return rounded\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html","title":"well_known_types","text":"<p>Contains well known classes.</p> This files defines well known classes which need extra maintenance including <ul> <li>Any</li> <li>Duration</li> <li>FieldMask</li> <li>Struct</li> <li>Timestamp</li> </ul>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Any","title":"<code>Any</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for Any Message type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>class Any(object):\n  \"\"\"Class for Any Message type.\"\"\"\n\n  __slots__ = ()\n\n  def Pack(self, msg, type_url_prefix='type.googleapis.com/',\n           deterministic=None):\n    \"\"\"Packs the specified message into current Any message.\"\"\"\n    if len(type_url_prefix) &lt; 1 or type_url_prefix[-1] != '/':\n      self.type_url = '%s/%s' % (type_url_prefix, msg.DESCRIPTOR.full_name)\n    else:\n      self.type_url = '%s%s' % (type_url_prefix, msg.DESCRIPTOR.full_name)\n    self.value = msg.SerializeToString(deterministic=deterministic)\n\n  def Unpack(self, msg):\n    \"\"\"Unpacks the current Any message into specified message.\"\"\"\n    descriptor = msg.DESCRIPTOR\n    if not self.Is(descriptor):\n      return False\n    msg.ParseFromString(self.value)\n    return True\n\n  def TypeName(self):\n    \"\"\"Returns the protobuf type name of the inner message.\"\"\"\n    # Only last part is to be used: b/25630112\n    return self.type_url.split('/')[-1]\n\n  def Is(self, descriptor):\n    \"\"\"Checks if this Any represents the given protobuf type.\"\"\"\n    return '/' in self.type_url and self.TypeName() == descriptor.full_name\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Any.Is","title":"<code>Is(descriptor)</code>","text":"<p>Checks if this Any represents the given protobuf type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def Is(self, descriptor):\n  \"\"\"Checks if this Any represents the given protobuf type.\"\"\"\n  return '/' in self.type_url and self.TypeName() == descriptor.full_name\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Any.Pack","title":"<code>Pack(msg, type_url_prefix='type.googleapis.com/', deterministic=None)</code>","text":"<p>Packs the specified message into current Any message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def Pack(self, msg, type_url_prefix='type.googleapis.com/',\n         deterministic=None):\n  \"\"\"Packs the specified message into current Any message.\"\"\"\n  if len(type_url_prefix) &lt; 1 or type_url_prefix[-1] != '/':\n    self.type_url = '%s/%s' % (type_url_prefix, msg.DESCRIPTOR.full_name)\n  else:\n    self.type_url = '%s%s' % (type_url_prefix, msg.DESCRIPTOR.full_name)\n  self.value = msg.SerializeToString(deterministic=deterministic)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Any.TypeName","title":"<code>TypeName()</code>","text":"<p>Returns the protobuf type name of the inner message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def TypeName(self):\n  \"\"\"Returns the protobuf type name of the inner message.\"\"\"\n  # Only last part is to be used: b/25630112\n  return self.type_url.split('/')[-1]\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Any.Unpack","title":"<code>Unpack(msg)</code>","text":"<p>Unpacks the current Any message into specified message.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def Unpack(self, msg):\n  \"\"\"Unpacks the current Any message into specified message.\"\"\"\n  descriptor = msg.DESCRIPTOR\n  if not self.Is(descriptor):\n    return False\n  msg.ParseFromString(self.value)\n  return True\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration","title":"<code>Duration</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for Duration message type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>class Duration(object):\n  \"\"\"Class for Duration message type.\"\"\"\n\n  __slots__ = ()\n\n  def ToJsonString(self):\n    \"\"\"Converts Duration to string format.\n\n    Returns:\n      A string converted from self. The string format will contains\n      3, 6, or 9 fractional digits depending on the precision required to\n      represent the exact Duration value. For example: \"1s\", \"1.010s\",\n      \"1.000000100s\", \"-3.100s\"\n    \"\"\"\n    _CheckDurationValid(self.seconds, self.nanos)\n    if self.seconds &lt; 0 or self.nanos &lt; 0:\n      result = '-'\n      seconds = - self.seconds + int((0 - self.nanos) // 1e9)\n      nanos = (0 - self.nanos) % 1e9\n    else:\n      result = ''\n      seconds = self.seconds + int(self.nanos // 1e9)\n      nanos = self.nanos % 1e9\n    result += '%d' % seconds\n    if (nanos % 1e9) == 0:\n      # If there are 0 fractional digits, the fractional\n      # point '.' should be omitted when serializing.\n      return result + 's'\n    if (nanos % 1e6) == 0:\n      # Serialize 3 fractional digits.\n      return result + '.%03ds' % (nanos / 1e6)\n    if (nanos % 1e3) == 0:\n      # Serialize 6 fractional digits.\n      return result + '.%06ds' % (nanos / 1e3)\n    # Serialize 9 fractional digits.\n    return result + '.%09ds' % nanos\n\n  def FromJsonString(self, value):\n    \"\"\"Converts a string to Duration.\n\n    Args:\n      value: A string to be converted. The string must end with 's'. Any\n          fractional digits (or none) are accepted as long as they fit into\n          precision. For example: \"1s\", \"1.01s\", \"1.0000001s\", \"-3.100s\n\n    Raises:\n      ValueError: On parsing problems.\n    \"\"\"\n    if not isinstance(value, str):\n      raise ValueError('Duration JSON value not a string: {!r}'.format(value))\n    if len(value) &lt; 1 or value[-1] != 's':\n      raise ValueError(\n          'Duration must end with letter \"s\": {0}.'.format(value))\n    try:\n      pos = value.find('.')\n      if pos == -1:\n        seconds = int(value[:-1])\n        nanos = 0\n      else:\n        seconds = int(value[:pos])\n        if value[0] == '-':\n          nanos = int(round(float('-0{0}'.format(value[pos: -1])) *1e9))\n        else:\n          nanos = int(round(float('0{0}'.format(value[pos: -1])) *1e9))\n      _CheckDurationValid(seconds, nanos)\n      self.seconds = seconds\n      self.nanos = nanos\n    except ValueError as e:\n      raise ValueError(\n          'Couldn\\'t parse duration: {0} : {1}.'.format(value, e))\n\n  def ToNanoseconds(self):\n    \"\"\"Converts a Duration to nanoseconds.\"\"\"\n    return self.seconds * _NANOS_PER_SECOND + self.nanos\n\n  def ToMicroseconds(self):\n    \"\"\"Converts a Duration to microseconds.\"\"\"\n    micros = _RoundTowardZero(self.nanos, _NANOS_PER_MICROSECOND)\n    return self.seconds * _MICROS_PER_SECOND + micros\n\n  def ToMilliseconds(self):\n    \"\"\"Converts a Duration to milliseconds.\"\"\"\n    millis = _RoundTowardZero(self.nanos, _NANOS_PER_MILLISECOND)\n    return self.seconds * _MILLIS_PER_SECOND + millis\n\n  def ToSeconds(self):\n    \"\"\"Converts a Duration to seconds.\"\"\"\n    return self.seconds\n\n  def FromNanoseconds(self, nanos):\n    \"\"\"Converts nanoseconds to Duration.\"\"\"\n    self._NormalizeDuration(nanos // _NANOS_PER_SECOND,\n                            nanos % _NANOS_PER_SECOND)\n\n  def FromMicroseconds(self, micros):\n    \"\"\"Converts microseconds to Duration.\"\"\"\n    self._NormalizeDuration(\n        micros // _MICROS_PER_SECOND,\n        (micros % _MICROS_PER_SECOND) * _NANOS_PER_MICROSECOND)\n\n  def FromMilliseconds(self, millis):\n    \"\"\"Converts milliseconds to Duration.\"\"\"\n    self._NormalizeDuration(\n        millis // _MILLIS_PER_SECOND,\n        (millis % _MILLIS_PER_SECOND) * _NANOS_PER_MILLISECOND)\n\n  def FromSeconds(self, seconds):\n    \"\"\"Converts seconds to Duration.\"\"\"\n    self.seconds = seconds\n    self.nanos = 0\n\n  def ToTimedelta(self):\n    \"\"\"Converts Duration to timedelta.\"\"\"\n    return datetime.timedelta(\n        seconds=self.seconds, microseconds=_RoundTowardZero(\n            self.nanos, _NANOS_PER_MICROSECOND))\n\n  def FromTimedelta(self, td):\n    \"\"\"Converts timedelta to Duration.\"\"\"\n    self._NormalizeDuration(td.seconds + td.days * _SECONDS_PER_DAY,\n                            td.microseconds * _NANOS_PER_MICROSECOND)\n\n  def _NormalizeDuration(self, seconds, nanos):\n    \"\"\"Set Duration by seconds and nanos.\"\"\"\n    # Force nanos to be negative if the duration is negative.\n    if seconds &lt; 0 and nanos &gt; 0:\n      seconds += 1\n      nanos -= _NANOS_PER_SECOND\n    self.seconds = seconds\n    self.nanos = nanos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.FromJsonString","title":"<code>FromJsonString(value)</code>","text":"<p>Converts a string to Duration.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>A string to be converted. The string must end with 's'. Any   fractional digits (or none) are accepted as long as they fit into   precision. For example: \"1s\", \"1.01s\", \"1.0000001s\", \"-3.100s</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>On parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromJsonString(self, value):\n  \"\"\"Converts a string to Duration.\n\n  Args:\n    value: A string to be converted. The string must end with 's'. Any\n        fractional digits (or none) are accepted as long as they fit into\n        precision. For example: \"1s\", \"1.01s\", \"1.0000001s\", \"-3.100s\n\n  Raises:\n    ValueError: On parsing problems.\n  \"\"\"\n  if not isinstance(value, str):\n    raise ValueError('Duration JSON value not a string: {!r}'.format(value))\n  if len(value) &lt; 1 or value[-1] != 's':\n    raise ValueError(\n        'Duration must end with letter \"s\": {0}.'.format(value))\n  try:\n    pos = value.find('.')\n    if pos == -1:\n      seconds = int(value[:-1])\n      nanos = 0\n    else:\n      seconds = int(value[:pos])\n      if value[0] == '-':\n        nanos = int(round(float('-0{0}'.format(value[pos: -1])) *1e9))\n      else:\n        nanos = int(round(float('0{0}'.format(value[pos: -1])) *1e9))\n    _CheckDurationValid(seconds, nanos)\n    self.seconds = seconds\n    self.nanos = nanos\n  except ValueError as e:\n    raise ValueError(\n        'Couldn\\'t parse duration: {0} : {1}.'.format(value, e))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.FromMicroseconds","title":"<code>FromMicroseconds(micros)</code>","text":"<p>Converts microseconds to Duration.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromMicroseconds(self, micros):\n  \"\"\"Converts microseconds to Duration.\"\"\"\n  self._NormalizeDuration(\n      micros // _MICROS_PER_SECOND,\n      (micros % _MICROS_PER_SECOND) * _NANOS_PER_MICROSECOND)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.FromMilliseconds","title":"<code>FromMilliseconds(millis)</code>","text":"<p>Converts milliseconds to Duration.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromMilliseconds(self, millis):\n  \"\"\"Converts milliseconds to Duration.\"\"\"\n  self._NormalizeDuration(\n      millis // _MILLIS_PER_SECOND,\n      (millis % _MILLIS_PER_SECOND) * _NANOS_PER_MILLISECOND)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.FromNanoseconds","title":"<code>FromNanoseconds(nanos)</code>","text":"<p>Converts nanoseconds to Duration.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromNanoseconds(self, nanos):\n  \"\"\"Converts nanoseconds to Duration.\"\"\"\n  self._NormalizeDuration(nanos // _NANOS_PER_SECOND,\n                          nanos % _NANOS_PER_SECOND)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.FromSeconds","title":"<code>FromSeconds(seconds)</code>","text":"<p>Converts seconds to Duration.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromSeconds(self, seconds):\n  \"\"\"Converts seconds to Duration.\"\"\"\n  self.seconds = seconds\n  self.nanos = 0\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.FromTimedelta","title":"<code>FromTimedelta(td)</code>","text":"<p>Converts timedelta to Duration.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromTimedelta(self, td):\n  \"\"\"Converts timedelta to Duration.\"\"\"\n  self._NormalizeDuration(td.seconds + td.days * _SECONDS_PER_DAY,\n                          td.microseconds * _NANOS_PER_MICROSECOND)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.ToJsonString","title":"<code>ToJsonString()</code>","text":"<p>Converts Duration to string format.</p> <p>Returns:</p> Type Description <p>A string converted from self. The string format will contains</p> <p>3, 6, or 9 fractional digits depending on the precision required to</p> <p>represent the exact Duration value. For example: \"1s\", \"1.010s\",</p> <p>\"1.000000100s\", \"-3.100s\"</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToJsonString(self):\n  \"\"\"Converts Duration to string format.\n\n  Returns:\n    A string converted from self. The string format will contains\n    3, 6, or 9 fractional digits depending on the precision required to\n    represent the exact Duration value. For example: \"1s\", \"1.010s\",\n    \"1.000000100s\", \"-3.100s\"\n  \"\"\"\n  _CheckDurationValid(self.seconds, self.nanos)\n  if self.seconds &lt; 0 or self.nanos &lt; 0:\n    result = '-'\n    seconds = - self.seconds + int((0 - self.nanos) // 1e9)\n    nanos = (0 - self.nanos) % 1e9\n  else:\n    result = ''\n    seconds = self.seconds + int(self.nanos // 1e9)\n    nanos = self.nanos % 1e9\n  result += '%d' % seconds\n  if (nanos % 1e9) == 0:\n    # If there are 0 fractional digits, the fractional\n    # point '.' should be omitted when serializing.\n    return result + 's'\n  if (nanos % 1e6) == 0:\n    # Serialize 3 fractional digits.\n    return result + '.%03ds' % (nanos / 1e6)\n  if (nanos % 1e3) == 0:\n    # Serialize 6 fractional digits.\n    return result + '.%06ds' % (nanos / 1e3)\n  # Serialize 9 fractional digits.\n  return result + '.%09ds' % nanos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.ToMicroseconds","title":"<code>ToMicroseconds()</code>","text":"<p>Converts a Duration to microseconds.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToMicroseconds(self):\n  \"\"\"Converts a Duration to microseconds.\"\"\"\n  micros = _RoundTowardZero(self.nanos, _NANOS_PER_MICROSECOND)\n  return self.seconds * _MICROS_PER_SECOND + micros\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.ToMilliseconds","title":"<code>ToMilliseconds()</code>","text":"<p>Converts a Duration to milliseconds.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToMilliseconds(self):\n  \"\"\"Converts a Duration to milliseconds.\"\"\"\n  millis = _RoundTowardZero(self.nanos, _NANOS_PER_MILLISECOND)\n  return self.seconds * _MILLIS_PER_SECOND + millis\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.ToNanoseconds","title":"<code>ToNanoseconds()</code>","text":"<p>Converts a Duration to nanoseconds.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToNanoseconds(self):\n  \"\"\"Converts a Duration to nanoseconds.\"\"\"\n  return self.seconds * _NANOS_PER_SECOND + self.nanos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.ToSeconds","title":"<code>ToSeconds()</code>","text":"<p>Converts a Duration to seconds.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToSeconds(self):\n  \"\"\"Converts a Duration to seconds.\"\"\"\n  return self.seconds\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Duration.ToTimedelta","title":"<code>ToTimedelta()</code>","text":"<p>Converts Duration to timedelta.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToTimedelta(self):\n  \"\"\"Converts Duration to timedelta.\"\"\"\n  return datetime.timedelta(\n      seconds=self.seconds, microseconds=_RoundTowardZero(\n          self.nanos, _NANOS_PER_MICROSECOND))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask","title":"<code>FieldMask</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for FieldMask message type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>class FieldMask(object):\n  \"\"\"Class for FieldMask message type.\"\"\"\n\n  __slots__ = ()\n\n  def ToJsonString(self):\n    \"\"\"Converts FieldMask to string according to proto3 JSON spec.\"\"\"\n    camelcase_paths = []\n    for path in self.paths:\n      camelcase_paths.append(_SnakeCaseToCamelCase(path))\n    return ','.join(camelcase_paths)\n\n  def FromJsonString(self, value):\n    \"\"\"Converts string to FieldMask according to proto3 JSON spec.\"\"\"\n    if not isinstance(value, str):\n      raise ValueError('FieldMask JSON value not a string: {!r}'.format(value))\n    self.Clear()\n    if value:\n      for path in value.split(','):\n        self.paths.append(_CamelCaseToSnakeCase(path))\n\n  def IsValidForDescriptor(self, message_descriptor):\n    \"\"\"Checks whether the FieldMask is valid for Message Descriptor.\"\"\"\n    for path in self.paths:\n      if not _IsValidPath(message_descriptor, path):\n        return False\n    return True\n\n  def AllFieldsFromDescriptor(self, message_descriptor):\n    \"\"\"Gets all direct fields of Message Descriptor to FieldMask.\"\"\"\n    self.Clear()\n    for field in message_descriptor.fields:\n      self.paths.append(field.name)\n\n  def CanonicalFormFromMask(self, mask):\n    \"\"\"Converts a FieldMask to the canonical form.\n\n    Removes paths that are covered by another path. For example,\n    \"foo.bar\" is covered by \"foo\" and will be removed if \"foo\"\n    is also in the FieldMask. Then sorts all paths in alphabetical order.\n\n    Args:\n      mask: The original FieldMask to be converted.\n    \"\"\"\n    tree = _FieldMaskTree(mask)\n    tree.ToFieldMask(self)\n\n  def Union(self, mask1, mask2):\n    \"\"\"Merges mask1 and mask2 into this FieldMask.\"\"\"\n    _CheckFieldMaskMessage(mask1)\n    _CheckFieldMaskMessage(mask2)\n    tree = _FieldMaskTree(mask1)\n    tree.MergeFromFieldMask(mask2)\n    tree.ToFieldMask(self)\n\n  def Intersect(self, mask1, mask2):\n    \"\"\"Intersects mask1 and mask2 into this FieldMask.\"\"\"\n    _CheckFieldMaskMessage(mask1)\n    _CheckFieldMaskMessage(mask2)\n    tree = _FieldMaskTree(mask1)\n    intersection = _FieldMaskTree()\n    for path in mask2.paths:\n      tree.IntersectPath(path, intersection)\n    intersection.ToFieldMask(self)\n\n  def MergeMessage(\n      self, source, destination,\n      replace_message_field=False, replace_repeated_field=False):\n    \"\"\"Merges fields specified in FieldMask from source to destination.\n\n    Args:\n      source: Source message.\n      destination: The destination message to be merged into.\n      replace_message_field: Replace message field if True. Merge message\n          field if False.\n      replace_repeated_field: Replace repeated field if True. Append\n          elements of repeated field if False.\n    \"\"\"\n    tree = _FieldMaskTree(self)\n    tree.MergeMessage(\n        source, destination, replace_message_field, replace_repeated_field)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.AllFieldsFromDescriptor","title":"<code>AllFieldsFromDescriptor(message_descriptor)</code>","text":"<p>Gets all direct fields of Message Descriptor to FieldMask.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def AllFieldsFromDescriptor(self, message_descriptor):\n  \"\"\"Gets all direct fields of Message Descriptor to FieldMask.\"\"\"\n  self.Clear()\n  for field in message_descriptor.fields:\n    self.paths.append(field.name)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.CanonicalFormFromMask","title":"<code>CanonicalFormFromMask(mask)</code>","text":"<p>Converts a FieldMask to the canonical form.</p> <p>Removes paths that are covered by another path. For example, \"foo.bar\" is covered by \"foo\" and will be removed if \"foo\" is also in the FieldMask. Then sorts all paths in alphabetical order.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <p>The original FieldMask to be converted.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def CanonicalFormFromMask(self, mask):\n  \"\"\"Converts a FieldMask to the canonical form.\n\n  Removes paths that are covered by another path. For example,\n  \"foo.bar\" is covered by \"foo\" and will be removed if \"foo\"\n  is also in the FieldMask. Then sorts all paths in alphabetical order.\n\n  Args:\n    mask: The original FieldMask to be converted.\n  \"\"\"\n  tree = _FieldMaskTree(mask)\n  tree.ToFieldMask(self)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.FromJsonString","title":"<code>FromJsonString(value)</code>","text":"<p>Converts string to FieldMask according to proto3 JSON spec.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromJsonString(self, value):\n  \"\"\"Converts string to FieldMask according to proto3 JSON spec.\"\"\"\n  if not isinstance(value, str):\n    raise ValueError('FieldMask JSON value not a string: {!r}'.format(value))\n  self.Clear()\n  if value:\n    for path in value.split(','):\n      self.paths.append(_CamelCaseToSnakeCase(path))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.Intersect","title":"<code>Intersect(mask1, mask2)</code>","text":"<p>Intersects mask1 and mask2 into this FieldMask.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def Intersect(self, mask1, mask2):\n  \"\"\"Intersects mask1 and mask2 into this FieldMask.\"\"\"\n  _CheckFieldMaskMessage(mask1)\n  _CheckFieldMaskMessage(mask2)\n  tree = _FieldMaskTree(mask1)\n  intersection = _FieldMaskTree()\n  for path in mask2.paths:\n    tree.IntersectPath(path, intersection)\n  intersection.ToFieldMask(self)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.IsValidForDescriptor","title":"<code>IsValidForDescriptor(message_descriptor)</code>","text":"<p>Checks whether the FieldMask is valid for Message Descriptor.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def IsValidForDescriptor(self, message_descriptor):\n  \"\"\"Checks whether the FieldMask is valid for Message Descriptor.\"\"\"\n  for path in self.paths:\n    if not _IsValidPath(message_descriptor, path):\n      return False\n  return True\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.MergeMessage","title":"<code>MergeMessage(source, destination, replace_message_field=False, replace_repeated_field=False)</code>","text":"<p>Merges fields specified in FieldMask from source to destination.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <p>Source message.</p> required <code>destination</code> <p>The destination message to be merged into.</p> required <code>replace_message_field</code> <p>Replace message field if True. Merge message   field if False.</p> <code>False</code> <code>replace_repeated_field</code> <p>Replace repeated field if True. Append   elements of repeated field if False.</p> <code>False</code> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def MergeMessage(\n    self, source, destination,\n    replace_message_field=False, replace_repeated_field=False):\n  \"\"\"Merges fields specified in FieldMask from source to destination.\n\n  Args:\n    source: Source message.\n    destination: The destination message to be merged into.\n    replace_message_field: Replace message field if True. Merge message\n        field if False.\n    replace_repeated_field: Replace repeated field if True. Append\n        elements of repeated field if False.\n  \"\"\"\n  tree = _FieldMaskTree(self)\n  tree.MergeMessage(\n      source, destination, replace_message_field, replace_repeated_field)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.ToJsonString","title":"<code>ToJsonString()</code>","text":"<p>Converts FieldMask to string according to proto3 JSON spec.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToJsonString(self):\n  \"\"\"Converts FieldMask to string according to proto3 JSON spec.\"\"\"\n  camelcase_paths = []\n  for path in self.paths:\n    camelcase_paths.append(_SnakeCaseToCamelCase(path))\n  return ','.join(camelcase_paths)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.FieldMask.Union","title":"<code>Union(mask1, mask2)</code>","text":"<p>Merges mask1 and mask2 into this FieldMask.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def Union(self, mask1, mask2):\n  \"\"\"Merges mask1 and mask2 into this FieldMask.\"\"\"\n  _CheckFieldMaskMessage(mask1)\n  _CheckFieldMaskMessage(mask2)\n  tree = _FieldMaskTree(mask1)\n  tree.MergeFromFieldMask(mask2)\n  tree.ToFieldMask(self)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.ListValue","title":"<code>ListValue</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for ListValue message type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>class ListValue(object):\n  \"\"\"Class for ListValue message type.\"\"\"\n\n  __slots__ = ()\n\n  def __len__(self):\n    return len(self.values)\n\n  def append(self, value):\n    _SetStructValue(self.values.add(), value)\n\n  def extend(self, elem_seq):\n    for value in elem_seq:\n      self.append(value)\n\n  def __getitem__(self, index):\n    \"\"\"Retrieves item by the specified index.\"\"\"\n    return _GetStructValue(self.values.__getitem__(index))\n\n  def __setitem__(self, index, value):\n    _SetStructValue(self.values.__getitem__(index), value)\n\n  def __delitem__(self, key):\n    del self.values[key]\n\n  def items(self):\n    for i in range(len(self)):\n      yield self[i]\n\n  def add_struct(self):\n    \"\"\"Appends and returns a struct value as the next value in the list.\"\"\"\n    struct_value = self.values.add().struct_value\n    # Clear will mark struct_value modified which will indeed create a struct.\n    struct_value.Clear()\n    return struct_value\n\n  def add_list(self):\n    \"\"\"Appends and returns a list value as the next value in the list.\"\"\"\n    list_value = self.values.add().list_value\n    # Clear will mark list_value modified which will indeed create a list.\n    list_value.Clear()\n    return list_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.ListValue.__getitem__","title":"<code>__getitem__(index)</code>","text":"<p>Retrieves item by the specified index.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def __getitem__(self, index):\n  \"\"\"Retrieves item by the specified index.\"\"\"\n  return _GetStructValue(self.values.__getitem__(index))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.ListValue.add_list","title":"<code>add_list()</code>","text":"<p>Appends and returns a list value as the next value in the list.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def add_list(self):\n  \"\"\"Appends and returns a list value as the next value in the list.\"\"\"\n  list_value = self.values.add().list_value\n  # Clear will mark list_value modified which will indeed create a list.\n  list_value.Clear()\n  return list_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.ListValue.add_struct","title":"<code>add_struct()</code>","text":"<p>Appends and returns a struct value as the next value in the list.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def add_struct(self):\n  \"\"\"Appends and returns a struct value as the next value in the list.\"\"\"\n  struct_value = self.values.add().struct_value\n  # Clear will mark struct_value modified which will indeed create a struct.\n  struct_value.Clear()\n  return struct_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Struct","title":"<code>Struct</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for Struct message type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>class Struct(object):\n  \"\"\"Class for Struct message type.\"\"\"\n\n  __slots__ = ()\n\n  def __getitem__(self, key):\n    return _GetStructValue(self.fields[key])\n\n  def __contains__(self, item):\n    return item in self.fields\n\n  def __setitem__(self, key, value):\n    _SetStructValue(self.fields[key], value)\n\n  def __delitem__(self, key):\n    del self.fields[key]\n\n  def __len__(self):\n    return len(self.fields)\n\n  def __iter__(self):\n    return iter(self.fields)\n\n  def keys(self):  # pylint: disable=invalid-name\n    return self.fields.keys()\n\n  def values(self):  # pylint: disable=invalid-name\n    return [self[key] for key in self]\n\n  def items(self):  # pylint: disable=invalid-name\n    return [(key, self[key]) for key in self]\n\n  def get_or_create_list(self, key):\n    \"\"\"Returns a list for this key, creating if it didn't exist already.\"\"\"\n    if not self.fields[key].HasField('list_value'):\n      # Clear will mark list_value modified which will indeed create a list.\n      self.fields[key].list_value.Clear()\n    return self.fields[key].list_value\n\n  def get_or_create_struct(self, key):\n    \"\"\"Returns a struct for this key, creating if it didn't exist already.\"\"\"\n    if not self.fields[key].HasField('struct_value'):\n      # Clear will mark struct_value modified which will indeed create a struct.\n      self.fields[key].struct_value.Clear()\n    return self.fields[key].struct_value\n\n  def update(self, dictionary):  # pylint: disable=invalid-name\n    for key, value in dictionary.items():\n      _SetStructValue(self.fields[key], value)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Struct.get_or_create_list","title":"<code>get_or_create_list(key)</code>","text":"<p>Returns a list for this key, creating if it didn't exist already.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def get_or_create_list(self, key):\n  \"\"\"Returns a list for this key, creating if it didn't exist already.\"\"\"\n  if not self.fields[key].HasField('list_value'):\n    # Clear will mark list_value modified which will indeed create a list.\n    self.fields[key].list_value.Clear()\n  return self.fields[key].list_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Struct.get_or_create_struct","title":"<code>get_or_create_struct(key)</code>","text":"<p>Returns a struct for this key, creating if it didn't exist already.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def get_or_create_struct(self, key):\n  \"\"\"Returns a struct for this key, creating if it didn't exist already.\"\"\"\n  if not self.fields[key].HasField('struct_value'):\n    # Clear will mark struct_value modified which will indeed create a struct.\n    self.fields[key].struct_value.Clear()\n  return self.fields[key].struct_value\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp","title":"<code>Timestamp</code>","text":"<p>               Bases: <code>object</code></p> <p>Class for Timestamp message type.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>class Timestamp(object):\n  \"\"\"Class for Timestamp message type.\"\"\"\n\n  __slots__ = ()\n\n  def ToJsonString(self):\n    \"\"\"Converts Timestamp to RFC 3339 date string format.\n\n    Returns:\n      A string converted from timestamp. The string is always Z-normalized\n      and uses 3, 6 or 9 fractional digits as required to represent the\n      exact time. Example of the return format: '1972-01-01T10:00:20.021Z'\n    \"\"\"\n    nanos = self.nanos % _NANOS_PER_SECOND\n    total_sec = self.seconds + (self.nanos - nanos) // _NANOS_PER_SECOND\n    seconds = total_sec % _SECONDS_PER_DAY\n    days = (total_sec - seconds) // _SECONDS_PER_DAY\n    dt = datetime.datetime(1970, 1, 1) + datetime.timedelta(days, seconds)\n\n    result = dt.isoformat()\n    if (nanos % 1e9) == 0:\n      # If there are 0 fractional digits, the fractional\n      # point '.' should be omitted when serializing.\n      return result + 'Z'\n    if (nanos % 1e6) == 0:\n      # Serialize 3 fractional digits.\n      return result + '.%03dZ' % (nanos / 1e6)\n    if (nanos % 1e3) == 0:\n      # Serialize 6 fractional digits.\n      return result + '.%06dZ' % (nanos / 1e3)\n    # Serialize 9 fractional digits.\n    return result + '.%09dZ' % nanos\n\n  def FromJsonString(self, value):\n    \"\"\"Parse a RFC 3339 date string format to Timestamp.\n\n    Args:\n      value: A date string. Any fractional digits (or none) and any offset are\n          accepted as long as they fit into nano-seconds precision.\n          Example of accepted format: '1972-01-01T10:00:20.021-05:00'\n\n    Raises:\n      ValueError: On parsing problems.\n    \"\"\"\n    if not isinstance(value, str):\n      raise ValueError('Timestamp JSON value not a string: {!r}'.format(value))\n    timezone_offset = value.find('Z')\n    if timezone_offset == -1:\n      timezone_offset = value.find('+')\n    if timezone_offset == -1:\n      timezone_offset = value.rfind('-')\n    if timezone_offset == -1:\n      raise ValueError(\n          'Failed to parse timestamp: missing valid timezone offset.')\n    time_value = value[0:timezone_offset]\n    # Parse datetime and nanos.\n    point_position = time_value.find('.')\n    if point_position == -1:\n      second_value = time_value\n      nano_value = ''\n    else:\n      second_value = time_value[:point_position]\n      nano_value = time_value[point_position + 1:]\n    if 't' in second_value:\n      raise ValueError(\n          'time data \\'{0}\\' does not match format \\'%Y-%m-%dT%H:%M:%S\\', '\n          'lowercase \\'t\\' is not accepted'.format(second_value))\n    date_object = datetime.datetime.strptime(second_value, _TIMESTAMPFOMAT)\n    td = date_object - datetime.datetime(1970, 1, 1)\n    seconds = td.seconds + td.days * _SECONDS_PER_DAY\n    if len(nano_value) &gt; 9:\n      raise ValueError(\n          'Failed to parse Timestamp: nanos {0} more than '\n          '9 fractional digits.'.format(nano_value))\n    if nano_value:\n      nanos = round(float('0.' + nano_value) * 1e9)\n    else:\n      nanos = 0\n    # Parse timezone offsets.\n    if value[timezone_offset] == 'Z':\n      if len(value) != timezone_offset + 1:\n        raise ValueError('Failed to parse timestamp: invalid trailing'\n                         ' data {0}.'.format(value))\n    else:\n      timezone = value[timezone_offset:]\n      pos = timezone.find(':')\n      if pos == -1:\n        raise ValueError(\n            'Invalid timezone offset value: {0}.'.format(timezone))\n      if timezone[0] == '+':\n        seconds -= (int(timezone[1:pos])*60+int(timezone[pos+1:]))*60\n      else:\n        seconds += (int(timezone[1:pos])*60+int(timezone[pos+1:]))*60\n    # Set seconds and nanos\n    self.seconds = int(seconds)\n    self.nanos = int(nanos)\n\n  def GetCurrentTime(self):\n    \"\"\"Get the current UTC into Timestamp.\"\"\"\n    self.FromDatetime(datetime.datetime.utcnow())\n\n  def ToNanoseconds(self):\n    \"\"\"Converts Timestamp to nanoseconds since epoch.\"\"\"\n    return self.seconds * _NANOS_PER_SECOND + self.nanos\n\n  def ToMicroseconds(self):\n    \"\"\"Converts Timestamp to microseconds since epoch.\"\"\"\n    return (self.seconds * _MICROS_PER_SECOND +\n            self.nanos // _NANOS_PER_MICROSECOND)\n\n  def ToMilliseconds(self):\n    \"\"\"Converts Timestamp to milliseconds since epoch.\"\"\"\n    return (self.seconds * _MILLIS_PER_SECOND +\n            self.nanos // _NANOS_PER_MILLISECOND)\n\n  def ToSeconds(self):\n    \"\"\"Converts Timestamp to seconds since epoch.\"\"\"\n    return self.seconds\n\n  def FromNanoseconds(self, nanos):\n    \"\"\"Converts nanoseconds since epoch to Timestamp.\"\"\"\n    self.seconds = nanos // _NANOS_PER_SECOND\n    self.nanos = nanos % _NANOS_PER_SECOND\n\n  def FromMicroseconds(self, micros):\n    \"\"\"Converts microseconds since epoch to Timestamp.\"\"\"\n    self.seconds = micros // _MICROS_PER_SECOND\n    self.nanos = (micros % _MICROS_PER_SECOND) * _NANOS_PER_MICROSECOND\n\n  def FromMilliseconds(self, millis):\n    \"\"\"Converts milliseconds since epoch to Timestamp.\"\"\"\n    self.seconds = millis // _MILLIS_PER_SECOND\n    self.nanos = (millis % _MILLIS_PER_SECOND) * _NANOS_PER_MILLISECOND\n\n  def FromSeconds(self, seconds):\n    \"\"\"Converts seconds since epoch to Timestamp.\"\"\"\n    self.seconds = seconds\n    self.nanos = 0\n\n  def ToDatetime(self, tzinfo=None):\n    \"\"\"Converts Timestamp to a datetime.\n\n    Args:\n      tzinfo: A datetime.tzinfo subclass; defaults to None.\n\n    Returns:\n      If tzinfo is None, returns a timezone-naive UTC datetime (with no timezone\n      information, i.e. not aware that it's UTC).\n\n      Otherwise, returns a timezone-aware datetime in the input timezone.\n    \"\"\"\n    delta = datetime.timedelta(\n        seconds=self.seconds,\n        microseconds=_RoundTowardZero(self.nanos, _NANOS_PER_MICROSECOND))\n    if tzinfo is None:\n      return _EPOCH_DATETIME_NAIVE + delta\n    else:\n      return _EPOCH_DATETIME_AWARE.astimezone(tzinfo) + delta\n\n  def FromDatetime(self, dt):\n    \"\"\"Converts datetime to Timestamp.\n\n    Args:\n      dt: A datetime. If it's timezone-naive, it's assumed to be in UTC.\n    \"\"\"\n    # Using this guide: http://wiki.python.org/moin/WorkingWithTime\n    # And this conversion guide: http://docs.python.org/library/time.html\n\n    # Turn the date parameter into a tuple (struct_time) that can then be\n    # manipulated into a long value of seconds.  During the conversion from\n    # struct_time to long, the source date in UTC, and so it follows that the\n    # correct transformation is calendar.timegm()\n    self.seconds = calendar.timegm(dt.utctimetuple())\n    self.nanos = dt.microsecond * _NANOS_PER_MICROSECOND\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.FromDatetime","title":"<code>FromDatetime(dt)</code>","text":"<p>Converts datetime to Timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>dt</code> <p>A datetime. If it's timezone-naive, it's assumed to be in UTC.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromDatetime(self, dt):\n  \"\"\"Converts datetime to Timestamp.\n\n  Args:\n    dt: A datetime. If it's timezone-naive, it's assumed to be in UTC.\n  \"\"\"\n  # Using this guide: http://wiki.python.org/moin/WorkingWithTime\n  # And this conversion guide: http://docs.python.org/library/time.html\n\n  # Turn the date parameter into a tuple (struct_time) that can then be\n  # manipulated into a long value of seconds.  During the conversion from\n  # struct_time to long, the source date in UTC, and so it follows that the\n  # correct transformation is calendar.timegm()\n  self.seconds = calendar.timegm(dt.utctimetuple())\n  self.nanos = dt.microsecond * _NANOS_PER_MICROSECOND\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.FromJsonString","title":"<code>FromJsonString(value)</code>","text":"<p>Parse a RFC 3339 date string format to Timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <p>A date string. Any fractional digits (or none) and any offset are   accepted as long as they fit into nano-seconds precision.   Example of accepted format: '1972-01-01T10:00:20.021-05:00'</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>On parsing problems.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromJsonString(self, value):\n  \"\"\"Parse a RFC 3339 date string format to Timestamp.\n\n  Args:\n    value: A date string. Any fractional digits (or none) and any offset are\n        accepted as long as they fit into nano-seconds precision.\n        Example of accepted format: '1972-01-01T10:00:20.021-05:00'\n\n  Raises:\n    ValueError: On parsing problems.\n  \"\"\"\n  if not isinstance(value, str):\n    raise ValueError('Timestamp JSON value not a string: {!r}'.format(value))\n  timezone_offset = value.find('Z')\n  if timezone_offset == -1:\n    timezone_offset = value.find('+')\n  if timezone_offset == -1:\n    timezone_offset = value.rfind('-')\n  if timezone_offset == -1:\n    raise ValueError(\n        'Failed to parse timestamp: missing valid timezone offset.')\n  time_value = value[0:timezone_offset]\n  # Parse datetime and nanos.\n  point_position = time_value.find('.')\n  if point_position == -1:\n    second_value = time_value\n    nano_value = ''\n  else:\n    second_value = time_value[:point_position]\n    nano_value = time_value[point_position + 1:]\n  if 't' in second_value:\n    raise ValueError(\n        'time data \\'{0}\\' does not match format \\'%Y-%m-%dT%H:%M:%S\\', '\n        'lowercase \\'t\\' is not accepted'.format(second_value))\n  date_object = datetime.datetime.strptime(second_value, _TIMESTAMPFOMAT)\n  td = date_object - datetime.datetime(1970, 1, 1)\n  seconds = td.seconds + td.days * _SECONDS_PER_DAY\n  if len(nano_value) &gt; 9:\n    raise ValueError(\n        'Failed to parse Timestamp: nanos {0} more than '\n        '9 fractional digits.'.format(nano_value))\n  if nano_value:\n    nanos = round(float('0.' + nano_value) * 1e9)\n  else:\n    nanos = 0\n  # Parse timezone offsets.\n  if value[timezone_offset] == 'Z':\n    if len(value) != timezone_offset + 1:\n      raise ValueError('Failed to parse timestamp: invalid trailing'\n                       ' data {0}.'.format(value))\n  else:\n    timezone = value[timezone_offset:]\n    pos = timezone.find(':')\n    if pos == -1:\n      raise ValueError(\n          'Invalid timezone offset value: {0}.'.format(timezone))\n    if timezone[0] == '+':\n      seconds -= (int(timezone[1:pos])*60+int(timezone[pos+1:]))*60\n    else:\n      seconds += (int(timezone[1:pos])*60+int(timezone[pos+1:]))*60\n  # Set seconds and nanos\n  self.seconds = int(seconds)\n  self.nanos = int(nanos)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.FromMicroseconds","title":"<code>FromMicroseconds(micros)</code>","text":"<p>Converts microseconds since epoch to Timestamp.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromMicroseconds(self, micros):\n  \"\"\"Converts microseconds since epoch to Timestamp.\"\"\"\n  self.seconds = micros // _MICROS_PER_SECOND\n  self.nanos = (micros % _MICROS_PER_SECOND) * _NANOS_PER_MICROSECOND\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.FromMilliseconds","title":"<code>FromMilliseconds(millis)</code>","text":"<p>Converts milliseconds since epoch to Timestamp.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromMilliseconds(self, millis):\n  \"\"\"Converts milliseconds since epoch to Timestamp.\"\"\"\n  self.seconds = millis // _MILLIS_PER_SECOND\n  self.nanos = (millis % _MILLIS_PER_SECOND) * _NANOS_PER_MILLISECOND\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.FromNanoseconds","title":"<code>FromNanoseconds(nanos)</code>","text":"<p>Converts nanoseconds since epoch to Timestamp.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromNanoseconds(self, nanos):\n  \"\"\"Converts nanoseconds since epoch to Timestamp.\"\"\"\n  self.seconds = nanos // _NANOS_PER_SECOND\n  self.nanos = nanos % _NANOS_PER_SECOND\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.FromSeconds","title":"<code>FromSeconds(seconds)</code>","text":"<p>Converts seconds since epoch to Timestamp.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def FromSeconds(self, seconds):\n  \"\"\"Converts seconds since epoch to Timestamp.\"\"\"\n  self.seconds = seconds\n  self.nanos = 0\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.GetCurrentTime","title":"<code>GetCurrentTime()</code>","text":"<p>Get the current UTC into Timestamp.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def GetCurrentTime(self):\n  \"\"\"Get the current UTC into Timestamp.\"\"\"\n  self.FromDatetime(datetime.datetime.utcnow())\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.ToDatetime","title":"<code>ToDatetime(tzinfo=None)</code>","text":"<p>Converts Timestamp to a datetime.</p> <p>Parameters:</p> Name Type Description Default <code>tzinfo</code> <p>A datetime.tzinfo subclass; defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>If tzinfo is None, returns a timezone-naive UTC datetime (with no timezone</p> <p>information, i.e. not aware that it's UTC).</p> <p>Otherwise, returns a timezone-aware datetime in the input timezone.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToDatetime(self, tzinfo=None):\n  \"\"\"Converts Timestamp to a datetime.\n\n  Args:\n    tzinfo: A datetime.tzinfo subclass; defaults to None.\n\n  Returns:\n    If tzinfo is None, returns a timezone-naive UTC datetime (with no timezone\n    information, i.e. not aware that it's UTC).\n\n    Otherwise, returns a timezone-aware datetime in the input timezone.\n  \"\"\"\n  delta = datetime.timedelta(\n      seconds=self.seconds,\n      microseconds=_RoundTowardZero(self.nanos, _NANOS_PER_MICROSECOND))\n  if tzinfo is None:\n    return _EPOCH_DATETIME_NAIVE + delta\n  else:\n    return _EPOCH_DATETIME_AWARE.astimezone(tzinfo) + delta\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.ToJsonString","title":"<code>ToJsonString()</code>","text":"<p>Converts Timestamp to RFC 3339 date string format.</p> <p>Returns:</p> Type Description <p>A string converted from timestamp. The string is always Z-normalized</p> <p>and uses 3, 6 or 9 fractional digits as required to represent the</p> <p>exact time. Example of the return format: '1972-01-01T10:00:20.021Z'</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToJsonString(self):\n  \"\"\"Converts Timestamp to RFC 3339 date string format.\n\n  Returns:\n    A string converted from timestamp. The string is always Z-normalized\n    and uses 3, 6 or 9 fractional digits as required to represent the\n    exact time. Example of the return format: '1972-01-01T10:00:20.021Z'\n  \"\"\"\n  nanos = self.nanos % _NANOS_PER_SECOND\n  total_sec = self.seconds + (self.nanos - nanos) // _NANOS_PER_SECOND\n  seconds = total_sec % _SECONDS_PER_DAY\n  days = (total_sec - seconds) // _SECONDS_PER_DAY\n  dt = datetime.datetime(1970, 1, 1) + datetime.timedelta(days, seconds)\n\n  result = dt.isoformat()\n  if (nanos % 1e9) == 0:\n    # If there are 0 fractional digits, the fractional\n    # point '.' should be omitted when serializing.\n    return result + 'Z'\n  if (nanos % 1e6) == 0:\n    # Serialize 3 fractional digits.\n    return result + '.%03dZ' % (nanos / 1e6)\n  if (nanos % 1e3) == 0:\n    # Serialize 6 fractional digits.\n    return result + '.%06dZ' % (nanos / 1e3)\n  # Serialize 9 fractional digits.\n  return result + '.%09dZ' % nanos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.ToMicroseconds","title":"<code>ToMicroseconds()</code>","text":"<p>Converts Timestamp to microseconds since epoch.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToMicroseconds(self):\n  \"\"\"Converts Timestamp to microseconds since epoch.\"\"\"\n  return (self.seconds * _MICROS_PER_SECOND +\n          self.nanos // _NANOS_PER_MICROSECOND)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.ToMilliseconds","title":"<code>ToMilliseconds()</code>","text":"<p>Converts Timestamp to milliseconds since epoch.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToMilliseconds(self):\n  \"\"\"Converts Timestamp to milliseconds since epoch.\"\"\"\n  return (self.seconds * _MILLIS_PER_SECOND +\n          self.nanos // _NANOS_PER_MILLISECOND)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.ToNanoseconds","title":"<code>ToNanoseconds()</code>","text":"<p>Converts Timestamp to nanoseconds since epoch.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToNanoseconds(self):\n  \"\"\"Converts Timestamp to nanoseconds since epoch.\"\"\"\n  return self.seconds * _NANOS_PER_SECOND + self.nanos\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.html#client.ayon_nuke.vendor.google.protobuf.internal.well_known_types.Timestamp.ToSeconds","title":"<code>ToSeconds()</code>","text":"<p>Converts Timestamp to seconds since epoch.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/well_known_types.py</code> <pre><code>def ToSeconds(self):\n  \"\"\"Converts Timestamp to seconds since epoch.\"\"\"\n  return self.seconds\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html","title":"wire_format","text":"<p>Constants and static functions to support protocol buffer wire format.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html#client.ayon_nuke.vendor.google.protobuf.internal.wire_format.IsTypePackable","title":"<code>IsTypePackable(field_type)</code>","text":"<p>Return true iff packable = true is valid for fields of this type.</p> <p>Parameters:</p> Name Type Description Default <code>field_type</code> <p>a FieldDescriptor::Type value.</p> required <p>Returns:</p> Type Description <p>True iff fields of this type are packable.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/wire_format.py</code> <pre><code>def IsTypePackable(field_type):\n  \"\"\"Return true iff packable = true is valid for fields of this type.\n\n  Args:\n    field_type: a FieldDescriptor::Type value.\n\n  Returns:\n    True iff fields of this type are packable.\n  \"\"\"\n  return field_type not in NON_PACKABLE_TYPES\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html#client.ayon_nuke.vendor.google.protobuf.internal.wire_format.PackTag","title":"<code>PackTag(field_number, wire_type)</code>","text":"<p>Returns an unsigned 32-bit integer that encodes the field number and wire type information in standard protocol message wire format.</p> <p>Parameters:</p> Name Type Description Default <code>field_number</code> <p>Expected to be an integer in the range [1, 1 &lt;&lt; 29)</p> required <code>wire_type</code> <p>One of the WIRETYPE_* constants.</p> required Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/wire_format.py</code> <pre><code>def PackTag(field_number, wire_type):\n  \"\"\"Returns an unsigned 32-bit integer that encodes the field number and\n  wire type information in standard protocol message wire format.\n\n  Args:\n    field_number: Expected to be an integer in the range [1, 1 &lt;&lt; 29)\n    wire_type: One of the WIRETYPE_* constants.\n  \"\"\"\n  if not 0 &lt;= wire_type &lt;= _WIRETYPE_MAX:\n    raise message.EncodeError('Unknown wire type: %d' % wire_type)\n  return (field_number &lt;&lt; TAG_TYPE_BITS) | wire_type\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html#client.ayon_nuke.vendor.google.protobuf.internal.wire_format.TagByteSize","title":"<code>TagByteSize(field_number)</code>","text":"<p>Returns the bytes required to serialize a tag with this field number.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/wire_format.py</code> <pre><code>def TagByteSize(field_number):\n  \"\"\"Returns the bytes required to serialize a tag with this field number.\"\"\"\n  # Just pass in type 0, since the type won't affect the tag+type size.\n  return _VarUInt64ByteSizeNoTag(PackTag(field_number, 0))\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html#client.ayon_nuke.vendor.google.protobuf.internal.wire_format.UnpackTag","title":"<code>UnpackTag(tag)</code>","text":"<p>The inverse of PackTag().  Given an unsigned 32-bit number, returns a (field_number, wire_type) tuple.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/wire_format.py</code> <pre><code>def UnpackTag(tag):\n  \"\"\"The inverse of PackTag().  Given an unsigned 32-bit number,\n  returns a (field_number, wire_type) tuple.\n  \"\"\"\n  return (tag &gt;&gt; TAG_TYPE_BITS), (tag &amp; TAG_TYPE_MASK)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html#client.ayon_nuke.vendor.google.protobuf.internal.wire_format.ZigZagDecode","title":"<code>ZigZagDecode(value)</code>","text":"<p>Inverse of ZigZagEncode().</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/wire_format.py</code> <pre><code>def ZigZagDecode(value):\n  \"\"\"Inverse of ZigZagEncode().\"\"\"\n  if not value &amp; 0x1:\n    return value &gt;&gt; 1\n  return (value &gt;&gt; 1) ^ (~0)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/internal/wire_format.html#client.ayon_nuke.vendor.google.protobuf.internal.wire_format.ZigZagEncode","title":"<code>ZigZagEncode(value)</code>","text":"<p>ZigZag Transform:  Encodes signed integers so that they can be effectively used with varint encoding.  See wire_format.h for more details.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/internal/wire_format.py</code> <pre><code>def ZigZagEncode(value):\n  \"\"\"ZigZag Transform:  Encodes signed integers so that they can be\n  effectively used with varint encoding.  See wire_format.h for\n  more details.\n  \"\"\"\n  if value &gt;= 0:\n    return value &lt;&lt; 1\n  return (value &lt;&lt; 1) ^ (~0)\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/pyext/index.html","title":"pyext","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/pyext/cpp_message.html","title":"cpp_message","text":"<p>Protocol message implementation hooks for C++ implementation.</p> <p>Contains helper functions used to create protocol message classes from Descriptor objects at runtime backed by the protocol buffer C++ API.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/pyext/cpp_message.html#client.ayon_nuke.vendor.google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType","title":"<code>GeneratedProtocolMessageType</code>","text":"<p>               Bases: <code>MessageMeta</code></p> <p>Metaclass for protocol message classes created at runtime from Descriptors.</p> <p>The protocol compiler currently uses this metaclass to create protocol message classes at runtime.  Clients can also manually create their own classes at runtime, as in this example:</p> <p>mydescriptor = Descriptor(.....) factory = symbol_database.Default() factory.pool.AddDescriptor(mydescriptor) MyProtoClass = factory.GetPrototype(mydescriptor) myproto_instance = MyProtoClass() myproto.foo_field = 23 ...</p> <p>The above example will not work for nested types. If you wish to include them, use reflection.MakeClass() instead of manually instantiating the class in order to create the appropriate class structure.</p> Source code in <code>client/ayon_nuke/vendor/google/protobuf/pyext/cpp_message.py</code> <pre><code>class GeneratedProtocolMessageType(_message.MessageMeta):\n\n  \"\"\"Metaclass for protocol message classes created at runtime from Descriptors.\n\n  The protocol compiler currently uses this metaclass to create protocol\n  message classes at runtime.  Clients can also manually create their own\n  classes at runtime, as in this example:\n\n  mydescriptor = Descriptor(.....)\n  factory = symbol_database.Default()\n  factory.pool.AddDescriptor(mydescriptor)\n  MyProtoClass = factory.GetPrototype(mydescriptor)\n  myproto_instance = MyProtoClass()\n  myproto.foo_field = 23\n  ...\n\n  The above example will not work for nested types. If you wish to include them,\n  use reflection.MakeClass() instead of manually instantiating the class in\n  order to create the appropriate class structure.\n  \"\"\"\n\n  # Must be consistent with the protocol-compiler code in\n  # proto2/compiler/internal/generator.*.\n  _DESCRIPTOR_KEY = 'DESCRIPTOR'\n</code></pre>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/pyext/python_pb2.html","title":"python_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/util/index.html","title":"util","text":""},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/util/json_format_pb2.html","title":"json_format_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/client/ayon_nuke/vendor/google/protobuf/util/json_format_proto3_pb2.html","title":"json_format_proto3_pb2","text":"<p>Generated protocol buffer code.</p>"},{"location":"autoapi/server/index.html","title":"server","text":""},{"location":"autoapi/server/settings/index.html","title":"settings","text":""},{"location":"autoapi/server/settings/index.html#server.settings.NukeSettings","title":"<code>NukeSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke addon settings.</p> Source code in <code>server/settings/main.py</code> <pre><code>class NukeSettings(BaseSettingsModel):\n    \"\"\"Nuke addon settings.\"\"\"\n\n    general: GeneralSettings = SettingsField(\n        default_factory=GeneralSettings,\n        title=\"General\",\n    )\n\n    imageio: ImageIOSettings = SettingsField(\n        default_factory=ImageIOSettings,\n        title=\"Color Management (imageio)\",\n    )\n\n    dirmap: DirmapSettings = SettingsField(\n        default_factory=DirmapSettings,\n        title=\"Nuke Directory Mapping\",\n    )\n\n    scriptsmenu: ScriptsmenuSettings = SettingsField(\n        default_factory=ScriptsmenuSettings,\n        title=\"Scripts Menu Definition\",\n    )\n\n    gizmo: list[GizmoItem] = SettingsField(\n        default_factory=list, title=\"Gizmo Menu\")\n\n    create: CreatorPluginsSettings = SettingsField(\n        default_factory=CreatorPluginsSettings,\n        title=\"Creator Plugins\",\n    )\n\n    publish: PublishPluginsModel = SettingsField(\n        default_factory=PublishPluginsModel,\n        title=\"Publish Plugins\",\n    )\n\n    load: LoaderPluginsModel = SettingsField(\n        default_factory=LoaderPluginsModel,\n        title=\"Loader Plugins\",\n    )\n\n    workfile_builder: WorkfileBuilderModel = SettingsField(\n        default_factory=WorkfileBuilderModel,\n        title=\"Workfile Builder\",\n    )\n\n    templated_workfile_build: TemplatedWorkfileBuildModel = SettingsField(\n        title=\"Templated Workfile Build\",\n        default_factory=TemplatedWorkfileBuildModel\n    )\n</code></pre>"},{"location":"autoapi/server/settings/common.html","title":"common","text":""},{"location":"autoapi/server/settings/conversion.html","title":"conversion","text":""},{"location":"autoapi/server/settings/create_plugins.html","title":"create_plugins","text":""},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.CreateWriteImageModel","title":"<code>CreateWriteImageModel</code>","text":"<p>               Bases: <code>DefaultPluginModel</code></p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>class CreateWriteImageModel(DefaultPluginModel):\n    temp_rendering_path_template: str = SettingsField(\n        title=\"Temporary rendering path template\"\n    )\n    default_variants: list[str] = SettingsField(\n        title=\"Default variants\",\n        default_factory=list\n    )\n    instance_attributes: list[str] = SettingsField(\n        default_factory=list,\n        enum_resolver=instance_attributes_enum,\n        title=\"Instance attributes\"\n    )\n    render_target: str = SettingsField(\n        enum_resolver=render_target_enum,\n        conditional_enum=True,\n        title=\"Render target\",\n        description=RENDER_TARGET_DESCRIPTION,\n    )\n    exposed_knobs: list[str] = SettingsField(\n        title=\"Write Node Exposed Knobs\",\n        default_factory=list\n    )\n    prenodes: list[PrenodeModel] = SettingsField(\n        default_factory=list,\n        title=\"Preceding nodes\",\n        description=PRENODES_LIST_DESCRIPTION,\n    )\n\n    @validator(\"prenodes\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.CreateWriteImageModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>@validator(\"prenodes\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.CreateWritePrerenderModel","title":"<code>CreateWritePrerenderModel</code>","text":"<p>               Bases: <code>DefaultPluginModel</code></p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>class CreateWritePrerenderModel(DefaultPluginModel):\n    temp_rendering_path_template: str = SettingsField(\n        title=\"Temporary rendering path template\"\n    )\n    default_variants: list[str] = SettingsField(\n        title=\"Default variants\",\n        default_factory=list\n    )\n    instance_attributes: list[str] = SettingsField(\n        default_factory=list,\n        enum_resolver=instance_attributes_enum,\n        title=\"Instance attributes\",\n        description = INSTANCE_ATTRIBUTES_DESCRIPTION\n    )\n    render_target: str = SettingsField(\n        enum_resolver=render_target_enum,\n        conditional_enum=True,\n        title=\"Render target\",\n        description=RENDER_TARGET_DESCRIPTION,\n    )\n    exposed_knobs: list[str] = SettingsField(\n        title=\"Write Node Exposed Knobs\", default_factory=list\n    )\n    prenodes: list[PrenodeModel] = SettingsField(\n        default_factory=list,\n        title=\"Preceding nodes\",\n        description=PRENODES_LIST_DESCRIPTION,\n    )\n\n    @validator(\"prenodes\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.CreateWritePrerenderModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>@validator(\"prenodes\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.CreateWriteRenderModel","title":"<code>CreateWriteRenderModel</code>","text":"<p>               Bases: <code>DefaultPluginModel</code></p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>class CreateWriteRenderModel(DefaultPluginModel):\n    temp_rendering_path_template: str = SettingsField(\n        title=\"Temporary rendering path template\"\n    )\n    default_variants: list[str] = SettingsField(\n        title=\"Default variants\",\n        default_factory=list\n    )\n    instance_attributes: list[str] = SettingsField(\n        default_factory=list,\n        enum_resolver=instance_attributes_enum,\n        title=\"Instance attributes\",\n        description=INSTANCE_ATTRIBUTES_DESCRIPTION\n    )\n    render_target: str = SettingsField(\n        enum_resolver=render_target_enum,\n        conditional_enum=True,\n        title=\"Render target\",\n        description=RENDER_TARGET_DESCRIPTION,\n    )\n    exposed_knobs: list[str] = SettingsField(\n        title=\"Write Node Exposed Knobs\",\n        default_factory=list\n    )\n    prenodes: list[PrenodeModel] = SettingsField(\n        default_factory=list,\n        title=\"Preceding nodes\",\n        description=PRENODES_LIST_DESCRIPTION\n    )\n\n    @validator(\"prenodes\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.CreateWriteRenderModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>@validator(\"prenodes\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.PrenodeModel","title":"<code>PrenodeModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>class PrenodeModel(BaseSettingsModel):\n    name: str = SettingsField(\n        title=\"Node name\",\n        description=(\n            \"Node name, use this as the name in 'Incoming dependency' on other\"\n            \" preceding nodes if a connection is needed.\"\n        )\n    )\n    nodeclass: str = SettingsField(\n        \"\",\n        title=\"Node class\",\n        description=\"Nuke node class (type) of the node to add.\"\n    )\n    dependent: str = SettingsField(\n        \"\",\n        title=\"Incoming dependency\",\n        description=(\n            \"Input node name of another preceding node that should\"\n            \"come before this node.\"\n        ),\n    )\n    knobs: list[KnobModel] = SettingsField(\n        default_factory=list,\n        title=\"Knobs\",\n    )\n\n    @validator(\"knobs\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.PrenodeModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>@validator(\"knobs\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.instance_attributes_enum","title":"<code>instance_attributes_enum()</code>","text":"<p>Return create write instance attributes.</p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>def instance_attributes_enum():\n    \"\"\"Return create write instance attributes.\"\"\"\n    return [\n        {\"value\": \"reviewable\", \"label\": \"Reviewable\"},\n        {\"value\": \"farm_rendering\", \"label\": \"Farm rendering\"},\n        {\"value\": \"use_range_limit\", \"label\": \"Use range limit\"},\n        {\n            \"value\": \"render_on_farm\",\n            \"label\": \"Render On Farm\"\n        }\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/create_plugins.html#server.settings.create_plugins.render_target_enum","title":"<code>render_target_enum()</code>","text":"<p>Return write render target enum.</p> Source code in <code>server/settings/create_plugins.py</code> <pre><code>def render_target_enum():\n    \"\"\"Return write render target enum.\"\"\"\n    return [\n        {\"value\": \"local\", \"label\": \"Local machine rendering\"},\n        {\"value\": \"frames\", \"label\": \"Use existing frames\"},\n        {\"value\": \"frames_farm\", \"label\": \"Use existing frames - farm\"},\n        {\"value\": \"farm\", \"label\": \"Farm rendering\"}\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/dirmap.html","title":"dirmap","text":""},{"location":"autoapi/server/settings/dirmap.html#server.settings.dirmap.DirmapSettings","title":"<code>DirmapSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke directory map source paths to destination paths.</p> Source code in <code>server/settings/dirmap.py</code> <pre><code>class DirmapSettings(BaseSettingsModel):\n    \"\"\"Nuke directory map source paths to destination paths.\"\"\"\n    _isGroup: bool = True\n\n    enabled: bool = SettingsField(title=\"enabled\")\n    paths: DirmapPathsSubmodel = SettingsField(\n        default_factory=DirmapPathsSubmodel,\n        title=\"Dirmap Paths\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/general.html","title":"general","text":""},{"location":"autoapi/server/settings/general.html#server.settings.general.GeneralSettings","title":"<code>GeneralSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke general project settings.</p> Source code in <code>server/settings/general.py</code> <pre><code>class GeneralSettings(BaseSettingsModel):\n    \"\"\"Nuke general project settings.\"\"\"\n\n    menu: MenuShortcut = SettingsField(\n        default_factory=MenuShortcut,\n        title=\"Menu Shortcuts\",\n    )\n</code></pre>"},{"location":"autoapi/server/settings/general.html#server.settings.general.MenuShortcut","title":"<code>MenuShortcut</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke general project settings.</p> Source code in <code>server/settings/general.py</code> <pre><code>class MenuShortcut(BaseSettingsModel):\n    \"\"\"Nuke general project settings.\"\"\"\n\n    create: str = SettingsField(\n        title=\"Create...\"\n    )\n    publish: str = SettingsField(\n        title=\"Publish...\"\n    )\n    load: str = SettingsField(\n        title=\"Load...\"\n    )\n    manage: str = SettingsField(\n        title=\"Manage...\"\n    )\n    build_workfile: str = SettingsField(\n        title=\"Build Workfile...\"\n    )\n    version_up_workfile: str = SettingsField(\n        title=\"Version Up Workfile\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/gizmo.html","title":"gizmo","text":""},{"location":"autoapi/server/settings/gizmo.html#server.settings.gizmo.GizmoItem","title":"<code>GizmoItem</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke gizmo item</p> Source code in <code>server/settings/gizmo.py</code> <pre><code>class GizmoItem(BaseSettingsModel):\n    \"\"\"Nuke gizmo item \"\"\"\n\n    toolbar_menu_name: str = SettingsField(\n        title=\"Toolbar Menu Name\"\n    )\n    toolbar_icon_path: MultiplatformPathModel = SettingsField(\n        default_factory=MultiplatformPathModel,\n        title=\"Toolbar Icon Path\",\n        description=\"Leave it empty to use the AYON icon.\"\n    )\n    options: str = SettingsField(\n        \"gizmo_source_dir\",\n        title=\"Gizmo Menu Options\",\n        description=\"Switch between gizmo menu options\",\n        enum_resolver=gizmo_enum_options,\n        conditional_enum=True,\n        section=\"Gizmos\"\n    )\n    gizmo_source_dir: MultiplatformPathListModel = SettingsField(\n        default_factory=MultiplatformPathListModel,\n        title=\"Gizmo Directory Path\"\n    )\n    gizmo_definition: list[GizmoDefinitionItem] = SettingsField(\n        default_factory=list, title=\"Gizmo Definition\")\n</code></pre>"},{"location":"autoapi/server/settings/imageio.html","title":"imageio","text":""},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.ImageIOSettings","title":"<code>ImageIOSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke color management project settings.</p> Source code in <code>server/settings/imageio.py</code> <pre><code>class ImageIOSettings(BaseSettingsModel):\n    \"\"\"Nuke color management project settings. \"\"\"\n\n    activate_host_color_management: bool = SettingsField(\n        True, title=\"Enable Color Management\")\n    file_rules: ImageIOFileRulesModel = SettingsField(\n        default_factory=ImageIOFileRulesModel,\n        title=\"File Rules\"\n    )\n    viewer: ViewProcessModel = SettingsField(\n        default_factory=ViewProcessModel,\n        title=\"Viewer\",\n        description=(\n            \"Viewer profile is used during Creation of new viewer node at knob\"\n            \" viewerProcess\"\n        )\n    )\n    monitor: MonitorProcessModel = SettingsField(\n        default_factory=MonitorProcessModel,\n        title=\"Monitor OUT\",\n        description=(\n            \"Viewer Monitor Out settings is used during creation of new viewer\"\n            \" node. This is used for external monitors used with a Nuke\"\n            \" viewer.\"\n        )\n    )\n    baking_target: ColorspaceConfigurationModel = SettingsField(\n        default_factory=ColorspaceConfigurationModel,\n        title=\"Baking Target Colorspace\"\n    )\n\n    workfile: WorkfileColorspaceSettings = SettingsField(\n        default_factory=WorkfileColorspaceSettings,\n        title=\"Workfile\"\n    )\n\n    nodes: NodesSetting = SettingsField(\n        default_factory=NodesSetting,\n        title=\"Nodes\"\n    )\n    \"\"\"# TODO: enhance settings with host api:\n    - [ ] no need for `inputs` middle part. It can stay\n      directly on `regex_inputs`\n    \"\"\"\n    regex_inputs: RegexInputsModel = SettingsField(\n        default_factory=RegexInputsModel,\n        title=\"Assign colorspace to read nodes via rules\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.ImageIOSettings.nodes","title":"<code>nodes = SettingsField(default_factory=NodesSetting, title='Nodes')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.ImageIOSettings.nodes--todo-enhance-settings-with-host-api","title":"TODO: enhance settings with host api:","text":"<ul> <li>[ ] no need for <code>inputs</code> middle part. It can stay   directly on <code>regex_inputs</code></li> </ul>"},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.OverrideNodesModel","title":"<code>OverrideNodesModel</code>","text":"<p>               Bases: <code>NodesModel</code></p> Source code in <code>server/settings/imageio.py</code> <pre><code>class OverrideNodesModel(NodesModel):\n    product_names: list[str] = SettingsField(\n        default_factory=list,\n        title=\"Product names\"\n    )\n\n    knobs: list[KnobModel] = SettingsField(\n        default_factory=list,\n        title=\"Knobs\",\n    )\n\n    @validator(\"knobs\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.OverrideNodesModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/imageio.py</code> <pre><code>@validator(\"knobs\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.RequiredNodesModel","title":"<code>RequiredNodesModel</code>","text":"<p>               Bases: <code>NodesModel</code></p> Source code in <code>server/settings/imageio.py</code> <pre><code>class RequiredNodesModel(NodesModel):\n    knobs: list[KnobModel] = SettingsField(\n        default_factory=list,\n        title=\"Knobs\",\n    )\n\n    @validator(\"knobs\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.RequiredNodesModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/imageio.py</code> <pre><code>@validator(\"knobs\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/imageio.html#server.settings.imageio.WorkfileColorspaceSettings","title":"<code>WorkfileColorspaceSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Workfile colorspace for Nuke root's project settings.</p> Source code in <code>server/settings/imageio.py</code> <pre><code>class WorkfileColorspaceSettings(BaseSettingsModel):\n    \"\"\"Workfile colorspace for Nuke root's project settings.\"\"\"\n\n    _isGroup: bool = True\n\n    color_management: Literal[\"Nuke\", \"OCIO\"] = SettingsField(\n        title=\"Color Management Workflow\",\n        description=(\n            \"Switch between native OCIO configs.\\n\\n\"\n            \"This is only used if global color management is **disabled** and\"\n            \" hence there is no global OCIO environment variable being set.\"\n        ),\n    )\n\n    native_ocio_config: str = SettingsField(\n        title=\"Native OpenColorIO Config\",\n        description=(\n            \"Nuke native OCIO config. The number between between the brackets\"\n            \" after the configs describe which Nuke versions these are\"\n            \" compatible with.\\n\\n\"\n            \"This is only used if global color management is **disabled** and\"\n            \" hence there is no global OCIO environment variable being set\"\n            \" **AND** Color Management Workflow above is set to 'OCIO'.\"\n        ),\n        enum_resolver=ocio_configs_switcher_enum,\n        conditional_enum=True\n    )\n\n    working_space: str = SettingsField(\n        title=\"Working Space\"\n    )\n    monitor_lut: str = SettingsField(\n        title=\"Thumbnails\"\n    )\n    monitor_out_lut: str = SettingsField(\n        title=\"Monitor Out\"\n    )\n    int_8_lut: str = SettingsField(\n        title=\"8-bit Files\"\n    )\n    int_16_lut: str = SettingsField(\n        title=\"16-bit Files\"\n    )\n    log_lut: str = SettingsField(\n        title=\"Log Files\"\n    )\n    float_lut: str = SettingsField(\n        title=\"Float Files\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/loader_plugins.html","title":"loader_plugins","text":""},{"location":"autoapi/server/settings/main.html","title":"main","text":""},{"location":"autoapi/server/settings/main.html#server.settings.main.NukeSettings","title":"<code>NukeSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke addon settings.</p> Source code in <code>server/settings/main.py</code> <pre><code>class NukeSettings(BaseSettingsModel):\n    \"\"\"Nuke addon settings.\"\"\"\n\n    general: GeneralSettings = SettingsField(\n        default_factory=GeneralSettings,\n        title=\"General\",\n    )\n\n    imageio: ImageIOSettings = SettingsField(\n        default_factory=ImageIOSettings,\n        title=\"Color Management (imageio)\",\n    )\n\n    dirmap: DirmapSettings = SettingsField(\n        default_factory=DirmapSettings,\n        title=\"Nuke Directory Mapping\",\n    )\n\n    scriptsmenu: ScriptsmenuSettings = SettingsField(\n        default_factory=ScriptsmenuSettings,\n        title=\"Scripts Menu Definition\",\n    )\n\n    gizmo: list[GizmoItem] = SettingsField(\n        default_factory=list, title=\"Gizmo Menu\")\n\n    create: CreatorPluginsSettings = SettingsField(\n        default_factory=CreatorPluginsSettings,\n        title=\"Creator Plugins\",\n    )\n\n    publish: PublishPluginsModel = SettingsField(\n        default_factory=PublishPluginsModel,\n        title=\"Publish Plugins\",\n    )\n\n    load: LoaderPluginsModel = SettingsField(\n        default_factory=LoaderPluginsModel,\n        title=\"Loader Plugins\",\n    )\n\n    workfile_builder: WorkfileBuilderModel = SettingsField(\n        default_factory=WorkfileBuilderModel,\n        title=\"Workfile Builder\",\n    )\n\n    templated_workfile_build: TemplatedWorkfileBuildModel = SettingsField(\n        title=\"Templated Workfile Build\",\n        default_factory=TemplatedWorkfileBuildModel\n    )\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html","title":"publish_plugins","text":""},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.ExtractReviewDataModel","title":"<code>ExtractReviewDataModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Add a raw reviewable representation from the output of a write node.</p> <p>This can be useful when you don't want to use e.g. Extract Review Intermediates with baking streams but are already writing ready for review images that don't need custom baking.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class ExtractReviewDataModel(BaseSettingsModel):\n    \"\"\"Add a raw reviewable representation from the output of a write node.\n\n    This can be useful when you don't want to use e.g. Extract Review\n    Intermediates with baking streams but are already writing ready for\n    review images that don't need custom baking.\n    \"\"\"\n    enabled: bool = SettingsField(title=\"Enabled\")\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.NodeModel","title":"<code>NodeModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class NodeModel(BaseSettingsModel):\n    name: str = SettingsField(\n        title=\"Node name\"\n    )\n    nodeclass: str = SettingsField(\n        \"\",\n        title=\"Node class\"\n    )\n    dependent: str = SettingsField(\n        \"\",\n        title=\"Incoming dependency\"\n    )\n    knobs: list[KnobModel] = SettingsField(\n        default_factory=list,\n        title=\"Knobs\",\n    )\n\n    @validator(\"knobs\")\n    def ensure_unique_names(cls, value):\n        \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n        ensure_unique_names(value)\n        return value\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.NodeModel.ensure_unique_names","title":"<code>ensure_unique_names(value)</code>","text":"<p>Ensure name fields within the lists have unique names.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>@validator(\"knobs\")\ndef ensure_unique_names(cls, value):\n    \"\"\"Ensure name fields within the lists have unique names.\"\"\"\n    ensure_unique_names(value)\n    return value\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.ReformatNodesConfigModel","title":"<code>ReformatNodesConfigModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Only reposition nodes supported.</p> <p>You can add multiple reformat nodes and set their knobs. Order of reformat nodes is important. First reformat node will be applied first and last reformat node will be applied last.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>class ReformatNodesConfigModel(BaseSettingsModel):\n    \"\"\"Only reposition nodes supported.\n\n    You can add multiple reformat nodes and set their knobs.\n    Order of reformat nodes is important. First reformat node will\n    be applied first and last reformat node will be applied last.\n    \"\"\"\n    enabled: bool = SettingsField(False)\n    reposition_nodes: list[ReformatNodesRepositionNodes] = SettingsField(\n        default_factory=list,\n        title=\"Reposition knobs\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.nuke_export_formats_enum","title":"<code>nuke_export_formats_enum()</code>","text":"<p>Return all nuke export format available in creators.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def nuke_export_formats_enum():\n    \"\"\"Return all nuke export format available in creators.\"\"\"\n    return [\n        {\"value\": \"abc\", \"label\": \"Alembic\"},\n        {\"value\": \"fbx\", \"label\": \"FBX\"},\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.nuke_product_base_types_enum","title":"<code>nuke_product_base_types_enum()</code>","text":"<p>Return all nuke families available in creators.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def nuke_product_base_types_enum():\n    \"\"\"Return all nuke families available in creators.\"\"\"\n    return [\n        {\"value\": \"nukenodes\", \"label\": \"Nukenodes\"},\n        {\"value\": \"model\", \"label\": \"Model\"},\n        {\"value\": \"camera\", \"label\": \"Camera\"},\n        {\"value\": \"gizmo\", \"label\": \"Gizmo\"},\n        {\"value\": \"source\", \"label\": \"Source\"}\n    ] + nuke_render_publish_types_enum()\n</code></pre>"},{"location":"autoapi/server/settings/publish_plugins.html#server.settings.publish_plugins.nuke_render_publish_types_enum","title":"<code>nuke_render_publish_types_enum()</code>","text":"<p>Return all nuke render families available in creators.</p> Source code in <code>server/settings/publish_plugins.py</code> <pre><code>def nuke_render_publish_types_enum():\n    \"\"\"Return all nuke render families available in creators.\"\"\"\n    return [\n        {\"value\": \"render\", \"label\": \"Render\"},\n        {\"value\": \"prerender\", \"label\": \"Prerender\"},\n        {\"value\": \"image\", \"label\": \"Image\"}\n    ]\n</code></pre>"},{"location":"autoapi/server/settings/scriptsmenu.html","title":"scriptsmenu","text":""},{"location":"autoapi/server/settings/scriptsmenu.html#server.settings.scriptsmenu.ScriptsmenuSettings","title":"<code>ScriptsmenuSettings</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Nuke script menu project settings.</p> Source code in <code>server/settings/scriptsmenu.py</code> <pre><code>class ScriptsmenuSettings(BaseSettingsModel):\n    \"\"\"Nuke script menu project settings.\"\"\"\n    _isGroup = True\n\n    name: str = SettingsField(title=\"Menu Name\")\n    definition: list[ScriptsmenuSubmodel] = SettingsField(\n        default_factory=list,\n        title=\"Definition\",\n        description=\"Scriptmenu Items Definition\"\n    )\n</code></pre>"},{"location":"autoapi/server/settings/scriptsmenu.html#server.settings.scriptsmenu.ScriptsmenuSubmodel","title":"<code>ScriptsmenuSubmodel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Item Definition</p> Source code in <code>server/settings/scriptsmenu.py</code> <pre><code>class ScriptsmenuSubmodel(BaseSettingsModel):\n    \"\"\"Item Definition\"\"\"\n    _isGroup = True\n\n    type: str = SettingsField(title=\"Type\")\n    command: str = SettingsField(title=\"Command\")\n    sourcetype: str = SettingsField(title=\"Source Type\")\n    title: str = SettingsField(title=\"Title\")\n    tooltip: str = SettingsField(title=\"Tooltip\")\n</code></pre>"},{"location":"autoapi/server/settings/templated_workfile_build.html","title":"templated_workfile_build","text":""},{"location":"autoapi/server/settings/templated_workfile_build.html#server.settings.templated_workfile_build.TemplatedWorkfileBuildModel","title":"<code>TemplatedWorkfileBuildModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>Settings for templated workfile builder.</p> Source code in <code>server/settings/templated_workfile_build.py</code> <pre><code>class TemplatedWorkfileBuildModel(BaseSettingsModel):\n    \"\"\"Settings for templated workfile builder.\"\"\"\n    profiles: list[TemplatedWorkfileProfileModel] = SettingsField(\n        default_factory=list\n    )\n</code></pre>"},{"location":"autoapi/server/settings/workfile_builder.html","title":"workfile_builder","text":""},{"location":"autoapi/server/settings/workfile_builder.html#server.settings.workfile_builder.WorkfileBuilderModel","title":"<code>WorkfileBuilderModel</code>","text":"<p>               Bases: <code>BaseSettingsModel</code></p> <p>[deprecated] use Template Workfile Build Settings instead.</p> Source code in <code>server/settings/workfile_builder.py</code> <pre><code>class WorkfileBuilderModel(BaseSettingsModel):\n    \"\"\"[deprecated] use Template Workfile Build Settings instead.\n    \"\"\"\n    create_first_version: bool = SettingsField(\n        title=\"Create first workfile\")\n    custom_templates: list[CustomTemplateModel] = SettingsField(\n        default_factory=list,\n        title=\"Custom templates\"\n    )\n    builder_on_start: bool = SettingsField(\n        default=False,\n        title=\"Run Builder at first workfile\"\n    )\n    profiles: list[BuilderProfileModel] = SettingsField(\n        default_factory=list,\n        title=\"Builder profiles\"\n    )\n</code></pre>"}]}